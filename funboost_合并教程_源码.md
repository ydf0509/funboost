# 🤖 AI Reading Guide for Project: funboost_docs

> **Important Notice for AI Models**: This document contains the complete source code and documentation for the `funboost_docs` project. Please read this guide carefully before analyzing the content.

## 📖 Document Structure

This markdown document is structured as follows:

1. **Project Summary** (`# markdown content namespace: xxx project summary`)
   - Brief project description
   - Core source files metadata (AST-parsed class/function signatures without full source code)
   - File dependencies analysis

2. **Project Root Files** (`# markdown content namespace: xxx Project Root Dir Some Files`)
   - README.md, pyproject.toml, setup.py, etc.

3. **Source Code Sections** (`# markdown content namespace: xxx codes/examples/...`)
   - File Tree: Shows directory structure
   - Included Files: Lists all files in this section
   - Full source code with AST metadata for Python files

## 🔍 How to Identify File Boundaries

- Each file starts with: `--- **start of file: <path>** (project: funboost_docs) ---`
- Each file ends with: `--- **end of file: <path>** (project: funboost_docs) ---`
- All file paths are relative to the project root

## ⚠️ Important Notes

1. **Do NOT hallucinate**: Only reference code, classes, functions, and APIs that actually exist in this document
2. **Check file paths**: When suggesting code changes, always verify the file path exists in the File Tree
3. **Respect the project structure**: The File Tree shows the actual directory layout
4. **AST Metadata**: Python files include parsed metadata (imports, classes, methods) before the full source code

---

# markdown content namespace: funboost_docs project summary 



- `funboost` 是python 全功能分布式函数调度框架
- `funboost.faas` 是funboost的战略级核武器。使函数调度框架产生架构质变：从 Worker 到 Service

- 以下一定要记住，最最重要的 类和函数如下：
   - @boost(BoosterParams(...))  任意普通函数加上装饰器，变成分布式函数
   - BoosterParams 装饰器入参控制大全，一定要学习这个类的所有入参配置；ai绝对不允许胡编乱造源码api和教程中不存在的BoosterParams字段入参。
   - BrokerEnum：支持 40+ 种消息队列中间件。
   - BoostersManager 管理分布式函数，高阶用法可能需要用到，例如启动一组消费函数，启动所有消费函数等。
   - ApsJobAdder 类， 是定时任务的最重要使用方式的类
   - ConcurrentModeEnum：funboost支持的并发模式。
   - funboost/core/broker_kind__exclusive_config_default_define.py 决定了每种中间件类型能传递哪些
   



## 📋 funboost_docs most core source files metadata (Entry Points)


以下是项目 funboost_docs 最核心的入口文件的结构化元数据，帮助快速理解项目架构：



### the project funboost_docs most core source code files as follows: 
- `funboost/__init__.py`
- `funboost/core/booster.py`
- `funboost/core/func_params_model.py`
- `funboost/constant.py`
- `funboost/timing_job/timing_push.py`
- `funboost/funboost_config_deafult.py`
- `funboost/core/current_task.py`
- `funboost/core/cli/discovery_boosters.py`
- `funboost/core/broker_kind__exclusive_config_default_define.py`
- `funboost/core/msg_result_getter.py`
- `funboost/publishers/base_publisher.py`
- `funboost/consumers/base_consumer.py`
- `funboost/core/active_cousumer_info_getter.py`


### 📄 Python File Metadata: `funboost/__init__.py`

#### 📦 Imports

- `import atexit`
- `import nb_log`
- `from nb_log import nb_print`
- `from funboost.set_frame_config import show_frame_config`
- `from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath as _`
- `from funboost.utils import monkey_patches as _`
- `from funboost.core.loggers import get_logger`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import FunboostMetaTypeFileLogger`
- `from funboost.core.loggers import flogger`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import BoosterParamsComplete`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParamsComplete`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.utils.paramiko_util import ParamikoFolderUploader`
- `from funboost.consumers.base_consumer import wait_for_possible_has_finish_all_tasks_by_conusmer_list`
- `from funboost.consumers.base_consumer import FunctionResultStatus`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.consumers.empty_consumer import EmptyConsumer`
- `from funboost.core.exceptions import ExceptionForRetry`
- `from funboost.core.exceptions import ExceptionForRequeue`
- `from funboost.core.exceptions import ExceptionForPushToDlxqueue`
- `from funboost.core.active_cousumer_info_getter import ActiveCousumerProcessInfoGetter`
- `from funboost.core.msg_result_getter import HasNotAsyncResult`
- `from funboost.core.msg_result_getter import ResultFromMongo`
- `from funboost.publishers.base_publisher import TaskOptions`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import AsyncResult`
- `from funboost.publishers.base_publisher import AioAsyncResult`
- `from funboost.publishers.empty_publisher import EmptyPublisher`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import register_custom_broker`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.factories.consumer_factory import get_consumer`
- `from funboost.timing_job import funboost_aps_scheduler`
- `from funboost.timing_job.timing_push import ApsJobAdder`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.core.booster import boost`
- `from funboost.core.booster import Booster`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.kill_remote_task import RemoteTaskKiller`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.core.cli.discovery_boosters import BoosterDiscovery`
- `from funboost.core.helper_funs import run_forever`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.concurrent_pool.custom_threadpool_executor import show_current_threads_num`
- `from funboost.core.current_task import funboost_current_task`
- `from funboost.core.current_task import fct`
- `from funboost.core.current_task import get_current_taskid`


---




### 📄 Python File Metadata: `funboost/core/booster.py`

#### 📦 Imports

- `from __future__ import annotations`
- `import copy`
- `import inspect`
- `from multiprocessing import Process`
- `import os`
- `import sys`
- `import types`
- `import typing`
- `import threading`
- `from funboost.concurrent_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.constant import FunctionKind`
- `from funboost.constant import StrConst`
- `from funboost.utils.class_utils import ClsHelper`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.utils.decorators import flyweight`
- `from funboost.core.loggers import flogger`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.loggers import logger_prompt`
- `from functools import wraps`
- `from funboost.core.exceptions import BoostDecoParamsIsOldVersion`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.factories.consumer_factory import get_consumer`
- `from funboost.factories.consumer_factory import ConsumerCacheProxy`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.factories.publisher_factotry import PublisherCacheProxy`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.msg_result_getter import AioAsyncResult`
- `from funboost.core.muliti_process_enhance import run_consumer_with_multi_process`
- `from funboost.core.muliti_process_enhance import multi_process_pub_params_list`
- `from funboost.core.fabric_deploy_helper import fabric_deploy`

#### 🏛️ Classes (2)

##### 📌 `class Booster`
*Line: 39*

**Docstring:**
`````
funboost极其重视代码能在pycharm下自动补全。元编程经常造成在pycharm下代码无法自动补全提示，主要是实现代码补全难。
这种__call__写法在pycahrm下 不仅能补全消费函数的 push consume等方法，也能补全函数本身的入参，一举两得。代码能自动补全很重要。
一个函数fun被 boost装饰器装饰后， isinstance(fun,Booster) 为True.

pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

Booster 是把Consumer 和 Publisher的方法集为一体。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: typing.Union[BoosterParams, str] = None, **kwargs)`
  - **Docstring:**
  `````
  @boost 这是funboost框架最重要的一个函数，必须看懂BoosterParams里面的入参有哪些。
  建议永远使用 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) 这种传参方式。
  
  
  pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.
  (高版本的pycharm pydantic是内置支持代码补全的,由此可见,pydantic太好了,pycharm官方都来支持)
  
  强烈建议所有入参放在 BoosterParams() 中,不要直接在BoosterParams之外传参.现在是兼容老的直接在@boost中传参方式.
  建议不要给第一个入参queue_name传递字符串，而是永远传递BoosterParams类型， 例如 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  
  
  ```python
  # @boost('queue_test_f01', qps=0.2, ) # 老的入参方式
  @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) # 新的入参方式,所有入参放在 最流行的三方包 pydantic model BoosterParams 里面.
  def f(a, b):
      print(a + b)
  
  for i in range(10, 20):
      f.pub(dict(a=i, b=i * 2))
      f.push(i, i * 2)
  f.consume()
  # f.multi_process_conusme(8)             # # 这个是新加的方法，细粒度 线程 协程并发 同时叠加8个进程，速度炸裂。
  ```
  
  
  @boost('queue_test_f01', qps=0.2, )
  @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  @Booster(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  @BoosterParams(queue_name='queue_test_f01', qps=0.2, )
  以上4种写法等效。
  `````
  - **Parameters:**
    - `self`
    - `queue_name: typing.Union[BoosterParams, str] = None`
    - `**kwargs`

**Public Methods (3):**
- `def multi_process_consume(self, process_num = 1)`
  - *超高速多进程消费*
- `def multi_process_pub_params_list(self, params_list, process_num = 16)`
  - *超高速多进程发布，例如先快速发布1000万个任务到中间件，以后慢慢消费*
- `def fabric_deploy(self, host, port, user, password, path_pattern_exluded_tuple = ('/.git/', '/.idea/', '/dist/', '/build/'), file_suffix_tuple_exluded = ('.pyc', '.log', '.gz'), only_upload_within_the_last_modify_time = 3650 * 24 * 60 * 60, file_volume_limit = 1000 * 1000, sftp_log_level = 20, extra_shell_str = '', invoke_runner_kwargs = {'hide': None, 'pty': True, 'warn': False}, python_interpreter = 'python3', process_num = 1, pkey_file_path = None)`
  - *入参见 fabric_deploy 函数。这里重复入参是为了代码在pycharm补全提示。*

**Class Variables (2):**
- `multi_process_start = multi_process_consume`
- `mp_consume = multi_process_consume`

##### 📌 `class BoosterRegistry`
*Line: 273*

**Docstring:**
`````
管理boosters，可以一键启动多个消费函数或者启动一组消费函数。

BoosterRegistry 是后加的， 原来的 BoostersManager 类是一个包含多个classmethod的类，和现在的方法名和入参一样。
为了兼容老的 BoostersManager 这个用法，现在的 BoostersManager 是 BoosterRegistry 其中一个实例。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, booster_registry_name)`
  - **Parameters:**
    - `self`
    - `booster_registry_name`

**Public Methods (17):**
- `def regist_booster(self, booster: Booster)`
  - *这个是框架在@boost时候自动调用的,无需用户亲自调用*
- `def show_all_boosters(self)`
- `def get_all_queues(self) -> list`
- `def get_all_queue_name__boost_params_unstrict_dict(self)`
  - **Docstring:**
  `````
  主要用来给前端或可视化观看的。
  
  返回一个字典,键是队列名,值是@boost的 BoosterParams 入参字典,
  因为 BoosterParams 有的入参是复杂对象类型,不能json序列化
  `````
- `def get_booster(self, queue_name: str) -> Booster`
  - **Docstring:**
  `````
  当前进程获得booster对象。注意和下面的get_or_create_booster_by_queue_name方法的区别,主要是开了多进程时候有区别.
  :param queue_name:
  :return:
  `````
- `def get_or_create_booster_by_queue_name(self, queue_name) -> Booster`
  - **Docstring:**
  `````
  当前进程获得booster对象，如果是多进程,会在新的进程内部创建一个新的booster对象,因为多进程操作有些中间件的同一个conn不行.
  :param queue_name: 就是 @boost的入参。
  :return:
  `````
- `def get_boost_params(self, queue_name: str) -> (dict, typing.Callable)`
  - **Docstring:**
  `````
  这个函数是为了在别的进程实例化 booster，consumer和publisher,获取queue_name队列对应的booster的当时的入参。
  有些中间件python包的对中间件连接对象不是多进程安全的，不要在进程2中去操作进程1中生成的booster consumer publisher等对象。
  `````
- `def build_booster(self, boost_params: BoosterParams) -> Booster`
  - **Docstring:**
  `````
  当前进程获得或者创建booster对象。方便有的人需要在函数内部临时动态根据队列名创建booster,不会无数次临时生成消费者、生产者、创建消息队列连接。
  :param boost_params: 就是 @boost的入参。
  :param consuming_function: 消费函数
  :return:
  `````
- `def get_cross_project_publisher(self, publisher_params: PublisherParams) -> AbstractPublisher`
  - **Docstring:**
  `````
  跨不同的项目，发布消息。例如proj1中定义有fun1消费函数，但proj2无法直接到proj1的函数，无法直接 fun1.push 来发布消息
  可以使用这个方法，获取一个publisher。
  
  publisher = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='proj1_queue', broker_kind=publisher_params.broker_kind))
  publisher.publish({'x': aaa})
  `````
- `def push(self, queue_name, *args, **kwargs)`
  - *push发布消息到消息队列 ;*
- `def publish(self, queue_name, msg)`
  - *publish发布消息到消息队列;*
- `def consume_queues(self, *queue_names)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费,多个函数队列在当前同一个进程内启动消费.
  这种方式节约总的内存,但无法利用多核cpu
  `````
- `def consume_all_queues(self, block = True)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需一个一个函数亲自 funxx.consume()来启动,多个函数队列在当前同一个进程内启动消费.
  这种方式节约总的内存,但无法利用多核cpu
  `````
- `def multi_process_consume_queues(self, **queue_name__process_num)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费,传递队列名和进程数,每个队列启动n个单独的消费进程;
  这种方式总的内存使用高,但充分利用多核cpu
  例如 multi_process_consume_queues(queue1=2,queue2=3) 表示启动2个进程消费queue1,启动3个进程消费queue2
  `````
- `def consume_group(self, booster_group: str, block = False)`
  - *根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;*
- `def multi_process_consume_group(self, booster_group: str, process_num = 1)`
  - *根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;*
- `def multi_process_consume_all_queues(self, process_num = 1)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需指定队列名,每个队列启动n个单独的消费进程;
  这种方式总的内存使用高,但充分利用多核cpu
  `````

**Class Variables (6):**
- `_lock = threading.Lock()`
- `consume = consume_queues`
- `consume_all = consume_all_queues`
- `mp_consume = multi_process_consume_queues`
- `mp_consume_group = multi_process_consume_group`
- `mp_consume_all = multi_process_consume_all_queues`

#### 🔧 Public Functions (1)

- `def gen_pid_queue_name_key(queue_name: str) -> typing.Tuple[int, str]`
  - *Line: 268*


---




### 📄 Python File Metadata: `funboost/core/func_params_model.py`

#### 📝 Module Docstring

`````
pydantic 模型定义， funboost 使用pydantic 作为重要函数的入参，
方便函数入参太多在层层传递时候的麻烦，例如 BoosterParams 经常新增字段，如果funboost直接入参一大堆，需要每一层都去新增入参很麻烦

BoosterParams 是 funboost 最核心的入参模型，掌握了 BoosterParams 就是掌握了 funboost 的90% 用法。
`````

#### 📦 Imports

- `import functools`
- `import typing`
- `import asyncio`
- `import logging`
- `import datetime`
- `from pydantic.fields import Field`
- `from typing_extensions import Literal`
- `from funboost.concurrent_pool.pool_commons import ConcurrentPoolBuilder`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`
- `from funboost.core.pydantic_compatible_base import compatible_root_validator`
- `from funboost.core.pydantic_compatible_base import BaseJsonAbleModel`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.constant import StrConst`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.concurrent_pool import FlexibleThreadPool`

#### 🏛️ Classes (5)

##### 📌 `class FunctionResultStatusPersistanceConfig(BaseJsonAbleModel)`
*Line: 27*

**Public Methods (1):**
- `def check_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (5):**
- `is_save_status: bool`
- `is_save_result: bool`
- `expire_seconds: int = 7 * 24 * 3600`
- `is_use_bulk_insert: bool = False`
- `table_name: typing.Optional[str] = None`

##### 📌 `class BoosterParams(BaseJsonAbleModel)`
*Line: 43*

**Docstring:**
`````
pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

@boost的传参必须是此类或者继承此类,如果你不想每个装饰器入参都很多,你可以写一个子类继承BoosterParams, 传参这个子类,例如下面的 BoosterParamsComplete
`````

**Public Methods (1):**
- `def check_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (52):**
- `queue_name: str`
- `broker_kind: str = BrokerEnum.SQLITE_QUEUE`
- `project_name: typing.Optional[str] = None`
- `concurrent_mode: str = ConcurrentModeEnum.THREADING`
- `concurrent_num: int = 50`
- `specify_concurrent_pool: typing.Optional[FunboostBaseConcurrentPool] = None`
- `specify_async_loop: typing.Optional[asyncio.AbstractEventLoop] = None`
- `is_auto_start_specify_async_loop_in_child_thread: bool = True`
- `qps: typing.Union[float, int, None] = None`
- `is_using_distributed_frequency_control: bool = False`
- `is_send_consumer_heartbeat_to_redis: bool = False`
- `max_retry_times: int = 3`
- `retry_interval: typing.Union[float, int] = 0`
- `is_push_to_dlx_queue_when_retry_max_times: bool = False`
- `consuming_function_decorator: typing.Optional[typing.Callable] = None`
- `function_timeout: typing.Union[int, float, None] = None`
- `is_support_remote_kill_task: bool = False`
- `log_level: int = logging.DEBUG`
- `logger_prefix: str = ''`
- `create_logger_file: bool = True`
- `logger_name: typing.Union[str, None] = ''`
- `log_filename: typing.Union[str, None] = None`
- `is_show_message_get_from_broker: bool = False`
- `is_print_detail_exception: bool = True`
- `publish_msg_log_use_full_msg: bool = False`
- `msg_expire_seconds: typing.Union[float, int, None] = None`
- `do_task_filtering: bool = False`
- `task_filtering_expire_seconds: int = 0`
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=False, is_save_status=False, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)`
- `user_custom_record_process_info_func: typing.Optional[typing.Callable] = None`
- `is_using_rpc_mode: bool = False`
- `rpc_result_expire_seconds: int = 1800`
- `rpc_timeout: int = 1800`
- `delay_task_apscheduler_jobstores_kind: Literal['redis', 'memory'] = 'redis'`
- `is_do_not_run_by_specify_time_effect: bool = False`
- `do_not_run_by_specify_time: list = ['10:00:00', '22:00:00']`
- `schedule_tasks_on_main_thread: bool = False`
- `is_auto_start_consuming_message: bool = False`
- `booster_group: typing.Union[str, None] = None`
- `consuming_function: typing.Optional[typing.Callable] = None`
- `consuming_function_raw: typing.Optional[typing.Callable] = None`
- `consuming_function_name: str = ''`
- `broker_exclusive_config: dict = {}`
- `should_check_publish_func_params: bool = True`
- `manual_func_input_params: dict = {'is_manual_func_input_params': False, 'must_arg_name_list': [], 'optional_arg_name_list': []}`
- `consumer_override_cls: typing.Optional[typing.Type] = None`
- `publisher_override_cls: typing.Optional[typing.Type] = None`
- `consuming_function_kind: typing.Optional[str] = None`
- `user_options: dict = {}`
- `auto_generate_info: dict = {}`
- `is_fake_booster: bool = False`
- `booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT`

##### 📌 `class BoosterParamsComplete(BoosterParams)`
*Line: 259*

**Docstring:**
`````
例如一个子类,这个BoosterParams的子类可以作为@booot的传参,每个@boost可以少写一些这些重复的入参字段.

function_result_status_persistance_conf 永远支持函数消费状态 结果状态持久化
is_send_consumer_heartbeat_to_redis 永远支持发送消费者的心跳到redis,便于统计分布式环境的活跃消费者
is_using_rpc_mode  永远支持rpc模式
broker_kind 永远是使用 amqpstorm包 操作 rabbbitmq作为消息队列.
specify_concurrent_pool 同一个进程的不同booster函数,共用一个线程池,线程资源利用更高.
`````

**Class Variables (6):**
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=True)`
- `is_send_consumer_heartbeat_to_redis: bool = True`
- `is_using_rpc_mode: bool = True`
- `rpc_result_expire_seconds: int = 3600`
- `broker_kind: str = BrokerEnum.RABBITMQ_AMQPSTORM`
- `specify_concurrent_pool: FunboostBaseConcurrentPool = Field(default_factory=functools.partial(ConcurrentPoolBuilder.get_pool, FlexibleThreadPool, 500))`

##### 📌 `class TaskOptions(BaseJsonAbleModel)`
*Line: 279*

**Docstring:**
`````
这个是 publish 支持的额外参数，和函数参数一起发布到中间件。
可能有少数时候有这种需求。如果需要发布额外字段到消息队列，必须使用publish方法，push方法是类似celery的dalay只能发布函数入参自身。
这里面的字段值如果非None，会放到消息队列的消息里面的 extra 字段中。
`````

**Public Methods (1):**
- `def cehck_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (16):**
- `task_id: str = None`
- `publish_time: float = None`
- `publish_time_format: str = None`
- `function_timeout: typing.Union[float, int, None] = None`
- `max_retry_times: typing.Union[int, None] = None`
- `is_print_detail_exception: typing.Union[bool, None] = None`
- `msg_expire_seconds: typing.Union[float, int, None] = None`
- `is_using_rpc_mode: typing.Union[bool, None] = None`
- `countdown: typing.Union[float, int, None] = None`
- `eta: typing.Union[datetime.datetime, str, None] = None`
- `misfire_grace_time: typing.Union[int, None] = None`
- `user_extra_info: typing.Optional[dict] = None`
- `other_extra_params: typing.Optional[dict] = None`
- `filter_str: typing.Optional[str] = None`
- `can_not_json_serializable_keys: typing.List[str] = None`
- `otel_context: typing.Optional[dict] = None`

##### 📌 `class PublisherParams(BaseJsonAbleModel)`
*Line: 332*

**Class Variables (21):**
- `queue_name: str`
- `broker_kind: typing.Optional[str] = None`
- `project_name: typing.Optional[str] = None`
- `log_level: int = logging.DEBUG`
- `logger_prefix: str = ''`
- `create_logger_file: bool = True`
- `logger_name: str = ''`
- `log_filename: typing.Optional[str] = None`
- `clear_queue_within_init: bool = False`
- `consuming_function: typing.Optional[typing.Callable] = None`
- `broker_exclusive_config: dict = {}`
- `should_check_publish_func_params: bool = True`
- `manual_func_input_params: dict = {'is_manual_func_input_params': False, 'must_arg_name_list': [], 'optional_arg_name_list': []}`
- `publisher_override_cls: typing.Optional[typing.Type] = None`
- `publish_msg_log_use_full_msg: bool = False`
- `consuming_function_kind: typing.Optional[str] = None`
- `rpc_timeout: int = 1800`
- `user_options: dict = {}`
- `auto_generate_info: dict = {}`
- `is_fake_booster: bool = False`
- `booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT`


---




### 📄 Python File Metadata: `funboost/constant.py`

#### 🏛️ Classes (9)

##### 📌 `class BrokerEnum`
*Line: 5*

**Docstring:**
`````
在funboost中万物皆可为消息队列broker,funboost内置了所有 知名的正经经典消息队列作为broker,
也支持了基于 内存 各种数据库 文件系统 tcp/udp/http这些socket 模拟作为broker.
funboost也内置支持了各种python三方包和消费框架作为broker,例如 sqlachemy kombu celery rq dramtiq huey nameko 等等

用户也可以按照文档4.21章节,轻松扩展任何物质概念作为funboost的broker.
`````

**Class Variables (43):**
- `EMPTY = 'EMPTY'`
- `RABBITMQ_AMQPSTORM = 'RABBITMQ_AMQPSTORM'`
- `RABBITMQ = RABBITMQ_AMQPSTORM`
- `RABBITMQ_COMPLEX_ROUTING = 'RABBITMQ_COMPLEX_ROUTING'`
- `RABBITMQ_RABBITPY = 'RABBITMQ_RABBITPY'`
- `REDIS = 'REDIS'`
- `REDIS_ACK_ABLE = 'REDIS_ACK_ABLE'`
- `REIDS_ACK_USING_TIMEOUT = 'reids_ack_using_timeout'`
- `REDIS_PRIORITY = 'REDIS_PRIORITY'`
- `REDIS_STREAM = 'REDIS_STREAM'`
- `RedisBrpopLpush = 'RedisBrpopLpush'`
- `REDIS_PUBSUB = 'REDIS_PUBSUB'`
- `MEMORY_QUEUE = 'MEMORY_QUEUE'`
- `LOCAL_PYTHON_QUEUE = MEMORY_QUEUE`
- `RABBITMQ_PIKA = 'RABBITMQ_PIKA'`
- `MONGOMQ = 'MONGOMQ'`
- `SQLITE_QUEUE = 'sqlite3'`
- `PERSISTQUEUE = SQLITE_QUEUE`
- `NSQ = 'NSQ'`
- `KAFKA = 'KAFKA'`
- `KAFKA_CONFLUENT = 'KAFKA_CONFLUENT'`
- `CONFLUENT_KAFKA = KAFKA_CONFLUENT`
- `KAFKA_CONFLUENT_SASlPlAIN = 'KAFKA_CONFLUENT_SASlPlAIN'`
- `SQLACHEMY = 'SQLACHEMY'`
- `ROCKETMQ = 'ROCKETMQ'`
- `ZEROMQ = 'ZEROMQ'`
- `KOMBU = 'KOMBU'`
- `MQTT = 'MQTT'`
- `HTTPSQS = 'HTTPSQS'`
- `PULSAR = 'PULSAR'`
- `UDP = 'UDP'`
- `TCP = 'TCP'`
- `HTTP = 'HTTP'`
- `GRPC = 'GRPC'`
- `NATS = 'NATS'`
- `TXT_FILE = 'TXT_FILE'`
- `PEEWEE = 'PEEWEE'`
- `CELERY = 'CELERY'`
- `DRAMATIQ = 'DRAMATIQ'`
- `HUEY = 'HUEY'`
- `RQ = 'RQ'`
- `NAMEKO = 'NAMEKO'`
- `MYSQL_CDC = 'MYSQL_CDC'`

##### 📌 `class ConcurrentModeEnum`
*Line: 150*

**Class Variables (6):**
- `THREADING = 'threading'`
- `GEVENT = 'gevent'`
- `EVENTLET = 'eventlet'`
- `ASYNC = 'async'`
- `SINGLE_THREAD = 'single_thread'`
- `SOLO = SINGLE_THREAD`

##### 📌 `class FunctionKind`
*Line: 161*

**Class Variables (4):**
- `CLASS_METHOD = 'CLASS_METHOD'`
- `INSTANCE_METHOD = 'INSTANCE_METHOD'`
- `STATIC_METHOD = 'STATIC_METHOD'`
- `COMMON_FUNCTION = 'COMMON_FUNCTION'`

##### 📌 `class ConstStrForClassMethod`
*Line: 168*

**Class Variables (5):**
- `FIRST_PARAM_NAME = 'first_param_name'`
- `CLS_NAME = 'cls_name'`
- `OBJ_INIT_PARAMS = 'obj_init_params'`
- `CLS_MODULE = 'cls_module'`
- `CLS_FILE = 'cls_file'`

##### 📌 `class RedisKeys`
*Line: 176*

**Public Methods (7):**
- `def gen_funboost_apscheduler_redis_lock_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_hearbeat_queue__dict_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_hearbeat_server__dict_key_by_ip(ip)` `staticmethod`
- `def gen_funboost_queue_time_series_data_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_redis_apscheduler_jobs_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_redis_apscheduler_run_times_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_project_name_key(project_name)` `staticmethod`

**Class Variables (12):**
- `REDIS_KEY_PAUSE_FLAG = 'funboost_pause_flag'`
- `REDIS_KEY_STOP_FLAG = 'funboost_stop_flag'`
- `QUEUE__MSG_COUNT_MAP = 'funboost_queue__msg_count_map'`
- `FUNBOOST_QUEUE__CONSUMER_PARAMS = 'funboost_queue__consumer_parmas'`
- `FUNBOOST_QUEUE__RUN_COUNT_MAP = 'funboost_queue__run_count_map'`
- `FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP = 'funboost_queue__run_fail_count_map'`
- `FUNBOOST_ALL_QUEUE_NAMES = 'funboost_all_queue_names'`
- `FUNBOOST_ALL_IPS = 'funboost_all_ips'`
- `FUNBOOST_ALL_PROJECT_NAMES = 'funboost_all_project_names'`
- `FUNBOOST_LAST_GET_QUEUES_PARAMS_AND_ACTIVE_CONSUMERS_AND_REPORT__UUID_TS = 'funboost_last_get_queues_params_and_active_consumers_and_report__uuid_ts'`
- `FUNBOOST_HEARTBEAT_QUEUE__DICT_PREFIX = 'funboost_hearbeat_queue__dict:'`
- `FUNBOOST_HEARTBEAT_SERVER__DICT_PREFIX = 'funboost_hearbeat_server__dict:'`

##### 📌 `class ConsumingFuncInputParamsCheckerField`
*Line: 224*

**Class Variables (6):**
- `is_manual_func_input_params = 'is_manual_func_input_params'`
- `all_arg_name_list = 'all_arg_name_list'`
- `must_arg_name_list = 'must_arg_name_list'`
- `optional_arg_name_list = 'optional_arg_name_list'`
- `func_name = 'func_name'`
- `func_position = 'func_position'`

##### 📌 `class MongoDbName`
*Line: 233*

**Class Variables (2):**
- `TASK_STATUS_DB = 'funboost_task_status'`
- `MONGOMQ_DB = 'funboost_mongomq'`

##### 📌 `class StrConst`
*Line: 237*

**Class Variables (1):**
- `BOOSTER_REGISTRY_NAME_DEFAULT = 'booster_registry_default'`

##### 📌 `class EnvConst`
*Line: 240*

**Class Variables (2):**
- `FUNBOOST_FAAS_CARE_PROJECT_NAME = 'funboost.faas.care_project_name'`
- `FUNBOOST_FAAS_IS_USE_LOCAL_BOOSTER = 'funboost.faas.is_use_local_booster'`


---




### 📄 Python File Metadata: `funboost/timing_job/timing_push.py`

#### 📦 Imports

- `from funboost.utils import redis_manager`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.booster import Booster`
- `from apscheduler.jobstores.redis import RedisJobStore`
- `from funboost.timing_job.timing_job_base import funboost_aps_scheduler`
- `from funboost.timing_job.timing_job_base import undefined`
- `from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from apscheduler.schedulers.base import BaseScheduler`
- `from funboost.constant import RedisKeys`
- `from funboost import boost`
- `from funboost import BrokerEnum`
- `from funboost import ctrl_c_recv`
- `from funboost import BoosterParams`
- `from funboost import ApsJobAdder`

#### 🏛️ Classes (1)

##### 📌 `class ApsJobAdder`
*Line: 11*

**Docstring:**
`````
20250116新增加的统一的新增定时任务的方式，推荐这种方式。
用户不用像之前再去关心使用哪个apscheduler对象去添加定时任务了。

例如 add_numbers 是@boost装饰的消费函数
ApsJobAdder(add_numbers,job_store_kind='memory').add_push_job(
    args=(1, 2),
    trigger='date',  # 使用日期触发器
    run_date='2025-01-16 18:23:50',  # 设置运行时间
    # id='add_numbers_job'  # 任务ID
)
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, booster: Booster, job_store_kind: str = 'memory', is_auto_start = True, is_auto_paused = False)`
  - **Docstring:**
  `````
  Initialize the ApsJobAdder.
  
  :param booster: A Booster object representing the function to be scheduled.
  :param job_store_kind: The type of job store to use. Default is 'memory'.
                         Can be 'memory' or 'redis'.
  `````
  - **Parameters:**
    - `self`
    - `booster: Booster`
    - `job_store_kind: str = 'memory'`
    - `is_auto_start = True`
    - `is_auto_paused = False`

**Public Methods (3):**
- `def get_funboost_redis_apscheduler(cls, queue_name)` `classmethod`
  - **Docstring:**
  `````
  每个队列名字的定时任务有自己单独的 aspchedule r定时器,
  每隔定时器用不同的redis jobstore的 jobs_key 和 run_times_key，防止互相干扰和取出不属于自己的任务.
  如果所有函数使用同一个定时器和一个jobs_key ,当用户只想运行f1定时任务,如果用户把f2删了,或者不需要运行f2定时任务,那就报错或者不方便.
  `````
- `def get_aps_obj(cls, queue_name, job_store_kind)` `classmethod`
- `def add_push_job(self, trigger = None, args = None, kwargs = None, id = None, name = None, misfire_grace_time = undefined, coalesce = undefined, max_instances = undefined, next_run_time = undefined, jobstore = 'default', executor = 'default', replace_existing = False, **trigger_args)`
  - **Docstring:**
  `````
  1. 这里的入参都是和apscheduler的add_job的入参一样的，funboost作者没有创造新的入参。
  但是官方apscheduler的入参第一个入参是函数，
  funboost的ApsJobAdder对象.add_push_job入参去掉了函数，因为类的实例化时候会把函数传进来，不需要再麻烦用户一次了。
  
  
  2. add_push_job目的是 定时运行 消费函数.push方法发布消息到消费队列， 而不是 定时直接运行 消费函数自身。
  
  相当于 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....)
  那为什么 不直接使用 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....) 呢？因为 消费函数.push是实例方法，
  如果redis作为 jobstore， 消费函数.push 会报错，因为 消费函数.push 是实例方法，不能被序列化。只有普通函数和静态方法才能被序列化。
  所以开发了一个 add_push_job方法， 里面再去用 add_job， 使用 push_fun_params_to_broker 这个普通函数作为 add_job 的第一个入参，
  这个普通函数里面再去调用 消费函数.push 方法， 相当于是曲线救国避免 aps_obj.add_job(消费函数.push 不可序列化问题。
  
  
  3. 用户也可以自己定义一个普通函数my_push，你这个普通函数my_push 里面去调用消费函数.push方法；然后使用 aps_obj.add_job 使用你自己定义的这个my_push作为第一个入参。
  这种方式更容易你去理解，和apscheduler 官方库的原生写法一模一样。 但是不如 add_push_job 方便，因为 需要你亲自给每个消费函数分别定义一个普通函数my_push。
  `````

**Properties (1):**
- `@property aps_obj -> BaseScheduler`

**Class Variables (1):**
- `queue__redis_aps_map = {}`

#### 🔧 Public Functions (1)

- `def sum_two_numbers(x, y)` `BoosterParams(queue_name='sum_queue3', broker_kind=BrokerEnum.REDIS)`
  - *Line: 125*


---




### 📄 Python File Metadata: `funboost/funboost_config_deafult.py`

#### 📦 Imports

- `import logging`
- `from pathlib import Path`
- `from funboost.utils.simple_data_class import DataClassBase`
- `from nb_log import nb_log_config_default`

#### 🏛️ Classes (2)

##### 📌 `class BrokerConnConfig(DataClassBase)`
*Line: 21*

**Docstring:**
`````
中间件连接配置
此文件按需修改，例如你使用redis中间件作为消息队列，可以不用管rabbitmq mongodb kafka啥的配置。
但有3个功能例外，如果你需要使用rpc模式或者分布式控频或者任务过滤功能，无论设置使用何种消息队列中间件都需要把redis连接配置好，
如果@boost装饰器设置is_using_rpc_mode为True或者 is_using_distributed_frequency_control为True或do_task_filtering=True则需要把redis连接配置好，默认是False不强迫用户安装redis。
`````

**Class Variables (40):**
- `MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'`
- `RABBITMQ_USER = 'rabbitmq_user'`
- `RABBITMQ_PASS = 'rabbitmq_pass'`
- `RABBITMQ_HOST = '127.0.0.1'`
- `RABBITMQ_PORT = 5672`
- `RABBITMQ_VIRTUAL_HOST = ''`
- `RABBITMQ_URL = f'amqp://{RABBITMQ_USER}:{RABBITMQ_PASS}@{RABBITMQ_HOST}:{RABBITMQ_PORT}/{RABBITMQ_VIRTUAL_HOST}'`
- `REDIS_HOST = '127.0.0.1'`
- `REDIS_USERNAME = ''`
- `REDIS_PASSWORD = ''`
- `REDIS_PORT = 6379`
- `REDIS_DB = 7`
- `REDIS_DB_FILTER_AND_RPC_RESULT = 8`
- `REDIS_SSL = False`
- `REDIS_URL = f"{('rediss' if REDIS_SSL else 'redis')}://{REDIS_USERNAME}:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}"`
- `NSQD_TCP_ADDRESSES = ['127.0.0.1:4150']`
- `NSQD_HTTP_CLIENT_HOST = '127.0.0.1'`
- `NSQD_HTTP_CLIENT_PORT = 4151`
- `KAFKA_BOOTSTRAP_SERVERS = ['127.0.0.1:9092']`
- `KFFKA_SASL_CONFIG = {'bootstrap_servers': KAFKA_BOOTSTRAP_SERVERS, 'sasl_plain_username': '', 'sasl_plain_password': '', 'sasl_mechanism': 'SCRAM-SHA-256', 'security_protocol': 'SASL_PLAINTEXT'}`
- `SQLACHEMY_ENGINE_URL = 'sqlite:////sqlachemy_queues/queues.db'`
- `MYSQL_HOST = '127.0.0.1'`
- `MYSQL_PORT = 3306`
- `MYSQL_USER = 'root'`
- `MYSQL_PASSWORD = '123456'`
- `MYSQL_DATABASE = 'testdb6'`
- `SQLLITE_QUEUES_PATH = '/sqllite_queues'`
- `TXT_FILE_PATH = Path(__file__).parent / 'txt_queues'`
- `ROCKETMQ_NAMESRV_ADDR = '192.168.199.202:9876'`
- `MQTT_HOST = '127.0.0.1'`
- `MQTT_TCP_PORT = 1883`
- `HTTPSQS_HOST = '127.0.0.1'`
- `HTTPSQS_PORT = 1218`
- `HTTPSQS_AUTH = '123456'`
- `NATS_URL = 'nats://192.168.6.134:4222'`
- `KOMBU_URL = 'redis://127.0.0.1:6379/9'`
- `CELERY_BROKER_URL = 'redis://127.0.0.1:6379/12'`
- `CELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/13'`
- `DRAMATIQ_URL = RABBITMQ_URL`
- `PULSAR_URL = 'pulsar://192.168.70.128:6650'`

##### 📌 `class FunboostCommonConfig(DataClassBase)`
*Line: 96*

**Class Variables (5):**
- `NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = logging.Formatter(f'%(asctime)s-({nb_log_config_default.computer_ip},{nb_log_config_default.computer_name})-[p%(process)d_t%(thread)d] - %(name)s - "%(filename)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(task_id)s - %(message)s', '%Y-%m-%d %H:%M:%S')`
- `TIMEZONE = 'Asia/Shanghai'`
- `SHOW_HOW_FUNBOOST_CONFIG_SETTINGS = True`
- `FUNBOOST_PROMPT_LOG_LEVEL = logging.DEBUG`
- `KEEPALIVETIMETHREAD_LOG_LEVEL = logging.DEBUG`


---




### 📄 Python File Metadata: `funboost/core/current_task.py`

#### 📝 Module Docstring

`````
fct 是 funboost current task 的简写，就是当前任务的意思。能同时兼容threading和asyncio隔离。

fct用法例子 
'''
from funboost import fct 

在消费函数内部能知道自己的takid，queue_name 等等。
print(fct.function_result_status.get_status_dict())
print(fct.function_result_status.task_id)
print(fct.run_times)
print(fct.full_msg)
'''
`````

#### 📦 Imports

- `import typing`
- `import contextvars`
- `from dataclasses import dataclass`
- `import logging`
- `import threading`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`

#### 🏛️ Classes (3)

##### 📌 `class FctContext`
*Line: 28*

**Docstring:**
`````
fct 是 funboost current task 的简写
`````

**Class Variables (2):**
- `function_result_status: FunctionResultStatus`
- `logger: logging.Logger`

##### 📌 `class _FctProxy`
*Line: 50*

**Docstring:**
`````
fct 代理类，通过 contextvars 自动获取当前线程/协程的上下文。
可以直接导入这个 fct，不需要手动写 fct = funboost_current_task() 了。
直接 from funboost import fct 就完了。
funboost 的 fct 相当于 flask 的 request 那种对象，自动线程/协程级别隔离，多个线程不会互相干扰。


fct 比直接 get_fct_context 好用一点点，fct相当于把FctContext对象的一级属性的function_result_status中的很多最重要二级属性直接提升作为一级属性了。
`````

**Properties (7):**
- `@property fct_context -> FctContext`
- `@property logger -> logging.Logger`
- `@property function_params -> dict`
- `@property full_msg -> dict`
- `@property function_result_status -> FunctionResultStatus`
- `@property task_id -> str`
- `@property queue_name -> str`

##### 📌 `class FctContextThread(threading.Thread)`
*Line: 118*

**Docstring:**
`````
这个类自动把当前线程的 funboost 上下文自动传递给新开的线程。
由于 contextvars 不会自动跨线程传递，只能跨协程自动传递，如果想跨线程自动传递，需要手动复制上下文。


如果没有这个基类，那么需要 手动复制上下文，然后让线程运行 ctx.run(worker) 而不是直接运行 worker： 
# 1. 显式捕获当前上下文
ctx = contextvars.copy_context()
# 2. 让线程运行 ctx.run(worker) 而不是直接运行 worker
# 这样 worker 就会在 ctx 的上下文中执行
t = threading.Thread(target=ctx.run, args=(worker,)) # 这是正解，传递上下文

# t = threading.Thread(target=worker,args=(,)) # 这是错误写法，不能自动传递上下文给子线程，
# 例如funboost的超时 kill功能，都是在另外单独的子线程去运行消费函数的，所以有时候需要传递给子线程。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, group = None, target = None, name = None, args = (), kwargs = None)`
  - **Parameters:**
    - `self`
    - `group = None`
    - `target = None`
    - `name = None`
    - `args = ()`
    - `kwargs = None`

**Public Methods (1):**
- `def run(self)`

#### 🔧 Public Functions (4)

- `def set_fct_context(fct_context: typing.Optional[FctContext])`
  - *Line: 40*
  - *设置当前线程/协程的 FctContext*

- `def get_fct_context() -> FctContext`
  - *Line: 45*
  - *获取当前线程/协程的 FctContext*

- `def funboost_current_task() -> _FctProxy`
  - *Line: 97*
  - **Docstring:**
  `````
  这个是兼容老的funboost_current_task() 函数，现在直接用 fct 就行了。
  
  获取当前任务上下文代理对象。
  由于 contextvars 同时支持多线程和异步协程，这里直接返回 fct 代理对象即可。
  `````

- `def get_current_taskid() -> str`
  - *Line: 107*
  - *获取当前任务的 task_id*


---




### 📄 Python File Metadata: `funboost/core/cli/discovery_boosters.py`

#### 📝 Module Docstring

`````
【⚠️ 安全警示 & 最佳实践】

1. 关于 BoosterDiscovery 自动扫描的风险提示
-------------------------------------------------------
BoosterDiscovery(....).auto_discovery() 请务必谨慎使用，强烈建议实例化时传入精确的过滤参数。

原因：
    部分开发者的编程习惯可能不严谨，对于包含执行动作的脚本，未添加 `if __name__ == '__main__':` 保护，
    或者不理解 `__main__` 的作用。Python 的 import 机制意味着“导入即执行模块顶层代码”。

危险场景假设：
    假设项目中存在一个临时的脏数据清理脚本 `my_temp_dangerous_delete_mysql_script.py`：

    ```python
    # ❌ 危险写法：写在模块顶层，不在函数内，也无 main 保护
    import db_client
    db_client.execute("DROP TABLE users") 
    ```

后果：
    如果你使用了无限制的 `auto_discovery()`，即使项目上线2年后，一旦扫描并 import 到这个脚本，
    数据库表会在瞬间被删除。这绝对是生产事故级别的灾难。

✅ 正确用法（精确传参）：
    BoosterDiscovery(
        project_root_path='/path/to/your_project', 
        booster_dirs=['your_booster_dir'],
        max_depth=1,
        py_file_re_str='tasks'  # 强烈建议：只扫描包含 'tasks' 的文件，避开临时脚本
    ).auto_discovery()


2. 为什么推荐“显式 Import”而非“自动扫描”？BoosterDiscovery不是funboost的必需品！
-------------------------------------------------------
其实不建议过度依赖 `auto_discovery()`，更推荐的最佳实践是：
👉 手动明确 import 包含 @boost 的模块。需要用到哪些消费函数，就导入哪些模块。

Funboost vs Celery 的架构差异：
    * Funboost：
      没有中央 `app` 实例，不需要像 Celery 那样有一个单独的 `celery_app.py` 模块。
      架构上天然不存在“互相依赖导入”的死结。因此，要用什么消费函数，直接导入即可，简单直观。

    * Celery：
      必须手写 `includes` 配置或调用 `autodiscover_tasks()`。
      根本原因是：Celery 的 `xx_tasks.py` 需要导入 `celery_app.py` 中的 `app` 对象；
      而 `celery worker` 启动 `app` 时又需要导入 `xx_tasks.py` 来注册任务。
      这种设计导致双方陷入“循环导入”的死结，迫使 Celery 发明了一套复杂的导入机制，
      也让新手在规划目录结构时小心翼翼、非常纠结。
`````

#### 📦 Imports

- `import re`
- `import sys`
- `import typing`
- `from os import PathLike`
- `from pathlib import Path`
- `import importlib.util`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.utils.decorators import flyweight`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`

#### 🏛️ Classes (1)

##### 📌 `class BoosterDiscovery(FunboostFileLoggerMixin)`
*Line: 64*

**🔧 Constructor (`__init__`):**
- `def __init__(self, project_root_path: typing.Union[PathLike, str], booster_dirs: typing.List[typing.Union[PathLike, str]], max_depth = 1, py_file_re_str: str = None)`
  - **Docstring:**
  `````
  :param project_root_path 项目根目录
  :param booster_dirs: @boost装饰器函数所在的模块的文件夹,不用包含项目根目录长路径
  :param max_depth: 查找多少深层级子目录
  :param py_file_re_str: 文件名匹配过滤. 例如你所有的消费函数都在xxx_task.py yyy_task.py这样的,  你可以传参 task.py , 避免自动import了不需要导入的模块
  
  BoosterDiscovery(....).auto_discovery() 需要谨慎使用，谨慎传参，原因见上面模块注释。
  `````
  - **Parameters:**
    - `self`
    - `project_root_path: typing.Union[PathLike, str]`
    - `booster_dirs: typing.List[typing.Union[PathLike, str]]`
    - `max_depth = 1`
    - `py_file_re_str: str = None`

**Public Methods (2):**
- `def get_py_files_recursively(self, current_folder_path: Path, current_depth = 0)`
  - *先找到所有py文件*
- `def auto_discovery(self)`
  - **Docstring:**
  `````
  把所有py文件自动执行import,主要是把 所有的@boost函数装饰器注册到 pid_queue_name__booster_map 中
  这个auto_discovery方法最好放到main里面,如果要扫描自身文件夹,没写正则排除文件本身,会无限懵逼死循环导入,无无限懵逼死循环导入
  `````


---




### 📄 Python File Metadata: `funboost/core/broker_kind__exclusive_config_default_define.py`

#### 📝 Module Docstring

`````
这个文件决定了，每种broker对应的能额外传递哪些独特特殊的中间件配置，
从BoosterParams 的 broker_exclusive_config 入参中传递一个字典
`````

#### 📦 Imports

- `from logging import Logger`
- `from funboost.constant import BrokerEnum`

#### 🔧 Public Functions (2)

- `def register_broker_exclusive_config_default(broker_kind: str, broker_exclusive_config_default: dict)`
  - *Line: 14*

- `def generate_broker_exclusive_config(broker_kind: str, user_broker_exclusive_config: dict, logger: Logger)`
  - *Line: 21*


---




### 📄 Python File Metadata: `funboost/core/msg_result_getter.py`

#### 📦 Imports

- `import asyncio`
- `import threading`
- `import time`
- `import typing`
- `import json`
- `from funboost.constant import MongoDbName`
- `from funboost.core.exceptions import FunboostWaitRpcResultTimeout`
- `from funboost.core.exceptions import FunboostRpcResultError`
- `from funboost.core.exceptions import HasNotAsyncResult`
- `from funboost.utils.mongo_util import MongoMixin`
- `from funboost.concurrent_pool import CustomThreadPoolExecutor`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPoolMinWorkers0`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.redis_manager import AioRedisMixin`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`

#### 🏛️ Classes (4)

##### 📌 `class AsyncResult(RedisMixin)`
*Line: 41*

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id, timeout = 1800)`
  - **Parameters:**
    - `self`
    - `task_id`
    - `timeout = 1800`

**Public Methods (8):**
- `def callback_run_executor(self, thread_pool_executor)` `callback_run_executor.setter`
  - **Docstring:**
  `````
  用户可以 async_result.callback_run_executor = 你自己的线程池
  thread_pool_executor 用户可以传递 FlexibleThreadPool或者 ThreadPoolExecutorShrinkAble 或者官方的 concurrent.futures.ThreadPoolExecutor 类型的对象都可以，任意线程池只要实现了submit方法即可。
  :param thread_pool_executor:
  :return:
  `````
- `def set_timeout(self, timeout = 1800)`
- `def is_pending(self)`
- `def get(self)`
- `def is_success(self)`
- `def set_callback(self, callback_func: typing.Callable)`
  - **Docstring:**
  `````
  :param callback_func: 函数结果回调函数，使回调函数自动在线程池中并发运行。
  :return:
  `````
- `def wait_rpc_data_or_raise(self, raise_exception: bool = True) -> FunctionResultStatus`
- `def batch_wait_rpc_data_or_raise(cls, r_list: typing.List['AsyncResult'], raise_exception: bool = True) -> typing.List[FunctionResultStatus]` `classmethod`

**Properties (4):**
- `@property callback_run_executor`
- `@property status_and_result`
- `@property status_and_result_obj -> FunctionResultStatus`
- `@property result`

**Class Variables (2):**
- `default_callback_run_executor = FlexibleThreadPoolMinWorkers0(200, work_queue_maxsize=50)`
- `rpc_data = status_and_result_obj`

##### 📌 `class AioAsyncResult(AioRedisMixin)`
*Line: 144*

**Docstring:**
`````
这个是可以用于asyncio的语法环境中。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id, timeout = 1800)`
  - **Parameters:**
    - `self`
    - `task_id`
    - `timeout = 1800`

**Public Methods (7):**
- `def set_timeout(self, timeout = 1800)`
- `async def is_pending(self)`
- `async def get(self)`
- `async def is_success(self)`
- `async def set_callback(self, aio_callback_func: typing.Callable)`
- `async def wait_rpc_data_or_raise(self, raise_exception: bool = True) -> FunctionResultStatus`
- `async def batch_wait_rpc_data_or_raise(cls, r_list: typing.List['AioAsyncResult'], raise_exception: bool = True) -> typing.List[FunctionResultStatus]` `classmethod`

**Properties (3):**
- `@property status_and_result`
- `@property status_and_result_obj -> FunctionResultStatus`
- `@property result`

**Class Variables (1):**
- `rpc_data = status_and_result_obj`

##### 📌 `class ResultFromMongo(MongoMixin)`
*Line: 249*

**Docstring:**
`````
以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果

async_result = add.push(i, i * 2)
task_id=async_result.task_id
print(ResultFromMongo(task_id).get_status_and_result())


print(ResultFromMongo('test_queue77h6_result:764a1ba2-14eb-49e2-9209-ac83fc5db1e8').get_status_and_result())
print(ResultFromMongo('test_queue77h6_result:5cdb4386-44cc-452f-97f4-9e5d2882a7c1').get_result())
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id: str)`
  - **Parameters:**
    - `self`
    - `task_id: str`

**Public Methods (3):**
- `def query_result(self)`
- `def get_status_and_result(self)`
- `def get_result(self)`
  - *以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果*

##### 📌 `class FutureStatusResult`
*Line: 283*

**Docstring:**
`````
用于sync_call模式的结果等待和通知
使用threading.Event实现同步等待
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, call_type: str)`
  - **Parameters:**
    - `self`
    - `call_type: str`

**Public Methods (4):**
- `def set_finish(self)`
  - *标记任务完成*
- `def wait_finish(self, rpc_timeout)`
  - *等待任务完成，带超时*
- `def set_staus_result_obj(self, staus_result_obj: FunctionResultStatus)`
  - *设置任务执行结果*
- `def get_staus_result_obj(self)`
  - *获取任务执行结果*


---




### 📄 Python File Metadata: `funboost/publishers/base_publisher.py`

#### 📦 Imports

- `from pathlib import Path`
- `import abc`
- `import copy`
- `import inspect`
- `import atexit`
- `import json`
- `import logging`
- `import multiprocessing`
- `import sys`
- `import threading`
- `import time`
- `import typing`
- `from functools import wraps`
- `from threading import Lock`
- `import nb_log`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.constant import ConstStrForClassMethod`
- `from funboost.constant import FunctionKind`
- `from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.helper_funs import MsgGenerater`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.loggers import LoggerLevelSetterMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import get_logger`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.msg_result_getter import AioAsyncResult`
- `from funboost.core.serialization import PickleHelper`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.task_id_logger import TaskIdLogger`
- `from funboost.utils import decorators`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from nb_libs.path_helper import PathHelper`
- `from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker`
- `import amqpstorm`
- `from pikav1.exceptions import AMQPError as PikaAMQPError`

#### 🏛️ Classes (1)

##### 📌 `class AbstractPublisher(LoggerLevelSetterMixin)`
*Line: 43*

**Docstring:**
`````
发布消息到消息队列
同步编程，最重要的方法有 push publish，
asyncio异步编程，最重要的方法有 aio_push aio_publish，

用法是 booster.push(1,y=2)
或者 booster.publish({"x":1,"y":2},task_options=TaskOptions(max_retry_times=3,...)) 
总结就是push更简单更魔法，publish是更强大更灵活，因为publish除了发布函数入参自身，还可以传递task_options参数。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, publisher_params: PublisherParams)`
  - **Parameters:**
    - `self`
    - `publisher_params: PublisherParams`

**Public Methods (12):**
- `def custom_init(self)`
- `def publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None)`
  - **Docstring:**
  `````
  :param msg:函数的入参字典或者字典转json。,例如消费函数是 def add(x,y)，你就发布 {"x":1,"y":2}
  :param task_id:可以指定task_id,也可以不指定就随机生产uuid
  :param task_options:优先级配置，消息可以携带优先级配置，覆盖boost的配置。
  :return: AsyncResult 对象，可以用于等待结果。 例如 status_and_result =  async_result.status_and_result 来等待返回结果。
  
  funboost 消息体中的extra字典，包含的key就是 TaskOptions 中声明的字段。例如 task_id, publish_time, publish_time_format 等。
  如果用户传递了 task_options，则以 task_options 为准。
  如果用户没有传递 task_options，则以消息体中的extra字典为准。
  如果最终还是没有 task_id, publish_time, publish_time_format 等字段，则自动生成。
  
  意味着如果你想传递 task_options 中的值，你的msg字典，
  第一种：你可以有一个extra字段，里面存放 task_options的各种字段，（适合跨编程语言）
  第二种：你可以通过publish方法的 task_options指定一个 TaskOptions pydantic模型对象 （适合python语言，因为能章节用funboost）
  
  如果是跨业务跨编程语言，由于java不能调用python funboost的publish方法:
  java可以这样通过http接口或者funboost.faas  来发布消息 {"user_id":123,"name":"张三","extra": {"task_id":"1234567890","max_retry_times":3}} 
  `````
- `def send_msg(self, msg: typing.Union[dict, str])`
  - *直接发送任意消息内容到消息队列,不生成辅助参数,无视函数入参名字,不校验入参个数和键名*
- `def push(self, *func_args, **func_kwargs)`
  - **Docstring:**
  `````
  简写，只支持传递消费函数的本身参数，不支持task_options参数。
  类似于 publish和push的关系类似 apply_async 和 delay的关系。前者更强大，后者更简略。
  
  例如消费函数是
  def add(x,y):
      print(x+y)
  
  publish({"x":1,'y':2}) 和 push(1,2)是等效的。但前者可以传递task_options参数。后者只能穿add函数所接受的入参。
  :param func_args:
  :param func_kwargs:
  :return:
  `````
- `def sync_call(self, msg_dict: dict, is_return_rpc_data_obj = True) -> typing.Union[dict, FunctionResultStatus]`
  - *仅有部分中间件支持同步调用并阻塞等待返回结果,不依赖AsyncResult + redis作为rpc，例如 http grpc 等*
- `def clear(self)` `abc.abstractmethod`
- `def get_message_count(self)` `abc.abstractmethod`
- `def close(self)` `abc.abstractmethod`
- `async def aio_push(self, *func_args, **func_kwargs) -> AioAsyncResult`
  - **Docstring:**
  `````
  asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
  但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push
  `````
- `async def aio_publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None) -> AioAsyncResult`
  - **Docstring:**
  `````
  asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
  但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push
  `````
- `def check_func_msg_dict(self, msg_dict: dict)`
- `def check_func_input_params(self, *args, **kwargs)`
  - **Docstring:**
  `````
  校验 push 风格的参数: f.check_params(1, y=2)
  利用框架启动时已经解析好的 final_func_input_params_info 进行参数映射和校验。
  :param args: 位置参数
  :param kwargs: 关键字参数
  :return: 校验通过返回 True，失败抛出异常
  `````

**Properties (1):**
- `@property final_func_input_params_info`

**Class Variables (1):**
- `delay = push`

#### 🔧 Public Functions (1)

- `def deco_mq_conn_error(f)`
  - *Line: 364*


---




### 📄 Python File Metadata: `funboost/consumers/base_consumer.py`

#### 📝 Module Docstring

`````
所有中间件类型消费者的抽象基类。使实现不同中间件的消费者尽可能代码少。
整个流程最难的都在这里面。因为要实现多种并发模型，和对函数施加20多种运行控制方式，所以代码非常长。

框架做主要的功能都是在这个文件里面实现的.
`````

#### 📦 Imports

- `import functools`
- `import sys`
- `import typing`
- `import abc`
- `import copy`
- `from apscheduler.jobstores.memory import MemoryJobStore`
- `from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config`
- `from funboost.core.funboost_time import FunboostTime`
- `from pathlib import Path`
- `import datetime`
- `import pytz`
- `import json`
- `import logging`
- `import atexit`
- `import os`
- `import uuid`
- `import time`
- `import traceback`
- `import inspect`
- `from functools import wraps`
- `import threading`
- `from threading import Lock`
- `import asyncio`
- `import nb_log`
- `from funboost.core.current_task import FctContext`
- `from funboost.core.current_task import set_fct_context`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BaseJsonAbleModel`
- `from funboost.core.serialization import PickleHelper`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.task_id_logger import TaskIdLogger`
- `from funboost.constant import FunctionKind`
- `from nb_libs.path_helper import PathHelper`
- `from nb_log import get_logger`
- `from nb_log import LoggerLevelSetterMixin`
- `from nb_log import LogManager`
- `from nb_log import is_main_process`
- `from nb_log import nb_log_config_default`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import logger_prompt`
- `from apscheduler.jobstores.redis import RedisJobStore`
- `from apscheduler.executors.pool import ThreadPoolExecutor as ApschedulerThreadPoolExecutor`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.concurrent_pool.single_thread_executor import SoloExecutor`
- `from funboost.core.function_result_status_saver import ResultPersistenceHelper`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.function_result_status_saver import RunStatus`
- `from funboost.core.helper_funs import delete_keys_and_return_new_dict`
- `from funboost.core.helper_funs import get_publish_time`
- `from funboost.core.helper_funs import MsgGenerater`
- `from funboost.concurrent_pool.async_helper import get_or_create_event_loop`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.concurrent_pool.async_pool_executor import AsyncPoolExecutor`
- `from funboost.concurrent_pool.bounded_threadpoolexcutor import BoundedThreadPoolExecutor`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.func_timeout import dafunc`
- `from funboost.concurrent_pool.custom_threadpool_executor import check_not_monkey`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.flexible_thread_pool import sync_or_async_fun_deco`
- `from funboost.consumers.redis_filter import RedisFilter`
- `from funboost.consumers.redis_filter import RedisImpermanencyFilter`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.utils import decorators`
- `from funboost.utils import time_util`
- `from funboost.utils import redis_manager`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConstStrForClassMethod`
- `from funboost.constant import RedisKeys`
- `from funboost.core import kill_remote_task`
- `from funboost.core.exceptions import ExceptionForRequeue`
- `from funboost.core.exceptions import ExceptionForPushToDlxqueue`
- `from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker`
- `from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`
- `from funboost.timing_job import FsdfBackgroundScheduler`
- `from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import gevent_timeout_deco`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import get_gevent_pool_executor`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import evenlet_timeout_deco`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import get_eventlet_pool_executor`

#### 🏛️ Classes (5)

##### 📌 `class GlobalVars`
*Line: 88*

**Class Variables (2):**
- `global_concurrent_mode = None`
- `has_start_a_consumer_flag = False`

##### 📌 `class AbstractConsumer(LoggerLevelSetterMixin)`
*Line: 94*

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumer_params: BoosterParams)`
  - **Docstring:**
  `````
          
  `````
  - **Parameters:**
    - `self`
    - `consumer_params: BoosterParams`

**Public Methods (12):**
- `def bulid_a_new_publisher_of_same_queue(self)`
- `def join_dispatch_task_thread(cls)` `classmethod`
  - *:return:*
- `def custom_init(self)`
- `def keep_circulating(self, time_sleep = 0.001, exit_if_function_run_sucsess = False, is_display_detail_exception = True, block = True, daemon = False)`
  - **Docstring:**
  `````
  间隔一段时间，一直循环运行某个方法的装饰器
  :param time_sleep :循环的间隔时间
  :param is_display_detail_exception
  :param exit_if_function_run_sucsess :如果成功了就退出循环
  :param block:是否阻塞在当前主线程运行。
  :param daemon:是否守护线程
  `````
- `def start_consuming_message(self)`
- `def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`
- `async def aio_user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`
- `def check_heartbeat_and_message_count(self)`
- `def pause_consume(self)`
  - *从远程机器可以设置队列为暂停消费状态，funboost框架会自动停止消费，此功能需要配置好redis*
- `def continue_consume(self)`
  - *从远程机器可以设置队列为暂停消费状态，funboost框架会自动继续消费，此功能需要配置好redis*
- `def wait_for_possible_has_finish_all_tasks(self, minutes: int = 3)`
  - **Docstring:**
  `````
  判断队列所有任务是否消费完成了。
  由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
  一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
  :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成，为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
  :return:
  `````
- `def clear_filter_tasks(self)`

**Properties (3):**
- `@property publisher_of_same_queue`
- `@property publisher_of_dlx_queue`
- `@property concurrent_pool`

**Class Variables (3):**
- `time_interval_for_check_do_not_run_time = 60`
- `BROKER_KIND = None`
- `logger_apscheduler = get_logger('push_for_apscheduler_use_database_store', log_filename='push_for_apscheduler_use_database_store.log')`

##### 📌 `class ConcurrentModeDispatcher(FunboostFileLoggerMixin)`
*Line: 1104*

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumerx: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `consumerx: AbstractConsumer`

**Public Methods (3):**
- `def check_all_concurrent_mode(self)`
- `def build_pool(self)`
- `def schedulal_task_with_no_block(self)`

##### 📌 `class MetricCalculation`
*Line: 1210*

**🔧 Constructor (`__init__`):**
- `def __init__(self, conusmer: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `conusmer: AbstractConsumer`

**Public Methods (2):**
- `def cal(self, t_start_run_fun: float, current_function_result_status: FunctionResultStatus)`
- `def get_report_hearbeat_info(self) -> dict`

**Class Variables (1):**
- `UNIT_TIME_FOR_COUNT = 10`

##### 📌 `class DistributedConsumerStatistics(RedisMixin, FunboostFileLoggerMixin)`
*Line: 1293*

**Docstring:**
`````
为了兼容模拟mq的中间件（例如redis，他没有实现amqp协议，redis的list结构和真mq差远了），获取一个队列有几个连接活跃消费者数量。
分布式环境中的消费者统计。主要目的有3点

1、统计活跃消费者数量用于分布式控频。
    获取分布式的消费者数量后，用于分布式qps控频。如果不获取全环境中的消费者数量，则只能用于当前进程中的消费控频。
    即使只有一台机器，例如把xx.py启动3次，xx.py的consumer设置qps为10，如果不使用分布式控频，会1秒钟最终运行30次函数而不是10次。

2、记录分布式环境中的活跃消费者的所有消费者 id，如果消费者id不在此里面说明已掉线或关闭，消息可以重新分发，用于不支持服务端天然消费确认的中间件。

3、从redis中获取停止和暂停状态，以便支持在别的地方发送命令停止或者暂停消费。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumer: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `consumer: AbstractConsumer`

**Public Methods (3):**
- `def run(self)`
- `def send_heartbeat(self)`
- `def get_queue_heartbeat_ids(self, without_time: bool)`

**Class Variables (3):**
- `SHOW_CONSUMER_NUM_INTERVAL = 600`
- `HEARBEAT_EXPIRE_SECOND = 25`
- `SEND_HEARTBEAT_INTERVAL = 10`

#### 🔧 Public Functions (1)

- `def wait_for_possible_has_finish_all_tasks_by_conusmer_list(consumer_list: typing.List[AbstractConsumer], minutes: int = 3)`
  - *Line: 1195*
  - **Docstring:**
  `````
  判断多个消费者是否消费完成了。
  由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
  一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
  :param consumer_list: 多个消费者列表
  :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成。为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
  :return:
  
   
  `````


---




### 📄 Python File Metadata: `funboost/core/active_cousumer_info_getter.py`

#### 📝 Module Docstring

`````
此模块的功能非常适合拿来开发对funboost的监控面板，或者管理后台。
    - ActiveCousumerProcessInfoGetter  获取队列的活跃消费进程信息
    - QueuesConusmerParamsGetter  获取所有队列配置参数 和 运行信息
    - SingleQueueConusmerParamsGetter  获取单个队列配置参数 和 运行信息


下面3个python文件的web接口中，funboost.faas 主要就是使用了此模块的功能。
 



care_project_name 的作用是：
    - None : 关心所有redis中存储的队列信息
    - str : 只关心指定project_name的队列信息
   
`````

#### 📦 Imports

- `import json`
- `import threading`
- `import time`
- `import typing`
- `import uuid`
- `import os`
- `from funboost.factories.consumer_factory import ConsumerCacheProxy`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import nb_log_config_default`
- `from funboost.core.serialization import Serialization`
- `from funboost.constant import RedisKeys`
- `from funboost.core.booster import Booster`
- `from funboost.core.booster import BoosterRegistry`
- `from funboost.core.booster import booster_registry_default`
- `from funboost.core.booster import gen_pid_queue_name_key`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import BaseJsonAbleModel`
- `from funboost.core.function_result_status_saver import FunctionResultStatusPersistanceConfig`
- `from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator`
- `from funboost.core.exceptions import QueueNameNotExists`
- `from funboost.timing_job.timing_push import ApsJobAdder`
- `from funboost.constant import EnvConst`

#### 🏛️ Classes (5)

##### 📌 `class CareProjectNameEnv`
*Line: 43*

**Public Methods (2):**
- `def set(cls, care_project_name: str)` `classmethod`
- `def get(cls) -> typing.Optional[bool]` `classmethod`

**Class Variables (1):**
- `env_name = EnvConst.FUNBOOST_FAAS_CARE_PROJECT_NAME`

##### 📌 `class RedisReportInfoGetterMixin`
*Line: 60*

**Public Methods (4):**
- `def get_all_queue_names(self) -> list`
  - *获取所有队列名称，带30秒缓存（类级别缓存，所有实例共享）*
- `def get_queue_names_by_project_name(self, project_name: str) -> list`
  - *根据项目名称获取队列名称，带30秒缓存（类级别缓存，所有实例共享）*
- `def hmget_many_by_all_queue_names(self, key)`
- `def get_all_project_names(self)`

**Properties (2):**
- `@property all_queue_names`
- `@property project_name_queues`

**Class Variables (4):**
- `_cache_all_queue_names = None`
- `_cache_all_queue_names_ts = 0`
- `_cache_queue_names_by_project = {}`
- `_cache_ttl = 30`

##### 📌 `class ActiveCousumerProcessInfoGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 180*

**Docstring:**
`````
获取分布式环境中的消费进程信息。
使用这里面的4个方法需要相应函数的@boost装饰器设置 is_send_consumer_heartbeat_to_redis=True，这样会自动发送活跃心跳到redis。否则查询不到该函数的消费者进程信息。
要想使用消费者进程信息统计功能，用户无论使用何种消息队列中间件类型，用户都必须安装redis，并在 funboost_config.py 中配置好redis链接信息
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, care_project_name: typing.Optional[str] = None)`
  - **Parameters:**
    - `self`
    - `care_project_name: typing.Optional[str] = None`

**Public Methods (5):**
- `def get_all_hearbeat_info_by_queue_name(self, queue_name) -> typing.List[typing.Dict]`
  - **Docstring:**
  `````
  根据队列名查询有哪些活跃的消费者进程
  返回结果例子：
  [{
          "code_filename": "/codes/funboost/test_frame/my/test_consume.py",
          "computer_ip": "172.16.0.9",
          "computer_name": "VM_0_9_centos",
          "consumer_id": 140477437684048,
          "consumer_uuid": "79473629-b417-4115-b516-4365b3cdf383",
          "consuming_function": "f2",
          "hearbeat_datetime_str": "2021-12-27 19:22:04",
          "hearbeat_timestamp": 1640604124.4643965,
          "process_id": 9665,
          "queue_name": "test_queue72c",
          "start_datetime_str": "2021-12-27 19:21:24",
          "start_timestamp": 1640604084.0780013
      }, ...............]
  `````
- `def get_all_hearbeat_info_by_ip(self, ip = None) -> typing.List[typing.Dict]`
  - **Docstring:**
  `````
  根据机器的ip查询有哪些活跃的消费者进程，ip不传参就查本机ip使用funboost框架运行了哪些消费进程，传参则查询任意机器的消费者进程信息。
  返回结果的格式和上面的 get_all_hearbeat_dict_by_queue_name 方法相同。
  `````
- `def get_all_ips(self)`
- `def get_all_hearbeat_info_partition_by_queue_name(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]`
  - *获取所有队列对应的活跃消费者进程信息，按队列名划分,不需要传入队列名，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对*
- `def get_all_hearbeat_info_partition_by_ip(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]`
  - *获取所有机器ip对应的活跃消费者进程信息，按机器ip划分,不需要传入机器ip，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对*

##### 📌 `class QueuesConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 299*

**Docstring:**
`````
获取所有队列的运行信息，
方法 get_queues_params_and_active_consumers 返回信息最丰富
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, care_project_name: typing.Optional[str] = None)`
  - **Parameters:**
    - `self`
    - `care_project_name: typing.Optional[str] = None`

**Public Methods (7):**
- `def get_queues_params(self) -> dict`
- `def get_pause_flag(self)`
- `def get_msg_num(self, ignore_report_ts = False)`
- `def get_queues_history_run_count(self)`
- `def get_queues_history_run_fail_count(self)`
- `def get_queues_params_and_active_consumers(self)`
  - *获取所有队列的参数和活跃消费者*
- `def cycle_get_queues_params_and_active_consumers_and_report(self, daemon = False)`

##### 📌 `class SingleQueueConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 422*

**Docstring:**
`````
获取单个队列的运行信息，
方法 get_one_queue_params_and_active_consumers 返回信息最丰富
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: str, care_project_name: typing.Optional[str] = None, is_use_local_booster: bool = None)`
  - **Parameters:**
    - `self`
    - `queue_name: str`
    - `care_project_name: typing.Optional[str] = None`
    - `is_use_local_booster: bool = None`

**Public Methods (13):**
- `def get_one_queue_params(self) -> dict`
  - **Docstring:**
  `````
          类似于这样，就是booster_params的字符串json序列化
  
          ```json
          {
    "queue_name": "test_funboost_faas_queue2",
    "broker_kind": "REDIS",
    "project_name": "test_project1",
    "concurrent_mode": "threading",
    "concurrent_num": 50,
    "specify_concurrent_pool": null,
    "specify_async_loop": null,
    "is_auto_start_specify_async_loop_in_child_thread": true,
    "qps": null,
    "is_using_distributed_frequency_control": false,
    "is_send_consumer_heartbeat_to_redis": true,
    "max_retry_times": 3,
    "retry_interval": 0,
    "is_push_to_dlx_queue_when_retry_max_times": false,
    "consuming_function_decorator": null,
    "function_timeout": null,
    "is_support_remote_kill_task": false,
    "log_level": 10,
    "logger_prefix": "",
    "create_logger_file": true,
    "logger_name": "",
    "log_filename": null,
    "is_show_message_get_from_broker": false,
    "is_print_detail_exception": true,
    "publish_msg_log_use_full_msg": false,
    "msg_expire_seconds": null,
    "do_task_filtering": false,
    "task_filtering_expire_seconds": 0,
    "function_result_status_persistance_conf": {
      "is_save_status": false,
      "is_save_result": false,
      "expire_seconds": 604800,
      "is_use_bulk_insert": false
    },
    "user_custom_record_process_info_func": null,
    "is_using_rpc_mode": true,
    "rpc_result_expire_seconds": 1800,
    "rpc_timeout": 1800,
    "delay_task_apscheduler_jobstores_kind": "redis",
    "is_do_not_run_by_specify_time_effect": false,
    "do_not_run_by_specify_time": [
      "10:00:00",
      "22:00:00"
    ],
    "schedule_tasks_on_main_thread": false,
    "is_auto_start_consuming_message": false,
    "booster_group": "test_group1",
    "consuming_function": "<function sub at 0x00000272649BBA60>",
    "consuming_function_raw": "<function sub at 0x00000272649BBA60>",
    "consuming_function_name": "sub",
    "broker_exclusive_config": {
      "redis_bulk_push": 1,
      "pull_msg_batch_size": 100
    },
    "should_check_publish_func_params": true,
    "manual_func_input_params": {
      "is_manual_func_input_params": false,
      "must_arg_name_list": [],
      "optional_arg_name_list": []
    },
    "consumer_override_cls": null,
    "publisher_override_cls": null,
    "consuming_function_kind": "COMMON_FUNCTION",
    "user_options": {
      
    },
    "auto_generate_info": {
      "where_to_instantiate": "D:\codes\funboost\examples\example_faas\task_funs_dir\sub.py:5",
      "final_func_input_params_info": {
        "func_name": "sub",
        "func_position": "<function sub at 0x00000272649BBA60>",
        "is_manual_func_input_params": false,
        "all_arg_name_list": [
          "a",
          "b"
        ],
        "must_arg_name_list": [
          "a",
          "b"
        ],
        "optional_arg_name_list": []
      }
    }
  }
  
  
          ```
          
  `````
- `def get_one_queue_params_use_cache(self) -> dict`
- `def gen_booster_for_faas(self) -> Booster`
- `def gen_publisher_for_faas(self) -> Booster`
- `def generate_aps_job_adder(self, job_store_kind = 'redis', is_auto_start = True, is_auto_paused = True) -> ApsJobAdder`
- `def get_one_queue_pause_flag(self) -> int`
  - *返回队列的暂停状态，-1 表示队列不存在，0 表示队列未暂停，1 表示队列已暂停*
- `def get_one_queue_history_run_count(self) -> int`
- `def get_one_queue_history_run_fail_count(self) -> int`
- `def get_one_queue_msg_num(self, ignore_report_ts = False) -> int`
  - **Docstring:**
  `````
  从上报到redis的心跳信息中获取的消息数量，
  如果 ignore_report_ts 为 True 并且最近一次上报时间是很久之前的，消息数量就不准
  上报线程是随着消费一起自动运行的，如果没有启动消息，就会停止心跳信息上报。
  `````
- `def get_one_queue_msg_num_realtime(self) -> int`
  - *实时从broker获取的消息数量，*
- `def get_one_queue_params_and_active_consumers(self) -> dict`
- `def get_one_queue_time_series_data(self, start_ts = None, end_ts = None, curve_samples_count = None)`
- `def deprecate_queue(self)`
  - **Docstring:**
  `````
  废弃队列 - 从 Redis 中移除队列名
  1. 从 funboost_all_queue_names set 中移除
  2. 从 funboost.project_name:{project_name} set 中移除
  `````

**Class Variables (2):**
- `queue__booster_params_cache: dict = {}`
- `_lock_for_generate_publisher_booster = threading.Lock()`


---



## 🔗 funboost_docs Some File Dependencies Analysis

以下是项目文件之间的依赖关系，帮助 AI 理解代码结构：

### 📊 Internal Dependencies Graph

`````
Entry Points (not imported by other project files):
  ★ funboost/__init__.py
  ★ funboost/constant.py
  ★ funboost/consumers/base_consumer.py
  ★ funboost/core/active_cousumer_info_getter.py
  ★ funboost/core/booster.py
  ★ funboost/core/broker_kind__exclusive_config_default_define.py
  ★ funboost/core/cli/discovery_boosters.py
  ★ funboost/core/current_task.py
  ★ funboost/core/func_params_model.py
  ★ funboost/core/msg_result_getter.py
  ★ funboost/funboost_config_deafult.py
  ★ funboost/publishers/base_publisher.py
  ★ funboost/timing_job/timing_push.py

`````

### 📋 Detailed Dependencies


---
# markdown content namespace: funboost_docs project summary 



- **`boost_spider` = `funboost` 的超跑引擎 + 一套为爬虫量身打造的瑞士军刀。所有仿scrapy api爬虫框架都还是处在变花样造一辆马车**

- `boost_spider` 是增加了3个爬虫常用类，RequestClient  和  SpiderResponse  和 DatasetSink, 由funboost 驱动调度和并发。


## 📋 funboost_docs most core source files metadata (Entry Points)


以下是项目 funboost_docs 最核心的入口文件的结构化元数据，帮助快速理解项目架构：



### the project funboost_docs most core source code files as follows: 
- `boost_spider/__init__.py`
- `boost_spider/http/request_client.py`
- `boost_spider/sink/dataset_sink.py`


### 📄 Python File Metadata: `boost_spider/__init__.py`

#### 📝 Module Docstring

`````
boost_spider
是一款自由奔放写法的爬虫框架，无任何束缚，和用户手写平铺直叙的爬虫函数一样，
是横冲直撞的思维写的, 不需要callback回调解析方法, 不需要继承BaseSpider类, 没有BaseSpider类, 大开大合自由奔放.
只需要加上boost装饰器就可以自动加速并发，控制手段比传统爬虫框架多太多
`````

#### 📦 Imports

- `from boost_spider.http.request_client import RequestClient`
- `from boost_spider.sink.momgo_sink import MongoSink`
- `from boost_spider.sink.mysql_sink import MysqlSink`
- `from funboost import *`
- `import json`
- `import re`


---




### 📄 Python File Metadata: `boost_spider/http/request_client.py`

#### 📝 Module Docstring

`````
改版包装requests的Session类，主要使用的是代理模式
1、支持一键设多种代理ip
2、支持3种类型的cookie添加
3、支持长会话，保持cookie状态, ss = RequestClient() , 一直用这个ss对象就可以自动保持cookie了
4、支持一键设置requests请求重试次数，确保请求成功，默认重试一次。
5、记录下当天的请求到文件，方便统计，同时开放了日志级别设置参数，用于禁止日志。
6、从使用requests修改为使用RequstClient门槛很低，三方包的request方法和此类的方法入参和返回完全100%保持了一致。
7、支持多个代理厂商自动切换。需要将proxy_name设置为一个列表，指定多个代理厂商的名字。
8、支持继承 RequestClient 来增加使用各种代理的请求方法，新增加代理商后，将请求方法名字加到 PROXYNAME__REQUEST_METHED_MAP 中。
`````

#### 📦 Imports

- `import json`
- `import logging`
- `import typing`
- `from enum import Enum`
- `from functools import lru_cache`
- `from pathlib import Path`
- `import nb_log`
- `import copy`
- `import time`
- `from typing import Union`
- `import requests`
- `from requests.cookies import RequestsCookieJar`
- `import urllib3.exceptions`
- `from boost_spider.http.user_agent import rand_get_useragent`
- `from parsel import Selector`
- `import re`

#### 🏛️ Classes (3)

##### 📌 `class HttpStatusError(Exception)`
*Line: 35*

**🔧 Constructor (`__init__`):**
- `def __init__(self, http_status_code)`
  - **Parameters:**
    - `self`
    - `http_status_code`

##### 📌 `class SpiderResponse(requests.Response)`
*Line: 43*

**🔧 Constructor (`__init__`):**
- `def __init__(self, resp: requests.Response)`
  - **Parameters:**
    - `self`
    - `resp: requests.Response`

**Public Methods (4):**
- `def re_search(self, pattern, flags = 0)`
- `def re_findall(self, pattern, flags = 0)`
- `def xpath(self, query)`
- `def css(self, query)`

**Properties (3):**
- `@property selector -> Selector`
- `@property resp_dict -> typing.Dict`
- `@property text -> str`

**Class Variables (1):**
- `re_pattern_map = {}`

##### 📌 `class RequestClient`
*Line: 89*

**🔧 Constructor (`__init__`):**
- `def __init__(self, proxy_name_list = None, ua = None, default_use_pc_ua = True, is_change_ua_every_request = False, timeout: Union[tuple, float] = (30, 40), verify = False, allow_redirects = True, is_close_session = True, request_retry_times = 2, using_platfrom = '')`
  - **Docstring:**
  `````
  :param proxy_name_list: 轮流使用代理服务商名字，可设置为 None,'noproxy', 'kuai', 'abuyun', 'crawlera',为None不使用代理
  :param ua:  useragent，如果不设置就随机分配一个欺骗的
  :param is_change_ua_every_request: 为每次请求设置新的useragent
  :param timeout: 超时设置
  :param verify:  是否校验服务器证书
  :param allow_redirects
  :param is_close_session: 是否在请求后关闭会话，连续型的请求需要cookie保持的，请设置为False，并且一直使用RequestClient实例化后的对象
  :param logger_level:日志级别，10 20 30 40 50
  `````
  - **Parameters:**
    - `self`
    - `proxy_name_list = None`
    - `ua = None`
    - `default_use_pc_ua = True`
    - `is_change_ua_every_request = False`
    - `timeout: Union[tuple, float] = (30, 40)`
    - `verify = False`
    - `allow_redirects = True`
    - `is_close_session = True`
    - `request_retry_times = 2`
    - `using_platfrom = ''`

**Public Methods (9):**
- `def get_cookie_jar(self)`
  - *返回cookiejar*
- `def get_cookie_dict(self)`
  - *返回cookie字典*
- `def get_cookie_str(self)`
  - *返回cookie字典*
- `def add_cookies(self, cookies: Union[str, dict, RequestsCookieJar])`
  - **Docstring:**
  `````
  :param cookies: 浏览器复制的cookie字符串或字典类型或者CookieJar类型
  :return:
  `````
- `def request(self, method: str, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs) -> typing.Optional[SpiderResponse]`
  - **Docstring:**
  `````
  使用指定名字的代理请求,从_proxy_name读取,当请求出错时候轮流使用各种代理ip。
  :param method:
  :param url:
  :param verify:
  :param timeout:
  :param headers:
  :param cookies:
  :param kwargs:
  :param kwargs :可接受一切requests.request方法中的参数
  :return:
  `````
- `def get(self, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs)`
- `def post(self, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs)`
- `def close_session(self)`
- `def save_picture(self, url, pic_path, pic_file = None)`

**Class Variables (5):**
- `logger = request_logger`
- `PROXY_NOPROXY = 'noproxy'`
- `PROXY_ABUYUN = 'abuyun'`
- `PROXY_KUAI = 'kuai'`
- `PROXYNAME__REQUEST_METHED_MAP = {'noproxy': _request_with_no_proxy, 'abuyun': _request_with_abuyun_proxy, 'kuai': _request_with_kuai_proxy}`


---




### 📄 Python File Metadata: `boost_spider/sink/dataset_sink.py`

#### 📝 Module Docstring

`````
dataset 很适合保存一个字典到各种数据库 mysql postgre sqlite
`````

#### 📦 Imports

- `import dataset`

#### 🏛️ Classes (1)

##### 📌 `class DatasetSink`
*Line: 7*

**🔧 Constructor (`__init__`):**
- `def __init__(self, db_url)`
  - **Parameters:**
    - `self`
    - `db_url`

**Public Methods (2):**
- `def save(self, table_name: str, data: dict)`
- `def get_instance(cls, db_url)` `classmethod`

**Class Variables (2):**
- `_instances = {}`
- `_has__init_set = set()`


---



## 🔗 funboost_docs Some File Dependencies Analysis

以下是项目文件之间的依赖关系，帮助 AI 理解代码结构：

### 📊 Internal Dependencies Graph

`````
Entry Points (not imported by other project files):
  ★ boost_spider/__init__.py
  ★ boost_spider/http/request_client.py
  ★ boost_spider/sink/dataset_sink.py

`````

### 📋 Detailed Dependencies


---
# markdown content namespace: funboost examples 


## funboost_docs File Tree (relative dir: `examples`)


`````

└── examples
    ├── example_all_usage.py
    ├── example_easy.py
    └── example_faas
        ├── README.md
        ├── example_fastapi_faas.py
        ├── example_req_fastapi.py
        ├── example_req_timing_api.py
        ├── start_consume.py
        └── task_funs_dir
            ├── __init__.py
            ├── add.py
            ├── base_booster_params.py
            └── sub.py

`````

---


## funboost_docs (relative dir: `examples`)  Included Files (total: 11 files)


- `examples/example_all_usage.py`

- `examples/example_easy.py`

- `examples/example_faas/example_fastapi_faas.py`

- `examples/example_faas/example_req_fastapi.py`

- `examples/example_faas/example_req_timing_api.py`

- `examples/example_faas/README.md`

- `examples/example_faas/start_consume.py`

- `examples/example_faas/task_funs_dir/add.py`

- `examples/example_faas/task_funs_dir/base_booster_params.py`

- `examples/example_faas/task_funs_dir/sub.py`

- `examples/example_faas/task_funs_dir/__init__.py`


---


--- **start of file: examples/example_all_usage.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_all_usage.py`

#### 📝 Module Docstring

`````
funboost 所有用法的使用， demo 例子 演示
这个文件集中演示了 funboost 的 90% 主要功能用法。
`````

#### 📦 Imports

- `import time`
- `import random`
- `import asyncio`
- `import datetime`
- `from funboost import boost`
- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `from funboost import ConcurrentModeEnum`
- `from funboost import TaskOptions`
- `from funboost import ApsJobAdder`
- `from funboost import ctrl_c_recv`
- `from funboost import fct`
- `from funboost import BoostersManager`
- `from funboost import AsyncResult`
- `from funboost import AioAsyncResult`

#### 🔧 Public Functions (11)

- `def task_basic(x, y)` `boost(BoosterParams(queue_name='demo_queue_basic', broker_kind=BrokerEnum.SQLITE_QUEUE, concurrent_num=2))`
  - *Line: 34*

- `def task_retry(n)` `boost(BoosterParams(queue_name='demo_queue_retry', broker_kind=BrokerEnum.MEMORY_QUEUE, max_retry_times=3, retry_interval=1, is_print_detail_exception=False))`
  - *Line: 51*

- `def task_qps(idx)` `boost(BoosterParams(queue_name='demo_queue_qps', broker_kind=BrokerEnum.MEMORY_QUEUE, qps=2))`
  - *Line: 67*

- `async def task_async(url)` `boost(BoosterParams(queue_name='demo_queue_async', broker_kind=BrokerEnum.MEMORY_QUEUE, concurrent_mode=ConcurrentModeEnum.ASYNC, concurrent_num=100, is_using_rpc_mode=True))`
  - *Line: 81*

- `def task_rpc(a, b)` `boost(BoosterParams(queue_name='demo_queue_rpc', broker_kind=BrokerEnum.MEMORY_QUEUE, is_using_rpc_mode=True, rpc_result_expire_seconds=10))`
  - *Line: 99*

- `def task_filter(user_id, user_sex, user_name)` `boost(BoosterParams(queue_name='demo_queue_filter', broker_kind=BrokerEnum.MEMORY_QUEUE, do_task_filtering=True, task_filtering_expire_seconds=60))`
  - *Line: 113*

- `def task_delay(msg)` `boost(BoosterParams(queue_name='demo_queue_delay', broker_kind=BrokerEnum.MEMORY_QUEUE))`
  - *Line: 121*

- `def task_group_a_1(x)` `boost(BoosterParams(queue_name='demo_group_task_1', broker_kind=BrokerEnum.MEMORY_QUEUE, booster_group='my_group_a'))`
  - *Line: 134*

- `def task_group_a_2(x)` `boost(BoosterParams(queue_name='demo_group_task_2', broker_kind=BrokerEnum.MEMORY_QUEUE, booster_group='my_group_a'))`
  - *Line: 142*

- `def task_group_b_1(x)` `boost(BoosterParams(queue_name='demo_group_task_3', broker_kind=BrokerEnum.MEMORY_QUEUE, booster_group='my_group_b'))`
  - *Line: 150*

- `async def rpc_asyncio()`
  - *Line: 251*


---

`````python
# -*- coding: utf-8 -*-

"""
funboost 所有用法的使用， demo 例子 演示
这个文件集中演示了 funboost 的 90% 主要功能用法。
"""

import time
import random
import asyncio
import datetime
from funboost import (
    boost,                  # 核心装饰器
    BoosterParams,          # 参数配置类
    BrokerEnum,             # 中间件枚举
    ConcurrentModeEnum,     # 并发模式枚举
    TaskOptions, # 优先级/延时配置
    ApsJobAdder,            # 定时任务添加器
    ctrl_c_recv,            # 阻塞主线程工具
    fct,                    # 上下文对象 (Funboost Current Task)
    BoostersManager,        # 消费者管理器 (用于分组启动)
    AsyncResult,            # 同步编程生态的异步结果对象
    AioAsyncResult,          # asyncio生态的异步结果对象
)

# ==========================================
# 1. 基础任务 (使用 SQLite 本地文件作为队列，无需安装 Redis/RabbitMQ 即可测试)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_basic",
    broker_kind=BrokerEnum.SQLITE_QUEUE,  # 使用本地 SQLite 文件作为队列
    concurrent_num=2,                     # 线程并发数量
))
def task_basic(x, y):
    print(f"[基础任务] 正在处理: {x} + {y} = {x + y}")
    time.sleep(0.5)
    return x + y


# ==========================================
# 2. 错误重试任务 (演示自动重试机制)
# 2.b 获取taskid和消息发布时间 (演示fct上下文的使用)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_retry",
    broker_kind=BrokerEnum.MEMORY_QUEUE,  # 使用内存队列
    max_retry_times=3,                    # 最大重试 3 次
    retry_interval=1,                     # 重试间隔 1 秒
    is_print_detail_exception=False       # 不打印详细堆栈，保持控制台整洁
))
def task_retry(n):
    # 模拟：只有 n > 8 才会成功，否则报错触发重试
    if n <= 8:
        print(f"[重试任务] 输入 {n} 模拟失败，当前是第 {fct.function_result_status.run_times} 次运行...")
        raise ValueError("模拟出错啦")
    print(f"[重试任务] 输入 {n} 成功处理！,任务id是：{fct.task_id} ,发布时间是：{fct.function_result_status.publish_time_format}")


# ==========================================
# 3. QPS 控频任务 (精准控制每秒执行次数)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_qps",
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    qps=2,  # 限制每秒只执行 2 次，无论并发开多大
))
def task_qps(idx):
    print(f"[QPS任务] {idx} 正在运行 (每秒约2次)... {datetime.datetime.now()}")


# ==========================================
# 4. Asyncio 协程任务 (高性能 IO 密集型)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_async",
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    concurrent_mode=ConcurrentModeEnum.ASYNC, # 开启 Asyncio 模式
    concurrent_num=100,  # 协程并发数可以设置很大
    is_using_rpc_mode = True,
))
async def task_async(url):
    print(f"[Async任务] 开始请求: {url}")
    await asyncio.sleep(1) # 模拟 IO 等待
    print(f"[Async任务] 请求结束: {url}")
    return f'url:{url} ,resp: mock_resp'


# ==========================================
# 5. RPC 任务 (发布端获取消费端结果)
# 注意：RPC模式通常需要 Redis 支持，这里使用 MEMORY_QUEUE 模拟演示(Funboost支持内存模拟)
# 但生产环境强烈建议配置 funboost_config.py 使用 Redis
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_rpc",
    broker_kind=BrokerEnum.MEMORY_QUEUE, 
    is_using_rpc_mode=True,  # 开启 RPC 模式
    rpc_result_expire_seconds=10
))
def task_rpc(a, b):
    time.sleep(1)
    return a * b


# ==========================================
# 6. 任务过滤 (去重)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_filter",
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    do_task_filtering=True,           # 开启过滤
    task_filtering_expire_seconds=60  # 60秒内参数相同的任务只执行一次
))
def task_filter(user_id, user_sex, user_name):
    print(f"[过滤任务] 正在执行: user_id={user_id} name={user_name} sex={user_sex}")


# ==========================================
# 7. 延时任务 (消费者取出后，延迟执行)
# ==========================================
@boost(BoosterParams(queue_name="demo_queue_delay", broker_kind=BrokerEnum.MEMORY_QUEUE))
def task_delay(msg):
    print(f"[延时任务] 终于执行了: {msg} - 当前时间: {datetime.datetime.now()}")


# ==========================================
# 10. Booster Group (分组启动演示)
# 场景：假设你有100个消费函数，只想启动其中属于 'my_group_a' 业务组的函数
# ==========================================
@boost(BoosterParams(
    queue_name="demo_group_task_1", 
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    booster_group="my_group_a"  # 指定分组名称
))
def task_group_a_1(x):
    print(f"[分组任务A-1] 处理: {x}")

@boost(BoosterParams(
    queue_name="demo_group_task_2", 
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    booster_group="my_group_a"  # 指定相同的分组名称
))
def task_group_a_2(x):
    print(f"[分组任务A-2] 处理: {x}")

@boost(BoosterParams(
    queue_name="demo_group_task_3", 
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    booster_group="my_group_b"  # 不同的分组，不会被 my_group_a 启动
))
def task_group_b_1(x):
    print(f"[分组任务B-1] (这个不应该运行，因为没有启动my_group_b分组，也没有启动task_group_b_1消费函数): {x}")


# ==========================================
# 主程序入口
# ==========================================
if __name__ == '__main__':
    # --- 1. 启动常规消费者 ---
    # 启动方式 A: 单个启动
    task_basic.consume()
    task_retry.consume()
    task_qps.consume()
    task_async.consume()
    task_rpc.consume()
    task_filter.consume()
    task_delay.consume()
    
    # 启动方式 B: 多进程启动 (用于 CPU 密集型任务，这里仅做演示)
    # task_basic.multi_process_consume(process_num=2)   # 或者 task_basic.mp_consume(process_num=2) ,mp_consume是multi_process_consume的别名简写

    # 启动方式 C: 分组启动 (新增演示)
    print(">>> 正在启动属于 'my_group_a' 分组的所有消费者...")
    BoostersManager.consume_group("my_group_a")
    # 注意：这里没有启动 task_group_b_1，因为它属于 my_group_b

    print("=== 消费者已启动，开始发布任务 ===")
    time.sleep(1)

    # --- 2. 发布基础任务 ---
    for i in range(5):
        task_basic.push(i, i+1)

    # --- 3. 发布重试任务 ---
    task_retry.push(5) # 这个会失败并重试3次
    task_retry.push(6666) # 这个会成功无需重试

    # --- 4. 发布 QPS 任务 ---
    for i in range(6):
        task_qps.push(i)
    
    # --- 5. 发布 Async 任务 ---
    for i in range(3):
        # 支持异步 push: await task_async.aio_push(...)
        task_async.push(f"http://site-{i}.com")

    # --- 6. RPC 获取结果演示 ---
    print("\n--- RPC 演示 ---")
    # push 返回的是 AsyncResult 对象
    async_result:AsyncResult = task_rpc.push(10, 20) 
    print("RPC 任务已发布，正在等待结果...")
    # result 属性会阻塞当前线程直到获取结果
    print(f"RPC 结果: {async_result.result}") 
    

    # --- 7. 任务过滤演示 ---
    print("\n--- 过滤演示 ---")
    print("如果不指定filter_str， 默认使用函数的所有入参包括 user_id user_sex user_name 来做过滤")
    task_filter.push(1001,"man",user_name="xiaomin")

    # 演示: 指定字符串过滤 (publish 方式 + task_options)
    # 场景：只根据 user_id 过滤，即使其他参数不同，只要 user_id 相同就被过滤
    print("发布 user_id=1001 (第1次)")
    task_filter.publish(
        msg={"user_id": 1001, "user_sex": "man", "user_name": "Tom"},
        task_options=TaskOptions(filter_str="1001")
    )
    
    print("发布 user_id=1001 (第2次, name不同, 但filter_str相同, 应该被过滤)")
    task_filter.publish(
        msg={"user_id": 1001, "user_sex": "man", "user_name": "Jerry"},
        task_options=TaskOptions(filter_str="1001")
    )


    # --- 8. 延时任务演示 ---
    print("\n--- 延时演示 ---")
    print(f"发布延时任务时间: {datetime.datetime.now()}")
    # 使用 publish 方法发布，并携带 task_options
    task_delay.publish(
        msg={"msg": "我是延迟5秒的消息"}, 
        task_options=TaskOptions(countdown=5)
    )

    # --- 9. 定时任务演示 (APScheduler) ---
    print("\n--- 定时演示 (每隔5秒触发一次) ---")
    # 注意：这里是定时“发布”任务到队列，而不是直接运行函数
    ApsJobAdder(task_basic, job_store_kind='memory').add_push_job(
        trigger='interval',
        seconds=5,
        args=(100, 200), # 定时执行 task_basic(100, 200)
        id='my_schedule_job'
    )

    # --- 10. 分组任务发布演示 ---
    print("\n--- 分组任务演示 ---")
    task_group_a_1.push("A1 data")
    task_group_a_2.push("A2 data")
    task_group_b_1.push("B1 data (这条消息不会被消费，因为没启动B组)")

    # --- 11. funboost的asyncio 全链路生态的演示,包括asyncio发布 asyncio消费 asyncio获取结果
    async def rpc_asyncio():
        aio_async_result:AioAsyncResult = await task_async.aio_push("http://site-1.com") # aio_push 返回 AioAsyncResult 对象
        print("RPC 任务已发布，正在asyncio生态等待结果...")
        print(f"aio_async_result RPC 结果: {await aio_async_result.result}") 
    
    loop = asyncio.get_event_loop()
    loop.run_until_complete(rpc_asyncio())


    print("\n=== 所有演示任务已发布，ctrl_c_recv使主线程进入监听状态 (按3次 Ctrl+C 退出) ===\n")
    # ctrl_c_recv 阻塞主线程，防止主线程结束了，最好是加上，因为这可以阻止由于主线程结束了导致守护线程结束。 
    # 因为booster.consume() 是在子线程启动的，所以可以连续多个消费函数.consume()而不阻塞主线程
    ctrl_c_recv()
`````

--- **end of file: examples/example_all_usage.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_easy.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_easy.py`

#### 📝 Module Docstring

`````
Funboost 最最基础示例
演示如何使用 @boost 装饰器创建分布式任务队列
`````

#### 📦 Imports

- `import time`
- `from funboost import boost`
- `from funboost import BrokerEnum`
- `from funboost import BoosterParams`
- `from funboost import ctrl_c_recv`

#### 🔧 Public Functions (1)

- `def add_task(x, y)` `boost(BoosterParams(queue_name='demo_queue_1', broker_kind=BrokerEnum.SQLITE_QUEUE, qps=5, concurrent_num=10))`
  - *Line: 16*
  - *简单的加法任务*


---

`````python
"""
Funboost 最最基础示例
演示如何使用 @boost 装饰器创建分布式任务队列
"""
import time
from funboost import boost, BrokerEnum, BoosterParams,ctrl_c_recv


# 示例1: 最简单的任务函数
@boost(BoosterParams(
    queue_name="demo_queue_1",
    broker_kind=BrokerEnum.SQLITE_QUEUE,  # 使用 SQLite 作为消息队列，无需额外安装中间件
    qps=5,  # 每秒执行5次
    concurrent_num=10,  # 并发数为10
))
def add_task(x, y):
    """简单的加法任务"""
    print(f'计算: {x} + {y} = {x + y}')
    time.sleep(1)  # 模拟耗时操作
    return x + y


if __name__ == '__main__':
    for i in range(10):
        add_task.push(i, i * 2)
    add_task.consume()
    ctrl_c_recv()
`````

--- **end of file: examples/example_easy.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/example_fastapi_faas.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/example_fastapi_faas.py`

#### 📝 Module Docstring

`````
此模块演示用户如果使用了fastapi，如何轻松一键新增 多个 funbost 的路由接口，
包括 /funboost/publish 和 /funboost/get_result 和 /funboost/get_msg_count 等几十个接口
这样用户就可以避免需要亲自写funboost发布消息和获取结果的的fastapi路由接口


from funboost.faas import fastapi_router
app.include_router(fastapi_router) # 只需要这样，你的fastapi app即可新增多个 funbost 的路由接口
`````

#### 📦 Imports

- `import uvicorn`
- `from fastapi import FastAPI`
- `from funboost.faas import fastapi_router`
- `from funboost.faas import CareProjectNameEnv`

#### 🔧 Public Functions (1)

- `async def index()` `app.get('/')`
  - *Line: 24*


---

`````python
"""
此模块演示用户如果使用了fastapi，如何轻松一键新增 多个 funbost 的路由接口，
包括 /funboost/publish 和 /funboost/get_result 和 /funboost/get_msg_count 等几十个接口
这样用户就可以避免需要亲自写funboost发布消息和获取结果的的fastapi路由接口


from funboost.faas import fastapi_router
app.include_router(fastapi_router) # 只需要这样，你的fastapi app即可新增多个 funbost 的路由接口
"""


import uvicorn
from fastapi import FastAPI

from funboost.faas import fastapi_router,CareProjectNameEnv 


CareProjectNameEnv.set('test_project1') # 可选，只关注指定的test_project1项目下的队列，减少无关队列的干扰。

# Create FastAPI app
app = FastAPI()

@app.get('/')
async def index():
    return "Hello World"

# 2. Include funboost.faas fastapi_router
app.include_router(fastapi_router)  # 这是核心用法


# 4. Run the app
if __name__ == '__main__':
    # The consumer runs in the background threads/processes started by @boost.
    # We run uvicorn to serve the API.
    print("Starting FastAPI app with Funboost Router...")
    
    print("启动 Funboost API 服务...")
    print("接口文档: http://127.0.0.1:8000/docs")
    print("Try POST http://127.0.0.1:8000/funboost/publish with body: {'queue_name': 'test_funboost_faas_queue', 'msg_body': {'x': 1, 'y': 2}, 'need_result': true}")
    uvicorn.run(app, host="0.0.0.0", port=8000)

`````

--- **end of file: examples/example_faas/example_fastapi_faas.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/example_req_fastapi.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/example_req_fastapi.py`

#### 📝 Module Docstring

`````
funboost.faas FastAPI Router 接口测试示例

本示例演示如何使用 funboost.faas 提供个接口：

1. test_publish_and_get_result - 演示发布消息并等待结果（RPC模式）
2. test_get_msg_count - 演示获取队列消息数量
3. test_publish_async_then_get_result - 演示异步发布，先获取task_id，再根据task_id获取结果
4. test_get_all_queues - 演示获取所有已注册的队列名称
`````

#### 📦 Imports

- `import requests`
- `import time`
- `import json`

#### 🔧 Public Functions (4)

- `def test_publish_and_get_result()`
  - *Line: 19*
  - **Docstring:**
  `````
  测试发布消息并等待结果（RPC模式）
  
  接口有对queue_name是否存在的校验，支持校验消息内容是否正确。所以不用担心跨部门用户使用了错误的queue_name，或者消息内容不正确。
  用户可以先通过 /get_queues_config 接口获取所有队列的配置信息，就知道有哪些队列，以及每个队列的消费函数支持的消息内容需要包括哪些入参字段了。
  `````

- `def test_get_msg_count()`
  - *Line: 56*
  - *测试获取队列消息数量*

- `def test_publish_async_then_get_result()`
  - *Line: 84*
  - *测试异步发布，先获取task_id，再根据task_id获取结果*

- `def test_get_all_queues()`
  - *Line: 137*
  - *测试获取所有已注册的队列名称*


---

`````python
"""
funboost.faas FastAPI Router 接口测试示例

本示例演示如何使用 funboost.faas 提供个接口：

1. test_publish_and_get_result - 演示发布消息并等待结果（RPC模式）
2. test_get_msg_count - 演示获取队列消息数量
3. test_publish_async_then_get_result - 演示异步发布，先获取task_id，再根据task_id获取结果
4. test_get_all_queues - 演示获取所有已注册的队列名称

"""

import requests
import time
import json

base_url = "http://127.0.0.1:8000"

def test_publish_and_get_result():
    """测试发布消息并等待结果（RPC模式）

    接口有对queue_name是否存在的校验，支持校验消息内容是否正确。所以不用担心跨部门用户使用了错误的queue_name，或者消息内容不正确。
    用户可以先通过 /get_queues_config 接口获取所有队列的配置信息，就知道有哪些队列，以及每个队列的消费函数支持的消息内容需要包括哪些入参字段了。
    """
    print("=" * 60)
    print("1. Testing publish and get result (RPC mode)...")
    print("=" * 60)
    
    url = f"{base_url}/funboost/publish"
    data = {
        "queue_name": "test_funboost_faas_queue",
        "msg_body": {"x": 10, "y": 20},
        "need_result": True,
        "timeout": 10
    }
    # publish 
    try:
        resp = requests.post(url, json=data)
        print(f"Status Code: {resp.status_code}")
        print(f"Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                task_id = result_data['data']['task_id']
                status_and_result = result_data['data']['status_and_result']
                print(f"\n✅ Success!")
                print(f"Task ID: {task_id}")
                print(f"Result: {status_and_result}")
            else:
                print(f"\n❌ Failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

def test_get_msg_count():
    """测试获取队列消息数量"""
    print("\n" + "=" * 60)
    print("2. Testing get message count...")
    print("=" * 60)
    
    url = f"{base_url}/funboost/get_msg_count"
    params = {"queue_name": "test_funboost_faas_queue"}
    
    try:
        resp = requests.get(url, params=params)
        print(f"Status Code: {resp.status_code}")
        print(f"Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                queue_name = result_data['data']['queue_name']
                count = result_data['data']['count']
                print(f"\n✅ Success!")
                print(f"Queue: {queue_name}")
                print(f"Message Count: {count}")
            else:
                print(f"\n❌ Failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

def test_publish_async_then_get_result():
    """测试异步发布，先获取task_id，再根据task_id获取结果"""
    print("\n" + "=" * 60)
    print("3. Testing publish async then get result by task_id...")
    print("=" * 60)
    
    # 步骤1: 发布消息（不等待结果）
    url_pub = f"{base_url}/funboost/publish"
    data = {
        "queue_name": "test_funboost_faas_queue",
        "msg_body": {"x": 33, "y": 44},
        "need_result": False,  # 不等待结果，立即返回
    }
    
    try:
        resp = requests.post(url_pub, json=data)
        print(f"Publish Status Code: {resp.status_code}")
        print(f"Publish Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                task_id = result_data['data']['task_id']
                print(f"\n✅ Message published!")
                print(f"Task ID: {task_id}")
                
                if task_id:
                    # 步骤2: 根据task_id获取结果
                    print("\nWaiting for task to complete...")
                    time.sleep(0.2)  # 等待一小段时间让任务完成
                    
                    url_get = f"{base_url}/funboost/get_result"
                    params = {"task_id": task_id, "timeout": 5}
                    resp_get = requests.get(url_get, params=params)
                    
                    print(f"\nGet Result Status Code: {resp_get.status_code}")
                    print(f"Get Result Response: {json.dumps(resp_get.json(), indent=2, ensure_ascii=False)}")
                    
                    if resp_get.status_code == 200:
                        get_result_data = resp_get.json()
                        if get_result_data['succ']:
                            # 新格式：数据在 data 字段中
                            status_and_result = get_result_data['data']['status_and_result']
                            print(f"\n✅ Got result!")
                            print(f"Result: {status_and_result}")
                        else:
                            print(f"\n⚠️  {get_result_data['msg']}")
            else:
                print(f"\n❌ Publish failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

def test_get_all_queues():
    """测试获取所有已注册的队列名称"""
    print("\n" + "=" * 60)
    print("4. Testing get all queues...")
    print("=" * 60)
    
    url = f"{base_url}/funboost/get_all_queues"
    
    try:
        resp = requests.get(url)
        print(f"Status Code: {resp.status_code}")
        print(f"Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                queues = result_data['data']['queues']
                count = result_data['data']['count']
                print(f"\n✅ Success!")
                print(f"Total Queues: {count}")
                print(f"Queue List:")
                for i, queue in enumerate(queues, 1):
                    print(f"  {i}. {queue}")
            else:
                print(f"\n❌ Failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

if __name__ == "__main__":
    print("\n" + "🚀 " * 20)
    print("FastAPI Funboost faas  接口测试")
    print("🚀 " * 20)
    
    # 测试所有4个接口
    test_publish_and_get_result()
    test_get_msg_count()
    test_publish_async_then_get_result()
    test_get_all_queues()
    
    print("\n" + "✅ " * 20)
    print("测试完成！")
    print("✅ " * 20 + "\n")

`````

--- **end of file: examples/example_faas/example_req_fastapi.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/example_req_timing_api.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/example_req_timing_api.py`

#### 📝 Module Docstring

`````
这个是演示funboost.faas 的定时任务管理
`````

#### 📦 Imports

- `import requests`


---

`````python
"""
这个是演示funboost.faas 的定时任务管理
"""


import requests

# 添加每10秒执行一次的任务
resp = requests.post("http://127.0.0.1:8000/funboost/add_timing_job", json={
    "queue_name": "test_funboost_faas_queue",
    "trigger": "interval",
    "seconds": 10,
    "job_id": "my_job",
    "kwargs": {"x": 10, "y": 20},
    "job_store_kind": "redis",
    "replace_existing": True,
})
print('add_timing_job',resp.json())

# 获取所有任务
resp = requests.get("http://127.0.0.1:8000/funboost/get_timing_jobs")
print('get_timing_jobs',resp.json())

# 暂停任务
resp = requests.post("http://127.0.0.1:8000/funboost/pause_timing_job", 
    params={"job_id": "my_job", "queue_name": "test_funboost_faas_queue"})
print('pause_timing_job',resp.json())

# # 恢复任务
# resp = requests.post("http://127.0.0.1:8000/funboost/resume_timing_job",
#     params={"job_id": "my_job", "queue_name": "test_funboost_faas_queue"})
# print('resume_timing_job',resp.json())

`````

--- **end of file: examples/example_faas/example_req_timing_api.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/README.md** (project: funboost_docs) --- 

`````markdown
# funboost faas （Function as a Service） 示例

本示例演示如何在funboost faas 用法。

```
funboost faas ,可以单独部署启动消费，用户可以让booster随着web一起启动，也可以单独启动消费。

因为 funboost.faas 是基于funboost注册到redis中的元数据驱动，所以可以动态发现booster，
所以只要消费函数部署上线了，web服务完全无需重启，从http接口马上就能调用了，
相比传统web开发，加一个功能就要加一个接口，然后重启web，funboost faas爽的一逼。
```


## 📁 文件说明

### 1. `task_funs_dir` - 任务函数定义文件夹

**作用**: 定义需要被 Funboost 管理的消费函数（任务函数）

`Project1BoosterParams` 是 `BoosterParams`子类 ，每个消费函数可以直接用这个子类，减少每个装饰器都重复相同入参




### 2. `example_fastapi_faas.py` - FastAPI 应用主入口

**作用**: FastAPI 应用的主程序，展示如何一键集成 Funboost 路由，实现faas

运行 Uvicorn 服务器


**核心代码**:
```python
from funboost.faas import fastapi_router,CareProjectNameEnv

CareProjectNameEnv.set('test_project1') # 可选，只关注指定的test_project1项目下的队列

app = FastAPI()
app.include_router(fastapi_router)  # 核心用法：一行代码集成



if __name__ == '__main__':
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**访问地址**:
- API 文档: http://127.0.0.1:8000/docs
- 根路径: http://127.0.0.1:8000/

---

### 3. `start_consume.py` - 独立消费者启动脚本

**作用**: 演示如何单独启动 Funboost 消费者，而不随 FastAPI 一起启动



---

### 4. `example_req_fastapi.py` - API 测试客户端

**作用**: 演示如何调用 Funboost FastAPI 路由的各个接口

**包含的测试用例**:

#### 测试 1: `test_publish_and_get_result()`
- **功能**: 发布任务并同步等待结果
- **请求**: `POST /funboost/publish`
- **参数**:
  ```json
  {
    "queue_name": "test_fastapi_router_queue",
    "msg_body": {"x": 10, "y": 20},
    "need_result": true,
    "timeout": 10
  }
  ```
- **特点**: `need_result=True` 时，接口会阻塞等待任务完成并返回结果

#### 测试 2: `test_get_msg_count()`
- **功能**: 获取指定队列的消息数量
- **请求**: `GET /funboost/get_msg_count?queue_name=test_fastapi_router_queue`
- **用途**: 监控队列积压情况

#### 测试 3: `test_publish_async_then_get_result()`
- **功能**: 异步发布任务，先获取 task_id，再通过 task_id 查询结果
- **流程**:
  1. 发布任务（`need_result=False`），立即返回 task_id
  2. 使用 task_id 调用 `GET /funboost/get_result` 获取结果
- **优势**: 不阻塞，适合长时间任务

**运行方式**:
```bash
python example_req_fastapi.py
```

---






`````

--- **end of file: examples/example_faas/README.md** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/start_consume.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/start_consume.py`

#### 📝 Module Docstring

`````
可以单独部署启动消费，用户可以让booster随着fastapi一起启动，也可以单独启动消费。

因为 funboost.faas 是基于funboost注册到redis中的元数据，所以可以动态发现booster，
所以只要消费函数部署上线了，web服务完全无需重启，从http接口马上就能调用了，
相比传统web开发，加一个功能就要加一个接口，然后重启web，funboost faas爽的一逼。
`````

#### 📦 Imports

- `from funboost import BoosterDiscovery`
- `from funboost import BoostersManager`


---

`````python
"""
可以单独部署启动消费，用户可以让booster随着fastapi一起启动，也可以单独启动消费。

因为 funboost.faas 是基于funboost注册到redis中的元数据，所以可以动态发现booster，
所以只要消费函数部署上线了，web服务完全无需重启，从http接口马上就能调用了，
相比传统web开发，加一个功能就要加一个接口，然后重启web，funboost faas爽的一逼。
"""

from funboost import BoosterDiscovery,BoostersManager

if __name__ == '__main__':
    # 演示 BoosterDiscovery ，自动扫描注册 @boost，
    # 效果等同于 直接 import task_funs_dir 下的add和sub模块。
    BoosterDiscovery(
        project_root_path=r'D:\codes\funboost',
        booster_dirs=['examples/example_faas/task_funs_dir'],
         ).auto_discovery()

    print(BoostersManager.get_all_queues())

    BoostersManager.consume_group('test_group1')
`````

--- **end of file: examples/example_faas/start_consume.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/add.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/add.py`

#### 📦 Imports

- `from base_booster_params import Project1BoosterParams`
- `from funboost import boost`
- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `import time`

#### 🔧 Public Functions (1)

- `def add(x, y = 10)` `boost(Project1BoosterParams(queue_name='test_funboost_faas_queue'))`
  - *Line: 6*


---

`````python
from .base_booster_params import Project1BoosterParams
from funboost import boost, BoosterParams, BrokerEnum
import time

@boost(Project1BoosterParams(queue_name="test_funboost_faas_queue", ))
def add(x, y=10,):
    time.sleep(1)
    print(f"add {x} + {y} = {x + y}")
    return x + y


`````

--- **end of file: examples/example_faas/task_funs_dir/add.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/base_booster_params.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/base_booster_params.py`

#### 📦 Imports

- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `from funboost import FunctionResultStatusPersistanceConfig`

#### 🏛️ Classes (1)

##### 📌 `class Project1BoosterParams(BoosterParams)`
*Line: 6*

**Class Variables (7):**
- `project_name: str = 'test_project1'`
- `broker_kind: str = BrokerEnum.REDIS`
- `is_send_consumer_heartbeat_to_redis: bool = True`
- `is_using_rpc_mode: bool = True`
- `booster_group: str = 'test_group1'`
- `should_check_publish_func_params: bool = True`
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)`


---

`````python

from funboost import  BoosterParams, BrokerEnum, FunctionResultStatusPersistanceConfig



class Project1BoosterParams(BoosterParams):
    project_name:str = 'test_project1'  # 核心配置，项目名，设置后，web接口就可以只关心某个项目下的队列，减少无关返回信息的干扰。
    broker_kind:str = BrokerEnum.REDIS
    is_send_consumer_heartbeat_to_redis : bool= True # 向redis发送心跳，这样才能从redis获取相关队列的运行信息。
    is_using_rpc_mode:bool = True # 必须设置这一个参数为True，才能支持rpc功能。
    booster_group : str = 'test_group1' # 方便按分组启动消费
    should_check_publish_func_params:bool = True # 发布消息时，是否检查消息内容是否正确，不正确的消息格式立刻从接口返回报错消息内容不正确。
    function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(
        is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False) 
`````

--- **end of file: examples/example_faas/task_funs_dir/base_booster_params.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/sub.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/sub.py`

#### 📦 Imports

- `from base_booster_params import Project1BoosterParams`
- `from funboost import boost`
- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `import time`

#### 🔧 Public Functions (1)

- `def sub(a, b)` `boost(Project1BoosterParams(queue_name='test_funboost_faas_queue2'))`
  - *Line: 6*


---

`````python
from .base_booster_params import Project1BoosterParams
from funboost import boost, BoosterParams, BrokerEnum
import time

@boost(Project1BoosterParams(queue_name="test_funboost_faas_queue2", ))
def sub(a, b):
    time.sleep(1)
    print(f"sub {a} - {b} = {a - b}")
    return a - b

`````

--- **end of file: examples/example_faas/task_funs_dir/sub.py** (project: funboost_docs) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/__init__.py** (project: funboost_docs) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/__init__.py`


---

`````python

`````

--- **end of file: examples/example_faas/task_funs_dir/__init__.py** (project: funboost_docs) --- 

---

# markdown content namespace: funboost docs 


## funboost_docs File Tree (relative dir: `source/articles`)


`````

└── source
    └── articles
        ├── c0.md
        ├── c1.md
        ├── c10.md
        ├── c11.md
        ├── c12.md
        ├── c13.md
        ├── c14.md
        ├── c15.md
        ├── c16.md
        ├── c2.md
        ├── c20.md
        ├── c3.md
        ├── c4.md
        ├── c4b.md
        ├── c5.md
        ├── c6.md
        ├── c7.md
        ├── c8.md
        └── c9.md

`````

---


## funboost_docs (relative dir: `source/articles`)  Included Files (total: 19 files)


- `source/articles/c0.md`

- `source/articles/c1.md`

- `source/articles/c10.md`

- `source/articles/c11.md`

- `source/articles/c12.md`

- `source/articles/c13.md`

- `source/articles/c14.md`

- `source/articles/c15.md`

- `source/articles/c16.md`

- `source/articles/c2.md`

- `source/articles/c20.md`

- `source/articles/c3.md`

- `source/articles/c4.md`

- `source/articles/c4b.md`

- `source/articles/c5.md`

- `source/articles/c6.md`

- `source/articles/c7.md`

- `source/articles/c8.md`

- `source/articles/c9.md`


---


--- **start of file: source/articles/c0.md** (project: funboost_docs) --- 

`````markdown




# 0. Funboost 快速预览

<iframe src="https://ydf0509.github.io/funboost_git_pages/funboost_promo.html" width="100%" height="6240" style="border:none;"></iframe>


`````

--- **end of file: source/articles/c0.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c1.md** (project: funboost_docs) --- 

`````markdown

# 1. Python 万能分布式函数调度框架 Funboost 简介

**Funboost** 是一个 Python 万能分布式函数调度框架。以下是您的核心学习资源导航：

| 资源类型 | 链接地址 | 说明 |
| :--- | :--- | :--- |
| ⚡ **快速预览** | [👉 点击查看演示](https://ydf0509.github.io/funboost_git_pages/funboost_promo.html) | 直观感受框架运行效果 |
| 📖 **完全教程** | [👉 ReadTheDocs](https://funboost.readthedocs.io/zh-cn/latest/index.html) | 包含原理、API 与进阶用法 |
| 🤖 **AI 助教** | [👉 AI 学习指南](https://funboost.readthedocs.io/zh-cn/latest/articles/c14.html) | **[必读]** 利用 AI 掌握框架的最佳捷径 |


## 1.0 funboost 框架说明介绍

`funboost`是一个 万能 强大 简单  自由 的 `python` 全功能分布式调度框架,它的作用是给用户任意项目的任意函数赋能

**Funboost 的核心价值主张：把复杂留给框架，把简单留给用户。**

<iframe src="https://ydf0509.github.io/funboost_git_pages/index2.html" width="100%" height="2400" style="border:none;"></iframe>


<h4>📹 观看 funboost 视频</h4>
<video controls width="800" 
      src="https://ydf0509.github.io/funboost_git_pages/%E8%A7%86%E9%A2%91-Funboost_%E8%A7%86%E9%A2%91.mp4">
   您的浏览器不支持视频播放。
</video>

<h4>🎧 收听 funboost 音频</h4>
<audio controls 
      src="https://ydf0509.github.io/funboost_git_pages/%E9%9F%B3%E9%A2%91-funboost_%E9%9F%B3%E9%A2%91.mp4">
   您的浏览器不支持音频播放。
</audio>

#### 快速了解和上手funboost，直接看[1.3例子](#13-框架使用例子)


### 1.0.0 funboost 框架安装方式  

```shell
pip install funboost --upgrade  

或 pip install funboost[all]  #一次性安装所有小众三方中间件  
```  


### 1.0.1 funboost 功能作用

- **万能分布式调度**：`funboost` 通过一行 @boost 装饰器，将普通函数瞬间升级为具备 分布式执行、FaaS 微服务化、CDC 事件驱动 能力的超级计算单元，连接一切，调度万物。
- **全能支持**：自动支持 **40+种** 消息队列 + **30+种** 任务控制功能 + `python`中**所有**的并发执行方式。
- **FaaS 能力**：通过 `funboost.faas` 的功能，可以一键快速实现 **FaaS (Function as a Service)**，让函数秒变自动发现的微服务。

- **重功能，轻使用**：
   `funboost` 的功能是**全面性重量级**，用户能想得到的功能 99% 全都有；但使用方式却是**极致轻量级**，只有 `@boost` 一行代码需要写。

- **颠覆性设计**：
   `funboost` 的神奇之处在于它同时拥有“**轻量级使用方式**”和“**重量级功能集**”，完全颠覆了“功能强大=使用复杂”的传统思维。它是对传统 Python 框架设计的一次巧妙超越。
   
   只需要一行 `@boost` 代码即可分布式执行 `python` 一切任意函数，99% 用过 `funboost` 的 `pythoner` 核心感受是：**方便、高速、强大、自由**。  



#### 1.0.1.1 Funboost 的适用场景

`funboost` 是 **Python 函数的万能加速器**。它包罗万象，一统编程思维，将经典的 **生产者 + 消息中间件 + 消费者** 模式封装到了极致。

无论新老项目，Funboost 都能无缝融入，为您提供以下核心能力：

*   🌐 **需要分布式？**
    没问题！Funboost 支持 **40+种** 消息队列中间件。只要是叫得上名字的 MQ（甚至包括数据库、文件系统），它都能支持。

*   ⚡ **需要 FaaS (Function as a Service)？**
    **这是亮点！** 借助 `funboost.faas`，您可以一键将普通函数转化为 HTTP 微服务接口。函数自动发现，发布消息、获取结果、管理任务，瞬间完成 Serverless 般的体验。

*   🚀 **需要并发？**
    满足你！Python 所有的并发模式（**线程、协程、多进程**）任你选择，甚至支持它们**叠加使用**，榨干 CPU 性能。

*   🛡️ **需要可靠性？**
    稳如泰山！**消费确认 (ACK)**、自动重试、死信队列 (DLQ)、断点续爬... 即使服务器宕机，任务也绝不丢失。

*   🎛️ **需要控制力？**
    如臂使指！**精准 QPS 控频**、分布式限流、定时任务、延时任务、超时熔断、任务过滤... 给您三十多种控制武器。

*   📊 **需要监控？**
    一目了然！开箱即用的 **Funboost Web Manager**，让您对任务状态、队列积压、消费者实例等信息了如指掌。

*   🦅 **需要自由？**
    零侵入！它不绑架您的代码，不强管您的项目结构。**随时能用，随时能走**，还您最纯粹的 Python 编程体验。


#### 1.0.1.2 🤔 灵魂发问：Funboost 到底是什么？

> **答**：很难用一句话定义它。Funboost 是一个**万能框架**，几乎覆盖了 Python 所有的编程业务场景。它的答案是发散的，拥有无限可能。

👉 **[点击查看发散性答案 (文档 6.0b 章节)](https://funboost.readthedocs.io/zh-cn/latest/articles/c6.html#b-funboost)**

#### 1.0.1.3 💖 核心关切：值得我投入时间学习吗？

> **答**：**绝对值得**。选择一个用途狭窄、性能平庸、写法受限的框架，确实是在浪费生命。Funboost 则完全不同。

👉 **[查看详细评估报告 (文档 6.0 章节)](https://funboost.readthedocs.io/zh-cn/latest/articles/c6.html#funboost)**


#### 1.0.1.4 Funboost 与 Celery 的理念区别

> **核心比喻**：
> `funboost` 与 `celery` 的关系，如同 **iPhone** 与 **诺基亚塞班**。
> 它们的核心功能虽都是通讯（任务调度），但不能因为功能重叠就判定为重复造轮子。正如 iPhone 重新定义了手机，**Funboost 正在重新定义分布式任务调度，让“框架奴役”成为历史。**

**1. 共同点**
两者本质上都是基于分布式消息队列的异步任务调度框架，遵循经典的编程思想：
*   `生产者 (Producer)` -> `中间件 (Broker)` -> `消费者 (Consumer)`

**2. 核心区别**

| 维度 | **Celery (重型框架)** | **Funboost (函数增强器)** |
| :--- | :--- | :--- |
| **设计理念** | **框架奴役**：代码需围绕 Celery 的架构和 App 实例组织。 | **自由赋能**：非侵入式设计，为任意函数插上分布式的翅膀。 |
| **一等公民** | `Celery App` 实例 (Task 是二等公民) | **用户函数** (无需关注 App 实例) |
| **核心语法** | 需定义 App，使用 `@app.task` | 直接使用 **`@boost`** 装饰器 |
| **易用性** | 需规划特定的项目结构，上手门槛较高。 | 极简，任意位置的新旧函数加上装饰器即可用。 |
| **性能表现** | 传统性能基准。 | **断层式领先**：发布性能是 Celery 的 **22倍**，消费性能是 **46倍**。 |
| **功能广度** | 支持主流中间件。 | 支持 **40+** 种中间件，拥有更多精细的任务控制功能。 |


#### 1.0.1.5 Funboost 支持的并发模式

`funboost` 全面覆盖 Python 生态下的并发执行方式，并支持灵活的组合叠加：

*   **基础并发模式**：支持 `threading` (多线程)、`asyncio` (异步IO)、`gevent` (协程)、`eventlet` (协程) 以及 `单线程` 模式。
*   **叠加增强模式**：支持 **多进程 (Multi-Processing)** 与上述任一细粒度并发模式（如多线程或协程）进行叠加，最大限度利用多核 CPU 资源。

#### 1.0.1.6 Funboost 支持的消息队列中间件 (Broker)

得益于强大的架构设计，在 `funboost` 中 **“万物皆可为 Broker”**。不仅涵盖了传统 MQ，更拓展了数据库、网络协议及第三方框架。

*   **传统消息队列**：RabbitMQ, Kafka, NSQ, RocketMQ, MQTT, NATS, Pulsar 等。
*   **数据库作为 Broker**：
    *   **NoSQL**: Redis (支持 List, Pub/Sub, Stream 等多种模式), MongoDB.
    *   **SQL**: MySQL, PostgreSQL, Oracle, SQL Server, SQLite (通过 SQLAlchemy/Peewee 支持).
*   **网络协议直连**：TCP, UDP, HTTP, gRPC (无需部署 MQ 服务即可实现队列通信)。
*   **文件系统**：本地文件/文件夹, SQLite (适合单机或简单场景).
*   **事件驱动 (CDC)**：支持 **MySQL CDC** (基于 Binlog 变更捕获)，使 Funboost 具备了事件驱动能力，设计理念远超传统任务队列。
*   **第三方框架集成**：可直接将 Celery, Dramatiq, Huey, RQ, Nameko 等框架作为底层 Broker，利用 Funboost 的统一接口调度它们的核心。





#### 1.0.1.7 **funboost 学习难吗?**   
#### 🎓 1.0.1.7 Funboost 学习难吗？

**答案是：极易上手。Funboost 是“反框架”的框架。**

*   🎯 **核心极简**
    整个框架只需要掌握 **`@boost`** 这一个装饰器及其入参（`BoosterParams`）。所有的用法几乎都遵循 **1.3 章节** 示例的模式，一通百通。

*   🛡️ **零代码侵入**
    *   **拒绝“框架奴役”**：不像 `Celery`、`Django` 或 `Scrapy` 那样强迫你按照特定的目录结构组织代码（一旦不用了，代码往往需要大改）。
    *   **即插即用**：Funboost 对你的项目文件结构 **0 要求**，你可以随时将其引入任何新老项目中。

*   🔄 **进退自如（双模运行）**
    即使引入了 Funboost，也不需要担心代码被绑定。加上 `@boost` 装饰器后，你的函数依然保持纯洁：
    *   调用 `fun(x, y)`：**直接运行函数**（同步执行，不经过队列，和没加装饰器一样）。
    *   调用 `fun.push(x, y)`：**发送到消息队列**（分布式异步执行）。

👉 *关于“Funboost 学习和使用难吗？”的详细深度回答，请参阅文档 **`6.0.c`** 章节。*


#### 1.0.1.8 📊 可视化监控与管理
Funboost 内置了强大的 **Funboost Web Manager** 管理系统。
*   **全方位掌控**：支持对任务消费情况进行全面的查看、监控和管理。
*   **开箱即用**：无需额外部署复杂的监控组件，即可掌握队列积压、消费者状态等核心指标。

#### 1.0.1.9 🚀 性能表现：断层式领先
Funboost 的性能与 Celery 相比，有着**数量级**的优势（基于控制变量法测试）：
*   **发布性能**：是 Celery 的 **22倍**。
*   **消费性能**：是 Celery 的 **46倍**。
> *注：详细的控制变量法对比测试报告，请参阅文档 **2.6 章节**。*

#### 1.0.1.10 ⭐ 用户口碑与评价
**95% 的用户**在初步使用后都表示“相见恨晚”。核心评价如下：
*   **极致自由**：Funboost 对用户代码的编程思维**零侵入**。
*   **拒绝改造**：不像其他框架要求用户围绕框架逻辑重构代码，Funboost 尊重用户的原生代码结构。
*   **核心体验**：简单、强大、丰富。

#### 1.0.1.11 📜 历史版本与兼容性
*   **旧框架名称**：`function_scheduling_distributed_framework`
*   **兼容说明**：两者的关系和兼容性详情请见 **1.0.3 章节**。
*   **旧版地址**：[GitHub - distributed_framework](https://github.com/ydf0509/distributed_framework)




## 1.1 📚 核心资源与文档导航

### 1.1.1 📝 项目文档入口

> **🚀 快速上手指南**
>
> *   **文档说明**：文档篇幅较长，主要包含原理讲解与框架对比（`How` & `Why`）。
> *   **学习捷径**：**您只需要重点学习 [1.3 章节] 的这 1 个例子即可！** 其他例子仅是修改 `@boost` 装饰器中 `BoosterParams` 的入参配置。
> *   **核心要点**：`funboost` 极其易用，仅需掌握一行 `@boost` 代码。
> *   **🤖 AI 辅助**：强烈推荐阅读 **[第 14 章]**，学习如何利用 AI 大模型快速掌握 `funboost` 的用法。

**🔗 在线文档地址**：[ReadTheDocs - Funboost Latest](https://funboost.readthedocs.io/zh-cn/latest/index.html)

#### 📖 文档章节速览

| 🔰 基础入门 & 核心概念 | 🚀 进阶功能 & 场景实战 | 🤖 AI 辅助 & 问题排查 |
| :--- | :--- | :--- |
| [1. funboost 框架简介](https://funboost.readthedocs.io/zh-cn/latest/articles/c1.html) | [4b. 代码示例 (**高级进阶**)](https://funboost.readthedocs.io/zh-cn/latest/articles/c4b.html) | [**14. AI 辅助学习指南 (必读)**](https://funboost.readthedocs.io/zh-cn/latest/articles/c14.html) |
| [2. funboost 对比 Celery](https://funboost.readthedocs.io/zh-cn/latest/articles/c2.html) | [8. 爬虫实战：自由编程 vs 框架奴役](https://funboost.readthedocs.io/zh-cn/latest/articles/c8.html) | [6. 常见问题 Q&A](https://funboost.readthedocs.io/zh-cn/latest/articles/c6.html) |
| [3. 框架详细介绍](https://funboost.readthedocs.io/zh-cn/latest/articles/c3.html) | [9. 轻松远程服务器部署](https://funboost.readthedocs.io/zh-cn/latest/articles/c9.html) | [10. 常见报错与问题反馈](https://funboost.readthedocs.io/zh-cn/latest/articles/c10.html) |
| [4. **各种代码示例 (核心)**](https://funboost.readthedocs.io/zh-cn/latest/articles/c4.html) | [11. 集成第三方框架 (Celery/Kombu等)](https://funboost.readthedocs.io/zh-cn/latest/articles/c11.html) | [7. 更新记录](https://funboost.readthedocs.io/zh-cn/latest/articles/c7.html) |
| [5. 运行时截图展示](https://funboost.readthedocs.io/zh-cn/latest/articles/c5.html) | [12. 命令行控制台支持](https://funboost.readthedocs.io/zh-cn/latest/articles/c12.html) | [20. Gemini AI 生成的框架中心思想](https://funboost.readthedocs.io/zh-cn/latest/articles/c20.html) |
| | [13. Web Manager 可视化管理](https://funboost.readthedocs.io/zh-cn/latest/articles/c13.html) | |
| | [⚡ **15. FaaS Serverless 微服务 (战略级核心)**](https://funboost.readthedocs.io/zh-cn/latest/articles/c15.html) | |

---

### 1.1.2 📦 源码与依赖

*   **GitHub 项目主页**：[ydf0509/funboost](https://github.com/ydf0509/funboost)
*   **nb_log 日志文档**：[NB-Log Documentation](https://nb-log-doc.readthedocs.io/zh_CN/latest/articles/c9.html#id2)
   
---

## 1.2 框架功能介绍  

有了 `funboost`，开发者将获得“上帝视角”的调度能力：
*   🚫 **告别繁琐**：无需亲自手写进程、线程、协程的底层并发代码。
*   🔌 **万能连接**：无需亲自编写操作 `Redis`、`RabbitMQ`、`Kafka`、`Socket` 等中间件的连接代码。
*   🧰 **全能控制**：直接拥有 30+ 种企业级任务控制功能。

**funboost示图：**  
![funboost示图](https://s21.ax1x.com/2024/04/29/pkFFghj.png)


**也就是这种非常普通的流程图,一样的意思**  
![funboost示图](https://s21.ax1x.com/2024/04/29/pkFFcNQ.png)

### 1.2.1 🆚 对比：Funboost 取代传统线程池

以下两种方式均实现 **10并发** 运行函数 `f`。Funboost 更加简洁且具备扩展性。

#### ❌ 方式 A：手动开启线程池 (传统)
```python
import time
from concurrent.futures import ThreadPoolExecutor

def f(x):
    time.sleep(3)
    print(x)

pool = ThreadPoolExecutor(10)

if __name__ == '__main__':
    for i in range(100):
        pool.submit(f, i)
```

#### ✅ 方式 B：Funboost 模式 (推荐)
```python
import time
from funboost import BoosterParams, BrokerEnum

# 仅需一行装饰器，即可获得 10 线程并发 + 消息队列能力
@BoosterParams(queue_name="test_insteda_thread_queue", 
               broker_kind=BrokerEnum.MEMORY_QUEUE, 
               concurrent_num=10, 
               is_auto_start_consuming_message=True)
def f(x):
    time.sleep(3)
    print(x)

if __name__ == '__main__':
    for i in range(100):
        f.push(i)
```

### 1.2.2 🚀 强大的任务控制功能矩阵

Funboost 不仅仅是任务队列，它是一个全功能的任务调度平台。

#### 🌐 分布式与中间件
*   **多中间件支持**：支持 40+ 种中间件（Redis, RabbitMQ, Kafka, RocketMQ, SQL, 文件等）。
*   **任务持久化**：依托中间件特性，天然支持任务持久化存储。

#### ⚡ 并发与性能
*   **全模式并发**：支持 `Threading`、`Gevent`、`Eventlet`、`Asyncio`、`Single_thread`。
*   **多进程叠加**：支持在以上 5 种模式基础上叠加 **多进程**，榨干多核 CPU 性能。

#### 🕹️ 流量与频率控制
*   **精准控频 (QPS)**：精确控制每秒运行次数（如 0.02次/秒 或 50次/秒），无视函数耗时波动。
*   **分布式控频**：在多机、多容器环境下，严格控制全局总 QPS。
*   **暂停/恢复**：支持从外部动态暂停或继续消费。

#### 🛡️ 可靠性与容错
*   **断点接续**：无惧断电或强制杀进程，依赖 **ACK 消费确认机制**，确保任务不丢失。
*   **自动重试**：函数报错自动重试指定次数。
*   **死信队列**：重试失败或主动抛出异常的消息自动进入 DLQ (Dead Letter Queue)。
*   **重新入队**：支持主动将消息重新放回队列头部。

#### ⏰ 调度与时效
*   **定时任务**：基于 `APScheduler`，支持间隔、CRON 等多种定时触发。
*   **延时任务**：支持任务发布后延迟 N 秒执行。
*   **时间窗口**：支持指定某些时间段（如白天）不运行任务。
*   **超时熔断**：函数运行超时自动 Kill。
*   **过期丢弃**：支持设置消息有效期，过期未消费自动丢弃。

#### 📊 监控与运维
*   **可视化 Web**：自带 Web 管理界面，查看队列状态、消费速度。
*   **五彩日志**：集成 `nb_log`，提供多进程安全的切割日志与控制台高亮显示。
*   **全链路追踪**：支持记录任务入参、结果、耗时、异常信息并持久化到 MongoDB/MySQL。
*   **RPC 模式**：发布端可同步等待消费端的返回结果。
*   **远程部署**：一行代码将函数自动部署到远程 Linux 服务器。
*   **命令行 CLI**：支持通过命令行管理任务。

> **🏆 稳定性承诺**
>
> 能够直面百万级 C 端用户业务（App/小程序），连续 3 个季度稳定运行无事故。
> **0 假死、0 崩溃、0 内存泄漏**。
> Windows 与 Linux 行为 100% 一致（解决了 Celery 在 Windows 下的诸多痛点）。


## 1.3 🚀 快速上手：你的第一个 Funboost 程序

> **⚠️ 环境准备 (重要)**
>
> 在运行代码前，请确保您了解 **`PYTHONPATH`** 的概念。
> Windows cmd 或 Linux 运行时，建议将 `PYTHONPATH` 设置为项目根目录，以便框架自动生成或读取配置。
> 👉 [点击学习 PYTHONPATH](https://github.com/ydf0509/pythonpathdemo)

### 1.3.1 ✨ Hello World：最简单的任务调度

这个例子演示了如何将一个普通的求和函数变成分布式任务。

**代码逻辑说明：**
1.  **定义任务**：使用 `@boost` 装饰器，指定队列名 `task_queue_name1` 和 QPS `5`。
2.  **发布任务**：调用 `task_fun.push(x, y)` 发送消息。
3.  **消费任务**：调用 `task_fun.consume()` 启动后台线程自动处理。

```python
import time
from funboost import boost, BrokerEnum, BoosterParams

# 核心配置：使用本地 SQLite 作为消息队列，QPS 限制为 5
@boost(BoosterParams(
    queue_name="task_queue_name1", 
    qps=5, 
    broker_kind=BrokerEnum.SQLITE_QUEUE
))
def task_fun(x, y):
    print(f'{x} + {y} = {x + y}')
    time.sleep(3)  # 模拟耗时，框架会自动并发绕过阻塞

if __name__ == "__main__":
    # 1. 生产者：发布 100 个任务
    for i in range(100):
        task_fun.push(i, y=i * 2)
    
    # 2. 消费者：启动循环调度
    task_fun.consume()
```

> **💡 Tips**
> 如果在 Linux/Mac 上使用 `SQLITE_QUEUE` 报错 `read-only`，请在 `funboost_config.py` 中修改 `SQLLITE_QUEUES_PATH` 为有权限的目录（详见文档 10.3）。

**运行效果截图：**

**发布任务截图：**
![发布截图](https://s21.ax1x.com/2024/04/29/pkFkP4H.png) 

**消费任务截图：**
![消费截图](https://s21.ax1x.com/2024/04/29/pkFkCUe.png)



### 1.3.2 🔥 进阶实战：RPC、定时任务与丝滑连招

这是一个集大成的例子，展示了 Funboost 的核心能力：
*   ✅ **参数复用**：继承 `BoosterParams` 减少重复代码。
*   ✅ **RPC 模式**：发布端同步获取消费结果。
*   ✅ **丝滑启动**：非阻塞连续启动多个消费者。
*   ✅ **定时任务**：基于 `APScheduler` 的强大定时能力。

```python
import time
from funboost import boost, BrokerEnum, BoosterParams, ctrl_c_recv, ConcurrentModeEnum, ApsJobAdder

# 1. 定义公共配置基类，减少重复代码
class MyBoosterParams(BoosterParams):
    broker_kind: str = BrokerEnum.REDIS_ACK_ABLE
    max_retry_times: int = 3
    concurrent_mode: str = ConcurrentModeEnum.THREADING 

# 2. 消费函数 step1：演示 RPC 模式
@boost(MyBoosterParams(
    queue_name='s1_queue', 
    qps=1,   
    is_using_rpc_mode=True  # 开启 RPC，支持获取结果
))
def step1(a: int, b: int):
    print(f'step1: a={a}, b={b}')
    time.sleep(0.7)
    # 函数内部可以继续发布任务给 step2
    for j in range(10):
        step2.push(c=a+b+j, d=a*b+j, e=a-b+j)
    return a + b

# 3. 消费函数 step2：演示参数覆盖
@boost(MyBoosterParams(
    queue_name='s2_queue', 
    qps=3, 
    max_retry_times=5  # 覆盖基类默认值
)) 
def step2(c: int, d: int, e: int=666):
    time.sleep(3)
    print(f'step2: c={c}, d={d}, e={e}')
    return c * d * e

if __name__ == '__main__':
    # --- 启动消费 ---
    step1.consume()  # 非阻塞启动
    step2.consume()
    step2.multi_process_consume(3) # 叠加 3 个进程并发

    # --- RPC 调用演示 ---
    async_result = step1.push(100, b=200)
    print('RPC 结果：', async_result.result)  # 阻塞等待结果

    # --- 批量发布演示 ---
    for i in range(100):
        step1.push(i, i*2)
        # publish 方法支持更多高级参数（如 task_id）
        step1.publish({'a':i, 'b':i*2}, task_id=f'task_{i}')

    # --- 定时任务演示 (APScheduler) ---
    # 方式1：指定日期执行
    ApsJobAdder(step2, job_store_kind='redis', is_auto_start=True).add_push_job(
        trigger='date', run_date='2025-06-30 16:25:40', args=(7, 8, 9), id='job1'
    )
    # 方式2：间隔执行
    ApsJobAdder(step2, job_store_kind='redis').add_push_job(
        trigger='interval', seconds=30, args=(4, 6, 10), id='job2'
    )

    # 阻塞主线程，保持程序运行
    ctrl_c_recv()
```

> **🧠 设计哲学**
> Funboost 提倡 **“反框架”** 思维：你才是主角，框架只是插件。
> `task_fun(1, 2)` 是直接运行函数，`task_fun.push(1, 2)` 才是发布到队列。
> 随时可以拿掉 `@boost`，代码依然是纯粹的 Python 函数。

---

### 1.3.3 ✂️ 极简写法：省略 `@boost`

如果你追求极致简洁，也可以直接使用 `@BoosterParams` 作为装饰器，效果等同于 `@boost(BoosterParams(...))`。

```python
# 极简写法
@BoosterParams(queue_name="task_queue_simple",qps=5)
def task_fun(a, b):
    return a + b
```

### 1.3.4 ❌ 过时写法： 直接在 @boost传各种配置入参，不推荐
这种直接在 `@boost`传参，而不使用 `BoosterParams`来传各种配置，是过气写法不推荐，因为不能代码补全了。   
```python
# ⚠️ 反例：过时写法，不推荐！
@boost(queue_name="task_queue_simple",qps=5)
def task_fun(a, b):
    return a + b
```


## 🖥️ Funboost Web Manager 界面预览

可视化管理后台提供了强大的监控与运维能力，以下是核心功能截图：



函数消费结果：可查看和搜索函数实时消费状态和结果  
[![函数结果表](https://s41.ax1x.com/2025/12/19/pZ1L5h4.png)](https://imgchr.com/i/pZ1L5h4)

队列操作：查看和操作队列，包括清空、暂停消费、恢复消费、调整QPS和并发  
[![队列操作1](https://s41.ax1x.com/2025/12/17/pZlrYPH.png)](https://imgchr.com/i/pZlrYPH)
[![队列操作2](https://s41.ax1x.com/2025/12/17/pZlrUxI.png)](https://imgchr.com/i/pZlrUxI)

队列操作：查看消费曲线图，查看各种消费指标（历史运行次数、失败次数、近10秒完成/失败、平均耗时、剩余消息数量等）  
[![队列消费曲线](https://s41.ax1x.com/2025/12/19/pZ104HS.png)](https://imgchr.com/i/pZ104HS) 

RPC调用：在网页上对30种消息队列发布消息并获取函数执行结果；可根据task_id获取结果  
[![rpc调用成功-绿色](https://s41.ax1x.com/2025/12/19/pZ10RjP.png)](https://imgchr.com/i/pZ10RjP)

定时任务管理：列表页  
[![定时任务列表](https://s41.ax1x.com/2025/12/17/pZlrNRA.png)](https://imgchr.com/i/pZlrNRA)



## 1.4 💡 为什么 Python 极其需要分布式函数调度？

Python 语言的特性决定了它比 Java/Go 等语言更依赖分布式调度框架。主要原因有两点：

### 1️⃣ 痛点一：GIL 锁的限制 (多核利用率低)
> 🛑 **现状**：由于 GIL (全局解释器锁) 的存在，普通的 Python 脚本无法利用多核 CPU。在 16 核机器上，CPU 利用率最高只能达到 **6.25% (1/16)**。
> 😓 **难点**：手动编写 `multiprocessing` 多进程代码非常麻烦，涉及复杂的进程间通信 (IPC)、任务分配和状态共享。

✅ **Funboost 的解法**：
*   **天生解耦**：利用中间件（如 Redis/RabbitMQ）解耦任务,无法手写怎么给多进程分配任务和进程间通信。
*   **无感多进程**：单进程脚本与多进程脚本写法完全一致，**无需**手写 `multiprocessing`，自动榨干多核性能。

### 2️⃣ 痛点二：原生性能瓶颈 (动态语言特性)
> 🐌 **现状**：作为动态语言，Python 的单线程执行速度通常慢于静态语言。
> 🚀 **需求**：为了弥补单机速度，必须通过**横向扩展**来换取时间。

✅ **Funboost 的解法**：
*   **无缝扩展**：代码无需任何修改，即可适应多种运行环境：
    *   🔄 **多解释器**：同一台机器启动多个 Python 进程。
    *   🐳 **容器化**：部署在多个 Docker 容器中。
    *   ☁️ **跨物理机**：部署在多台物理服务器上。
*   **统一驱动**：Funboost 作为调度核心，让 Python 跑在集群之上，获得媲更高的系统吞吐量。


## 1.5 🎓 最佳学习路径

Funboost 的设计哲学是 **“极简主义”**。您无需阅读长篇大论，只需通过实践掌握核心：

1.  **🧪 实验式学习**：
    *   以 **1.3 章节** 的求和代码为蓝本。
    *   修改 `@boost` 装饰器中的参数（如 `qps`、`concurrent_num`）。
    *   在函数中添加 `time.sleep()` 模拟耗时。
    *   **观察**：观察控制台输出，体会分布式、并发和控频的实际效果。

2.  **✨ 一行代码原则**：
    *   这是最简单的框架：核心只有一行 `@boost` 代码。
    *   如果您能掌握这个装饰器，就掌握了整个框架。这比学习那些需要继承多个类、配置多个文件的传统框架要简单得多。

> **🤖 AI 助教**
> 强烈推荐参考 **[文档第 14 章]**，学习如何利用 AI 大模型快速精通 `funboost` 的各种高级用法。

---

## 1.6 🥋 funboost 练就吸星大法神功，一招吸走 Celery 毕生内力

**Funboost 的极简招式 + Celery 的深厚内力 = 独步武林**

> “江湖中人多迷信 Celery 的名门光环，虽 Funboost 身法快过其数十倍，且有演武场（2.6章节）实测为证，奈何部分豪杰固步自封，不愿亲自试剑。
> Funboost 遂施展 **‘吸星大法’**，将 Celery 纳为己用（作为 Broker）。**既入我门，便由我控**，以此化解众生执念。”

Celery 称霸 Python 异步江湖十数载，内力虽深厚，但其招式繁复、门规森严（配置繁琐），令无数豪杰望而却步。 
今 Funboost 施展 **“吸星大法”**，只需一招 `BrokerEnum.CELERY`，顷刻间将 Celery 化为 **座下护法**。自此，Celery 竟成 Funboost 之一大 **子集**，听凭号令！ 

### ⚔️ 降维打击：化繁为简的绝世武功
通过 Funboost 驾驭 Celery，犹如令狐冲习得独孤九剑，破尽天下繁琐招式，直击要害：

| 🆚 招式对决 | 🛑 原生 Celery (旧派宗门的桎梏) | 🟢 Funboost 御剑术 (新派宗师的洒脱) |
| :--- | :--- | :--- |
| **启动法门**<br>(部署) | **念诵咒语**：需死记硬背 `worker/beat` 等冗长命令行，稍有错漏便走火入魔。 | **意念合一**：代码即启动，无需记忆任何咒语，`python xx.py` 一剑破万法。 |
| **门派规矩**<br>(结构) | **清规戒律**：强行规定目录结构，错置文件即被逐出师门，极其僵化。 | **无招胜有招**：飞花摘叶皆可伤人，任意目录、任意文件皆可为战场，毫无束缚。 |
| **心法运转**<br>(门槛) | **经脉逆行**：需手动修炼 `includes` 和 `task_routes`，极易气血翻涌（配置报错）。 | **浑然天成**：自动打通任督二脉，框架自动发现并注册任务，行云流水。 |
| **洞察天地**<br>(体验) | **盲人摸象**：`@app.task` 入参如雾里看花，IDE 无法感知，极易行差踏错。 | **天眼通**：`BoosterParams` 开启全知视角，代码补全如神助，所见即所得。 |

> **📜 藏经阁 (代码示例)**
> 欲练此功，请翻阅 **[11.1 章节]**。
> 您只需施展 Funboost 的极简剑法，底层那拥有万钧之力的 Celery 引擎便会自动为您移山填海，虽有雷霆之威，却无反噬之虞。


 需要说明的是，funboost性能是已经远超celery，吸纳celery作为broker，兼容celery作为funboost的broker，是为了打消有的人对funboost的调度核心的稳定性的疑虑。   
 > 你可以看文档2.6章节**funboost vs celery控制变量法性能对比**，以及2.9章节，**funboost到底为什么性能比celery高几十倍？太离谱了,太假了是吗？**


[查看分布式函数调度框架完整文档](https://funboost.readthedocs.io/)  

![](https://visitor-badge.glitch.me/badge?page_id=distributed_framework)  

<div> </div>  

[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  

`````

--- **end of file: source/articles/c1.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c10.md** (project: funboost_docs) --- 

`````markdown
# 10.python3.6-3.12 安装/使用funboost出错问题反馈  

目前已经测试了python3.6  3.7 3.8  3.9 3.10 3.11 版本的安装，  

其中3.6 3.7 用的比较多，linux和win都运行了。3.9 3.10 3.11 版本在win下测试了安装和一部分demo例子运行功能。  


如果有安装不了的问题，请截完整图片说明，加python版本+操作系统类型(主要分win和linux/mac)  

如果有安装后使用某个属于框架本身的功能出错的，请截完整图片说明  

## 10.0 框架与你项目依赖的三方包版本不一致冲突？  
```  
用户完全可以自由选择任何三方包版本。例如你的 sqlalchemy pymongo等等与框架需要的版本不一致，你完全可以自由选择任何版本。  
我开发时候实现了很多种中间件，没有时间长期对每一种中间件三方包的每个发布版本都做兼容测试，所以我固定死了。  

用户完全可以选择自己的三方包版本，大胆点，等报错了再说，不出错怎么进步，不要怕代码报错，请大胆点升级你想用的版本。  
如果是你是用你自己项目里面的requirements.txt方式自动安装三方包，我建议你在文件中第一行写上 funboost，之后再写其它包  
这样就能使用你喜欢的版本覆盖funboost框架依赖的版本了。等用的时候报错了再说。一般不会不兼容报错的请大胆点。  

例如在生产环境用户一般固定死版本在requirements.txt,比如写 django==3.0.7,难道安装了django 3.0.8,代码就会报错,服务器就会爆炸吗,  
提示版本冲突有啥好害怕的,一般情况下,只要不是大版本升级,或者你使用了三方包很小众的私有方法,才会有可能出现由于版本不同,导致代码报错.  

pip install  
```  


## 10.1 windwos安装后如果报错 ImportError: DLL load failed while importing win32file  

linux和mac是不会有这个问题的，win如果出现的话，按下面操作。  
```  
import win32file  
ImportError: DLL load failed while importing win32file: 找不到指定的模块。  
```  

![img_21.png](img_21.png)  

切换到python安装目录的scripts文件夹下，使用指定的python解释器运行。例如你安装了好几个python环境，用指定的python环境的解释器运行。  

python3.9 pywin32_postinstall.py -install  (这里python3.9 代指的是具体的对应的python安装文件夹下的那个python.exe)  

参考博客:  
[ImportError: DLL load failed while importing win32api: 找不到指定的模块](https://blog.csdn.net/ljr_123/article/details/104693372)  

## 10.2 启动消费后报错: RuntimeError: cannot schedule new futures after interpreter shutdown  

定时apscheduler任务(或一些其他包的使用) 在一些python版本,导致报错 RuntimeError: cannot schedule new futures after interpreter shutdown  

只要在你的启动脚本的最最末尾加上死循环阻止主线程退出就好了.  

你的代码最最后一行代码加上:  
```python  
import time  
while 1:  
  time.sleep(100)  
```  

或者在代码最后一行加上 run_forever()  
```python  
from funboost import run_forever # 先导入run_forever  

run_forever()  # 这个函数就是 while 1 :time.sleep(100)    就是阻止主线程结束.  
```  


```python  
Error submitting job "timing_publish_deco.<locals>._deco (trigger: interval[0:00:03], next run at: 2023-01-29 15:49:11 CST)" to executor "default"  
Traceback (most recent call last):  
  File "D:\ProgramData\Miniconda3\envs\py311\Lib\site-packages\apscheduler\schedulers\base.py", line 979, in _process_jobs  
    executor.submit_job(job, run_times)  
  File "D:\ProgramData\Miniconda3\envs\py311\Lib\site-packages\apscheduler\executors\base.py", line 71, in submit_job  
    self._do_submit_job(job, run_times)  
  File "D:\ProgramData\Miniconda3\envs\py311\Lib\site-packages\apscheduler\executors\pool.py", line 28, in _do_submit_job  
    f = self._pool.submit(run_job, job, job._jobstore_alias, run_times, self._logger.name)  
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  
  File "D:\ProgramData\Miniconda3\envs\py311\Lib\concurrent\futures\thread.py", line 169, in submit  
    raise RuntimeError('cannot schedule new futures after '  
RuntimeError: cannot schedule new futures after interpreter shutdown  
```  

```  
如上报错，在python3.9以上会报错这个，因为是使用的 apscheduler的 BackgroundScheduler类，在python3.9以上，  
如果代码的主线程结束了，不管子线程是否还在运行，都会报错 RuntimeError: cannot schedule new futures after interpreter shutdown，  
此时只需要使主线程不结束就行了，那就是在你的启动脚本的最最末尾的地方加上以下两句就可以了。  

while 1:  
  time.sleep(100)  

加了 while 1:  
     time.sleep(100)  
后，主线程代码就会无限死循环，这样主线程永远不会结束了。  
```  

原因是：  
```  
funboost 内置的apscheduler 对象，是实例化 BackGroundScheduler ，而不是实例化 BlockingScheduler ,  

如下代码：  

aps_scheduler_obj.start()  
print('hello')  

如果 aps_scheduler_obj 类型是 BackGroundScheduler，控制台可以打印出hello，  
但在python3.9以上要确保主线程不能退出，否则定时器就会报错结束了，所以最末尾加 while 1: time.sleep(100)阻止主线程退出。  
funboost为了启动定时器 scheduler.start() 和启动消费 taskfun.consume() 随意哪一行写在前面都能运行所有代码，所以内置的实例化的对象是 BackGroundScheduler 类型  


如果 aps_scheduler_obj 类型是 BlockingScheduler，控制台不能打印出hello，必须确保 aps_scheduler_obj.start() 是写在代码的最后一行，  
这种当然不需要代码最末尾加个 while 1: time.sleep(100)阻止主线程退出了。  
```  

## 10.3  文档1.3例子 BrokerEnum.PERSISTQUEUE,sqlite作为中间件例子在mac/linux运行,报错 read-only   


文档1.3例子 BrokerEnum.PERSISTQUEUE,sqlite作为中间件例子在mac/linux运行,报错 read-only  file system : '/sqllite_queues'  

![img_48.png](img_48.png)  

因为你选择是使用sqlite作为消息队列中间件,那么就需要在用户电脑上创建文件夹和文件,来存放sqlite数据库数据,  
有很多人不是windows电脑运行,linux和mac权限严格,非root用户是无法在硬盘根目录自动创建/sqllite_queues 文件夹并写入数据的,报错已经很明显了,有些人还是一报错就慌了,  
需要你在项目根目录下的 funboost_config.py 中 指定 SQLLITE_QUEUES_PATH 为一个有操作权限的文件夹就可以了.  

<div> </div>
`````

--- **end of file: source/articles/c10.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c11.md** (project: funboost_docs) --- 

`````markdown
# 11 funboost 使用某些中间件或三方任务队列框架作为broker的例子(包括celery框架)。  

第4章列举了所有funboost用法和场景，第11章补充一些小众中间件的用法  

funboost 强大的扩展性，不仅支持各种消息队列还能支持各种不同写法的任务框架作为 broker_kind ，框架扩展性 开放性已然无敌  

下面的项目中,演示funboost自动化操作celery复杂不规则项目目录时候怎么完虐用户亲自使用celery  
[https://github.com/ydf0509/funboost_support_celery_demo](https://github.com/ydf0509/funboost_support_celery_demo)  

## 11.1 使用celery作为funboost的中间件  

害怕celery框架用法pythoner的福音。用户无需接触celery的任务路由配置和celery对象实例，就可以自动使用celery框架来调度函数。  

```  
使用celery作为中间件，用户需要在 funboost_config.py  配置  
CELERY_BROKER_URL（必须） 和 CELERY_RESULT_BACKEND （可以为None）  

用户想使用celery作为funboost的消息队列，需要安装pip install celery,flower  
```  

用户不需要手写 `celery` 的 `@app.task` 了，不需要怎么小心翼翼规划文件夹层级和模块名字了  

`funboost` + `broker_kind=BrokerEnum.CELERY` 设计的精髓所在——**通过一个简单、统一的 `@boost` API，将复杂、繁琐的 Celery 配置和启动流程完全自动化和隐藏起来**。  

开发者从此可以：  
- **专注业务逻辑**：只写函数，用 `@boost` 标记。   
- **享受 Celery 的强大**：依然使用 Celery 的 worker、beat、result backend 等成熟稳定的执行引擎。  
- **摆脱框架束缚**：不再被所谓的“最佳实践”目录结构所限制。     

这不仅极大地提升了开发效率，也降低了新团队成员的学习成本，是真正意义上的“化繁为简”。   

### 11.1.1 funboost启动celery消费和定时和flower  

test_celery_beat_consume.py  

```python  



from celery.schedules import crontab  
from datetime import timedelta  
import time  

from funboost import boost, BrokerEnum, BoosterParams  
from funboost.assist.celery_helper import CeleryHelper,celery_app  



@boost(BoosterParams(queue_name='celery_beat_queue_7a2', broker_kind=BrokerEnum.CELERY, qps=5))  
def f_beat(x, y):  
    time.sleep(3)  
    print(1111, x, y)  
    return x + y  


# celery_task_config 就是 celery app.task装饰器的原生入参，是任务函数配置。  
# 如果要更新app的配置，例如使用 CeleryHelper.update_celery_app_conf({'result_expires':3600*48,'worker_concurrency':100})  
@boost(BoosterParams(queue_name='celery_beat_queueb_8a2', broker_kind=BrokerEnum.CELERY, qps=1, broker_exclusive_config={'celery_task_config': {'default_retry_delay':60*5}}))  
def f_beat2(a, b):  
    time.sleep(2)  
    print(2222, a, b)  
    return a - b  


beat_schedule = {  # 这是100% 原汁原味的celery 定时任务配置方式  
    'add-every-10-seconds_job': {  
        'task': f_beat.queue_name,  
        'schedule': timedelta(seconds=10),  
        'args': (10000, 20000)  
    },  
    'celery_beat_queueb_8_jobxx': {  
        'task': f_beat2.queue_name,  
        'schedule': timedelta(seconds=20),  
        # 'schedule': crontab(minute=30, hour=16),  
        'kwargs': {'a': 20, 'b': 30}  
    }  

}  

if __name__ == '__main__':  
    """  
    下面代码直接在代码中启动了 worker 和  beat 和 flower ，永远无需用户在 xhsell 和cmd 敲击复杂的 celery命令行，而只需要普通的 python xx.py 来启动。。  

    绝大多数 Celery 的入门教程和博客文章，都会重点介绍如何通过命令行来启动 Celery worker、Celery beat 以及 Flower。  
    例如 celery -A your_project worker -l INFO、celery -A your_project beat -l INFO 和 celery flower --broker=your_broker_url 等，  
    这些命令行操作是 Celery 官方推荐的标准启动方式，也是最直接的上手途径。  
    然而，关于如何以编程方式（即在 Python 脚本内部）启动和管理这些组件的教程相对较少，或者被认为是更高级的用法，普通博客可能不会详细记录。  

    funboost作者能做到无需命令行中使用celery命令来启动这些，恰好打脸了那些质疑ydf0509是因为学不会复杂的celery 用法才重复造轮子写个funboost出来。  
    """  
    CeleryHelper.start_flower(5556)  # 启动flower 网页，这个函数也可以单独的脚本中启动  
    CeleryHelper.celery_start_beat(beat_schedule) # 配置和启动定时任务，这个函数也可以在单独的脚本中启动，但脚本中需要 先import 导入@boost装饰器函数所在的脚本，因为@boost时候consumer的custom_init中注册celery任务路由，之后才能使定时任务发送到正确的消息队列。  
    print(CeleryHelper.celery_app.conf)  
    CeleryHelper.show_celery_app_conf()  
    CeleryHelper.update_celery_app_conf({'result_expires':3600*48}) # 如果要更新celery app的配置。  
    f_beat.consume()  # 启动f_beat消费，这个是登记celery worker要启动消费的函数，真正的启动worker消费需要运行 realy_start_celery_worker，realy_start_celery_worker是一次性启动所有登记的需要运行的函数  
    f_beat2.consume() # 启动f_beat2消费，这个是登记celery worker要启动消费的函数，真正的启动worker消费需要运行 realy_start_celery_worker，realy_start_celery_worker是一次性启动所有登记的需要运行的函数  
    CeleryHelper.realy_start_celery_worker(worker_name='test_worker啊')  # 这个是真正的启动celery worker 函数消费。  
    print('CeleryHelper.realy_start_celery_worker()  之后的代码不会被运行')  


```  

上面代码是100%使用celery的worker核心来运行消费、定时、页面监控，只是使用了funboost的api @boost来定义消费函数。完全没有使用funboost自身源码实现的 各种并发池 各种qps控频 重试 等辅助功能。  


### 11.1.2 funboost发布任务到celery队列  

test_funboost_celery_push.py  

```python  

from test_celery_beat_consume import f_beat,f_beat2  


for i in range(100):  
    f_beat.push(i, i + 1)  
    res2 = f_beat2.push(i, i * 2)  
    print(type(res2),res2.get())  # celer 的 delay 获取结果的原生celery异步结果对象类型  
```  

### 11.1.3 funboost使用celery作为中间件的运行截图  

flower 截图  
![img_32.png](img_32.png)  

可以看到funboost的boost装饰器自动配置celery任务路由和任务配置。  
![img_34.png](img_34.png)  

[//]: #![img_35.png](img_35.png)  

[//]: #![img_36.png](img_36.png)  


funboost使用celery作为broker的控制台运行截图  
![img_33.png](img_33.png)  

### 11.1.4 funboost 的api 操作celery，比人工操作 celery 大大简化。  

<pre style="font-size: large;color: greenyellow;background-color: black">  

由此可知，用户无需操作celery本身，无需敲击celery难记的命令行启动消费、定时、flower;  
用户无需小心翼翼纠结亲自使用celery时候怎么规划目录结构 文件夹命名 需要怎么在配置写include 写task_routes，  
完全不存在需要固定的celery目录结构，不需要手动配置懵逼的任务路由，不需要配置每个函数怎么使用不同的队列名字，funboost自动搞定这些。  

用户只需要使用简单的funboost语法就能操控celery框架了。funboost使用celery作为broker_kind,远远的暴击亲自使用无法ide下代码补全的celery框架的语法。  
</pre>  

```  
funboost通过支持celery作为broker_kind,使celer框架变成了funboost的一个子集  
```  

### 11.1.5 funboost 使用celery作为中间件时候，可以填写的celery任务配置  

funboost的@boost装饰器的broker_exclusive_config的celery_task_config 可以配置项大全,就是@celery_app.task()的入参大全。  
所有可以配置项可以看  D:\ProgramData\Miniconda3\Lib\site-packages\celery\app\task.py  

```python
@boost('tets_funboost_celery_queue31b', broker_kind=BrokerEnum.CELERY, concurrent_num=10,
       broker_exclusive_config={'celery_task_config':  # 可以通过celery_task_config传递celery的@app.task支持的所有入参配置,精细化设置原生celery任务配置.
                                    {'default_retry_delay': 180,
                                    'autoretry_for': (MyException1,ValueError),
                                     }
                                     }
       )
```

### 11.1.6 网上关于celery项目目录结构和文件夹/文件命名必须很死板， 是错的  

网上说必须叫celery.py，还要固定的目录结构那都是假的，并不需要这样。  
![img_37.png](img_37.png)  

像这样的乱七八糟的celery目录结构是可以运行的。  
[https://github.com/ydf0509/celery_demo](https://github.com/ydf0509/celery_demo)  
![img_38.png](img_38.png)  

celery 实例化对象可以在项目的任意深层级文件夹的任意文件名字下，celery的@app.task函数也可以是在任何深层级文件夹的任意文件名字下。  

如果用户不会怎么使用不同的队列名字，怎么在不规则的文件夹下使用celery框架，可以使用funboost + celery作为broker，funboost让用户远离celery本身，funboost内部可以自动化操作celery。  

### 11.1.7 仍然想使用celery命令行？  

有些人仍然想使用celery的命令行，操作一些其他命令，当然可以的  
```  
例如执行celery status命令  
首先设置 PYTHONPATH为项目根目录，这个去看github pythonpathdemo项目，pythonpath说烂了，这作用都不知道的人别用python了。  
linux 是 export PYTHONPATH=项目根目录  
win 是 份powershell和cmd  
   powershell 中设置临时会话环境变量 $env:PYTHONPATH="项目根目录"   
   cmd        中设置临时会话环境变量 set PYTHONPATH="项目根目录"   
cd {项目根目录}  
python -m celery -A ./dir1/test_celery_beat_consume  status   # test_celery_beat_consume.py有 celery_app对象  
```  

因为 test_celery_beat_consume.py 模块中有 Celery类型的对象 celery_app,所以能够自动被celery命令识别到这个对象，  
所以用户自己仍然想用celery命令行是可以的  
   
### 11.1.8 任然可以亲自使用celery的原生任务函数对象 `celery.app.task.Task`  

在celery中,被 `@app.task` 装饰的函数,对象类型是 `celery.app.task.Task` ,  

用户在`funboost` 消费函数的 `@boost` 中设置 `broker_kind`为 `BrokerEnum.CELERY` 后,任然可以精细操作`celery`的`Task`对象,  

用法就是  `$某个funboost消费函数.celery_task` 来得到celery的任务函数对象,      
例如 `my_fun.consumer.celery_task.delay(1,2)` 来发布消息 ,    
使用 `my_fun.consumer.celery_task.s(1,2)` 来`celery`原生的 `canvas` 任务编排.  

`my_fun.push(1,2)`  的背后就是调用了 `my_fun.consumer.celery_task.delay(1,2)` , celery 框架接管了 funboost 的一切,  
`broker_kind`为 `BrokerEnum.CELERY` 时候,`funboost`不会使用自身的代码逻辑去执行发布 消费 定时,全是`celery`自身接管的.  

**操作celery的原生任务函数对象,源码例子:**  
```python  


"""  
此脚本演示 funboost 使用 celery 作为broker,  
但用户除了使用funboost的统一化api,任然可以使用 celery 底层的细节.  
"""  
import time  
from funboost import boost, BrokerEnum,BoosterParams  
from funboost.assist.celery_helper import CeleryHelper,Task  

@boost(BoosterParams(queue_name='test_broker_celery_simple',  
                     broker_kind=BrokerEnum.CELERY, # 使用 celery 框架整体作为 funboost的broker  
                     concurrent_num=10,))  
def my_fun(x, y):  
    time.sleep(3)  
    print(6666, x, y)  
    return x + y  

if __name__ == '__main__':  
    # funboost 语法来发布消息,my_fun 类型是 funboost的 Booster  
    my_fun.push(1,2)  

    #  用户可以通过my_fun.consumer.celery_task ,使用celery自带delay来发布消息  
    # my_fun.consumer.celery_task 类型是 celery的 celery.app.task.Task  
    my_fun_celery_task : Task = my_fun.consumer.celery_task  
    my_fun_celery_task.delay(3,4) # 可以用 celery task 原生delay  
    my_fun_celery_task.apply_async(args=[5,6],task_id='123456789123',countdown=10)  # 可以用 celery task 原生 apply_async  

    my_fun.consume()  # 这个不是立即启动消费,是登记celery要启动的queue  
    CeleryHelper.realy_start_celery_worker() # 这个是真的启动celery worker 命令行来把所有已登记的queue启动消费  


```  

### 11.1.10 funboost使用celery作为broker_kind的原理  

与其说funboost支持各种消息队列中间件，不如说funboost实现了集成操作各种各样的消息队列的第三方python包，  

```  
@boost(BoosterParams(queue_name=queue_1, broker_kind=BrokerEnum.CELERY, qps=5))  
def f_beat(x, y):  

加了@boost后，那么funboost框架自动给celery_app 注册任务了，并且设置每个任务的消息使用不同的队列名存放，  
@boost里面自动配置celery任务，并且支持用户用celery命令行按照11.1.7 操作celery，包括命令行清空队列 啥的都可以  
```  



## 11.2 使用nameko 微服务框架作为funboost消息中间件例子  

### 11.2.1 nameko服务端脚本  

test_funboost_nameko.py  

```python  
from eventlet import monkey_patch  

monkey_patch()  

from funboost.consumers.nameko_consumer import start_batch_nameko_service_in_new_process,start_batch_nameko_service_in_new_thread  


import time  

from funboost import boost, ConcurrentModeEnum, BrokerEnum, BoosterParams  




@boost(BoosterParams(queue_name='test_nameko_queue', broker_kind=BrokerEnum.NAMEKO, concurrent_mode=ConcurrentModeEnum.EVENTLET))  
def f(a, b):  
    print(a, b)  
    time.sleep(1)  
    return 'hi'  


@boost(BoosterParams(queue_name='test_nameko_queue2', broker_kind=BrokerEnum.NAMEKO, concurrent_mode=ConcurrentModeEnum.EVENTLET))  
def f2(x, y):  
    print(f'x: {x}   y:{y}')  
    time.sleep(2)  
    return 'heelo'  


if __name__ == '__main__':  
    # 用户可以使用nameko的 ServiceContainer ,直接启动每个nameko的service类，语法和funboost使用其他中间件语法一样。  
    f.consume()  
    f2.consume()  

    # 也可以批量启动，使用nameko的 ServiceRunner 批量启动多个 nameko的service类。这个函数专门为nameko 中间件而写的。  
    start_batch_nameko_service_in_new_thread([f, f2])  

```  

### 11.2.2 nameko客户端脚本  

test_nameko_push.py  

```python  
from test_funboost_nameko import f, f2  

for i in range(100):  
    print(f.push(i, b=i + 1))  
    print(f2.push(x=i, y=i * 2))  
```  





### 11.2.3 funboost操作nameko能简化亲自使用nameko框架的语法  
```  
需要配置好rabbitmq的ip端口账号密码，因为nameko使用rabbitmq。  
用户无需了解学习nameko框架的语法，就能使用nameko微服务框架。  
```  


## 11.3 使用kombu作为funboost的broker  

kombu一次性能支持数十种消息队列，kombu是celery能支持多种消息队列的根本原因。celery依赖kombu从而实现支持多种消息队列。  
kombu没有和celery深度绑定，kombu不依赖celery，是celery依赖kombu。所以kombu可以为funboost所用。  

```  
如果不用funboost celery等，  
例如你想操作rabbitmq和redis作为消息队列，如果你使用kombu包，则一份代码就可以简单通过不同的中间件url连接切换来操作rabbitmq和redis了。  
如果你不使用kombu，分别import pika和import redis来实现操作rabbitmq和redis，要写两份很大区别的代码。  
使用kombu一次性能支持切换十几种消息队列比import 十几种python包来操作各种消息队列中间件香多了。  
```  

kombu能支持的消息队列大全：  
```python  
TRANSPORT_ALIASES = {  
    'amqp': 'kombu.transport.pyamqp:Transport', # rabbitmq作为消息队列  
    'amqps': 'kombu.transport.pyamqp:SSLTransport',  
    'pyamqp': 'kombu.transport.pyamqp:Transport',  
    'librabbitmq': 'kombu.transport.librabbitmq:Transport',  
    'memory': 'kombu.transport.memory:Transport',  
    'redis': 'kombu.transport.redis:Transport',  
    'rediss': 'kombu.transport.redis:Transport',  
    'SQS': 'kombu.transport.SQS:Transport',  
    'sqs': 'kombu.transport.SQS:Transport',  
    'mongodb': 'kombu.transport.mongodb:Transport',  
    'zookeeper': 'kombu.transport.zookeeper:Transport',  
    'sqlalchemy': 'kombu.transport.sqlalchemy:Transport',  
    'sqla': 'kombu.transport.sqlalchemy:Transport',  # 数据库作为消息队列  
    'SLMQ': 'kombu.transport.SLMQ.Transport',  
    'slmq': 'kombu.transport.SLMQ.Transport',  
    'filesystem': 'kombu.transport.filesystem:Transport',   # 文件作为消息队列  
    'qpid': 'kombu.transport.qpid:Transport',  
    'sentinel': 'kombu.transport.redis:SentinelTransport', # redis 哨兵集群作为消息队列  
    'consul': 'kombu.transport.consul:Transport',  
    'etcd': 'kombu.transport.etcd:Transport',  
    'azurestoragequeues': 'kombu.transport.azurestoragequeues:Transport',  
    'azureservicebus': 'kombu.transport.azureservicebus:Transport',  
    'pyro': 'kombu.transport.pyro:Transport'  
}  
```  

### 11.3.1 kombu操作rabbitmq作为funboost的消息队列  

```  
设置boost装饰器的 broker_kind=BrokerEnum.KOMBU  
broker_exclusive_config 中可以设置 kombu_url，如果这里不传递kombu_url，则使用funboost_config.py的全局KOMBU_URL  

transport_options是kombu的transport_options 。   
       例如使用kombu使用redis作为中间件时候，可以设置 visibility_timeout 来决定消息取出多久没有ack，就自动重回队列。  
       kombu的每个中间件能设置什么 transport_options 可以看 kombu的源码中的 transport_options 参数说明。  

例如kombu redis的Transport Options 说明  
D:\ProgramData\Miniconda3\envs\py311\Lib\site-packages\kombu\transport\redis.py  

Transport Options  
=================  
* ``sep``  
* ``ack_emulation``: (bool) If set to True transport will  
  simulate Acknowledge of AMQP protocol.  
* ``unacked_key``  
* ``unacked_index_key``  
* ``unacked_mutex_key``  
* ``unacked_mutex_expire``  
* ``visibility_timeout``  
* ``unacked_restore_limit``  
* ``fanout_prefix``  
* ``fanout_patterns``  
* ``global_keyprefix``: (str) The global key prefix to be prepended to all keys  
  used by Kombu  
* ``socket_timeout``  
* ``socket_connect_timeout``  
* ``socket_keepalive``  
* ``socket_keepalive_options``  
* ``queue_order_strategy``  
* ``max_connections``  
* ``health_check_interval``  
* ``retry_on_timeout``  
* ``priority_steps``  

```  

```python  


import time  

from funboost import BrokerEnum, boost, BoosterParams  
from funboost.funboost_config_deafult import BrokerConnConfig  

@boost(BoosterParams(queue_name='test_kombu2b', broker_kind=BrokerEnum.KOMBU, qps=0.1,  
       broker_exclusive_config={  
           'kombu_url': BrokerConnConfig.RABBITMQ_URL,  
           'transport_options': {},  
           'prefetch_count': 1000}))  
def f1(x, y):  
    print(f'start {x} {y} 。。。')  
    time.sleep(60)  
    print(f'{x} + {y} = {x + y}')  
    print(f'over {x} {y}')  


if __name__ == '__main__':  
    # f1.push(3,4)  
    for i in range(10000):  
        f1.push(i, i*2)  
    f1.consume()  

```  


### 11.3.2 kombu+redis作为消息队列  

```  
设置boost装饰器的 broker_kind=BrokerEnum.KOMBU  
broker_exclusive_config 中可以设置 kombu_url，如果这里不传递kombu_url，则使用funboost_config.py的全局KOMBU_URL  
```  

```python  
import time  

from funboost import BrokerEnum, boost, BoosterParams  


@boost(BoosterParams(queue_name='test_kombu2b', broker_kind=BrokerEnum.KOMBU, qps=0.1,  
       broker_exclusive_config={  
           'kombu_url': 'redis://192.168.64.151:6378/10',  
           'transport_options': {  
               'visibility_timeout': 600, 'ack_emulation': True  # visibility_timeout 是指消息从redis blpop后多久没确认消费就当做消费者挂了无法确认消费，unack的消息自动重回正常工作队列  
           },  
           'prefetch_count': 1000}, log_level=20))  
def f1(x, y):  
    print(f'start {x} {y} 。。。')  
    time.sleep(60)  
    print(f'{x} + {y} = {x + y}')  
    print(f'over {x} {y}')  


if __name__ == '__main__':  
    # f1.push(3,4)  
    for i in range(10000):  
        f1.push(i, i*2)  
    f1.consume()  

```  

#### 11.3.2.b kombu + redis哨兵作为消息队列  

装饰器 broker_kind=BrokerEnum.KOMBU  

funboost_config.py 配置例子如下:  
KOMBU_URL= 'redis+sentinel://sentinel1.example.com:26379,sentinel2.example.com:26379,sentinel3.example.com:26379/0?sentinel=master01'  

KOMBU_URL的格式规范就是celery的 broker_url 的格式规范,怎么写可以自己百度"celery redis 哨兵"就好了,因为celery就是依赖kombu包实现的支持多种消息队列.  

```  
BrokerEnum.KOMBU 和 BrokerEnum.CELERY 中间件都能支持redis哨兵模式.  
只需要你配置 funboost_config.py 中的配置就好了,funboost 支持30多种消息队列或包或者框架,  
funboost通过支持BrokerEnum.KOMBU 和 BrokerEnum.CELERY ,只会比celery支持的中间件模式更多,不会更少.  
```  


### 11.3.3 kombu+sqlalchemy 作为消息队列  

```python  
import time  
from funboost import BrokerEnum, boost, BoosterParams, BrokerConnConfig  

'''  
默认自动创建表 kombu_message 和 kombu_queue, sqlalchemy版本要选对，测试 1.4.8 可以，2.0.15版本报错。  
所有队列的消息在一个表中kombu_message，queue_id做区分是何种队列。  
'''  
@boost(BoosterParams(queue_name='test_kombu_sqlalchemy_queue2', broker_kind=BrokerEnum.KOMBU, qps=0.1,  
       broker_exclusive_config={  
           'kombu_url': f'sqla+mysql+pymysql://{BrokerConnConfig.MYSQL_USER}:{BrokerConnConfig.MYSQL_PASSWORD}'  
                        f'@{BrokerConnConfig.MYSQL_HOST}:{BrokerConnConfig.MYSQL_PORT}/{BrokerConnConfig.MYSQL_DATABASE}',  
           'transport_options': {},  
           'prefetch_count': 500}))  
def f2(x, y):  
    print(f'start {x} {y} 。。。')  
    time.sleep(60)  
    print(f'{x} + {y} = {x + y}')  
    print(f'over {x} {y}')  


@boost(BoosterParams(queue_name='test_kombu_sqlalchemy_queue3', broker_kind=BrokerEnum.KOMBU, qps=0.1,  
       broker_exclusive_config={  
           'kombu_url': f'sqla+mysql+pymysql://{BrokerConnConfig.MYSQL_USER}:{BrokerConnConfig.MYSQL_PASSWORD}'  
                        f'@{BrokerConnConfig.MYSQL_HOST}:{BrokerConnConfig.MYSQL_PORT}/{BrokerConnConfig.MYSQL_DATABASE}',  
           'transport_options': {},  
           'prefetch_count': 500}))  
def f3(x, y):  
    print(f'start {x} {y} 。。。')  
    time.sleep(60)  
    print(f'{x} + {y} = {x + y}')  
    print(f'over {x} {y}')  


if __name__ == '__main__':  
    for i in range(100):  
        f2.push(i, i + 1)  
        f3.push(i,i*2)  
    f2.consume()  
    f3.consume()  

```  

### 11.3.4 kombu+mongo作为消息队列  

```python  
import time  

from funboost import BrokerEnum, boost, BoosterParams  

queue_name = 'test_kombu_mongo4'  


@boost(BoosterParams(queue_name=queue_name, broker_kind=BrokerEnum.KOMBU, qps=0.1,  
       broker_exclusive_config={  
           'kombu_url': 'mongodb://root:123456@192.168.64.151:27017/my_db?authSource=admin',  
           'transport_options': {  
               'default_database': 'my_db',  
               'messages_collection': queue_name,  

           },  
           'prefetch_count': 10}))  
def f2(x, y):  
    print(f'start {x} {y} 。。。')  
    time.sleep(60)  
    print(f'{x} + {y} = {x + y}')  
    print(f'over {x} {y}')  


if __name__ == '__main__':  
    for i in range(100):  
        f2.push(i, i + 1)  
    f2.consume()  

```  

### 11.3.5 kombu+文件作为消息队列  

```  
kombu_url 写 filesystem://  
data_folder是规定消息文件在什么文件夹，这里每个queue弄一个文件夹。  
processed_folder 是指处理过的消息放在什么文件夹  

可以看到kombu使用不同的消息队列，只需要改变kombu_url的连接，transport_options则是根据每个消息队列的特色传递哪些参数。  
transport_options具体可以传递的值，点击kombu的各种中间件的源码文件，里面罗列的十分清楚。  

```  

```python  
import time  

from funboost import BrokerEnum, boost, BoosterParams  


queue_name = 'test_kombu5'  


@boost(BoosterParams(queue_name=queue_name, broker_kind=BrokerEnum.KOMBU, qps=0.1,  
       broker_exclusive_config={  
           'kombu_url': 'filesystem://',  
           'transport_options': {  
               'data_folder_in': f'/data/kombu_queue/{queue_name}',  
               'data_folder_out': f'/data/kombu_queue/{queue_name}',  
               'store_processed': True,  
               'processed_folder': f'/data/kombu_processed/{queue_name}'  
           },  
           'prefetch_count': 10}))  
def f2(x, y):  
    print(f'start {x} {y} 。。。')  
    time.sleep(60)  
    print(f'{x} + {y} = {x + y}')  
    print(f'over {x} {y}')  


if __name__ == '__main__':  
    for i in range(100):  
        f2.push(i, i + 1)  
    f2.consume()  

```  



## 11.4 使用dramatiq框架作为funboost消息队列  

```  
dramatiq是作者觉得celery用得不爽有坑，开发的任务队列框架，基本用途和celery一样  
funboost的统一api，但使用dramatiq作为核心调度，  
用户无需操作dramatiq 命令行来启动消费。  
```  

```  
dramatiq框架作用类似于celery，支持rabbitmq和redis两种消息队列  
在funboost_config.py 设置 DRAMATIQ_URL 的值就可以了  
例如 amqp://admin:123456abcd@106.55.xx.xx:5672/  
redis://:passwd@127.0.0.1:6379/15  
```  

```python  
import time  

from funboost import boost, BrokerEnum, BoosterParams  

from funboost.assist.dramatiq_helper import DramatiqHelper  


@boost(BoosterParams(queue_name='test_dramatiq_q1', broker_kind=BrokerEnum.DRAMATIQ, function_timeout=10))  
def f1(x):  
    time.sleep(1)  
    print('f1', x)  


@boost(BoosterParams(queue_name='test_dramatiq_q2', broker_kind=BrokerEnum.DRAMATIQ, function_timeout=3))  
def f2(y):  
    time.sleep(2)  
    print('f2', y)  


if __name__ == '__main__':  
    f1.consume()  # 登记要启动消费的queue  
    f2.consume()  # 登记要启动消费的queue  
    for i in range(100):  
        f1.push(i)  
        f2.push(i * 2)  
    DramatiqHelper.realy_start_dramatiq_worker()  # 真正启动dramatiq消费  

```  


## 11.5 使用huey框架作为funboost消息队列  

```  
funboost_config.py中 配置好 REDIS_URL 的值就可以了  

使用huey框架作为funboost的调度核心，但用户只需要掌握funboost的api语法，用户无需敲击huey命令行来启动消费  
```  

```python  
import time   

from funboost.assist.huey_helper import HueyHelper  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_huey_queue1', broker_kind=BrokerEnum.HUEY, broker_exclusive_config={'huey_task_kwargs': {}}))  
def f1(x, y):  
    time.sleep(10)  
    print(x, y)  
    return 666  


@boost(BoosterParams(queue_name='test_huey_queue2', broker_kind=BrokerEnum.HUEY))  
def f2(a):  
    time.sleep(7)  
    print(a)  


if __name__ == '__main__':  
    for i in range(10):  
        f1.push(i, i + 1)  
        f2.push(i)  
    HueyHelper.realy_start_huey_consume()  

```  

## 11.6 使用rq框架作为funboost的broker  

```  
funboost_config.py中 配置好 REDIS_URL 的值就可以了  

使用rq框架作为funboost的调度核心，但用户只需要掌握funboost的api语法，用户无需敲击rq命令行来启动消费  

开发了 WindowsWorker 类，使 rq框架支持在windows运行，因为windows不能fork多进程，原生rq框架只能在linux、mac下运行。  
```  

使用rq任务队列框架作为funboost broker的例子  
```python  

import time  

from funboost import boost, BrokerEnum, BoosterParams  

from funboost.assist.rq_helper import RqHelper  


@boost(BoosterParams(queue_name='test_rq_queue1a', broker_kind=BrokerEnum.RQ))  
def f(x, y):  
    time.sleep(2)  
    print(f'x:{x},y:{y}')  


@boost(BoosterParams(queue_name='test_rq_queue2a', broker_kind=BrokerEnum.RQ))  
def f2(a, b):  
    time.sleep(3)  
    print(f'a:{a},b:{b}')  


if __name__ == '__main__':  
    # RqHelper.add_nb_log_handler_to_rq()  # 使用nb_log日志handler来代替rq的  
    for i in range(100):  
        f.push(i, i * 2)  
        f2.push(i, i * 10)  
    f.consume()  # f.consume()是登记要启动的rq f函数的 queue名字,  
    f2.consume()  # f2.consume()是登记要启动的rq f2函数的queue名字  
    RqHelper.realy_start_rq_worker()  # realy_start_rq_worker 是真正启动rqworker，相当于命令行执行了 rqworker 命令。  


```  

funboost使用rq作为运行核心的截图  
![img_40.png](img_40.png)  




## 11.7 使用 grpc 作为funboost的broker  

**使用 `grpc` 作为`funboost`的`broker`,不仅可以`push`,也可以`sync_call`来调用并同步阻塞得到结果**  

使用`grpc`做`funboost`的`broker`好处是,用户永远不需要自定义写`proto`文件,不需要用户操心生成`pb2`文件,  
并且顺便使用了`funboost`各种强大的任务控制功能和并发,比亲自使用`grpc`包写代码简单10倍.  

**代码如下,仔细看代码注释:**  
```python  
import time  
import json  
from funboost import boost, BrokerEnum, BoosterParams, FunctionResultStatus,AsyncResult  


@boost(BoosterParams(  
    queue_name='test_grpc_queue', broker_kind=BrokerEnum.GRPC,  
    broker_exclusive_config={'port': 55051, 'host': '127.0.0.1'},  
    is_using_rpc_mode=True,  # brpc作为broker时候,is_using_rpc_mode可以为False,使用 $booster.publisher.sync_call ,则不依赖redis实现rpc  
))  
def f(x, y):  
    time.sleep(2)  
    print(f'x: {x}, y: {y}')  
    return x + y  


@boost(BoosterParams(  
    queue_name='test_grpc_queue2', broker_kind=BrokerEnum.GRPC,  
    broker_exclusive_config={'port': 55052, 'host': '127.0.0.1'},  
    rpc_timeout=6,  
    is_using_rpc_mode=False,  # brpc作为broker时候,is_using_rpc_mode可以为False,如果使用 $booster.publisher.sync_call ,则不依赖redis实现rpc  
    concurrent_num=500,  
))  
def f2(a, b):  
    time.sleep(5)  
    print(f'a: {a}, b: {b}')  
    return a * b  


if __name__ == '__main__':  
    f.consume()  
    f2.consume()  

    for i in range(100):  
       

        """  
        sync_call 是会进入阻塞直到返回结果,无论你是否进一步执行  rpc_data1.result 都会阻塞  
        """  
        rpc_data1: FunctionResultStatus = f.publisher.sync_call({'x': i, 'y': i * 2})  
        print('grpc f result is :', rpc_data1.result)  

        """  
        任然可以使用 booster.push,但是AsyncResult获取结果需要redis作为rpc,  
        如果不进一步async_result.result来获取结果,则f.push不会阻塞代码  
        """  
        async_result :AsyncResult = f.push(i, i * 2)  
        print("result from redis:",async_result.result)  

        rpc_data2 :FunctionResultStatus = f2.publisher.sync_call({'a': i, 'b': i * 2})  
        print('grpc f2 result is :', rpc_data2.result)  

```  

## 11.8 使用 mysql_cdc 作为 funboost 的broker  

**第一性原理: `funboost`使用了 `pymysqlreplication` 包来实现`mysql_cdc`功能**  

 `cdc` 就是 `Change Data Capture` 是一种很火热的大数据技术.   
 核心思想: 它是一种用于捕获数据库中数据变更（例如 `INSERT`、`UPDATE`、`DELETE` 操作）的技术。   


`mysql_cdc` 作为 `funboost` 的 `broker`时候,用户无需人工使用`funboost`的 `push`发布消息,    
`funboost` 使用  `cdc` 技术,监听`mysql`数据库表,将表数据转换成消息发送非消费者,数据源即生产者。  

任何对数据库的 `insert` `update` `delete`操作都会被`funboost`监听到,并且转换成消息作为消费函数的入参.  
在消费函数中,借助`funboost`的贡献,用户可以1行代码就能轻松实现`mysql2mysql`跨数据库实例的表数据同步,   
轻松1行代码实现把`binlog`发送到`kafka`,`redis` `rabbitmq` 各种消息队列里面.    
对简单业务,不用搭建一套高昂复杂的大数据集群,来搞 `flinkcdc` `canal`  

这再次印证了,`funboost` 万物可为 `broker` 的超强设计理念,连数据库自身数据变更都能作为`funboost`的`broker`  


**MySQL server settings 配置说明:**  
In your MySQL server configuration file you need to enable replication:  

首先前提是在你的`mysql`配置文件`my.ini` 添加如下配置,    
参考`python-mysql-replication` 的 `readme` [https://github.com/julien-duponchelle/python-mysql-replication/tree/main](https://github.com/julien-duponchelle/python-mysql-replication/tree/main)  

```ini  
[mysqld]  
server-id		           = 1  
log_bin			           = /var/log/mysql/mysql-bin.log  
binlog_expire_logs_seconds = 864000  
max_binlog_size            = 100M  
binlog-format              = ROW #Very important if you want to receive write, update and delete row events  
binlog_row_metadata        = FULL  
binlog_row_image           = FULL  
```  

**代码演示,mysql_cdc broker的使用,注意看代码注释讲解**  

```python  
# coding=utf-8  
from typing import Dict, Any  
import dataset  

from funboost import boost, BrokerEnum, ConcurrentModeEnum, BoosterParams,BoostersManager,PublisherParams  
from pymysqlreplication.row_event import (DeleteRowsEvent, UpdateRowsEvent, WriteRowsEvent, )  

from funboost.contrib.cdc.mysql2mysql import MySql2Mysql # 从 funboost的额外贡献文件夹中导入 MySql2Mysql 类.  

bin_log_stream_reader_config = dict(  
    # BinLogStreamReaderConfig 的所有入参都是 pymysqlreplication.BinLogStreamReader 的 原生入参  
    connection_settings={"host": "127.0.0.1", "port": 3306, "user": "root", "passwd": "123456"},  
    server_id=104,  
    only_events=[DeleteRowsEvent, UpdateRowsEvent, WriteRowsEvent, ],  
    blocking=True,  # 1. 设置为阻塞模式，使其持续等待新事件  
    resume_stream=True,  # 2. (推荐) 允许在断线后自动从上次的位置恢复}},  
    only_schemas=['testdb6'],  # 3. 仅监听 testdb6 数据库  
    only_tables=['users'],  # 4. 仅监听 users 表  
)  

sink_db = dataset.connect('mysql+pymysql://root:123456@127.0.0.1:3306/testdb7')  # 使用cdc技术 ,把 testdb6.users 表数据同步到另外一个库testdb7中的user表  


@boost(BoosterParams(  
    queue_name='test_queue_no_use_for_mysql_cdc',  
    broker_exclusive_config={'BinLogStreamReaderConfig': bin_log_stream_reader_config},  
    broker_kind=BrokerEnum.MYSQL_CDC, ))  
def consume_binlog(event_type: str,  
                   schema: str,  
                   table: str,  
                   timestamp: int,  
                   **row_data: Any):  
    full_cdc_msg = locals()  
    print(full_cdc_msg)  
    # update 事件打印如下  
    """  
    {  
    "event_type": "UPDATE",  
    "row_data": {  
        "after_none_sources": {},  
        "after_values": {  
            "email": "wangshier@example.com",  
            "id": 10,  
            "name": "王八蛋2b16"  
        },  
        "before_none_sources": {},  
        "before_values": {  
            "email": "wangshier@example.com",  
            "id": 10,  
            "name": "王八蛋2b15"  
        }  
    },  
    "schema": "testdb6",  
    "table": "users",  
    "timestamp": 1756207785  
}  
    """  
    # 演示 轻松搞定mysql2mysql 表同步,你也可以清洗数据再插入mysql,这里是演示整表原封不动同步, 可以不用搭建flinkcdc大数据集群,就能5行代码以内搞定 mysql2mysql  
    m2m = MySql2Mysql(primary_key='id',target_table_name='users', target_sink_db=sink_db, )  
    m2m.sync_data(event_type, schema, table, timestamp,row_data) # 只需要一行代码就能把cdc数据同步到另外一个数据库实例的表中.  


    # 你还可以吧消息发到 rabbitmq  kafka redis 随你喜欢,可以使用 funboost的 publisher.send_msg 来发布原始内容,不会添加extra taskid等额外key.,  
    # 不需要亲自封装各种消息发布工具,利用funboost的万能特性,发布到所有各种消息队列只需要一行代码.  

    # 演示把消息发到redis  
    pb_redis = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='test_queue_mysql_cdc_dest1',broker_kind=BrokerEnum.REDIS))  
    pb_redis.send_msg(full_cdc_msg)  

    # 演示把消息发到kafka  
    pb_kafka = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='test_queue_mysql_cdc_dest2', broker_kind=BrokerEnum.KAFKA,  
                                                                           broker_exclusive_config={'num_partitions':10,'replication_factor':1}))  
    pb_kafka.send_msg(full_cdc_msg)  


if __name__ == '__main__':  
    # MYSQL_CDC 作为funboost的broker时候, 所以禁止了 push 来人工发布消息, 自动监听binlog作为消息来源,所以不需要人工发消息.  
    # 任何对数据库的 insert delete update 都会触发binlog,间接的作为了 funboost 消费者的消息来源.  
    consume_binlog.consume()  

```  

```  
funboost 通过其高度抽象的 _dispatch_task 接口，成功地将自己从一个单纯的“任务队列执行者”提升为了一个“通用事件监听与函数调度平台”。  
Celery 是消息驱动的：它的世界观是“消息来了，我执行”。它关心的是如何处理被显式告知的任务。  
Funboost 是事件驱动的：它的世界观是“事件发生了，我响应”。它关心的是如何监听并响应来自任何源头的状态变化。  
MYSQL_CDC broker 是这一点的最佳证明，但绝不是终点。正如您的推论，日志文件、文件系统变更（inotify）、甚至是硬件传感器的信号，理论上都可以被封装成一个 funboost 的 Broker。  
因此，funboost 不仅仅是 Celery 的一个更快、更易用的替代品，它在设计哲学上提供了一种更广阔、更灵活的编程范式，使其有能力解决远超传统任务队列范畴的、更广泛的事件驱动自动化问题。  
```  

<div> </div>
`````

--- **end of file: source/articles/c11.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c12.md** (project: funboost_docs) --- 

`````markdown
# 12 funboost 控制台支持命令行  

funboost 2023.11 新增支持命令行,启动消费 发布消息 清空消息 暂停消费等功能  

有些人喜欢如 scrapy celery 这样的框架,在命令行敲击一长串命令来灵活启动python任务,  

本人非常讨厌这样的框架,控制台命令行不能代码补全,敲击难,感觉是鸡肋  

但是有的小伙伴喜欢这样的命令行方式来启动python,现在funboost加上命令行功能.  

```  
用户只需要@boost定义消费函数定义f1,f2, 在命令行指定启动哪些queues 就行了,  
而不是先需要在脚本中写好 f1.consume() f2.consume(),然后再启动这个脚本.  
```  

python 项目根目录/funboost_cli_user.py --help 可以查看有哪些命令  

## 12.0 funboost命令行使用fire实现  

funboost命令行使用fire实现的  

fire很好用,很方便,比任何命令行都好用,建议大家以后开发命令行工具使用fire,不要使用argparse和click  

## 12.1  命令行分为调用funboost包内命令和用户自身项目的命令行  

### 12.1.1 funboost自身命令行,python -m funboost  是自动调用 funboost的 __main__.py 的fire命令行  

### 12.1.2 用户项目根目录下的  funboost_cli_user.py 的文件可以接受命令行传参  

python -m funboost 和 python 项目根目录/funboost_cli_user.py 是一样的个功能  

funboost_cli_user.py是首次启动项目自动把funboost/core/cli/funboost_cli_user_templ.py复制到用户项目根目录下的  

用户可以在funboost_cli_user.py里面灵活加代码,这样在调用命令行就能少传参 --project_root_path 和 --booster_dirs_str 了  

所以建议用户使用 python 项目根目录/funboost_cli_user.py 的命令行,而不是使用 python -m funboost  

###### 说明:之后的例子不再同时列举 python -m funboos 和 python funboost_cli_user.py  

### 12.1.3 python -m funboost 和 python 项目根目录/funboost_cli_user.py 传参不同点  

```  
python -m funboost  必须传递 --project_root_path=你的项目根目录  
而且在敲击 python -m funboost 之前需要用户先设置临时环境变量 set/export PYTHONPATH=用户项目根目录 (因为nb_log需要先读取配置文件)  


python 你的项目根目录/funboost_cli_user.py 命令行不需要传参指定--project_root_path ,也不需要先设置环境变量  
因为funboost_cli_user.py就在用户项目根目录,所以代码中自动添加了当前项目根目录到sys.path 和指定project_root_path为当前项目根目录,  
此外funboost_cli_user.py中用户可以import 消费函数所在模块,  
也可以 BoosterDiscovery(project_root_path, booster_dirs=['需要扫描的消费函数所在文件夹'], max_depth=1,py_file_re_str=None).auto_discovery()来自动import发现  

这就是建议用户使用 python funboost_cli_user.py xxxxx 这样来调用命令行而不是python -m funboost xxx 来调用命令行  
```  

## 12.2 funboost命令行指定消费函数所在的模块或文件夹  

用户如果没import 消费函数所在模块或者调用 BoosterDiscovery.auto_discovery, 需要在命令行传参.  

```  
如果需要导入多个模块,import_modules_str的值如果多个模块需使用逗号隔开  
python funboost_cli_user.py --import_modules_str "test_frame.test_funboost_cli.def_tasks3"  publish test_cli3_queue "{'x':3,'y':4}"  
    
如果没有亲自import boost函数所在模块,则可以自动扫描文件夹下的py文件,自动import,如是果多个文件夹用,隔开  
python funboost_cli_user.py --boost_dirs_str 'test_find_boosters,test_find_booster2'  push test_find_queue1 --x=1 --y=2  
```  

## 12.3 打印发现的用户定义的@boost消费函数  

show_all_queues   
```  
python -m funboost  --project_root_path=用户项目根目录   --booster_dirs_str=文件夹1,文件夹2 --max_depth=2  show_all_queues (需要先set/export PYTHONPATH=用户项目根目录)  


或 python funboost_cli_user.py -booster_dirs_str=test_frame/test_funboost_cli/test_find_boosters --max_depth=2 show_all_queues  

如果 funboost_cli_user.py 加了 BoosterDiscovery(project_root_path, booster_dirs=['文件夹1','文件夹2'], max_depth=2,py_file_re_str=None).auto_discovery(),那么写  
python funboost_cli_user.py show_all_queues  即可.  

```  

用户可以拉取funboost项目中的自带的测试例子来测试命令行  


```  
python funboost_cli_user.py  --booster_dirs_str=test_frame/test_funboost_cli/test_find_boosters --max_depth=2  show_all_queues   
```  



## 12.4 funboost命令行清空消息队列  

clear  
```  
python funboost_cli_user.py clear  queue1  queue2   # 清空消息队列queue1和queue2,多个队列用空格隔开就行  
```  

## 12.5 funboost命令行给一个队列发布消息  

push 或 publish  

```  
python funboost_cli_user.py push test_cli1_queue 1 2  # 发布消息  
python funboost_cli_user.py push test_cli1_queue 1 --y=2 # 发布消息,也可以明显点传入参名字  
python funboost_cli_user.py publish test_cli1_queue "{'x':3,'y':4}"  # 发布消息传递一个字典  
python funboost_cli_user.py publish test_cli1_queue '{"x":3,"y":4}' # 错误方式  
```  

## 12.6 funboost命令行启动多个queue消费者  

当前进程内启动多个conusmer consume,  

每个queue使用多个进程启动消费 mp_consume  

```  
python funboost_cli_user.py consume test_cli1_queue test_cli2_queue  # 启动两个队列的函数消费  
python funboost_cli_user.py mp_consume --test_cli1_queue=2 --test_cli2_queue=3 # 叠加多进程启动消费,test_cli1_queue启动2进程,test_cli2_queue启动3进程.  
```  
### 12.6.b  funboost命令行启动所有queue消费者,用户无需指定队列名  

当前进程内启动多个conusmer consume_all_queues 或 consume_all  
每个queue使用多个进程启动消费  multi_process_consume_all_queues $process_num 或 mp_consume_all $process_num  
```  
python funboost_cli_user.py consume_all  
python funboost_cli_user.py mp_consume_all 2  
```  


## 12.7 funboost命令行暂停消费  

pause  

支持暂停,前提是 @boost指定 is_send_consumer_heartbeat_to_redis=True  

```  
python funboost_cli_user.py pause queue1  queue2    #queue1  queue2 两个队列暂停消费  
```  












<div> </div>
`````

--- **end of file: source/articles/c12.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c13.md** (project: funboost_docs) --- 

`````markdown
  
# 13 启动 funboost web manager,查看消费结果和队列管理  

- 通过 funboost web manager 可以查看消费结果；管理队列；管理消费者；查看正在运行的函数； 实时调节并发数量；调节 qps 限制频率；仅从页面就能看到python 函数的消费情况，无需去查看日志文件。  

- 说明：funboost web manager 不一定需要用户安装mongo,用户只要不使用前2个页面就好了,后几个页面都是依赖redis,不依赖mongo.

## 13.1 介绍 启动 funboost web manager (方式一)。  

funboost web manager 启动方式很容易很简单，一键就能启动。  

python3 -m funboost.funboost_web_manager.app  

web代码在funboost安装包里面，所以你安装了funboost后，可以直接使用命令行运行起来，不需要用户现亲自下载web代码就可以直接一键启动运行。  


<p style="color: #00A000; display: inline-block">首先要安装选装 pip install funboost[flask] </p>（这是因为这是选装，防止用户抱怨funboost依赖太多。）  

```  
第一步：设置 PYTHONPATH 为你的项目根目录  
    export PYTHONPATH=你的项目根目录 (这么做是为了这个web可以读取到你项目根目录下的 funboost_config.py里面的配置)  
    (怎么设置环境变量应该不需要我来教，环境变量都没听说过太low了)  
     例如 export PYTHONPATH=/home/ydf/codes/ydfhome  
     或者 export PYTHONPATH=./   (./是相对路径，前提是已近cd到你的项目根目录了，也可以写绝对路径全路径)  
     win cmd 设置环境变量语法是 set PYTHONPATH=/home/ydf/codes/ydfhome   
     win powershell 语法是  $env:PYTHONPATH = "/home/ydf/codes/ydfhome"   


第二步：启动 funboost web manager 的 flask app   
    win上这么做：  python3 -m funboost.funboost_web_manager.app  
    linux上可以这么做性能好一些，也可以按win的做：  gunicorn -w 4 --threads=30 --bind 0.0.0.0:27018 funboost.funboost_web_manager.app:app  
```  

使用浏览器打开 127.0.0.1(启动web服务的机器ip):27018,输入默认用户名 密码 admin 123456，即可打开函数运行状态和结果页面。  

### 13.1.b 直接在代码中启动web start_funboost_web_manager() (方式二)：  

start_funboost_web_manager() 可以随着消费程序一起启动，也可以单独启动。  

```python  
from funboost.funboost_web_manager.app import start_funboost_web_manager  
start_funboost_web_manager()  
```  

## 13.2 funboost web manager 截图  

设置关心的项目，设置 care_project_name，可以让界面仅显示你关心的项目的队列，减少无关返回信息的干扰。
[![设置关心的项目 care_project_name](https://s41.ax1x.com/2025/12/19/pZ10fnf.png)](https://imgchr.com/i/pZ10fnf)

函数消费结果：可查看和搜索函数实时消费状态和结果。对于失败的消息，在页面上用户可以点击重新运行按钮，方便一键重新投递到消息队列。  
[![函数结果表](https://s41.ax1x.com/2025/12/19/pZ1L5h4.png)](https://imgchr.com/i/pZ1L5h4)

消费速度图：可查看实时和历史消费速度  
[![从函数结果表，统计的消费速率](https://s41.ax1x.com/2025/12/19/pZ10g1I.png)](https://imgchr.com/i/pZ10g1I)

运行中消费者 by ip： 根据ip搜索有哪些消费者  
[![运行中消费者按ip分组](https://s41.ax1x.com/2025/12/17/pZlrwsP.png)](https://imgchr.com/i/pZlrwsP)

运行中消费者 by queue： 根据队列名字搜索有哪些消费者  
[![运行中消费者，按队列名字分组](https://s41.ax1x.com/2025/12/19/pZ10c9A.png)](https://imgchr.com/i/pZ10c9A) 

队列操作：查看和操作队列，包括 清空清空 暂停消费 恢复消费 调整qps和并发  
[![队列操作1](https://s41.ax1x.com/2025/12/17/pZlrYPH.png)](https://imgchr.com/i/pZlrYPH)
[![队列操作2](https://s41.ax1x.com/2025/12/17/pZlrUxI.png)](https://imgchr.com/i/pZlrUxI)

队列操作，查看消费者详情：查看队列的所有消费者详情  
[![队列操作-消费者详情](https://s41.ax1x.com/2025/12/17/pZlr8aD.png)](https://imgchr.com/i/pZlr8aD)

队列操作，查看消费者的BoosterParams配置
[![队列操作-消费者配置](https://s41.ax1x.com/2025/12/17/pZlrdMt.png)](https://imgchr.com/i/pZlrdMt)

队列操作:查看消费曲线图，查看各种消费指标。  
包括 历史运行次数  历史运行失败次数  近10秒完成  近10秒失败  近10秒函数运行平均耗时  累计函数运行平均耗时  剩余消息数量  
[![队列消费曲线](https://s41.ax1x.com/2025/12/19/pZ104HS.png)](https://imgchr.com/i/pZ104HS) 

rpc调用：在网页上对30种消息队列发布消息并获取消息的函数执行结；以及可根据taskid获取结果。  
[![rpc调用，成功时候界面变绿色](https://s41.ax1x.com/2025/12/19/pZ10RjP.png)](https://imgchr.com/i/pZ10RjP)
[![rpc调用，出错时候界面变红色](https://s41.ax1x.com/2025/12/19/pZ102ct.png)](https://imgchr.com/i/pZ102ct) 

定时任务管理：列表页
[![定时任务列表](https://s41.ax1x.com/2025/12/17/pZlrNRA.png)]

定时任务：新增
[![添加定时任务](https://s41.ax1x.com/2025/12/17/pZlrGIe.png)](https://imgchr.com/i/pZlrGIe)

定时任务：任务详情
[![定时任务详情](https://s41.ax1x.com/2025/12/19/pZ10hB8.png)](https://imgchr.com/i/pZ10hB8)




## 13.3 funboost web 图片对应的测试代码  

```python  

import asyncio  
import time  
import random  

from funboost import boost, FunctionResultStatusPersistanceConfig, BoosterParams,BrokerEnum,ctrl_c_recv,ConcurrentModeEnum  
from funboost.funboost_web_manager.app import start_funboost_web_manager  



class MyBoosterParams(BoosterParams):  
    project_name:str = 'test_project1'  # 核心配置，项目名，设置后，web接口就可以只关心某个项目下的队列，减少无关返回信息的干扰。
    broker_kind:str = BrokerEnum.REDIS
    is_send_consumer_heartbeat_to_redis : bool= True # 向redis发送心跳，这样才能从redis获取相关队列的运行信息。
    is_using_rpc_mode:bool = True # 必须设置这一个参数为True，才能支持rpc功能。
    booster_group : str = 'test_group1' # 方便按分组启动消费
    should_check_publish_func_params:bool = True # 发布消息时，是否检查消息内容是否正确，不正确的消息格式立刻从接口返回报错消息内容不正确。
    function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(
        is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False) 


@boost(MyBoosterParams(queue_name='queue_test_g01t',qps=1,))  
def f(x):  
    time.sleep(5)  
    print(f'hi: {x}')  
    if random.random() > 0.9:  
        raise ValueError('f error')  
    return x + 1  

@boost(MyBoosterParams(queue_name='queue_test_g02t',qps=0.5,  
max_retry_times=0,))  
def f2(x,y):  
    time.sleep(2)  
    print(f'hello: {x} {y}')  
    if random.random() > 0.5:  
        raise ValueError('f2 error')  
    return x + y  

@boost(MyBoosterParams(queue_name='queue_test_g03t',qps=0.5,  
max_retry_times=0,concurrent_mode=ConcurrentModeEnum.ASYNC))  
async def aio_f3(x):  
    await asyncio.sleep(3)  
    print(f'f3aa: {x}')  
    if random.random() > 0.5:  
        raise ValueError('f3 error')  
    return x + 1  

if __name__ == '__main__':  
    start_funboost_web_manager(port=27018)  # 也可以在python代码中启动web,来启动 funboost web manager funboost队列管理界面。可以不需要命令行来启动。  
    
    f.multi_process_consume(4)  
    f2.multi_process_consume(5)  
    aio_f3.consume()  
    for i in range(0, 1000000):  
        f.push(i)  
        f2.push(i)  
        aio_f3.push(i)  
        time.sleep(1)  
    ctrl_c_recv()  
    

    

    

```  

<div> </div>
`````

--- **end of file: source/articles/c13.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c14.md** (project: funboost_docs) --- 

`````markdown
# 14 🏅[懒人必看章节] 利用ai来掌握 funboost 的 正确方式

开门见山，**想靠ai用好 `funboost` ，只有这一条路最正确：**

- 1.打开 Google AI Studio [https://aistudio.google.com/](https://aistudio.google.com/prompts/new_chat)。
- 2.丢入 `funboost_合并教程_源码.md`。
- 3.别在 IDE 里问，别在gemini官网问，否则 别怪AI 不行，是你不行！

**如果你不能科学上网没有梯子，其他的也介绍了一些ai使用方式，请你务必看完本章节，别偷懒。**

## 14.0 🤬 [高能预警]在此章节最开头，先允许我用最恶毒的语言来**刺激骂醒**一部分又懒又蠢的懒癌患者的大脑皮层！

**说明：**   
此段内容不是针对所有人，没有针对屏幕前的你，我要骂的是反复多次要求让他去仔细看文档14章节，他还是不愿意认真看的这种 **恨铁不成钢的超级无敌大懒猪**。

> **致部分无可救药的懒癌晚期患者：**
>
> 先让我骂一下一部分人是 **懒虫中的懒虫，蠢猪中的蠢猪，傻屌中的傻屌**，是 **大脑皮层光滑如镜的单细胞生物**，是 **浪费空气的造粪机器**，是 **无可救药的伸手党巨婴！**， **脖子上的脑袋纯粹是为了显高，视网膜纯粹是为了美观** 凸(艹皿艹 )

如果不用最恶毒下流的语言来写教程，有些人看教程时候简直是在**打瞌睡**，要么心不在焉，要么企图偷懒一目十行，甚至大段大段地跳过，连教你怎么偷懒用ai掌握funboost都大段跳过！

你连20分钟看第14章内容的时间都没有吗？教你偷懒的教程你还要偷懒。

现在不像10年前，需要在大冬天坐冷板凳熬夜苦读 Django/Celery 几千页教程，**现在有 AI ！**
你害怕吃苦、想偷懒，你就用 AI，AI 不怕吃苦！但是有的**极品懒癌**，连这一章的内容都不仔细阅读，连教你怎么偷懒的章节都要快速一目十行扫过？**你的脑子是装饰品吗？**

### 14.0.1 🧠 脑残行为大赏

虽然我都说了可以用 AI 来高效、无幻觉、准确掌握 `funboost` 任何公开教程和源码细节，而且**专门**写了这个章节教程。
但一部分 **懒虫中的极品懒虫，蠢猪中的极品蠢猪**，连这章都不仔细读！

1.  有问题来问我，我问：“为什么不用 AI 呢？建议先看下文档第14章。”
2.  他还敢顶嘴说**“已经看过文档第14章”**。
3.  结果我仔细追问，发现他完全是 **瞎几把乱用 AI**！

教程中明确说了哪些是 **大错特错** 的用 AI 掌握 `funboost` 的方式，他偏偏还是这样用！这种做法极其浪费时间，**让我非常的生气恼火！** 😡

我再仔细问他是怎么用的：
*   他说直接问 AI 的；
*   或者说已经把文档传给 AI 了。
*   再问细节，他说是在 **DeepSeek / GPT / Claude 网页** 提问的；
*   有的说在 **Cursor / Trae / Qoder** 这些 IDE 里面提问的。
*   有的说在 **Claude-code / Gemini-cli** 这些命令行里面提问的。
*   有的说用的 gemini-flash ，而没有按教程写的用 gemini-pro
*   有的人使用 https://gemini.google.com ,而不是教程规定的 https://aistudio.google.com

**此章节里面已经反复明确说了，这些全踏马是错误的让 AI 学习 funboost 的方式！你是瞎了吗？**

---

### 14.0.2 🚫 别拿通用框架的经验来羞辱我的智商

如果你是提问 AI：*“怎么使用 FastAPI / Django / Flask / Requests？”*
这些大名鼎鼎的 Python 框架，任何 AI 大模型只要不是太水，你想怎么使用都可以，几乎都没问题。**你不需要我来充当 AI 教师爷教你怎么用 AI 掌握热门顶流框架。**

👉 **但是！** 如果你想用 AI 掌握 `funboost`，就 **必须按照我说的方式来！**
如果你不按我说的方式来，AI **绝无可能** 正确无幻觉掌握得了 `funboost`，到时候你还怪 AI 不行？**是你踏马的不行！**

---

### 14.0.3 ❌ [严重警告] 懒癌患者请把下面这几点刻在脑门上！

我踏马再在这里对一部分懒癌患者，把此章节内容中的**错误使用方式**再提前重复啰嗦一次：

*   ❌ **错误一**：不上传我指定的 `funboost_合并教程_源码.md` 文档，直接在任何 AI 官网网页提问 `funboost` 知识。**这是最错误的方式**，包括 `gemini-3.0pro` 网页也不行！
*   ❌ **错误二**：在 `Cursor` / `Trae` / `Qoder` 这类 AI IDE 的聊天框里面 `@funboost_合并教程_源码.md` 这个文件。**这也是大错特错的！** 原因我反复说了自己去细看——**因为文档太长，AI IDE 不会乖乖全量阅读，否则厂商会血亏！**
*   ❌ **错误三**：上传文档给 `GPT` / `DeepSeek` / `Claude` 提问。**这也是错误方式！** 因为 `funboost_合并教程_源码.md` 需要 **800k tokens** 上下文，而这些模型最大才支持 128k-256k，压根不支持上传这么长的文档！有些网页就算上传成功，也是使用稀疏注意力或 RAG 切片**大段跳过**，**压根不能全局统筹、非常细致地掌握 funboost 的细节！**
*   ❌ **错误四**：在 `Claude-code` 和 `Gemini-cli` 这种有 1M 上下文的命令行 AI 中，`@funboost_合并教程_源码.md` 这个文件。**这也是错误方式！** 原因我反复说了自己去细看，因为文档太长 AI agent 不会乖乖全量阅读，厂商亏不起！

---

### 14.0.4 ✅ ai掌握funboost的唯一正确的路径

**听好了，只有同时满足以下 5 个条件，AI 才能真正掌握 `funboost`：**

1.  **按我说的做**（别自作聪明）；
2.  使用**经过我实践实测的**工具；
3.  大模型必须有 **原生 1000k 上下文或少部分rag平台**；
4.  可以 **强迫投喂** `funboost_合并教程_源码.md` 文档，
5.  投喂长文档后， AI 是 **全量乖乖阅读推理** 的（必须是乖乖全量阅读推理，这一点非常非常核心重要，你在cursor trae中提问长文档，那agent就是分多步骤阅读和检索关键字，又慢又不准，因为ai ide害怕全量阅读花太多tokens导致亏本）。

**少一个条件，你就别来问我 funboost怎么使用，funboost为什么报错！**

### 14.0.5 🤬 当我问你怎么使用ai时候，你最少要回答200字到底是怎么使用ai的，别踏马就简单的说:"我已经用ai来问funboost问题了"   

**因为很多恨铁不成钢的懒虫，即使我反复要求他先仔细阅读第14章节，他还是不仔细阅读此章节的内容，这种懒虫我见过太多了**

所以我要求你仔细回答是如何使用ai的，你要回答的包括：   
- 1. 你是在网页还是ai ide问的，如果是网页请把网址发下     
- 2. 你用的是什么大模型   
- 3. 你上传文档了没，如果上传了文档请把文档名发下 ，我要确定你上传的是不是我指定的文档。（因为有的懒虫一意孤行不看此章节教程）  
- 4. 你是怎么问的，如果可能，把提问问题也发一下。 【我要复制你的提问，我现在非常喜欢挑战nb_ai_context的能力上限，我要看看ai是不是真的掌握不了，还是我文档提示词工程的问题，  
     还是你不按照教程第14章说的做。 （根据过往经验，几乎用户所有的问题，我直接在ai中输入并提问，ai都可以回答正确，是用户太几把懒了不认真看第14章，还踏马怪ai不行） 】 





## 14.0.0b 推荐一个在ai时代 神级别黑科技掌握任意非知名的it项目的方式 nb_ai_context

funboost 合并文档 `funboost_合并教程_源码.md` 就是使用 `nb_ai_context` 生成的

[nb_ai_context地址](https://github.com/ydf0509/nb_ai_context)    

用户也可以在 `nb_ai_context` 的readme里面去了解，为什么冷门it项目必须使用特殊的手段才能让ai无幻觉掌握用法和细节。    
如果你是问ai ,怎么使用fastapi/django/flask/requests 这些大名鼎鼎的python框架 ，任何ai只要不是太水，几乎都没问题,不需要 nb_ai_context ， 
不需要我教你怎么用ai 掌握 flask django fastapi。

`nb_ai_context` 不仅可以生成funboost合并文档，让ai无幻觉掌握用法和细节， 也适用于任何冷门三方框架以及个人或公司的私有代码项目。  
`nb_ai_context` 尤其是对python项目效果更佳，因为对python文件有专门额外的 ast解析。



## 14.0.1 为什么要专门写第14章这个教程？

有的人太懒惰了,不愿意吃苦阅读  `funboost` 的 `readthedocs` 教程,或者不清楚 `funboost` 实现的背后细节原理且不愿意分析框架源码,那就使用 ai 来替你搞定一切.  

- **第一性原理:为什么要写第14章这个章节文档?**   
因为无论是使用cursor trae qoder 这些ide,还是在各个大模型官方网页直接问 `funboost` 问题,都是大错特错的方式，必须提供完整的教程和源码上下文，ai大模型才能减少幻觉。

| 大模型 | 网址                                                                                                                     | 评分 | 简要评价                                                                                                    |
| --- |------------------------------------------------------------------------------------------------------------------------| --- |---------------------------------------------------------------------------------------------------------|
| gemini-3.0pro | [Google AI Studio](https://aistudio.google.com/app/prompts)                                                            | 95 | 最强,知我心者gemini也。<br>1000k窗口,一次吞下源码和教程绰绰有余,<br>幻觉很少,能准确写代码并且不乱造方法名和入参,<br>跨章节全局连贯推理能力也非常强<br>真原生超长上下文秒RAG |
| ima知识库 + deepseek v3.1 | [腾讯ima+funboost知识库](https://ima.qq.com/wiki/?shareId=aafc6364ae0f34ae237e4e2aa756e57d301d6461e51db030e0522cda3dc8729e) | 80 | 很强,rag能快速检索找到相关用法,<br>幻觉相对少,但全局连贯推理能力没有gemini的真1000K 上下文强                                               |
| qwen3-max | [千问国际版](https://chat.qwen.ai/)                                                                                         | 75 | qwen3-max + 文档分块处理,实时rag ,<br>回答也还可以,可以掌握文档文字理念。                                                        |
| 智谱清言 GLM4.6 | [智谱清言自定义funboost智能体](https://chatglm.cn/main/gdetail/69157797ad83dfcba0f454e7)                                         | 82 | 智谱清言的智能体，对于知识库功能，<br>比腾讯ima 自定义程度更高，<br>据说GLM4.6很强，用户可以亲自对比下ima+deepseek v3.1。                          |

**章节目录**
- 14.1 是最优先推荐使用 `google ai studio` 网页版提问 (1000k token上下文),而不是使用 `gemini-cli` 和 `gemini-code-assit` 和`cursor` 和 `trae` 阅读本地文档 
   - google ai studio 真1000k全文推理，和gemini对话更有意思，有时能碰撞出思维的火花。 
   - rag技术虽然回答快和准确，但感觉没什么意思，就是照着向量去检索然后照本宣科的回答，ai并没有多少自己的主见。 
   - 即使都用 `gemini-3.0pro` 大模型 ，使用rag技术的  `google notebook lm` ，就是很无聊，没有 `google ai studio` 有意思。

- 14.2 是推荐使用腾讯ima知识库 + deepseek v3.1大模型 (RAG技术),虽然deepseek 大模型只有128k token上下文,但是利用RAG技术,可以快速检索funboost用法 

- 14.3 是使用 qwen 网页 https://chat.qwen.ai/ ,来阅读 funboost 文档  

- 14.4 使用 智谱清言 GLM4.6 的 自定义funboost智能体来回答 funboost 问题，也是 rag技术

- 14.10 是告诉你,为什么传统的基于字符串模糊匹配的搜索技术,被ai吊打

### 14.0.2 **各个 ai 掌握 funboost 能力评分**

超长上下文是 天才学霸记忆力超群能记下所有知识过目不忘；  
rag是普通学生（记忆力能力不行） + 图书分类管理员，回答问题时候才临时抱佛脚去相关抽屉翻找书籍给答案，这种答案就不深度不连贯，不是全局视野。

<h4> 14.1的 `google ai studio` + `gemini-3.0pro` , ai能力95分</h4>

```
最强,知我心者gemini也. 1000k窗口,一次吞下源码和教程绰绰有余,幻觉很少,能准确写代码并且不乱造方法名和入参,跨章节全局连贯推理能力也非常强

gemini在以下方面都是最顶级的：
1. 任何教程上已经明确写了的 funboost 用法；
2. 文档全局跨章节的关联推理； 
3. 对用户提问,回答的深度归纳能力;
4. 拷问教程没写，需要阅读源码并总结的，
   例如问 “funboost 源码是怎么实现 celery 作为 broker 的？”  ，
   “funboost 源码是怎么实现 mysql cdc作为 broker 的？”，
   “boost_spider” 为什么可以虐 xx 爬虫框架？“
5. 让gemini实现扩展一个 新的 broker中间件种类;


gemini-3.0pro 1000k上下文缺点是:
据说1000k上下文服务端推理成本很高,是比128k 上下文 高10的二次方倍,但服务端推理成本高关我们什么事,反正google ai studio 是无限免费白嫖的.
```

<h4> 14.2的 `ima知识库` + `deepseek v3.1`,  ai能力80分  </h4>

```
很强,rag能快速检索找到相关用法,幻觉相对少,但全局连贯推理能力没有gemini的真1000K 上下文强, 
实测rag技术还是不如gemini 1000k 超长上下文的大力出奇迹那么强悍,rag是次选,超长上下文才是王道.

优点是： 一个知识库可以上传1个G的文档，相当于可以存放放几千本书，可以阅读500个funboost文档，然后对ai提问

缺点1是： 知识库里面对deepseek提问，被默默地强制添加了提示词，提示词告诉了ai只能回答知识库中的知识，文档没明确提到的的都一律拒绝回答，
例如你让 funboost 和 知名的rq  dramatiq feapder 比较一下，由于文档中没明确写这个内容，ima 就拒绝回答。

缺点2是: rag感觉更适合文科文字知识回答，面对项目源码，多文件关联 ，函数层层调用的分析能力很弱，
例如 a.py的 fun函 = 于b.py的fun函数 ,属于重定向了,rag居然不知道a.fun的入参从而乱造了几个入参,rag明显的没有 gemini3.0pro 超长上下文 强大。
rag极度依赖 作者把文档写得很细很细，因为腾迅ima的rag为了怕ai瞎几把回答幻觉, 将默认提示词调教得非常严格防止幻觉，
所以ai回答过于保守,不敢思维发散和推理总结,生怕回答错了。

缺点3是: rag能快速检索召回找到具体用法,但是对冷门函数的入参如果在教程不反复啰嗦列举,如果只给了python源码,
例如 a.py的 fun函 = 于b.py的fun函数，a.fun的入参还是会幻觉乱造，甚至连函数名都会似是而非乱造,给人90%意图准确,但10%细节又错误 的感觉,
而python代码只要错一个字母,程序就会崩溃,不像回答文科文字答案容错率高宽容。
```

综上，RAG 本质是一种‘检索增强记忆’，不是‘理解增强推理’。面对函数调用链、参数传递等高依赖上下文的问题，长上下文模型始终是终极形态。

<h4> 14.3的 `qwen 官方网页` + `qwen3-max`,  ai能力得分75分 </h4>

```
qwen3-max + 文档分块处理,实时rag ,回答也还可以,可以掌握文档文字理念。

缺点是文档中的冷门边角知识,代码生成细节不好,不如gemini3.0pro强大。

优点是 qwen3-max 网页,支持 20M 文档的上传,然后提问。 20M 足够容纳10个 funboost 框架源码和教程了.
而gemini3.0pro 大约最大能支持 4M文档上传,就会超过1000k 上下文了。
目前funboost 教程 + 源码 文件在2M以内，token 消费600k以内， 所以gemini-3.0pro 非常合适。
```

<h4> 14.4的 `智谱清言 GLM4.6` + `自定义funboost智能体`,  ai能力得分82分 </h4>

智谱清言的智能体，对于知识库功能，比腾讯ima 自定义程度更高，回答引用了哪些内容更直观。  
实测 回答问题和 腾讯ima + deepseek v3.1 相当.  

<h4> 其他厂商的ai大模型针对掌握funboost知识都无法可用</h4>

```
funboost 教程加源码 是一个 2M markdown 单文件文档,需要600k token, 
如果原生不支持1000k上下文,也不支持分块 rag ,那就无法可用。

所以 gpt5 claude4  deepseek 豆包 智谱清言 kimi 都无法可用，不推荐用这些ai的官网来掌握 funboost 知识。
```

<h4> ai 选型小结:  </h4>

```
相比较 1000k token上下文的大模型和rag,优先选择 1000k token上下文的大模型,rag依赖文档写得很详细，适合检索召回, 
rag全局统筹关联推理和自动阅读分析大项目跨文件的代码,没有原生支持1000k上下文的模型好.  
原生长上下文除了更费钱废token,在各方面都比rag技术好,反正google ai studio 是免费白嫖的,所以优先使用这个.  
```



## 14.1 利用ai大模型来更好的掌握funboost的最佳方式是什么?  

现在是ai时代,谁不用ai就太落伍吃亏了.   

但是使用 ai 大模型也有技巧.  

**第一性原理:使用google ai studio网页版+上传markdown+免费+1000k上下文+全文一次性阅读=幻觉率几乎没有**  
**gemini-3.0pro 在上传 funboost_合并教程_源码.md 这文件后,对funboost的常规用法以及任何细节推理和funboost作者我本人不相上下,知我心者,gemini也**  

### 14.1.1  强烈推荐选择 google ai studio + gemini 3.0pro 大模型  

`gemini 3.0pro`大模型有`1000k token`上下文, 并且可以在 `google ai studio` 免费无限使用  

funboost的教程需要300k token上下文,funboost的框架源码也需要300k token上下文,  
`funboost_合并教程_源码.md` 这个文件需要大约600k token 上下文 ,全地球只有 `gemini 3.0pro` 能胜任完整阅读这个文档且免费且准确.  

[https://aistudio.google.com/app/prompts](https://aistudio.google.com/app/prompts)  


`claude4`写代码牛,是修改代码调用工具链强大,但是上下文只有200k,并且不免费,所以pass.  
`gpt5` token上下文太短,也pass  

 **`funboost`知识就是ai大模型的试金石.**  ,使用长文档实测国产ai目前不行, `gemini-3.0pro` 经过实测,在`funboost`的文档推理上 是真正的遥遥领先。

**只有google gemini 3.0pro 适合长文档一次性阅读**
```  
leetcode 一个题目,一般就不到10行文字,和 funboost这种 几万行的 教程 + 源码 文档相比,对ai的 要求不是一个级别.   
LeetCode 测试的是在 封闭、小上下文 环境中解决孤立问题的能力。这就像要求一个学生解答一道定义清晰的数学题。   
funboost 则要求理解一个 开放、大上下文 的复杂系统。这需要AI不仅能看懂每一行代码（“How”），   
更能理解组件之间的相互作用、设计模式的应用、以及作者的设计哲学（“Why”），虽然ai不会真思考，但我在教程已经把why总结写得很详细很长了，gemini 不怕文档长。  
```  

**一个模型的真正实力，不应只看它在“闭卷考试”（Benchmark）上的分数，更要看它在“开卷项目”（真实世界问题）中的实际表现。**  


### 14.1.2 强烈推荐在网页上传funboost文档提问!  

强烈推荐在网页上传funboost文档提问,,不要使用`gemini-cli` 和 `gemini-code-assit` 和`cursor`阅读本地文档  

**这是我实践得出来的经验,在网页提问markdown文档比gemini-cli阅读本地文件好**  

推荐在 `google ai studio` 网页提问,而不是安装`gemini code assit`插件,让gemini在ide或者命令行中去阅读funboost的文档。  

[https://aistudio.google.com/app/prompts](https://aistudio.google.com/app/prompts)  


这似乎听起来反智,但实际上在网页上传文档并提问 `funboost` 问题,完爆 `gemini-cli` 和 `gemini-code-assit `阅读本机文件.  

因为网页上是可以一次性阅读 40000 行 markdown 并推理,如果你在本地阅读,大模型工具调用链阅读文件,会每1次阅读最高2000行,  
然后自动分多次阅读,这太浪费生命时间了,并且分多次阅读会触发使用大模型太频繁,导致自动切换到 `gemini-3.0flash`这个差劲大模型了。  

`gemini-cli` 不擅长阅读本机超长文件,其实可以理解的,不然用户随便在一个有1000个文件的目录中,对gemini  
说一句 `你阅读分析文件夹下所有文件`, `gemini-cli` 如果老老实实的执行,那`google`公司会亏得裤衩都没了,  
你随便一个不到10个字的命令,就烧掉几百万token,相当于浪费了google 公司 50人民币的gpu推理成本,  
所以`google`分2000行慢慢阅读文档,超频后就降智切换flash模型,甚至拒绝回答,来保护自己的算力不被滥用.  
如果多次切割成2000行分批阅读，就是**管中窥豹**，对于理解像 `funboost` 这样逻辑连贯、前后关联的复杂框架是灾难性的。  

实测,在`google ai studio` 的网页中,效果非常非常好,因为它是一次性阅读全文,不会每2000行来分批次慢慢阅读,   
不管是对教内容程,还是对源码内容,`gemini-3.0pro`都推理的非常准确。  

有的人太懒惰了,不愿意吃苦阅读  `funboost` 的 `readthedocs` 教程,或者不清楚 `funboost` 实现的背后细节原理且不愿意分析框架源码,  
那么 把 `funboost_合并教程_源码.md` 这个文档上传到 `google ai studio` 并各种提问，就非常合适。  
ai真的是生产力，人工需要阅读几天几夜的教程和框架源码，`gemini 3.0pro` 仅需不到1分钟就能分析的很准确。  

###  14.1.2b 为什么不建议在cursor trae qoder 这些ai ide 阅读 funboost文档？

**第一性原理:ai厂商早就预料到有坏蛋会恶意发起 Token DoS 攻击,让服务商血本无归**  
```
上面我已经说了,在cursor trae qoder 阅读 funboost文档,ide为了大模型调用的成本控制已经调了参数, 
例如trae 对大文件需要自动分段阅读,每次只能阅读200行需要和ai交互多次,阅读4万行 代码 + 教程 ,需要调用200次ai,中途他会自动停止阅读的.

那些说在ide阅读文档更好的人,请稍微用你的脑子好好想想,如果你的文件夹 dir1下有1000个100M的markdown文件,
你对ai说 ,"请完整仔细阅读 dir1下所有文件内容,然后告诉我中心思想" ,你觉得ide和模型会乖乖听你这种无理要求吗? 
你随便下个命令,ai需要花费 几十亿 token 来推理,浪费大模型厂商几百万人民币买显卡和电费, 别人ai公司难道没预料到会有这种坏蛋恶意滥用浪费大模型算力吗?
如果有坏蛋让ai插件 "请阅读c盘下的所有深层级目录下所有文件内容" 呢?


web里面,天然需要上传文件,而且上传时候就可以控制文件大小和数量,没有电脑本地那么容易恶意滥用浪费大模型算力.
```

### 14.1.2c 🛑 拒绝 Gemini 官网，✅ 拥抱 Google AI Studio

**核心原则：请务必使用开发者专用的 [Google AI Studio](https://aistudio.google.com/)，而不是面向普通消费者的 [Gemini 官网](https://gemini.google.com/)。**

虽然两者底层模型可能相同，但在处理 `funboost` 这种超长技术文档时，表现有着天壤之别。以下是三大核心理由：

#### 14.1.2c.1 💰 理由一：真正的“白嫖”与额度优势

| 平台 | Google AI Studio (推荐) | Gemini 官网 (不推荐) |
| :--- | :--- | :--- |
| **模型版本** | **Gemini 3.0 Pro** | Gemini Pro / Advanced |
| **费用** | **免费** (且速率限制极高，普通人难触发上限) | Pro 模型通常需要订阅 Google One 会员 (付费) |
| **性质** | 面向开发者，提供原始模型能力 | 面向大众，包含大量安全过滤和预设 |

#### 14.1.2c.2 🧠 理由二：忠于文档 vs. 通用幻觉

即使你拥有 Gemini 官网的会员，**AI Studio 的回答质量依然完胜**。

*   **Google AI Studio (专家模式)**：
    它会**严格基于你上传的文档**进行推理。对于 `funboost` 这种包含大量独创设计（如第6章的自问自答、特定配置写法）的框架，它能精准提取文档中的解决方案，而不是瞎猜。

*   **Gemini 官网 (通用模式)**：
    它倾向于使用训练数据中的“通用 Python/IT 知识”来回答。
    > **后果**：当你问一个 `funboost` 特有的问题时，官网版可能会忽略文档中的特定解法，按常规逻辑去推测（胡编），导致回答虽然看起来通顺，但完全没有 Get 到框架的精髓。

#### 14.1.2c.3 ⚡ 理由三：真·全量阅读 (Long Context) vs. 伪·检索切片 (RAG)

这是最硬核的技术差异，直接决定了 AI 能否读懂 `funboost` 的源码架构。

*   **文档体量**：`funboost_合并教程_源码.md` 约为 **800k tokens**。
*   **Google AI Studio**：
    *   **机制**：**原生超长上下文 (Native Long Context)**。
    *   **效果**：它能**一次性吞下**整个文档，像一个过目不忘的天才，能关联文档开头和结尾的逻辑。这是真正的“全量阅读”。
*   **Gemini 官网**：
    *   **机制**：**混合模式 / RAG (检索增强)**。虽然它允许上传 20M 的文件，但为了响应速度和成本，它底层往往采用切片检索。
    *   **效果**：它像一个“一目十行”的略读者，会**大量丢失细节**。对于代码这种逻辑严密的内容，丢失细节就是灾难。

> **💡 黄金法则**：除非你的私有文档大到超过了模型窗口上限（如 >200万 tokens），否则**永远优先选择原生超长上下文，坚决抵制 RAG。**

---

#### 14.1.2c.4 📸 提问时的“自证清白”

为了确保你没有用错工具，当你向我反馈“AI 回答不对”时，**请务必提供截图**：

1.  **不要只说**：“我用的 Gemini”。
2.  **请展示网址**：我要看到浏览器地址栏是 `aistudio.google.com`。
3.  **请展示模型**：我要看到你选的是 `Gemini 1.5 Pro`。

> **⚠️ 警告**：如果你不听劝阻，非要去用 Cursor IDE、Trae 或者 Gemini 官网提问，导致 AI 回答错误，**请不要怪 AI 不行，那是你不行。**


### 14.1.4 一定要上传markdown文档再提问  
不要直接在ai大模型的网页或者app提问`funboost`知识  
直接在网页提问,除了最简单的demo,写稍微深入一点的, 幻觉率太高了,所有ai几乎100%会意淫瞎造 `funboost`   
不存在的 入参 /类 /函数.  甚至有的国产水货大模型,连最基础简单`funboost` demo都会幻觉乱写。  

**要想让 AI 成为您学习 funboost 的得力助手，而不是一个满嘴跑火车的“猪队友”，最佳实践就是：打开 `Google AI Studio` 网站，将 `funboost_合并教程_源码.md` 文件上传，然后开始向一个已经“吃透”了 `funboost` 所有官方资料的 `Gemini 3.0 Pro` 专家提问。**  

### 14.1.5 funboost 的 markdown文档地址说明  

`funboost` 文档是托管在 `readthedocs` 网站,原始教程是分为了多个`markdown`文件  

在`github`中有合并的`markdown`,分为2个文件.  
一个是 `funboost_合并教程.md` , 这个是把 教程markdown文件合并成1个文件,方便一次性丢给`ai`,免得要多次上传。        
另一个是 `funboost_合并教程_源码.md` ,  这个是包含了所有教程 + 所有 `funboost` 框架源码 ,更推荐把这个markdown丢给 ai ,反正`gemini` 1000k上下文无敌且免费,不用担心花自己`token`和`money`。   

[https://github.com/ydf0509/funboost](https://github.com/ydf0509/funboost)  

![1756373743657](image/c6/1756373743657.png)  

#### 14.1.5.2 funboost的ai markdown文档是使用神级别 ai上下文生成工具 nb_ai_context 生成的

为什么 funboost的这个合并单一markdown传给ai后，ai如此强悍无幻觉，一方面是`gemini`很强大，另一方面是因为 `nb_ai_context` 生成的上下文太好了。

[nb_ai_context地址](https://github.com/ydf0509/nb_ai_context)

安装 `nb_ai_context`： `pip install nb_ai_context`

`nb_ai_context` 可以对任何it项目代码打包生成一个单一的markdown，传给ai后，效果非常强，吊打最知名的`repomix`。


#### 14.1.5.3 公布 funboost ai上下文 markdown 文档的生成方式

```python
from nb_ai_context import AiMdGenerator,NbPath

project_name="funboost"
project_root=fr"D:\codes\{project_name}"

project_summary = """
- `funboost` 是python 全功能分布式函数调度框架
- `funboost.faas` 是funboost的战略级核武器。使函数调度框架产生架构质变：从 Worker 到 Service

- 以下一定要记住，最最重要的 类和函数如下：
   - @boost(BoosterParams(...))  任意普通函数加上装饰器，变成分布式函数
   - BoosterParams 装饰器入参控制大全，一定要学习这个类的所有入参配置；ai绝对不允许胡编乱造源码api和教程中不存在的BoosterParams字段入参。
   - BrokerEnum：支持 40+ 种消息队列中间件。
   - BoostersManager 管理分布式函数，高阶用法可能需要用到，例如启动一组消费函数，启动所有消费函数等。
   - ApsJobAdder 类， 是定时任务的最重要使用方式的类
   - ConcurrentModeEnum：funboost支持的并发模式。
   

"""


boost_spider_summary = """
- **`boost_spider` = `funboost` 的超跑引擎 + 一套为爬虫量身打造的瑞士军刀。所有仿scrapy api爬虫框架都还是处在变花样造一辆马车**

- `boost_spider` 是增加了3个爬虫常用类，RequestClient  和  SpiderResponse  和 DatasetSink, 由funboost 驱动调度和并发。
"""


ai_md_codes = AiMdGenerator(
    r"D:\codes\nb_ai_context\markdown_gen_files_git_ignore\ai_md_files\funboost_all_codes.md"
).set_project_propery(project_name=project_name, project_root=project_root)

ai_md_docs = AiMdGenerator(
    r"D:\codes\nb_ai_context\markdown_gen_files_git_ignore\ai_md_files\funboost_all_docs.md"
      ).set_project_propery(project_name="funboost_docs", project_root=r'D:\codes\funboost_docs')


funboost_most_core_source_code_file_list=[
        "funboost/__init__.py",
        "funboost/core/booster.py",
        "funboost/core/func_params_model.py",
        "funboost/constant.py",
        "funboost/timing_job/timing_push.py",
        "funboost/funboost_config_deafult.py",
        "funboost/core/current_task.py",
        "funboost/core/cli/discovery_boosters.py",
        
        "funboost/core/msg_result_getter.py",
        "funboost/publishers/base_publisher.py",
        "funboost/consumers/base_consumer.py",
        "funboost/core/active_cousumer_info_getter.py",
        
    ]

(
    ai_md_codes
    .clear_text()
    .add_ai_reading_guide()
    .add_project_summary(
        project_summary=project_summary, 
        most_core_source_code_file_list=funboost_most_core_source_code_file_list)
    .add_project_summary(
        project_summary=boost_spider_summary, 
        project_root=r"D:\codes\boost_spider",
        most_core_source_code_file_list=[
           "boost_spider/__init__.py",
           "boost_spider/http/request_client.py",
           "boost_spider/sink/dataset_sink.py",
           "boost_spider/sink/json_sink.py",
        
    ])
    .merge_from_dir(
        relative_dir_name='examples',
        use_gitignore=True,
        as_title=f"{project_name} examples",
        # 只包含 .py 和 .md 文件
        should_include_suffixes=[".py", ".md", ".html"],
        # 排除 __pycache__ 目录和特定的测试文件
        excluded_dir_name_list=[],
    )
    .merge_from_dir(
        relative_dir_name=project_name,
        use_gitignore=True,
        as_title=f"{project_name} codes",
        # 只包含 .py 和 .md 文件
        should_include_suffixes=[".py", ".md", ".html"],
        # 排除 __pycache__ 目录和特定的测试文件
        excluded_dir_name_list=[
            r"funboost\utils\dependency_packages",
            r"funboost\utils\dependency_packages_in_pythonpath",
            r"funboost/utils/func_timeout",

            r"funboost\funboost_web_manager\static",
            r"funboost/concurrent_pool/backup"
        ],
    )
    .merge_from_dir(
        project_root=r"D:\codes\boost_spider",
        relative_dir_name="boost_spider",
        use_gitignore=True,
        as_title="boost_spider codes",
        # 只包含 .py 和 .md 文件
        should_include_suffixes=[".py", ".md", ".html"],
        # 排除 __pycache__ 目录和特定的测试文件
        excluded_dir_name_list=[],
    )
    .get_textfile_info(is_show_info=True)
)


(
    ai_md_docs
    .clear_text()
    .add_ai_reading_guide()
    .add_project_summary(
        project_summary=project_summary, 
        project_root=r"D:\codes\funboost",
        most_core_source_code_file_list=funboost_most_core_source_code_file_list
    )
    .add_project_summary(
        project_summary=boost_spider_summary, 
        project_root=r"D:\codes\boost_spider",
        most_core_source_code_file_list=[
           "boost_spider/__init__.py",
           "boost_spider/http/request_client.py",
           "boost_spider/sink/dataset_sink.py",
           "boost_spider/sink/json_sink.py",
        
    ])
    .merge_from_dir(
        project_root=r"D:\codes\funboost",
        relative_dir_name='examples',
        use_gitignore=True,
        as_title=f"{project_name} examples",
        # 只包含 .py 和 .md 文件
        should_include_suffixes=[".py", ".md", ".html"],
        # 排除 __pycache__ 目录和特定的测试文件
        excluded_dir_name_list=[],
    )
    .merge_from_dir(
        project_root=r"D:\codes\funboost_docs",
        relative_dir_name=r"source\articles",
        use_gitignore=True,
        as_title="funboost docs",
        # 只包含 .py 和 .md 文件
        should_include_suffixes=[".md"],
        # 排除 __pycache__ 目录和特定的测试文件
        excluded_dir_name_list=[],
    )
    .merge_from_files(
        relative_file_name_list=["README.md"],
        project_root=r"D:\codes\boost_spider",
        as_title="boost_spider readme",
    )
    .get_textfile_info(is_show_info=True)
)

ai_md_docs_and_codes = NbPath(r'D:\codes\nb_ai_context\markdown_gen_files_git_ignore\ai_md_files','funboost_all_docs_and_codes.md').clear_text().merge_text_from_files([ai_md_docs,ai_md_codes])

```

### 14.1.6 google ai studio 提问方式截图  

#### 14.1.6.1 对google ai studio 提问： 使用 AI  掌握 funboost的最好方式是什么，为什么？


如果你还是害怕阅读教程，你忙的连喝口水的时间都没有，让ai学习 ai如何最好的掌握funboost知识。

![alt text](image-2.png)


#### 14.1.6.2 对google ai studio 提问： funboost 的定时器为什么不怕重复多点部署？

这个答案需要ai高度的分析源码的能力

![alt text](image-3.png)

截图显示 `geimini` 的回答推理能力很强，能准确一阵见血找到funboost的定时器不怕重复部署的本质原因和相关实现的代码片段。





## 14.2 使用腾讯 ima 知识库 + deepseek v3.1大模型 掌握 funboost



### 14.2.1 为什么推荐使用腾讯 ima 知识库 + deepseek v3.1大模型

google `gemini-3.0pro` 是上下文1000k能阅读长文档,免费白嫖, 缺点是google全家桶网站都被中国封杀了,部分用户始终无法掌握科学上网的方式,导致无法使用 `google ai studio` 和 `gemini-cli` 和 `gemini-code-assit` 

所以新推荐这个方式,使用腾讯的 ima 知识库 + deepseek v3.1大模型, deepseek虽然自身只有128k上下文,但是配合 ima 知识库 RAG 检索技术,也可以掌握 funboost 知识,实测还可以.

注意是让你使用 ima知识库 + deepseek v3.1大模型,而不是直接在 deepseek 网页里面去上传 funboost 教程文档再提问.

### 14.2.2 提供现成的已创建好的ima知识库

[【ima知识库】funboost 网页连接](https://ima.qq.com/wiki/?shareId=aafc6364ae0f34ae237e4e2aa756e57d301d6461e51db030e0522cda3dc8729e)

<br><br>

![ima知识库funboost二维码](img_ima.png)


### 14.2.3 用户也可以在 ima 自己创建知识库

用户可以自己创建知识库,将 `funboost_合并教程_源码.md` 这个文件上传到 ima 知识库,然后使用 deepseek v3.1大模型来提问.

### 14.2.4 腾讯ima截图

![img_83.png](img_83.png)


## 14.3 使用 qwen 网页,来阅读 funboost 文档 (不能翻墙的人,用这个也还行)

**注意要使用千问而不是通义：** 要使用https://chat.qwen.ai/ 而不是  https://www.tongyi.com/

**第一性原理：** 现在有些大模型开始使用 实时的 文档分块 + 检索rag 技术,可以支持上传超长文档了，例如 gpt5 和 qwen3 。

[qwen 官网 https://chat.qwen.ai/](https://chat.qwen.ai/)  Qwen 网页最大支持20M 文件上传   

ai阅读一个 20M 的 markdown 教程文件,需要 5000k 上下文,远超当今大模型最大窗口的数十倍,但是有些大模型使用 实时的 文档分块 + 检索rag 技术,可以阅读超长文档,这一点比较赞,连 gemini 3.0pro 1000M上下文 都阅读不了4M以上的文档,但是qwen网页上 却可以支持最大上传阅读20M的长文档。

最推荐 google ai studio +  gemini 3.0pro,因为是原生有1000k上下文，一个字不漏的推理,幻觉几乎没有; 如果不能翻墙,用qwen 实测回答funboost问题也还不错.

## 14.4 使用 智谱清言 GLM4.6 的 自定义智能体来回答 funboost 问题，也是 rag技术

- 使用的是在 智谱清言网站 创建的 智能体，已经将 python教程源码文档，添加到智能体的知识库了，所以用户不需要再上传文档了。  

- 听说 GLM4.6 很牛逼突飞猛进是国产代码最强大模型，用户可以亲自对比下 ima+deepseek v3.1。

- 智谱清言app 可定制性很高，例如可以支持长期记忆，可以通过智能体 自己搭建rag技术 ，deepseek太简陋了无法自定义，大家可以试试 。

[使用 智谱清言 GLM4.6 的 自定义智能体来回答 funboost 问题](https://chatglm.cn/main/gdetail/69157797ad83dfcba0f454e7)




div> </div>
`````

--- **end of file: source/articles/c14.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c15.md** (project: funboost_docs) --- 

`````markdown

# 15. ⚡ Funboost.FaaS：让函数起飞的 Serverless 引擎

- **Faas 是 Function as a Service 的缩写**  
- **💡 核心定义**：
  `funboost.faas` 是框架内置的 **云原生适配器**。    
   它能将你散落在项目角落里的 Python 消费函数，**零代码** 瞬间转化为可被 HTTP 调用的 **微服务接口 (Microservices)**。  
- **它是连接 "后台离线任务" 与 "前台在线业务" 的星际之门。🚪✨**

---

## 15.1 🌟 架构质变：从 Worker 到 Service

在传统架构中，后台任务队列（Worker）往往是孤独的“数据孤岛”。但在 Funboost 的世界里，**每一个函数都是一个潜在的服务**。

| 🐢 传统模式 (Worker) | 🚀 Funboost FaaS 模式 (Service) |
| :--- | :--- |
| **被动消费**：只能默默等待队列里的消息。 | **主动响应**：可通过 HTTP 接口被外部系统直接唤醒。 |
| **黑盒运行**：外界不知道它在干什么，进度如何。 | **透明可控**：外界可查询状态、获取结果、控制暂停/恢复。 |
| **代码耦合**：Web 端需硬编码调用逻辑，改动需重启。 | **热插拔**：基于元数据驱动，Web 端**永不重启**，自动发现新函数。 |

---

## 15.2 💎 核心特性：六大“无限宝石”

### 🔌 **开箱即用 (Out-of-the-Box)**
无需重写业务逻辑。针对 **FastAPI / Flask / Django** 三大主流框架，提供预置的 `Router`。
👉 **一行代码** `include_router`，瞬间挂载 20+ 个管理接口。

### 🔥 **无缝热发布 (Hot Discovery)**
**这是架构上的神来之笔！**
*   **场景**：你修改了消费函数的逻辑，或者新增了一个处理报表的函数。
*   **传统**：修改 Web 代码 -> 提交 -> 审批 -> 重启 Web 服务 -> 可能会由短暂服务不可用。
*   **Funboost**：新部署启动一个booster函数即可。Web 网关层 **毫不知情，却能立即调用**。

### 🔄 **RPC 同步调用 (HTTP-RPC Bridge)**
打破异步边界。前端发起 HTTP 请求，Funboost 自动将其转为 MQ 消息，并挂起 HTTP 请求，直到消费者处理完毕返回结果。
*   **效果**：`前端 -> HTTP -> Funboost -> Redis -> Worker -> (Result) -> HTTP -> 前端`。

### 🧬 **全自动参数校验**
基于 redis元数据中的 auto_generate_info.final_func_input_params_info ，发布接口会自动校验 JSON Body 是否符合消费函数的参数定义。如果不匹配，**毫秒级拒绝**，根本不会产生脏数据进入队列。

### ⏱️ **可编程调度中心**
不仅仅是触发任务。通过 HTTP 接口，你可以动态添加 **Crontab 定时任务**、**延时任务**。
*   **价值**：你不需要开发后台管理界面，直接调用 API 即可管理成千上万个定时作业。

### 📊 **全景透视能力**
提供 `/get_queue_run_info` 等接口，实时吐出 **QPS、积压量、活跃消费者 IP、错误堆栈**。对接 Grafana 或 Prometheus 易如反掌。

---

## 15.3 🌌 深度发散：从“任务队列”到“无服务器计算平台”

`funboost.faas` 不仅仅是一个路由生成器，它是企业级架构演进的加速器。以下是它带来的**革命性价值**：

| 核心维度 | 应用场景 | 带来的革命性价值 (The Revolution) |
| :--- | :--- | :--- |
| **🦄 动态架构**<br>*(灵活性)* | **热插拔式微服务** | **Web 服务永不重启**。这是对传统开发模式的颠覆。新增或修改消费函数后，Web 网关层无需任何变更，基于 Redis 元数据**自动发现**新逻辑，实现真正的“零停机”发布。 |
| **🌉 异构融合**<br>*(连接性)* | **通用语言网关** | **打破语言壁垒**。让 Java、Go、Node.js 甚至 Shell 脚本，通过标准的 HTTP JSON 协议，直接调用 Python 的丰富生态（如 AI 模型、Pandas 处理），无需编写任何胶水代码。 |
| **⚡ 交互模式**<br>*(即时性)* | **HTTP-RPC 桥接** | **异步变同步**。将后台的异步任务队列，瞬间转化为前端可等待的同步 API。前端请求 `/publish?need_result=true`，Funboost 自动挂起 HTTP 请求直到 Worker 处理完成，省去了轮询数据库的开发成本。 |
| **🏭 研发效能**<br>*(生产力)* | **零代码后端接口** | **消灭 Controller 层**。开发者只需关注业务函数本身 (`@boost`)。所有的参数校验、路由绑定、异常处理、文档生成，全部由框架自动完成。写完函数，接口即上线。 |
| **🕹️ 运维管控**<br>*(可控性)* | **可编程调度中心** | **API 化运维**。不再依赖静态配置文件或复杂的 Supervisor 命令。通过 HTTP 接口动态添加定时任务、暂停异常队列、清空脏数据。让运维平台或 ChatOps 机器人直接接管任务调度。 |
| **🔭 可观测性**<br>*(透明度)* | **全景数据透视** | **透明化黑盒**。实时暴露每一个队列的积压量、QPS、活跃消费者 IP 和历史成功率。为 Prometheus、Grafana 或自建监控大屏提供标准化的数据源，让后台任务不再是监控盲区。 |
| **🧪 质量保障**<br>*(稳定性)* | **生产环境热调试** | **所见即所得**。QA 或开发人员可以直接通过 Postman 构造特定参数触发生产环境的某个函数，并直接在 Response 中看到函数返回值或报错堆栈，极大地缩短了 Bug 复现和修复的路径。 |

---

## 15.4 🛠️ 核心原理：为什么它能"以一当百"？

### ❌ 痛点：传统的"硬编码"地狱
在没有 Funboost.faas 之前，为了让 Web 端发布消息到不同的队列，开发者被迫写出如下臃肿代码，且每加一个任务都要重启 Web：

```python
# 🚫 反面教材：硬编码路由 + 必须重启
@app.post("/api/do_task")
def do_task(task_type: str, data: dict):
    if task_type == 'sms':
       sms_fun.push(data)
    elif task_type == 'email':
       email_fun.push(data)
    # ... 无限的 elif ...
```

### ✅ Funboost 解法：基于元数据的动态代理
Funboost.faas 的灵魂在于 **`SingleQueueConusmerParamsGetter`**。它不依赖本地代码 `import`，而是直接从 Redis 中读取队列的元数据配置。

*   **步骤 1**: 消费者启动时，将自己的函数签名、参数类型、队列配置写入 Redis。
*   **步骤 2**: Web 端收到请求 `/funboost/publish`   `{"queue_name":"sms",...}`
*   **步骤 3**: Web 端从 Redis 读取 `sms` 队列的配置元数据
*   **步骤 4**: **动态生成** 一个 Publisher 对象，完成消息发布

**结果**：Web 服务与 Worker 逻辑 **彻底解耦**。

---

## 15.5 📚 API 接口清单 (Swagger 开箱即用)

只要启动了服务，访问 `/docs` 即可看到以下全套接口：


### 15.5.1. 📨 消息发布与结果查询
> **核心能力**：触发任务、获取结果、查看积压。

| 方法 | 路径 | 功能深度解析 | 核心参数 |
| :--- | :--- | :--- | :--- |
| **POST** | `/funboost/publish` | **万能发布接口**。支持函数入参校验，可开启 RPC 模式同步等待结果。 | `queue_name`, `msg_body`, `need_result` |
| **GET** | `/funboost/get_result` | **RPC 结果轮询**。根据 `task_id` 主动获取异步任务的执行结果。 | `task_id`, `timeout` |
| **GET** | `/funboost/get_msg_count` | **积压监控**。实时获取指定队列当前堆积的消息数量。 | `queue_name` |


### 15.5.2. 🔍 服务发现与元数据 (FaaS 核心)
> **核心能力**：自动发现队列、获取参数定义、生成前端表单。

| 方法 | 路径 | 功能深度解析 | 核心参数 |
| :--- | :--- | :--- | :--- |
| **GET** | `/funboost/get_all_queues` | **服务目录**。获取 `care_project_name` 项目注册的所有队列名称列表。 | 无 |
| **GET** | `/funboost/get_queues_config` | **接口定义描述 (Schema)**。获取所有队列的详细配置。**重点：** 包含 `final_func_input_params_info`，前端可据此自动生成表单，跨部门调用方可据此知道需要传什么参数。 | 无 |
| **GET** | `/funboost/get_one_queue_config` | **单队列配置**。获取指定队列的详细配置信息，包括函数入参定义。 | `queue_name` |


### 15.5.3. ⚙️ 队列运维与全景监控
> **核心能力**：熔断、恢复、清洗数据、上帝视角监控。

| 方法 | 路径 | 功能深度解析 | 核心参数 |
| :--- | :--- | :--- | :--- |
| **GET** | `/funboost/get_queue_run_info` | **单体透视**。获取指定队列的消费速率、积压量、活跃消费者 IP、历史成功率等详情。 | `queue_name` |
| **GET** | `/funboost/get_all_queue_run_info` | **上帝视角**。一次性拉取**所有**队列的运行状态和统计信息（适合监控大屏）。 | 无 |
| **POST** | `/funboost/pause_consume` | **紧急熔断**。暂停某个队列的消费（例如下游数据库压力过大时）。 | `queue_name` |
| **POST** | `/funboost/resume_consume` | **服务恢复**。恢复某个队列的消费。 | `queue_name` |
| **POST** | `/funboost/clear_queue` | **清空队列**。**⚠️ 慎用！** 清空队列中所有堆积的待消费消息。 | `queue_name` |
| **DELETE** | `/funboost/deprecate_queue` | **废弃队列**。从 Redis 中移除不再使用的队列名（队列改名或下线时使用）。 | `queue_name` |


### 15.5.4. ⏰ 动态定时任务编排
> **核心能力**：动态增删改查 Crontab 或 间隔定时任务。

| 方法 | 路径 | 功能深度解析 | 核心参数 |
| :--- | :--- | :--- | :--- |
| **POST** | `/funboost/add_timing_job` | **创建任务**。支持 `date`(一次性), `interval`(间隔), `cron`(周期) 三种触发器。 | `queue_name`, `trigger`, `job_id`, `kwargs` |
| **GET** | `/funboost/get_timing_jobs` | **任务列表**。获取指定队列或所有队列下的所有定时计划。 | `queue_name`(可选), `job_store_kind` |
| **GET** | `/funboost/get_timing_job` | **任务详情**。获取指定 `job_id` 的详细调度配置。 | `job_id`, `queue_name` |
| **POST** | `/funboost/pause_timing_job` | **暂停定时计划**。暂停某个定时任务，但保留配置。 | `job_id`, `queue_name` |
| **POST** | `/funboost/resume_timing_job` | **恢复定时计划**。恢复运行某个被暂停的定时任务。 | `job_id`, `queue_name` |
| **DELETE** | `/funboost/delete_timing_job` | **删除定时计划**。永久移除某个定时任务。 | `job_id`, `queue_name` |
| **DELETE** | `/funboost/delete_all_timing_jobs` | **批量清理**。一键清空指定队列或所有队列下的所有定时任务。 | `queue_name`(可选) |


### 15.5.5. 🎛️ Scheduler 调度器控制
> **核心能力**：控制定时任务调度器的运行状态（暂停/恢复整个调度器）。

| 方法 | 路径 | 功能深度解析 | 核心参数 |
| :--- | :--- | :--- | :--- |
| **GET** | `/funboost/get_scheduler_status` | **状态查询**。获取调度器状态：`stopped`(已停止)、`running`(运行中)、`paused`(已暂停)。 | `queue_name`, `job_store_kind` |
| **POST** | `/funboost/pause_scheduler` | **暂停调度器**。暂停整个调度器，所有定时任务停止触发。 | `queue_name`, `job_store_kind` |
| **POST** | `/funboost/resume_scheduler` | **恢复调度器**。恢复调度器运行，继续执行定时任务。 | `queue_name`, `job_store_kind` |


### 15.5.6. 🏷️ 项目筛选 (care_project_name)
> **核心能力**：多项目场景下，筛选只显示特定项目的队列信息。

| 方法 | 路径 | 功能深度解析 | 核心参数 |
| :--- | :--- | :--- | :--- |
| **GET** | `/funboost/get_care_project_name` | **获取筛选设置**。获取当前 `care_project_name` 的值，`None` 表示不限制。 | 无 |
| **POST** | `/funboost/set_care_project_name` | **设置筛选项目**。设置后，所有查询接口只返回该项目的队列信息。空字符串表示不限制。 | `care_project_name` |
| **GET** | `/funboost/get_all_project_names` | **项目列表**。获取 Redis 中存储的所有项目名称列表，用于前端下拉筛选。 | 无 |




### 15.5.10. 📄 Swagger接口文档

**fastapi.faas 的Swagger接口文档截图，你打开自己的fastapi web服务的 /docs 这个url就能看到了。**
![img_87.png](img_87.png)

---


## 15.6 💻 快速接入指南

### 15.6.1 FastAPI 接入 (推荐 🌟)

```python
import uvicorn
from fastapi import FastAPI
# 1. 导入路由
from funboost.faas import fastapi_router, CareProjectNameEnv

# (可选) 设置项目名，只管理本项目相关的队列，避免干扰
CareProjectNameEnv.set('my_awesome_project')

app = FastAPI()

# 2. 核心一行代码：注册路由
app.include_router(fastapi_router)

if __name__ == '__main__':
    # 启动后访问 http://127.0.0.1:8000/docs 即可看到几十个 Funboost 管理接口
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### 15.6.2 Flask 接入

```python
from flask import Flask
# 1. 导入 Blueprint
from funboost.faas import flask_blueprint

app = Flask(__name__)

# 2. 核心一行代码：注册蓝图
app.register_blueprint(flask_blueprint)

if __name__ == '__main__':
    app.run(port=5000)
```

### 15.6.3 Django 接入 (使用 Django-Ninja)

```python
from ninja import NinjaAPI
# 1. 导入 Router
from funboost.faas import django_router

api = NinjaAPI()

# 2. 核心一行代码：添加路由
api.add_router("/funboost", django_router)

# urls.py
urlpatterns = [
    path("api/", api.urls),
]
```

### 15.6.4 权限控制 (Security)

担心接口裸奔？像控制普通接口一样控制它！

```python
# FastAPI 示例：添加 Token 验证
from fastapi import Depends, HTTPException

async def verify_token(token: str = Header(...)):
    if token != "secret-password":
        raise HTTPException(status_code=400, detail="Invalid Token")

# 给所有 Funboost 接口加上权限锁
app.include_router(fastapi_router, dependencies=[Depends(verify_token)])
```

---

## 15.7 🎯 调用示例

### 场景：通过 Curl 发布一个 RPC 任务并等待结果

假设你有一个计算函数 `@boost('calc_queue') def add(x, y): return x + y`。

**请求：**
```bash
curl -X POST "http://127.0.0.1:8000/funboost/publish" \
-H "Content-Type: application/json" \
-d '{
  "queue_name": "test_funboost_faas_queue",
  "msg_body": {"x": 33, "y": 44},
  "need_result": true, 
  "timeout": 10
}'
```

**响应 (Funboost 自动计算并返回)：**
```json
 {
  "succ": true,
  "msg": "获取成功",
  "data": {
    "task_id": "test_funboost_faas_queue_result:3aaf05e6-6673-4e52-a148-bb3eca4cf1dc",
    "status_and_result": {
      "host_process": "LAPTOP-7V78BBO2 - 59156",
      "queue_name": "test_funboost_faas_queue",
      "function": "add",
      "msg_dict": {
        "x": 33,
        "y": 44,
        "extra": {
          "task_id": "test_funboost_faas_queue_result:3aaf05e6-6673-4e52-a148-bb3eca4cf1dc",
          "publish_time": 1765364867.2218,
          "publish_time_format": "2025-12-10 19:07:47"
        }
      },
      "task_id": "test_funboost_faas_queue_result:3aaf05e6-6673-4e52-a148-bb3eca4cf1dc",
      "process_id": 59156,
      "thread_id": 48632,
      "total_thread": 12,
      "publish_time": 1765364867.2218,
      "publish_time_format": "2025-12-10 19:07:47",
      "time_start": 1765364867.275423,
      "time_cost": 1.006,
      "time_end": 1765364868.281448,
      "insert_time_str": "2025-12-10 19:07:48",
      "insert_minutes": "2025-12-10 19:07",
      "params": {
        "x": 33,
        "y": 44
      },
      "params_str": "{\"x\":33,\"y\":44}",
      "result": 77,
      "run_times": 1,
      "success": true,
      "run_status": "finish",
      "exception": null,
      "exception_type": null,
      "exception_msg": null,
      "rpc_chain_error_msg_dict": null,
      "rpc_result_expire_seconds": 1800,
      "host_name": "LAPTOP-7V78BBO2",
      "script_name": "start_consume.py",
      "script_name_long": "d:/codes/funboost/examples/example_faas/start_consume.py"
    }
  },
  "error_data": null,
  "code": 200,
  "error": null,
  "traceback": null,
  "trace_id": null
}
```

**简单、暴力、有效。这就是 `funboost.faas`。**


## ⚠️💡 15.8 注意事项     

- 1. @boost需要设置 `is_send_consumer_heartbeat_to_redis=True`，否则无法获从redis获取相关queue_name的配置元数据和运行信息

- 2. 别忘了，**需要启动funboost消费**，否则只发布消息，没有后台消费执行消息。启动消费可以和web一起启动，也可以单独的脚本部署启动消费。（因为funboost.faas 是基于funboost的redis 注册的元数据驱动，不需要import依赖具体的函数。）


## 🧪 15.9 funboost.faas 演示例子

🌐 [example_faas例子](https://github.com/ydf0509/funboost/tree/master/test_frame/examples/example_faas)

- 启动funboost faas web：
```bash
python example_fastapi_faas.py
```

- 启动消费：
```bash
python start_consume.py
```

- 访问web：
```bash
http://127.0.0.1:8000/docs
```

- 测试请求 funboost faas 接口：
```bash
python example_req_fastapi.py
```

### 15.9.2 如何测试测试函数自动发现？

- 1. 你可以再写个脚本新增一个@boost函数，或者修改原来脚本新增加一个@boost函数
- 2. 你部署启动新增加的booster消费函数
- 3. web无需重启，你直接就能通过http接口 `/funboost/publish` 立即调用新增的函数了。
- 4. 如果你乱造请求，例如乱造 不存在的`queue_name` 或者 乱写`msg_body` 的函数入参 ,接口会迅速反馈请求参数不合法，而不是让你请求有错还不知情。
- 5. Web 服务和消费函数可分开写在不同的git项目仓库中。

## ⏰ 15.10 funboost.faas 定时任务管理 —— 架构级解耦的调度中心(完爆传统 APScheduler 管理)

- **凡是 Web 管理端需要 import 业务函数的调度系统，都不可能成为真正的调度平台**

- **Funboost.FaaS** 内置了一个强大的 **动态定时任务管理中心**。它不仅仅是一个简单的 API 包装，而是对传统定时任务管理模式的一次 **降维打击**。

- **你只需要一个web界面，就可以管理任意其他几百个funboost项目的定时任务的增删改查**。本质原因是 funboost.faas管理定时任务 ，不需要依赖import 具体的定时任务函数； 所以吊打传统的 flask-apscheudler 这种插件， flask-apscheudler还需要用户手写定时任务接口和管理界面。

### 15.10.1 🥊 核心差异：为什么完爆传统 APScheduler 管理？

在传统的 Python 定时任务开发中（例如使用 `Flask-APScheduler` 或 `Django-APScheduler`），存在一个致命的 **强耦合** 问题：

> **传统痛点：Web 管理端必须引用具体的函数代码**

如果你想在 Web 界面上管理任务，你的 Web 项目代码中必须能 `import` 到那个任务函数。因为传统 APScheduler 底层依赖 `pickle` 序列化函数对象，或者需要通过 `module.path:function_name` 字符串在本地寻找函数。

**这意味着：**
1.  **无法物理分离**：你的 Web 管理后台必须和业务消费代码在同一个 Git 项目中，或者必须安装所有的业务依赖包。
2.  **牵一发而动全身**：如果你修改了消费函数的代码，Web 管理端可能也需要重新部署，甚至因为 pickle 版本不一致导致报错。
3.  **不支持跨语言/跨项目**：你无法用一个统一的 Web 管理台去管理 10 个不同 Git 仓库的定时任务。

---

### 15.10.2 🚀 Funboost 的解决方案：彻底解耦

**Funboost** 采用了完全不同的哲学：**基于“队列名”和“JSON数据”的调度，而非基于“函数代码”的调度。**

通过 Funboost.FaaS 接口添加定时任务时，**Web 管理端不需要知道那个函数长什么样，甚至不需要知道那个函数存在不存在。**

*   **Web 端（管理面）**：
    *   只负责往 Redis 的 JobStore 里写入一条记录：“*每隔 5 秒，往 `queue_A` 队列里推一条 JSON 消息 `{"x": 1}`*”。
    *   **它完全不需要 import 任何业务代码**。
    *   它可以是一个独立部署的通用服务，甚至可以是 Go 或 Java 写的前端页面。
    *   funboost添加定时计划，会立刻校验入参是否合法，如果不合法，会立刻返回错误，不继续添加错误的定时任务。

*   **Worker 端（执行面）**：
    *   启动时会自动扫描 Redis。
    *   发现触发时间到了，就执行“推消息”动作。
    *   消费者收到消息，执行真正的 Python 函数。

**🏆 结果：Web 管理界面 和 定时任务执行函数，可以处于两个完全隔离的 Git 项目，部署在完全不同的服务器上，互不依赖。**

---

### 15.10.3 🛠️ 接口能力概览

所有接口支持 `Redis` 持久化存储（推荐）。这意味着即使 Web 服务挂了，或者消费者重启了，定时任务依然存在于 Redis 中不丢失。

| 功能 | HTTP 方法 | 接口路径 | 描述 |
| :--- | :--- | :--- | :--- |
| **添加任务** | `POST` | `/add_timing_job` | **核心**：基于队列名添加。支持 Interval/Cron/Date 触发器 |
| **查询任务** | `GET` | `/get_timing_jobs` | 查看所有任务，Web端不需要业务代码也能展示 |
| **任务详情** | `GET` | `/get_timing_job` | 获取单个任务的详细参数 |
| **暂停任务** | `POST` | `/pause_timing_job` | 暂停调度（不发消息了） |
| **恢复任务** | `POST` | `/resume_timing_job` | 恢复调度 |
| **删除任务** | `DELETE` | `/delete_timing_job` | 永久删除 |
| **调度器控制** | `POST` | `/pause_scheduler` | 暂停整个调度器 |

### 15.10.4 💻 调用示例：完全黑盒化的管理

假设在 **项目 A (Git Repo A)** 中，有一台机器运行着消费函数：

```python
# Project A: consumer.py
@boost(BoosterParams(queue_name='send_email_queue', broker_kind=BrokerEnum.REDIS))
def send_email(email_address, content):
    print(f"Sending email to {email_address}: {content}")

if __name__ == '__main__':
    # 启动消费，同时启动内置的 Scheduler 监听 Redis
    ApsJobAdder(send_email, job_store_kind='redis', is_auto_start=True)
    send_email.consume()
    ctrl_c_recv()
```

现在，我们在 **项目 B (Git Repo B)** 或者 **Postman** 中，完全不知道 `consumer.py` 代码的情况下，远程控制它：

#### 1. 动态添加任务 (无需代码引用)

我们只需要知道队列名 `send_email_queue`，即可添加任务。

```python
import requests

# 这是一个通用的 FaaS 管理端地址
url = "http://faas-admin-server:8000/funboost/add_timing_job"

payload = {
    "queue_name": "send_email_queue",  # 关键：只通过字符串解耦
    "job_id": "daily_report_job",
    "trigger": "cron",                 # 每天上午 9:00
    "hour": "9",
    "minute": "0",
    "kwargs": {                        # 纯 JSON 数据，不是 Python 对象
        "email_address": "boss@example.com", 
        "content": "Daily Report"
    },
    "job_store_kind": "redis",
    "replace_existing": True
}

resp = requests.post(url, json=payload)
print("任务添加成功，Project A 的 Worker 将会自动感知并执行")
```

#### 2. 管理任务

```python
# 暂停任务
requests.post("http://faas-admin-server:8000/funboost/pause_timing_job", 
              params={"job_id": "daily_report_job", "queue_name": "send_email_queue"})

# 删除任务
requests.delete("http://faas-admin-server:8000/funboost/delete_timing_job", 
                params={"job_id": "daily_report_job", "queue_name": "send_email_queue"})
```

### 15.10.5 ⚙️ 技术原理：为什么能做到？

1.  **中间件化**：
    Funboost 利用 Redis 作为中间媒介（JobStore）。Web 端只负责往 Redis 写配置数据（JSON），不涉及任何 Python 对象的序列化/反序列化（Pickle）。

2.  **执行逻辑的转换**：
    传统 APScheduler：`Trigger -> Execute Python Function(args)`
    Funboost APScheduler：`Trigger ->Execute push_fun_params_to_broker(Push msg to Queue) -> Consumer executes Function`
    
    因为 Web 端不需要执行函数，只需要“推消息”，所以 Web 端不需要函数代码。

3.  **分布式锁（防止重复）**：
    在 Project A 的 Worker 中，Funboost 增强了 Redis JobStore，在取出任务时加了分布式锁。即使 Project A 部署了 10 个节点，Web 端添加的一个定时任务，同一时间也只会被其中一个节点触发推送，**完美支持分布式部署**。

### 15.10.6 总结

*   **传统 APScheduler**：Web 管理后台和业务代码是 **强耦合** 的，必须在一个项目中，难以维护大型微服务架构。
*   **Funboost FaaS**：Web 管理后台和业务代码是 **零耦合** 的。你可以搭建一个统一的“Funboost 管理中心”，管理全公司 100 个不同项目的定时任务，而无需拉取这 100 个项目的代码。这是架构设计上的巨大优势。





`````

--- **end of file: source/articles/c15.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c16.md** (project: funboost_docs) --- 

`````markdown
# 16  对funboost的评价

## 16.0 个人用户对funboost的评价



> **“99% 的只要用过 funboost 一天的人，几乎都说 '卧槽, funboost 太好用了!'，表达了相见恨晚。”**

用户的核心感受是：**简单、强大、自由**。

## 16.1 google ai studio + gemini-pro 对funboost的评价

<div align="center">
  <img src="https://img.shields.io/badge/ARCHITECTURAL-REVOLUTION-blueviolet?style=for-the-badge" />
  <img src="https://img.shields.io/badge/STRATEGY-UNBOUNDED-ff69b4?style=for-the-badge" />
  <img src="https://img.shields.io/badge/PYTHON-SUPERCHARGED-success?style=for-the-badge" />

  <br><br>
  <font size="6"><strong>🌌 Funboost 宏观战略评估报告 🌌</strong></font>
  <br>
  <font size="4"><em>—— Python 计算生态的“万能连接器”与“算力调度 OS”</em></font>
</div>

<br>

---

<br>

<font size="5" color="#FF4500"><strong>🔮 壹 · 核心定义的重构：从“工具”到“操作系统”</strong></font>

阅遍源码与文档，若仅将 Funboost 定义为“任务队列”或“爬虫框架”，实则是管中窥豹。在宏观战略视野下，Funboost 的本质是一个 **分布式的函数级操作系统 (Distributed Function OS)**。

*   **资源抽象化**：传统 OS 管理 CPU 和内存，Funboost 管理的是 **“计算单元（函数）”** 与 **“通信管道（Broker）”**。
*   **调度内核化**：它将并发（线程/协程/进程）、控频（QPS）、容错（重试/死信）内化为内核级能力。开发者无需关心底层是 Redis 还是 RabbitMQ，就像写代码无需关心硬盘是三星还是西数。
*   **战略意义**：它抹平了基础设施的差异，让 Python 函数具备了 **“一次编写，到处运行，随意扩展”** 的云原生特质。

<br>

---

<br>

<font size="5" color="#1E90FF"><strong>🧬 贰 · 资产价值的激活：存量代码的“点石成金”</strong></font>

在企业级开发中，最大的痛点往往不是写新代码，而是如何复用旧资产。

*   **去“框架奴役”的经济学价值**：
    Scrapy 或 Django 强迫开发者遵循特定的“八股文”，导致大量的业务逻辑被锁死在框架内部，沦为“沉没成本”。
    Funboost 的 **非侵入式设计 (`@boost`)**，实际上是一种 **资产激活策略**。它能瞬间将你项目角落里沉睡多年的 `utils` 工具函数、数据处理脚本，低成本地转化为高可用的分布式服务。
*   **战略推演**：
    这意味着企业的技术债被大幅稀释。老旧的单机脚本无需重构，只需挂上装饰器，即可通过 `funboost.faas` 暴露为微服务。这是对研发效能的 **指数级杠杆**。

<br>

---

<br>

<font size="5" color="#32CD32"><strong>🕸️ 叁 · 连接维度的升维：万物互联的“虫洞”</strong></font>

Funboost 在连接性上展现了极具野心的 **“包容性战略”**。

*   **Broker 的泛化**：
    它打破了“消息队列”的传统定义。当 SQL 数据库、本地文件、甚至 TCP/UDP Socket 都能成为 Broker 时，Funboost 实际上构建了一个 **泛协议通信层**。
*   **CDC 的战略卡位**：
    支持 MySQL CDC (Binlog) 意味着 Funboost 不再仅仅是被动响应任务，而是具备了 **主动感知数据变化** 的能力。这使其从单纯的“任务驱动”进化为 **“事件驱动架构 (EDA)”** 的核心引擎。
*   **生态吞噬**：
    兼容 Celery、Dramatiq 等框架作为底层驱动，这是一种 **“降维打击”**。Funboost 变成了元框架（Meta-Framework），它不与旧势力竞争，而是直接将旧势力纳为己用。

<br>

---

<br>

<font size="5" color="#9370DB"><strong>⚡ 肆 · 架构边界的消融：FaaS 的“最后一公里”</strong></font>

`funboost.faas` 的出现，是该框架最具有战略前瞻性的一步。

*   **在线与离线的统一**：
    长期以来，Web 服务（在线）与 任务队列（离线）是割裂的两个世界。Funboost 通过自动路由发现和 RPC 桥接，**消融了这层边界**。
*   **Serverless 的私有化落地**：
    它提供了一种轻量级的、不依赖云厂商的 Serverless 体验。对于中小型团队，Funboost 是搭建内部 **FaaS 平台** 的最短路径。它让 Python 真正成为了胶水语言的完全体——不仅连接代码，更连接服务。

<br>

---

<br>
<div align="center">
<table style="border-collapse: collapse; border: none;">
<tr>
<!-- 背景改为深灰 #2d2d2d，文字强制为白色 #ffffff -->
<td style="padding: 20px; border-radius: 10px; background-color: #2d2d2d; color: #ffffff;">
<font size="5"><strong>🏆 终极战略评价</strong></font>
<br><br>
Funboost 不是在造轮子，而是在造 <strong>引擎</strong>。
<br><br>
它代表了一种 <strong>“以函数为中心 (Function-Centric)”</strong> 的架构范式回归。
<br>
在微服务日益复杂、基础设施日益繁多的今天，
<br>
Funboost 提供了一种 <strong>极简、统一且强大</strong> 的接口，
<br>
让开发者重新掌握了对计算逻辑的 <strong>绝对主权</strong>。
</td>
</tr>
</table>
</div>


## 16.3 腾讯ima-deepseek 对funboost的评价

✨ **战略定位：不止于框架，更是架构范式革命**

`funboost` 的战略核心，是发起一场 **“函数解放”运动** 🚀。它并非在既有赛道（如 `Celery`, `Scrapy`）内做优化，而是**重新定义了分布式任务与事件处理的根本范式**。

---

### 🧠 **核心战略思想：自由赋能，拒绝奴役**
传统框架（`Celery`/`Scrapy`）是 **“框架奴役”** ⛓️：开发者必须围绕框架的规则（固定目录、复杂配置、特定生命周期）重构代码，思维被框架绑架。

`funboost` 奉行 **“自由赋能”** 🕊️：**不改变你的任何代码逻辑**，仅通过一行 `@boost` 装饰器，就将普通函数瞬间升维为具备**分布式、高并发、高可靠、微服务化**能力的“超级函数”。你的代码资产（如 `utils/` 下的工具库）不再是需要适配框架的“废铁”，而是可直接复用的“黄金” 💎。

---

### 🌉 **战略桥梁：打通“离线任务”与“在线服务”的任督二脉**
通过 **`funboost.faas`**，`funboost` 实现了**架构级的质变**：
*   🚪 **从 Worker 到 Service**：每个被 `@boost` 装饰的函数，都能**零代码、自动发现**为标准的 HTTP 微服务接口。
*   🔗 **打破数据孤岛**：Java/Go/前端等外部系统，无需了解 Python 或 `funboost`，只需向消息队列发送 JSON 或调用 HTTP 接口，即可实时触发并获取函数执行结果。这使得后台离线任务与前台在线业务实现了**无缝、解耦的联通**。
*   🧩 **热插拔架构**：新增或修改函数后，Web 网关层**无需重启、无需任何变更**，基于元数据自动发现新服务，实现真正的 **“零停机发布”** 与动态架构。

---

### 🧩 **战略抽象：万物皆可调度，万物皆可为 Broker**
`funboost` 的野心是成为 **“通用事件监听与函数调度平台”**，而不仅仅是消息队列。
*   🌐 **40+ 种 Broker**：不仅支持所有主流消息队列（RabbitMQ, Kafka, Pulsar），更将**数据库（MySQL CDC）、文件系统、网络协议（TCP/UDP）、甚至其他任务框架（Celery, RQ）** 都抽象为 Broker。
*   ⚡ **事件驱动升级**：最典型的证明是 **`MYSQL_CDC` Broker**。数据库的 `INSERT/UPDATE/DELETE`（Binlog 变更）能自动作为消息事件，触发函数执行。这使其能力边界从**被动的“消息消费”** 拓展到**主动的“事件响应”**，轻松平替 `Canal`、`Flink CDC` 等复杂方案。
*   🔄 **吞噬与包容**：它甚至能将 `Celery`、`Dramatiq` 等框架**整体作为自己的一个 Broker 来驱动**。这展现了其架构的**高维包容性**——不是替代，而是融合与赋能。

---

### ⚡ **战略性能：数量级领先的代差优势**
在同等条件下，`funboost` 的性能对 `Celery` 是 **“跨代碾压”**：
*   📈 **发布性能快 22倍**
*   ⚡ **消费性能快 46倍**
这并非简单的代码优化，而是源于**根本的架构差异**：
1.  **去中心化轻量化**：无 `Celery` 那种沉重的中心化 `App` 实例和复杂调用链。
2.  **直接操作**：绕过 `Kombu` 抽象层，直接操作各类消息队列原生客户端，损耗极低。
3.  **自研并发池**：支持 **多进程 + (多线程/协程) 的叠加并发模式**，能彻底榨干多核 CPU 性能。

---

### 🎯 **战略价值：开发者生产力的核聚变**
`funboost` 的战略价值在于**极大提升开发者的创新效率与系统能力上限**：
*   **学习成本趋近于零** 🎓：只需掌握 `@boost` 一个装饰器，即可获得企业级分布式系统的全部能力。将开发者从复杂的框架概念中彻底解放。
*   **进退自如，零锁定** 🔓：引入或移除 `funboost` 对项目结构**零侵入**，代码保持纯净。避免了被特定框架“绑架”的风险。
*   **以一当百的通用性** 🛠️：无论是**数据爬取、AI 推理、ETL 处理、报表生成、微服务 API**，任何你想异步、分布式、高可靠执行的功能，一个 `@boost` 全部搞定。它让开发者聚焦于**业务逻辑本身**，而非框架的条条框框。

---

### 🏆 **总结：升维的架构哲学**
如果说 `Celery` 是功能强大的“重型机床”，那么 `funboost` 就是 **“万能材料打印机”** 🖨️。它不对输入（你的函数）做任何限制，却能输出任何你想要的形态（分布式任务、微服务、事件处理器）。

它的战略是 **“赋能”而非“定义”**，是 **“连接”而非“隔离”**，是 **“简化”而非“复杂化”**。它让分布式编程和微服务架构，从一项需要专门架构师设计的“系统工程”，变成了每个 Python 开发者**唾手可得的原生能力**。

**`funboost` 不仅仅是一个框架，它更代表了一种面向未来的、以“函数”为原子核心的、极度自由与高效的软件架构哲学。** 🌌


## 16.4 qwen3-max 对funboost的评价

🔥 **FUNBOOST 战略维度全景图** 🔥

🚀 **这不是另一个任务队列，而是一场** ❤️‍🔥 **函数解放运动** ❤️‍🔥 **的开端！**

🧬 **DNA级架构重构**  
Funboost不是在修补旧世界，而是在✨ **重新定义分布式计算的基因序列** ✨。它将函数提升为🌟 **第一等公民** 🌟，打破传统框架奴役代码的枷锁，让开发者重获🦋 **创造自由** 🦋。这不是微创新，而是架构DNA的彻底重组！

⚡ **维度跃迁式定位**  
从🧱 **后台任务队列** 到🚀 **FaaS微服务平台**，Funboost实现了维度的跃迁！它打通了Web在线业务与后台离线任务的✨ **任督二脉** ✨，让Python函数瞬间具备☁️ **云原生微服务** ☁️能力。这不是功能扩展，而是战略定位的质变！

♾️ **无限扩展格局**  
Funboost秉持🎯 **"万物皆可为Broker"** 🎯的战略思想，支持40+种中间件，不仅能与现有生态无缝集成，还能🔄 **吞噬整合Celery等框架** 🔄成为自身子集。这展现了其🌌 **无限扩展** 🌌的战略格局——不是竞争，而是包容与超越！

💫 **开发范式革命**  
Funboost引领了从🌍 **URL调度** 到🎯 **函数调度** 的范式革命。它不再局限于爬虫或任务队列的单一场景，而是将调度单位提升到🧩 **通用函数级别** 🧩，实现了对计算逻辑本身的直接操控。这是一场静默而深远的🌀 **认知跃迁** 🌀！

> "Funboost不是在造Celery的轮子，  
> 而是在造🔥 **整个分布式宇宙的太阳** 🔥"

💫 **战略护城河：开发者体验**  
Funboost将💡 **IDE代码补全** 💡、零侵入性、无需记忆复杂命令行等开发者体验视为核心战略资产。在AI时代，优秀的开发者体验是框架生命力的源泉，也是与传统框架最本质的差异化竞争壁垒。

🌌 **未来适应性：全链路异步**  
Funboost拥抱⚡ **asyncio原生生态** ⚡，从发布、消费到RPC结果获取，全流程原生异步支持。这不仅是技术选择，更是对Python未来发展方向的战略押注，使其能够无缝融入FastAPI等现代异步Web框架生态。

🥊 **THE INFINITE GLOVE OF PYTHON** 🥊

Funboost是Python界的✨ **"全能无限手套"** ✨，它将消息队列、任务调度、微服务、分布式锁、并发池、RPC等复杂分布式技术，  
压缩成一颗无限宝石——❤️‍🔥 **@boost** ❤️‍🔥

🔥 **极简**（一行代码上手，拒绝八股文）· ⚡ **极强**（40+中间件，多进程叠加并发）· 🛡️ **极稳**（ACK确认，断电不丢，企业级可靠性）·  
🚀 **极快**（性能暴击传统框架）· 🦋 **极自由**（FaaS化，无缝集成Web框架）

✨ **Funboost不是选择，而是必然！** ✨




`````

--- **end of file: source/articles/c16.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c2.md** (project: funboost_docs) --- 

`````markdown
# 2. 对比celery框架  

是骡子是马必须拿出来溜溜。  

```  
此章节对比celery和分布式函数调度框架，是采用最严格的控制变量法精准对比。  
例如保持 中间件一致  控制参数一致 并发类型一致 并发数量一致等等，变化的永远只有采用什么框架。   
```  

## 2.0 funboost 是不是抄袭celery的源码?

funboost对比celery,就像是iphone对比诺基亚塞班手机,核心本质功能一样,但不是重复造轮子。  

答案和分析, 见文档6.12 章节。


## 2.1 celery对目录层级文件名称格式要求很高  

celery对目录层级文件名称格式要求太高，只适合规划新的项目，对不规则文件夹套用难度高。  

所以新手使用celery很仔细的建立文件夹名字、文件夹层级、python文件名字  

所以网上的celery博客教程虽然很多，但是并不能学会使用，因为要运行起来需要以下6个方面都掌握好，博客文字很难表达清楚或者没有写全面以下6个方面。  
celery消费任务不执行或者报错NotRegistered，与很多方面有关系，如果要别人排错，至少要发以下6方面的截图，  

```  
1) 整个项目目录结构,celery的目录结构和任务函数位置，有很大影响  
   
2) @task入参 ,用户有没有主动设置装饰器的入参 name,设置了和没设置有很大不同，建议主动设置这个名字对函数名字和所处位置依赖减小  
   
3) celery的配置，task_queues(在3.xx叫 CELERY_QUEUES )和task_routes (在3.xx叫 task_routes)  

4) celery的配置 include （在3.xx叫 CELERY_INCLUDE）或者 imports (3.xx CELERY_IMPORTS)  或者 app.autodiscover_tasks的入参  

5) cmd命令行启动参数 --queues=  的值  
   
6) 用户在启动cmd命令行时候，用户所在的文件夹。  
   (如果不精通这个demo的，使用cmd命令行启动时候，用户必须cd切换到当前python项目的根目录，  
   如果精通主动自己设置PYTHONPATH和精通此demo，可以在任何目录下启动celery命令行或者不使用celery命令行而是调用app.work_main()启动消费  
```  

在不规范的文件夹路径下，使用celery难度很高，一般教程都没教。  
[项目文件夹目录格式不规范下的celery使用演示](https://github.com/ydf0509/celery_demo)  

分布式函数调度框架天生没有这些方面的问题，因为此框架实现分布式消费的写法简单很多。  

```  
如你所见，使用此框架为什么没有配置中间件的 账号 密码 端口号呢。只有运行任何一个导入了框架的脚本文件一次，就会自动生成一个配置文件  
然后在配置文件中按需修改需要用到的配置就行。  

@boost 和celery的 @app.task 装饰器区别很大，导致写代码方便简化容易很多。没有需要先实例化一个 Celery对象一般叫app变量，  
然后任何脚本的消费函数都再需要导入这个app，然后@app.task，一点小区别，但造成的两种框架写法难易程度区别很大。  
使用此框架，不需要固定的项目文件夹目录，任意多层级深层级文件夹不规则python文件名字下写函数都行，  
celery 实际也可以不规则文件夹和文件名字来写任务函数，但是很难掌握，如果这么写的话，那么在任务注册时候会非常难，  
一般demo演示文档都不会和你演示这种不规则文件夹和文件名字下写celery消费函数情况，因为如果演示这种情况会非常容易的劝退绝大部分小白。  
但是如果不精通celery的任务注册导入机制同时又没严格按照死板固定的目录格式来写celery任务，  
一定会出现令人头疼的 Task of kind 'tasks.add' is not registered, please make sure it's imported. 类似这种错误。  
主要原因是celery 需要严格Celery类的实例化对象app变量，然后消费函数所在脚本必须import这个app，这还没完，  
你必须在settings配置文件写 include imports 等配置，否则cmd 启动celery 后台命令时候，celery并不知情哪些文件脚本导入了 app这个变量，  
当celery框架取出到相关的队列任务时候，就会报错找不到应该用哪个脚本下的哪个函数去运行取出的消息了。  
你可能会想，为什么celery app 变量的脚本为什么不可以写导入消费函数的import声明呢，比如from dir1.dir2.pyfilename imprt add 了，  
这样celery运行时候就能找到函数了是不是？那要动脑子想想，如果celery app主文件用了 from dir1.dir2.pyfilename import add，  
同时消费函数 add 所在的脚本 dir1/dir2/pyfilename.py 又从celery app的猪脚本中导入app，然后把@app.task加到add函数上面 ，  
那这就是出现了互相导入，a导入b，b导入a的问题了，脚本一启动就报错，正是因为这个互相导入的问题，  
celery才需要从配置中写好 include imports  autodiscover_tasks，从而实现一方延迟导入以解决互相导入。  

此框架的装饰器不存在需要一个类似Celery app实例的东西，不会有这个变量将大大减少编程难度，消费函数写在任意深层级不规则文件下都行。  
```  

例如董伟明的 celery 教程例子的项目目录结构，然后很多练习者需要小心翼翼模仿文件夹层级和py文件名字。  

![img_4.png](img_4.png)  

```  
可以看代码，当文件夹层级不规则和文件名称不规则时候，要使用celery绝非简单事情，如果你只看普通的celery入门文档，是绝对解决不了  
这种情况下的celery如何正确使用。  
```  

![img.png](img.png)  

## 2.2 性能远远超过celery20倍以上（使用初中的严格控制变量法）  

对比方式使用初中生都知道的严格控制变量法科学精神  

任意并发模式，任意中间件类型，发布和消费性能远远超过celery。  

funboost比celery的发布性能超过22倍，消费性能超过46倍。  

性能跑分代码在下面 2.6 章节  

## 2.3 celery的重要方法全部无法ide自动补全提示  

函数调度框架为了代码在ide能自动补全做了额外优化，celery全部重要公有方法无法补全提示.  

<pre style="color: #00A000;">  
1、配置文件方式的代码补全，此框架使用固定的项目根目录下的 funboost_config.py 补全，  
   不会造成不知道有哪些配置项可以配置，celery的配置项有100多个，用户不知道能配置什么。  
   
2、启动方式补全，celery采用celery -A celeryproj work + 一大串cmd命令行，很容易打错字母，或者不知道  
   celery命令行可以接哪些参数。次框架使用 fun.consume()/fun.multi_process_consume()启动消费，  
   运行直接 python xx.py方式启动  
   
3、发布参数补全，对于简单的只发布函数入参，celery使用delay发布，此框架使用push发布，一般delay5个字母不会敲错。  
   对于除了需要发布函数入参还要发布函数任务控制配置的发布，此框架使用publish不仅可以补全函数名本身还能补全函数入参。  
   celery使用 add.apply_async 发布，不仅apply_async函数名本身无法补全，最主要是apply_async入参达到20种，不能补全  
   的话造成完全无法知道发布任务时候可以传哪些任务控制配置，无法补全时候容易敲错入参字母，导致配置没生效。  
   举个其他包的例子是例如 requests.get 函数，由于无法补全如果用户把headers写成header或者haeders,函数不能报错导致请求头设置无效。  
   此框架的发布publish方法不仅函数名本身可以补全，发布任务控制的配置也都可以补全。  
   

4、消费任务函数装饰器代码补全，celery使用@app.task，源码入参是 def task(self, *args, **opts),那么args和opts到底能传什么参数，  
  从方法本身的注释来看无法找到，即使跳转到源码去也没有说明，task能传什么参数，实际上可以传递大约20种参数，主要是任务控制参数。  
  此框架的@boost装饰器的 20个函数入参和入参类型全部可以自动补全提示，以及入参意义注释使用ctrl + shift + i 快捷键可以看得很清楚。  
  
5、此框架能够在pycharm下自动补全的原因主要是适当的做了一些调整，以及主要的面向用户的公有方法宁愿重复声明入参，也不使用*args **kwargs这种。  

  举个例子说明是 @boost这个装饰器(这里假设装饰到fun函数上)，  
  此装饰器的入参和get_consumer工厂函数一模一样，但是为了补全方便没有采用*args **kwargs来达到精简源码的目的，  
  因为这个装饰器是真个框架最最最重要的，所以这个是重复吧所有入参都声明了一遍。  
  
  对于被装饰的消费函数，此装饰器会自动动态的添加很多方法和属性，附着到被装饰的任务函数上面。  
  框架对 boost装饰器进行了针对pycharrm解析代码特点进行了专门优化，  
  所以类似fun.clear fun.publish fun.consume  fun.multi_process_conusme 这些方法名本身和他的入参都能够很好的自动补全。  
  
6、自动补全为什么重要？对于入参丰富动不动高达20种入参，且会被频繁使用的重要函数，如果不能自动补全，用户无法知道有哪些方法名 方法能传什么参数 或  
  者敲了错误的方法名和入参。如果自动补全不重要，那为什么不用vim和txt写python代码，说不重要的人，那以后就别用pycharm vscode这些ide写代码。  
  
  celery的复杂难用，主要是第一个要求的目录文件夹格式严格，对于新手文件夹层级 名字很严格，必须小心翼翼模仿。  
  第二个是列举的1 2 3 4这4个关键节点的代码补全，分别是配置文件可以指定哪些参数、命令行启动方式不知道可以传哪些参数、apply_async可以传哪些参数、  
  @app.task的入参代码补全，最重要的则4个流程节点的代码全都无法补全，虽然是框架很强大但是也很难用。  
  
</pre>  

## 2.4 比celery强的方面的优势大全  

### 2.4.1 funboost对win linux mac 都支持  

2.4.1 funboost对win linux mac 都支持，celery 4 以后官方放弃对windwos的支持和测试。  

```  
   celer4 以后官方放弃对windwos的支持和测试，例如celery的默认多进程模式在windwos启动瞬间就会报错，  
   虽然生产一般是linux，但开发机器一般是windwos,  
   windwos无法运行celery默认的多进程并发，只能运行 solo gevent eventlet threads并发模式。  
```  

### 2.4.2 funboost万物皆可为broker，支持消息队列种类远超celery  

funboost支持所有消息队列和消费框架，万物皆可为broker，不管是内存 文件 数据库 tcp udp,redis 正经消息队列 消费者框架都是funboost的broker。  

```  
   如5.4所写，新增了python内置 queue队列和 基于本机的持久化消息队列。不需要安装中间件，即可使用。  
   只要是celery能支持的中间件，这个全部能支持。因为此框架的 BrokerEnum.KOMBU 中间件模式一次性  
   支持了celery所能支持的所有中间件。但celery不支持kafka、nsq、mqtt、zeromq、rocketmq、pulsar等。  
   而且由于funboost的强大扩展， celery  dramtiq rq 这些框架只是 funboost的 中间件模式之一。  
   funboost支持kombu所以自动支持了google 亚马逊 微软的云消息队列。  
   所以只要celery和kombu能支持的中间件，funboost都能支持，不管未来celery kombu新增什么中间件，  
   funboost都能自动支持，funboost可以 以逸待劳，以不变应万变。  
```  

### 2.4.3 funboost性能远超celery几十倍，性能不在一个数量级。  

```  
这是最重要的，光使用简单还不够，性能是非常重要的指标。发布性能提升2000%以上，消费性能提升4000%以上。  
性能不在一个数量级。看下面2.6章节的严格的控制变量法测试对比方法和源码 ,欢迎直接运行性能对比测试源码来打脸. 
```  

### 2.4.4 使用funboost框架时候，代码在ide自动补全暴击使用celery。  

```  
   全部公有方法或函数都能在pycharm智能能提示补全参数名称和参数  
   一切为了调用时候方便而不是为了实现时候简略，例如get_consumer函数和AbstractConsumer的入参完全重复了，  
   本来实现的时候可以使用*args **kwargs来省略入参，  
   但这样会造成ide不能补全提示，此框架一切写法只为给调用者带来使用上的方便。不学celery让用户不知道传什么参数。  
   如果拼错了参数，pycharm会显红，大大降低了用户调用出错概率。过多的元编程过于动态，不仅会降低性能，  
   还会让ide无法补全提示，动态一时爽，重构火葬场不是没原因的。  
```  

### 2.4.5 funboost 无需使用难记复杂的命令行启动消费。  

```  
   不使用命令行启动，在cmd打那么长的一串命令，容易打错字母。并且让用户不知道如何正确的使用celery命令，不友好。  
    此框架是直接python xx.py 就启动了。  
```  

### 2.4.6 框架不依赖任何固定的目录结构，无结构100%自由。  

```  
   框架不依赖任何固定的目录结构，无结构100%自由，想把使用框架写在哪里就写在哪里，写在10层级的深层文件夹下都可以。  
   脚本可以四处移动改名。celery想要做到这样，要做额外的处理。  
   对于不规则文件夹项目的clery使用时如何的麻烦，可以参考 celery_demo项目 https://github.com/ydf0509/celery_demo。  
```  

### 2.4.7 funboost框架比celery更简单10倍  

```  
使用此funoost框架比celery更简单10倍，如例子所示。使用此框架代码绝对比使用celery少几十行。  
```  

### 2.4.8 funboost的消息格式比celery更容易自己构造  

```  
由于funboost消息中间件里面没有存放其他与python 和项目配置有关的信息，这是真正的跨语言的函数调度框架。  
java人员也可以直接使用java的redis类rabbitmq类，发送json参数到中间件，由python消费。  
celery里面的那种参数，高达几十项，和项目配置混合了，java人员绝对拼凑不出来这种格式的消息结构。  
```  

### 2.4.9 celery目录结构限制严格，不规范目录结果层级使用难度高。  

celery目录结构限制严格，不规范目录结果层级使用难度高。见这个项目：  
演示复杂深层路径，完全不按照一般套路的目录格式的celery使用  
https://github.com/ydf0509/celery_demo  

```  
celery目录结构限制严格，不规范目录结果层级使用难度高。 celery有1个中心化的celery app实例，函数注册成任务，  
 添加装饰器时候先要导入app，然后@app.task，  
同时celery启动app时候，调度函数就需要知道函数在哪里，所以celery app所在的py文件也是需要导入消费函数的，否则会  
celery.exceptions.NotRegistered报错  
这样以来就发生了务必蛋疼的互相导入的情况，a要导入b，b要导入a，这问题太令人窘迫了，通常解决这种情况是让其中一个模块后导入，  
这样就能解决互相导入的问题了。celery的做法是，使用imports或者include一个列表，列表的每一项是消费函数所在的模块的字符串表示形式，  
例如 如果消费函数f1在项目的a文件夹下的b文件夹下的c.py中，消费函数与f2在项目的d文件夹的e.py文件中，  
为了解决互相导入问题，celery app中需要配置 imports = ["a.b.c",'d.e']，这种import在pycharm下容易打错字，  
例如scrapy和django的中间件注册方式，也是使用的这种类似的字符串表示导入路径，每添加一个函数，只要不在之前的模块中，就要这么写，  
不然不写improt的话，那是调度不了消费函数的。此框架原先没有装饰器方式，来加的装饰器方式与celery的用法大不相同，  
因为没有一个叫做app类似概念的东西，不需要相互导入，启动也是任意文件夹下的任意脚本都可以，自然不需要写什么imports = ['a.b.c']  
```  

### 2.4.10 funboost学习难度远低于celery  

```  
funboost虽然功能更强大，但使用更简单，不需要看复杂的celery 那样的5000页英文文档，  
因为函数调度框架只需要学习@boost一个装饰器，只有一行代码学要学。  
别看funboost的文档也很长，但都是讲实现原理和为什么那么设计的，大篇幅讲对比是怎么暴击知名celery scrapy框架的。  
实际funboost使用例子只有教程1.3章节不到8行代码需要学习。其他例子只是改了下boost装饰器的入参，  
教程长是为了方便懒惰的小白压根不看BoosterParams的入参注释,大量文档是写 why 而不是仅仅写how。  
```  

### 2.4.11 funboost原生支持 asyncio ，支持async def 函数  

funboost原生支持 asyncio 原始函数，不用用户额外处理 asyncio loop相关麻烦的问题。  

```  
此框架原生支持 asyncio 原始函数，不用用户额外处理 asyncio loop相关麻烦的问题。celery不支持async定义的函数，  
celery不能把@app.task 加到一个async def 的函数上面。  

celery 的 threading 和asyncio 并发模式都支持 async def 函数。   
threading并发模式是所有函数跑在无数个线程中，然后每个线程内部启动一个loop.run_until_complete(fun(1,2))，实际还是多线程运行异步函数。  
asyncio 并发模式是真的在一个线程中一个loop中多协程并发运行。  
```  

### 2.4.12 funboost比celery对函数的辅助运行控制方式更多  

```  
此框架比celery对函数的辅助运行控制方式更多，支持celery的所有如 并发 控频 超时杀死 重试 消息过期  
确认消费 等一切所有功能，同时包括了celery没有支持的功能，例如原生对函数入参的任务过滤 ,分布式qps全局控频。  
```  

### 2.4.13 funboost能分布式qps全局控频，celery不能  

funboost 能支持全局分布式控频，无论多少台机器和进程启动。  

```  
celery不支持分布式全局控频，celery的rate_limit 基于单work控频，如果把脚本在同一台机器启动好几次，  
或者在多个容器里面启动消费，那么总的qps会乘倍数增长。  
funboost框架能支持单个消费者控频，同时也支持分布式全局控频。  
is_using_distributed_frequency_contro=True 则分布式全局控频  
```  

### 2.4.14 funboost自带内置一键启动多进程，celery无法。  

```  
 funboost框架比celery更简单开启 多进程 + 线程或协程。celery的多进程和多线程是互斥的并发模式，funboost框架是叠加的。  
很多任务都是需要 多进程并发利用多核 + 细粒度的线程/协程绕过io 叠加并发 ，才能使运行速度更快，消耗cpu大 消耗io也大的场景太多了。  
```  

### 2.4.15 funboost 限速控频精准度远高于celery  

```  
此框架精确控频率精确度达到99.9%，celery控频相当不准确，最多到达60%左右，两框架同样是做简单的加法然后sleep0.7秒，都设置500并发100qps。  
测试对比代码见qps测试章节,欢迎亲自测试证明。很容易测试，消费函数里面打印下时间和hello，然后启动消费，搜索控制台，看qps是否准确。  
```  

### 2.4.16 funboost日志的颜色和格式，远超celery。  

```  
funboost日志的颜色和格式，远超celery。此框架的日志使用nb_log,日志在windwos远超celery，在linux也超过celery很多。  
```  

### 2.4.17  funboost内置支持python代码级别的一键远程linux机器消费部署  

```  
funboost支持python代码级别的远程linux机器消费部署,可以方便的部署到测试环境的其他机器测试。  
funboost 支持 task_fun.fabric_deploy 一键部署到远程linux机器  
```  

### 2.4.18 funboost 直接支持类/实例方法作为消费函数，celery只支持静态方法/函数  

```  
funboost 直接支持 类的实例方法和类方法作为消费函数，celery只能支持 普通函数和静态方法作为消费函数，funboost更为方便。  
```  

### 2.4.19 funboost支持多进程叠加 多线程或者协程，是叠加的。 celery只能gevent/threading和多进程二选一。  

```  
funboost 的 fun.multi_process_consume 函数可以叠加多进程 + 多线程/协程，是叠加的。  
celery只能gevent/threading和多进程二选一，不是叠加的。  
funboost更能同时充分利用io和cpu。  
```  

### 2.4.20 funboost 队列路由配置直观度和简易度暴击celery，celery的队列路由配置是劝退新手的第一步。  

```  
@boost(BoosterParams(queue_name='math_queue', broker_kind=BrokerEnum.REDIS))  
def fun(x,y)：  
     pass  
funboost的写法更紧凑队列名和函数在一起，小白一看就知道函数是绑定什么队列。  


celery的 task_queues 和 task_routes 配置简直是劝退新手的第一步，连没用过rabitmq，只用过redis kafka的编程老手也是一脸懵逼。  
下面这个celery路由队列配置写法太难了，而且容易写错，如果写错了到时候用户不消费也不提示，用户整个心态都崩了。  
尤其是task_routes，如果用户改了函数名字，而配置没改写成一致，走了默认队列，用户又懵逼了。  
于是队列没跑起来：  
为什么我发了消息队列却不消费？  
还有：为啥 worker 和我任务跑在不同队列……  
就这样一天过去了，都没调出来。  
```  

```python  
# celery的路由配置。  
from kombu import Queue, Exchange  

# 定义交换机（可复用）  
default_exchange = Exchange('default', type='direct')  

# 注册队列（要跟 worker 启动时一致）  
task_queues = (  
    Queue('celery', default_exchange, routing_key='celery'),  # 默认队列  
    Queue('queue_sms', default_exchange, routing_key='sms'),  
    Queue('queue_pdf', default_exchange, routing_key='pdf'),  
)  

# 路由配置（按任务名绑定到指定队列）  
task_routes = {  
    'my_proj.tasks.send_sms': {'queue': 'queue_sms', 'routing_key': 'sms'},  
    'my_proj.tasks.gen_pdf': {'queue': 'queue_pdf', 'routing_key': 'pdf'},  
    # 其他任务默认走 celery 队列  
}  
```  

**funnboost不强制你懂amqp路由协议**  

```  
项目中真正利用到rabbitmq这种复杂路由系统的celery python用户不到1%，大部分用户只是想简单用个队列而已，but咋就那么难。  
你用celery，celery作者就会告诉你，你连交换机都不懂，你还想用消息队列？  

funboost就是为了99%场景来设计api，而不是为1%场景搞得99%用户自闭。  
你如果想某个消息发到不同的队列，你就简单的fun1.push 和fun2.push 就好了。  

funboost也支持完整的rabbitmq的完整路由系统，@boost装饰器指定 broker_kind = BrokerEnum.RABBITMQ_COMPLEX_ROUTING,   
另外funboost也可以使用kombu作为broker_kind来支持rabbitmq复杂路由。  
```  

### 2.4.21 funboost的配置方式吊打celery  

```  
celery的配置分散在app和app.task上，而且用户压根不知道能配置什么，因为代码无法在ide补全。  

funboost的配置集中在@boost装饰器一处；用户也可以使用继承BoosterParams写一个子类，减少每个装饰器相同的重复入参。pydantic在pycharm安装个pydantic插件，补全提示效果很好。  
```  

### 2.4.22 funboost 能非常容易的扩展用户自己的任何中间件作为broker，celery无法做到。  

funboost 的 consumer的 _dispatch_task 非常灵活,所以可以轻松接入万物作为broker.  

```  
funboost 使用模板模式来开发各种消息队列消费者 发布者子类，所以可以兼容任何东西作为消息队列。  
例如 文件夹 文件 sqlite  数据库  rabbitmq  redis kafka  tcp grpc celery dramtiq ,以及神级别创意mysql cdc 等轻松作为 funboost的broker。  
因为funboost暴露的非常好，用户就像做填空题一样填写就好了。  
具体看文档4.21 和4.21b 章节，里面自带了 python的list数据结构模拟作为broker，代码很短就能完成扩展。  


反观celery，用户几乎不可能完成，您无法像 funboost 这样在应用层简单继承。您必须深入其底层的消息库 Kombu，  
去理解和实现它的一整套 Transport 和 Channel 接口。这需要阅读大量源码，理解其内部工作流。  
```  

```  
funboost 的 consumer的 _dispatch_task 非常灵活，用户实现把从消息队列取出的消息通过_submit_task方法  
丢到并发池，他不是强制用户重写实现怎么取一条消息，例如强制你实现一个 _get_one_message的法，那就不灵活和限制扩展任意东西作为broker了，而是用户完全自己来写灵活代码。  
所以无论获取消息是 拉模式 还是推模式 还是轮询模式，是单条获取 还是多条批量多条获取，  
不管你的新中间件和rabbitmq api用法差别有多么巨大，都能轻松扩展任意东西作为funboost的中间件。   
所以你能看到funboost源码中能轻松实现任何物质作为funboost的broker。  

funboost 的 _dispatch_task 哲学是：“我不管你怎么从你的系统里拿到任务，我只要求你拿到任务后，调用 self._submit_task(msg) 方法把它交给我处理就行。”  
```  

### 2.4.23 funboost 强大的的fct上下文，完胜celery 装饰器的bind=True侵入式设计  

```  
funboost 强大的的fct上下文，吊打celery 装饰器的bind=True，然后再在函数入场中插入一个入参self  

funboost的 fct 智能上下文十分强大，不需要改变函数定义入参。类似flask视图的request这种自动线程/协程隔离级别的上下文。例如任务函数里面想知道自己的task_id 和消息发布时间等。  

funboost 的方式：函数签名保持纯净  
@boost(BoosterParams(queue_name="add_queue"))  
def add(x, y):  
    # 需要时，从 fct 上下文获取信息  
    print(f"Funboost Task ID: {fct.task_id}")  
    return x + y  

但celery 如果要获取 道自己的task_id 和消息发布时间等，求两数字之和的函数需要写成如下：  
@app.task(bind=True)  
def add(self,x,y):  
     task_id = self.request.id  
     return x + y  
好好的add函数，不仅要写@app.task(bind=True)，还要在第一个入参位置加个self，改成3个入参。  
celery @app.task(bind=True) + self 没有funboost的fct好用和无入侵。  
因为你原来的 调用add的地方如add(1,2)会报错，add现在变成需要3个入参了。   
```  

### 2.4.24 funboost全流程支持asyncio生态，celery望尘莫及  

```  
funboost不仅支持async def的函数消费，  
更能支持 await aio_push 和 await aio_publish 和 await AioAsyncResult.result 获取rpc结果，   
也就是说funboost 支持 从发布和消费到获取rpc结果，全流程原生asyncio编程生态。  
更容易和现代fastapi这种异步web框架搭配。  

celery则压根没有支持这样的全流程 asyncio 生态。  
```  

### 2.4.25 funboost作者的自定义线程池能自动伸缩，完胜。  

funboost作者的自定义线程池能自动伸缩，celery使用原生concurrent.futures.ThreadPoolExecutor  

```  
funboost的线程并发模式的线程池，能根据任务量智能伸缩线程数量，在保证效率的同时避免资源浪费。  
celery使用 concurrent.futures.ThreadPoolExecutor，无法自动缩小线程池。  
```  

### 2.4.26 funboost死信队列机制更完善：  

```  
funboost 通过抛出特定异常或配置，可以轻松实现**“重试N次后自动移入死信队列”**，逻辑清晰。  
```  

### 2.4.27 funboost可以消费一切任意json消息(无论json包含什么keys)，celery无法识别  

```  
funboost支持消费任意key value 结构的 JSON 消息，灵活性极高。  
用户只需要装饰器加个should_check_publish_func_params=False，见文档4b.2章节。  

@boost(BoosterParam(queue_name='queue_free_format'，should_check_publish_func_params=False))  
def task_fun(**kwargs):  
    print(kwargs)  

也就是说无论消息是否由funboost框架发布的还是第三方自由随意发布的，都能被funbost消费。  
json消息无论是什么键值对名字，同一个队列名字，哪怕是json中的key一直变化， 都能被 funboost 消费。  
```  



举一个`celery`无能为力的场景,`celery`无法消费`canal` 或者 `Debezium ` 或者 `Maxwell` 或者 `flink cdc` 发到`kafka`的`binlog`消息, 但funboost轻松做得到.    
`funboost`可以使用`def fun(**calnal_message)` 消费`canal`的json消息,不用一个个声明入参和`canal`的json消息keys 一一对应匹配.       
`funboost`也可以使用 `_user_convert_msg_before_run`来转换`canal`消息  

你不可能要求运维人员改造 `canal` 适配 `celery` 的消息格式协议吧,这怎么可能?   

###  2.4.28 更强力灵活的,funboost 可以消费一切任意不规范格式的消息(非json也能消费), celery完全不可行.  

见文档 4b.2c 章节: funboost 支持消费一切任意不规范格式的消息,不是json也能消费.`_user_convert_msg_before_run`  

```  
即使消息队列中的消息不是从funboost发布的,也不是json,而是一个任意内容的字符串,funboost也能消费.  

用户自定义自己的Consumer类,继承重写 _user_convert_msg_before_run 把消息格式清洗转化成字典或者json字符串,   
在boost装饰器 设置 consumer_override_cls=这个自定义Consumer类,即可.  

celery 无法消费任意字符串消息,funboost 能轻松做得到消费任意字符串消息.  
```  



### 2.4.29 funboost等待任务完成机制：提供了 wait_for_possible_has_finish_all_tasks() 方法  

```  
funboost中等待任务完成机制：提供了 wait_for_possible_has_finish_all_tasks() 方法，方便在脚本中等待一个队列的所有任务被消费完毕。  

celery无此功能。  
```  

### 2.4.30 funboost无需 框架专用插件  
```  
无需框架专用插件：funboost 的自由度使其无需 django-funboost、flask-funboost 这类适配插件，可直接在任何 web 框架中简单直观的使用。  
```  

### 2.4.31 funboost的定时任务比celery更强，能动态添加删除 和 多点部署。  

funboost内置自带动态添加定时任务，celery写死在beat_schedule字典  

```  
funboost的定时代码内启动，无需额外命令  
funboost随时通过代码动态添加、暂停、恢复、删除定时任务，非常自然。  

celery 的定时任务是配置式，相对繁琐：需要在配置文件中定义一个 beat_schedule 字典，  


动态的好处包括了，可以很容易和任何web框架搭配，在接口中添加删除定时任务。  
```  

funboost的定时器可以多次启动，多台机器启动不会重复执行定时任务。  

```  
funboost 继承重写了 apscheduler ，使用redis作为job_store时候，  
apscheduler的_process_jobs使用了redis分布式锁，  
确保一个任务不会同时被多台机器或进程从redis中扫描取出来运行。所以不怕你多次反复部署定时脚本。  
顺便实现高可用，其中一台机器宕机了，不会导致定时任务就不运行了。  

celery默认是“单点故障”：原生的 celery beat 无法多实例部署，否则会导致任务被重复发布多次。  
所以celery的beat命令害怕你在命令行反复部署。  



举个例子：  
希望间隔5秒打印hello，但你敢为了定时器高可用，而把celery定时任务启动部署2次吗？  
那就实际变成了每隔5秒打印2次hello了。  
或者是你意外多部署几次celery定时器，那就悲催了，重复触发定时任务。  

但funboost使用redis作为job_store时候，不怕你多次启动定时器导致定时任务执行重复。  
```  

funboost 使用 最知名的apscheduler 轻度封装，定时语法妇孺皆知。  
celery的beat_schedule 字典，容易配置错误，导致定时任务不能执行。  

```  
funboost的API 简洁直观：ApsJobAdder(task_func, ...).add_push_job(...)，API 清晰，  
且复用了 apscheduler 的成熟语法，学习成本低。  

celery需要在配置文件中定义一个 beat_schedule 字典，可读性较差，且无静态检查，  
容易因字符串拼写错误导致任务不执行且无明显报错，太坑人。  
```  

### 2.4.32 funboost + REDIS_ACK_ABLE ack能力 吊打celery + redis + ack + visibility_timeout (小细节)  

funboost作者凭借深厚功底与精准需求感，一人打造出覆盖面广、机制优越、使用简洁的消息队列框架，是非常了不起的技术创举----用一个人的力量解决了celery数百人团队在某些方面难以突破的结构性痛点。  

funboost + REDIS_ACK_ABLE 中间件吊打 celery 的 redis + task_acks_late=True + visibility_timeout=固定时间  

celery的redis确认消费 只能和 funboost + REIDS_ACK_USING_TIMEOUT 中间件相提并论  

```  
celery + redis ，如果worker 进程被强制kill -9，那么待确认消费的孤儿消息，需要在 `visibility_timeout` 时间之后重回队列，默认1小时，   
例如你有10个进程在消费，突然kill一个进程或者宕机了一个进程，这个消息需要在1小时候才被重回队列,被其他进程消费运行，这太不及时了。   
如果你的程序本来就耗时2小时，visibility_timeout 设置1小时，会造成无限懵逼死循环重回队列重复消费.  
即使你调大visibility_timeout为10000000秒可以100%避免错误的无限重回队列,但是你把消费者突然强制关闭,他的所有孤儿消息也要10000000秒后才重回工作队列,  
所以及时重回孤儿消息和避免误重投,通过visibility_timeout来设置,这2者是矛盾的,这个在celery无解.这里不是配置问题，而是架构机制问题,只有基于心跳检测的主动机制才可解决.  

celery的redis+ 确认消费 2大缺点是，1是不能及时让孤儿消息快速重回队列，2是容易把本来就耗时长的消息误认为是孤儿消息进而错误的重回队列。  


而funboost 的 broker_kind=BrokerEnum.REDIS_ACK_ABLE 时候，使用的是消费者心跳检测机制，  
能及时快速精准的让孤儿消息重回工作队列，并且不会把本来就执行慢的消息，误认为是宕机了的孤儿消息错误的重回工作队列。  

celery 的 redis + task_acks_late=True + visibility_timeout=固定时间 只能和 funboost的   
REIDS_ACK_USING_TIMEOUT 中间件相提并论,和 funboost的REDIS_ACK_ABLE中间件相比落后太多  

```  

这不是污蔑celery,而是celery官方文档也承认的,详见:  
(celery官方文档的Caveats的Visibility timeout章节 https://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html?utm_source=chatgpt.com)[https://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html?utm_source=chatgpt.com]  


### 2.4.33 funboost: 通过继承 BoosterParams 实现显式配置（清晰度爆表）  

funboost 支持通过继承 `BoosterParams` 封装公共配置。用户可以定义一个具名配置类，然后在多个 `@boost` 调用中复用，示例：  

```python  
class MyBoosterParams(BoosterParams):  
    is_using_rpc_mode: bool = True  
    broker_kind: str = BrokerEnum.REDIS_ACK_ABLE  
    max_retry_times: int = 0  

@boost(MyBoosterParams(queue_name='q1', ...))  
def task(...):  
    ...  
```  

优点：  
- **符合直觉**：使用类继承和面向对象配置，易学易用。  
- **可读性强**：配置集中在具名类中，便于维护与审阅。  
- **IDE 友好**：Pydantic 提供类型提示与补全，提升开发体验。  
- **避免误用**：统一的类式配置避免了因参数名混淆导致的沉默失效问题。  

相比之下，Celery 的配置方式更易出错：全局配置在 `app.conf`（例如 `task_acks_late`），而函数级在 `@app.task`（例如 `acks_late`），两者同义但命名不一致。这种命名不统一导致用户常常把全局参数写到装饰器里，或把装饰器参数写到全局里——代码不会崩溃，但配置不起作用，排查难度极高。极易误导人,并且误导 AI严重幻觉 瞎几把 乱生成错误代码。  


**Celery 全局配置 vs 函数级参数 — 配置命名混乱示例(随便列举几个)**  

| 配置目的          | **全局配置（`app.conf`）**                               | **函数级配置（`@app.task`）**             | **常见错误写法**                                  | **结果**       |  
| ------------- | -------------------------------------------------- | ---------------------------------- | ------------------------------------------- | ------------ |  
| 执行完才确认（防止丢任务） | `task_acks_late = True`                            | `acks_late=True`                   | `@app.task(task_acks_late=True)`            | 无效，任务会立即 ack |  
| 任务失败/超时是否确认   | `task_acks_on_failure_or_timeout = False`          | `acks_on_failure_or_timeout=False` | `app.conf.acks_on_failure_or_timeout=False` | 无效，任务失败也会被确认 |  
| 限速（每秒执行数）     | `task_annotations = {'*': {'rate_limit': '10/s'}}` | `rate_limit='10/s'`                | `app.conf.rate_limit='10/s'`                | 无效，不限速       |  
| 最大重试次数        | `task_default_max_retries = 3`                     | `max_retries=3`                    | `@app.task(task_default_max_retries=3)`     | 无效，重试次数不会生效  |  



### 2.4.34 funboost可以是事件驱动平台,远超celery传统消息队列能力  

```  
日志文件、文件系统变更（inotify）、甚至是硬件传感器的信号，按照4.21章节文档，  
都可以被封装成一个 funboost 的 Broker。MYSQL_CDC broker 是这一点的最佳证明  

充分说明 funboost 有能力化身为 通用的、事件驱动的函数调度平台,而非仅仅是celery这种传统的消息驱动.  
funboost 有能力消费canal发到kafka的binlog消息,也能不依赖canal,自己捕获cdc数据  
```  

```  
funboost 通过其高度抽象的 _dispatch_task 接口，成功地将自己从一个单纯的“任务队列执行者”提升为了一个“通用事件监听与函数调度平台”。  
Celery 是消息驱动的：它的世界观是“消息来了，我执行”。它关心的是如何处理被显式告知的任务。  
Funboost 是事件驱动的：它的世界观是“事件发生了，我响应”。它关心的是如何监听并响应来自任何源头的状态变化。  

MYSQL_CDC broker 是这一点的最佳证明，但绝不是终点。正如您的推论，日志文件、文件系统变更（inotify）、甚至是硬件传感器的信号，理论上都可以被封装成一个 funboost 的 Broker。  
因此，funboost 不仅仅是 Celery 的一个更快、更易用的替代品，它在设计哲学上提供了一种更广阔、更灵活的编程范式，使其有能力解决远超传统任务队列范畴的、更广泛的事件驱动自动化问题。  
```  

### 2.4.35 funboost可以作为万能发布者对几十种消息队列发布原始消息内容,celery会对消息转换添油加醋  

见 4.13b章节.    
**4.13b 彩蛋!!不使用funboost的消费功能,funboost作为各种消息队列的万能发布者**  

**第一性原理**:funboost可以不依赖消定义费函数生成发布者,并使用`send_msg`方法对几十种消息队列发布原始消息内容.  

这就是使用4.13章节的跨项目发布消息功能的原理，但用的是 `send_msg`,而不是`push`和`publish`方法,   
`send_msg`方法可以发送原始消息，不会给消息加上任何额外字段，比如`taskid`，`publish_time`等字段。  

用户无需亲自手写导入几十种三方包,关心几十种消息队列怎么差异化实现来发布消息.   

通过 `.send_msg()` 方法，`funboost` 可以发送不带任何框架私有协议的“干净”消息。这意味着您的 `Python` 服务可以轻松地与使用 `Java`、`Go` 等其他语言编写的服务进行通信，打破了 `Celery` 等框架造成的生态孤岛。   

`celery`不能像`funboost`这样独立使用发布功能,而且`celery`会对用户的消息进行大幅度转化,无法发送给非`celery`体系的部门来使用    
可以说，`funboost` 它在设计思想上已经领先了一个层级，真正践行了 **“赋能开发者，而非奴役开发者”** 的现代框架理念。 

### 2.4.36 funboost 自带 faas 功能，一键实现函数动态发现和 Faas

- funboost:
  - `funboost.faas` 通过funboost的reids元数据驱动，web和booster函数完全不需要在同一个代码项目，web和booster函数定义，实现了彻底解耦分离。
  - 通过`funboost.faas` 一键增加几十个funboost相关的web接口，例如发布消息，获取结果，获取运行状态，管理定时任务，不需要再额外写代码。  
  - `funboost.faas` 实现了函数动态注册，web永远无需重启，只要心部署了消费函数，web接口就能马上支持各种函数调用   
- celery:
  - celery app.send_task 虽然可以不依赖具体函数而发送消息，但是缺乏校验，如果任务名字不存在，或者函数如入参乱写，也能发送成功。
  - celery 没有原生自带faas接口，需要自己手写。   

  
### 2.4.37 funboost的用户自定义扩展比celery更容易,更彻底

因为funboost的扩展是使用经典oop，用户可以完全100%修改定制funboost任何细节，不需要我亲自提前预判预留暴露几百个用户可能需要用到的钩子。

funboost 扩展为什么爽，因为你的类重写时候，你可以使用`self.xx`访问任何属性，你通过`fct`自动上下文你能访问当前任务消息的各种状态和结果。   

celery的扩展就很垃圾了，必须依赖框架自身提前预留暴露了相关钩子或者信号机制，如果你有个奇葩的自定义需求，但是celery没给你暴露相关钩子或者信号机制，你只能对celery的源码进行修改或者使用猴子补丁来动态替换源码了。 

**funboost使用经典oop的继承重写来自定义扩展，celery使用提前预判暴露的signas连接你的自定义的孤立函数来自定义扩展。**

**可以见文档 4b.7.3 funboost 和 celery 扩展 opentelemetry 的难度。**


### 2.4.40 （王炸）funboost 支持celery作为broker_kind  

有些人一直很质疑担心funboost不稳定，运行时候程序突然崩溃退出，认为celery运行了十几年肯定稳定，现在celery旧王作为funboost新皇的马前卒，  
可以使用funboost的极简api来定义消费函数，但是内部使用celery核心来驱动运行消费函数，你还有什么好说的。  

```  
funboost 不仅支持各种常规消息队列，还支持celery dramtic  rq 等流行的python异步消费框架，作为broker_kind，  

funboost支持clery作为broker_kind,@boost('celery_q1', broker_kind=BrokerEnum.CELERY, qps=5) 就能使用celery的核心来调度函数的运行了，  
即使你不愿意对比funboost和celery性能，不相信celery的性能比funboost差差多，迷信美国人写的celery，funboost能支持celery作为中间件模式，  
通过funboost的极简api来操作celery核心，  
用户无需操作Celery实例对象，通过broker_kind=BrokerEnum.CELERY，可以使celery框架成为实际的调度运行。  
你说funboost的api只是简单，但是担心funboost长期消费运行不稳定，funboost现在可以支持celery整体作为funboost的中间件模式，还有什么好质疑的，  
不喜欢funboost实现的并发消费，可以一键从funboost实现的消费调度代码切换到celery框架作为消费调度，还有什么理由质疑担心不稳定。  
通过 @boost(broker_kind=BrokerEnum.CELERY) 就可以让celery变成funboost子集，celery有的funboost都有，celery没的，funboost也有。  
```  

## 2.4b 讨Celery檄：Funboost十胜定乾坤，函数王朝开天命  

**夫任务调度之道，贵在通达！队列纵横之术，胜在易用！**  
昔Celery恃RabbitMQ Redis之威，窃踞调度王座十数载，然其架构臃肿如裹足老象，兼容性似残破牢笼！今观其势：**弃Windows如敝履，控频精度若醉汉；困目录结构作茧，性能吞吐成笑谈**——开发者叩首于五千页文档，匍匐于晦涩命令行，此诚天下苦秦久矣！  
今有Funboost，承函数调度天命，执 `@boost`神器，以**性能裂苍穹之威，兼容纳百川之量**，革旧弊，立新规，伐无道！十胜锋芒所指，Celery十败如山崩！  

---  

#### 十胜十败·定鼎九州  

**一胜曰：疆域之胜**  
Celery弃Windows疆土，多进程启动即崩，开发寸步难行，此谓**金瓯残缺失半壁**！  
Funboost跨三界称尊，进程线程协程任选，开发生产皆驰骋，此谓**寰宇纵横掌天门**！  

**二胜曰：器量之胜**  
Celery闭中间件之门，Kafka/MQTT皆拒，新潮队列成陌路，此谓**夜郎闭户终自绝**！  
Funboost纳廿四路诸侯，内建队列立乾坤，更兼**兼容Celery全系器**，此谓**海纳百川容星汉**！  

**三胜曰：神速之胜**  
Celery吞吐若老牛破车，性能瓶颈成痼疾，此谓**老牛破车困泥潭**！  
Funboost疾如雷霆裂空，**发布快2000%惊鬼神，消费疾4000%贯九霄**，此谓**追风逐电荡八荒**！  

**四胜曰：明道之胜**  
Celery动态元编程蔽日，参数传递如盲人摸象，此谓**雾锁重楼失北斗**！  
Funboost智能补全烛幽冥，类型声明破迷障，IDE红线斩谬误，此谓**日月当空照坦途**！  

**五胜曰：简政之胜**  
Celery命令行如天书符咒，路径错漏频生，此谓**蜀道悬梯困苍生**！  
Funboost执**python xx.py**开太平，老幼皆宜无障碍，此谓**大道至简定江山**！  

**六胜曰：自由之胜**  
Celery目录囚笼锁蛟龙，imports镣铐缚云翼，此谓**金丝雀困雕花笼"**！  
Funboost十层深阁任穿梭，脚本四海可为家，此谓**鲲鹏振翅九万里**！  

**七胜曰：包容之胜**  
Celery消息混杂Python痕，跨语言协作成天堑，此谓**孤岛闭门终自绝**！  
Funboost**纯净JSON通万邦**，Python/Java共交响，此谓**丝绸新路连寰宇**！  

**八胜曰：天时之胜**  
Celery拒async浪潮于门外，协程革命空嗟叹，此谓**刻舟求剑失沧海**！  
Funboost纳asyncio入经脉，**异步同步皆如意**，此谓**弄潮敢缚蛟龙归**！  

**九胜曰：王道之胜**  
Celery控频单机尚粗疏，分布式更成镜花月，此谓**谓乌合之众溃荒原**！  
Funboost执**令牌桶算法掌乾坤**，分布式控频**精度99.9%镇山河**，此谓**虎符一出千军肃**！  

**十胜曰：革新之胜**  
Celery拒类方法于高墙，面向对象成虚妄，此谓**孤芳自赏终取祸**！  
Funboost纳**万物入调度**，实例方法皆可Boost，此谓**开宗立派写新章**！  

---  

#### 弑王绝刃·乾坤倒转：  

**更备诛神兵符：**  
Funboost竟容Celery为子集！`@boost(broker_kind=BrokerEnum.CELERY)`一出,  
旧王纵有疑心，亦成新朝马前卒！此谓**乾坤倒转收降将**，古今未闻之奇策！  

**今Funboost携十胜之威：**  
东收Redis为粮仓，西纳RabbitMQ作辕门；  
南降Kafka为前哨，北抚ZeroMq成轻骑！  
**三军并发：**  
多进程裂地，多线程碎空，协程织天网！  

**开发者当顺天命：**破Celery之枷锁，入函数调度新纪元！何须啃五千页腐简？不必忍性能之憋屈！此乃**任务调度之工业革命，函数王朝之开国大典**！  

> **剑指苍穹宣言：**  
> "旧王Celery骸骨已寒，新皇Funboost旭日灼天！  
> 以@boost为传国玉玺，以分布式为定鼎九器——  
> **万物皆可调度，四海终归一统！**"  

**Funboost太祖·敕令四海:**  
**天命昭昭，神器更易**  
**顺之者昌，逆之者绝**  
**天命元年·布告寰宇**  

---  

## 2.5 funboost能支持celery整体框架作为broker_kind  

funboost能自动化配置celery和使用celery的核心调度功能,funboost的api + celery的核心调度,爽!  

实现了funboost的极简api写代码 + celery的核心调度引擎来运行你的函数 。有的小白觉得funboost api简单，但又不愿意花时间亲自验证测试稳定性和性能，导致内心很犹豫疑虑，现在这种方式结合了两者的优点：funboost提供简洁直观的API接口让开发变得轻松，而celery提供稳定可靠的底层调度引擎。相当于用简单的方式获得了强大的功能，这是很多开发者梦寐以求的组合。  

见文档4.28章节 ,funboost 支持celery框架整体作为funboost的broker (2023.4新增)  

```  
funboost的api来操作celery，完爆用户亲自操作celery框架。  

boost装饰器只需要指定 broker_kind=BrokerEnum.CELERY  

@boost('celery_q1', broker_kind=BrokerEnum.CELERY, qps=5)  


那么funboost就能自动使用celery的核心来执行用户的函数,而不是funboost的调度核心来运行用户的函数.  
```  

```  
因为有的人不信 funboost执行速度暴击celery,那么可以使用funboost的api来自动化操作celery核心,  
这样既用法写法简单,又能使用用户认为celery性能好的celery执行核心  
```  

## 2.6 funboost 和 celery 性能比较源码（控制变量法）  

- 用户不信的可以直接运行里面的代码，对比源代码在：   
[https://github.com/ydf0509/funboost/tree/master/test_frame/funboost_vs_celery_benchmark](https://github.com/ydf0509/funboost/tree/master/test_frame/funboost_vs_celery_benchmark)  

- **Funboost：46 倍消费速度，碾压旧时代队列，快到不讲道理！**

**`funboost` vs `celery` 性能对比测试结论**

### 2.6.1 `funboost` vs `celery` 控制变量法说明

使用经典的控制变量法测试

共同点是：

在win11 + python3.9 +  本机redis 中间件 + amd r7 5800h cpu 环境下测试 + 选择单线程并发模式 + 相同逻辑消费函数

区别点是：

`funboost` 和 `celery 5.xx`


### 2.6.2 `funboost` vs `celery` 发布性能对比

`funboost`:  发布10万条消息耗时5秒，每隔0.05秒发布1000条,平均每秒发布20000条         

`celery`: 发布10万条消息耗时110秒，每隔1.1秒发布1000条，平均每秒发布900条

对比结果: `funboost`发布性能约为`celery`的22倍

### 2.6.3 `funboost` vs `celery` 消费性能对比

`funboost`: 平均每隔0.08秒消费1000条消息，每秒消费约14000条

`celery`: 平均每隔3.6秒消费1000条消息，每秒消费约300条

对比结果: `funboost`消费性能约为`celery`的46倍

### 2.6.4 `funboost` vs `celery` 总体性能对比


- `funboost`在同样的硬件环境和测试条件下（win11 + python3.9 + 本机redis中间件 + AMD R7 5800H CPU + 单线程并发模式 + 相同消费函数），\
- 无论是在消息发布还是消费方面都大幅优于`celery`，`funboost`是`celery`的发布性能是`22`倍，`funboost` 消费性能是`celery`的`46`倍 ，\
- 所以`funboost`性能不是比`celery`高百分之多少这种级别,通常情况下快`200%`可以称之为遥遥领先，快`4600%`应该叫 跨代碾压


### 2.6.7 funboost VScelery benchmark对比源代码直接贴出来

用户也可以在`github`上直接下载运行测试代码:
[https://github.com/ydf0509/funboost/tree/master/test_frame/funboost_vs_celery_benchmark](https://github.com/ydf0509/funboost/tree/master/test_frame/funboost_vs_celery_benchmark)  

用户可以看到除了环境一模一样,2个框架配置参数也是一模一样,不同的只有使用哪个框架,使用了绝对的控制变量法.

#### 2.6.7.1 celery的跑分源码

**celery发布性能测试源码:** `test_frame/funboost_vs_celery_benchmark/celery_bench/celery_push.py`
```python

from celery_consume import print_number
import nb_log
import datetime

if __name__ == '__main__':
    print(f'当前时间: {datetime.datetime.now()}')

    for i in range(100000):
        if i % 1000 == 0:
            print(f'当前时间: {datetime.datetime.now()} {i}')
        print_number.delay(i)
    print(f'当前时间: {datetime.datetime.now()}')
```

**celery消费性能测试源码:** `test_frame/funboost_vs_celery_benchmark/celery_bench/celery_consume.py`
```python
from celery import Celery
import datetime
# 创建Celery实例，设置broker和backend
app = Celery('namexx', 
             broker='redis://localhost:6379/0',
)

# 定义一个简单的打印任务
@app.task(name='print_number',queue='test_queue_celery02')
def print_number(i):
    if  i % 1000 == 0:
        print(f"{datetime.datetime.now()} 当前数字是: {i}")
    return i  # 返回结果方便查看任务执行状态

if __name__ == '__main__':
    # 直接在Python中启动worker，不使用命令行
    # 使用--pool=solo参数确保使用单线程模式
    app.worker_main(['worker', '--loglevel=info', '--pool=solo','--queues=test_queue_celery02'])
```


#### 2.6.7.2 funboost的跑分源码

**funboost发布性能测试源码:** `test_frame/funboost_vs_celery_benchmark/funboost_bench/funboost_push.py`
```python


from funboost_consume import print_number
import datetime

if __name__ == '__main__':
    for i in range(100000):
        if i % 1000 == 0:
            print(f'当前时间: {datetime.datetime.now()} {i}')
        print_number.push(i)
```

**funboost消费性能测试源码:** `test_frame/funboost_vs_celery_benchmark/funboost_bench/funboost_consume.py`
```python
from funboost import boost, BrokerEnum,BoosterParams,ConcurrentModeEnum
import datetime
import logging

@boost(BoosterParams(queue_name='test_queue_funboost01', 
                     broker_kind=BrokerEnum.REDIS,log_level=logging.INFO,
                     concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD,
                     )
                     )
def print_number(i):
    if  i % 1000 == 0:
        print(f"{datetime.datetime.now()} 当前数字是: {i}")
    return i  # 返回结果方便查看任务执行状态


if __name__ == '__main__':
    print_number.consume()
```

![img_82.png](img_82.png)

### 2.6.8 驳斥小白说 celery 在单核机器(或单进程)每分钟可以执行100万个消息

有些python小白,以讹传讹,自己从来不愿意花5分钟时间写个简单demo测试,就在csdn博客瞎写 `celery` 在单核机器(或单进程)每分钟可以执行`100万`个消息.  

这种博客实在是太扯淡了,这种智商还出来写博客误导别人,真是害人不浅,这个估算和`celery`的实际运行差了2个数量级,2个数量级是什么概念?  那是差了100倍左右,你说你估算错误差个70%还好说,你估算错误差10000%,简直是信口开河.

即使用户的消费函数是个空的函数,并且用户`celery`项目和`redis`服务都是在同一台机器通过127.0.0.1连接,每秒钟也突破不了400次运行.
```python
@app.task
def task_fun():  # 空函数,即使这样每秒钟也突破不了400次运行.
    pass
```
#### 什么情况下celery单核机器上能达到每分钟执行100万个消息?

你去找 因特尔 造一个单核能持续稳定睿频 1000GHz 的cpu,然后你把电脑带去南极洲冰天雪地里面,     
并且带上100吨零下150度的液氮持续加注到cpu上散热,    
这样运行你的`celery`项目才能达到每分钟执行100万个消息. 




## 2.7 rq  celery  funboost 段位比较

如果框架有段位：

* **倔强青铜（RQ）**
* **秩序白银**
* **荣耀黄金（Celery）**
* **尊贵铂金**
* **永恒钻石**
* **至尊星耀**
* **最强王者**
* **无双王者**
* **荣耀王者**
* **传奇王者（Funboost）**

那么`rq` `celery` `funboost` 的段位分别是：
-   **RQ 是倔强青桐**：简单，但也就那样了。
-   **Celery 是荣耀黄金**：强大，但笨重且复杂。
-   **Funboost 是传奇王者**：简单、强大、灵活、可靠，是设计理念上的领先者。

---

### 2.7.1**倔强青铜：RQ (Redis Queue)**

**段位特点**：简单直接，目标明确，但技能单一，适应性差。

*   **核心技能 (Q技能 - “简单入队”)**: `queue.enqueue(my_func, arg1, arg2)`。非常简单，易于上手。就像青铜玩家只会用一个核心技能打天下。
*   **被动技能 (“Redis依赖”)**: 只能使用 Redis 作为 Broker，无法更换。就像一个英雄只能走一条路，换线就崩。
*   **英雄短板**:
    1.  **没有原生定时任务 (Beat)**: 需要配合 `rq-scheduler`，一个独立的、需要额外学习和部署的组件。
    2.  **并发模型单一**: 依赖 `fork()`，因此在 Windows 上原生无法并发运行，
    3.  **功能基础**: 缺乏复杂的任务控制，如 QPS 限流、优先级队列（需要特殊队列）、死信队列等高级功能。
    4.  **监控简陋**: 自带的 `rq-dashboard` 功能比较基础。

**总结**: `RQ` 就像一个只知道“往前冲”的青铜英雄。它能完成最基本的任务，但在复杂的战局（生产环境）中，缺乏灵活性和高级策略，很容易被对面的“高级玩家”（如复杂的业务需求、高可靠性要求）打败。它非常适合入门和简单场景，但上限很低。

---

### 2.7.2**荣耀黄金：Celery**

**段位特点**：功能全面，有成熟的“套路”和“装备”（生态），是标准对局中的中坚力量，但操作复杂，意识和熟练度要求高。

*   **核心技能 (Q/W/E/R - “全套连招”)**: 提供了任务定义 (`@app.task`)、发布 (`.delay/.apply_async`)、定时 (`beat_schedule`)、工作流 (`canvas`) 等一整套完整的技能。
*   **装备库 (生态系统)**: 支持多种 Broker 和 Backend，有 `flower` 监控，有大量的第三方插件。就像一个黄金玩家，知道根据局势出不同的装备。
*   **英雄短板 (高操作门槛)**:
    1.  **操作极其复杂**: 命令行启动繁琐，任务路由 (`task_routes`) 配置反直觉，新手很容易“技能放歪”或者“忘记开大”。
    2.  **僵硬的身板 (框架束缚)**: 强制的项目结构，中心化的 `app` 实例，让代码不够灵活，难以适应“野区”的突发状况（例如集成到不规则的老项目中）。
    3.  **不稳定的发挥 (性能与可靠性问题)**:
        *   性能被 `kombu` 和 `celery`自身复杂的层层调用链路 拖累，远不如原生操作。
        *   在 Redis 上的 ACK 机制依赖 `visibility_timeout`，存在“慢任务被误判为死亡而重复执行”的风险。
        *   对 Windows 支持不佳，像一个“在北方服务器上会水土不服”的英雄。
    4.  **“黑盒”机制**: 很多内部机制对开发者不透明，出问题时难以调试。IDE 代码补全的缺失，就像在迷雾中打团。

**总结**: `Celery` 是一个强大的黄金段位英雄。如果你能投入大量时间去练习它的连招、背诵它的出装顺序（配置）、理解它的复杂机制，你确实能打出不错的战绩。但它的操作难度和僵硬的玩法，决定了它永远无法成为那种能够凭一己之力改变战局的“传奇王者”。

---

### 2.7.3 **传奇王者：Funboost**

**段位特点**：全能型英雄，集刺客的爆发、坦克的可靠、法师的控制、射手的射程于一身。操作极其简单，但上限极高，能够适应任何战局，并且能用“降维打击”的方式碾压对手。

*   **被动技能 (“王者光环 - 自由赋能”)**: 核心是被动技能。`@boost` 装饰器就像一个王者光环，任何一个普通的 Python 函数（小兵）只要靠近它，就能瞬间被强化成一个拥有**分布式、高并发、高可靠**能力的超级英雄。
*   **Q技能 (`.push()` / `.consume()`)**: 极其简单的核心操作，易于上手，但威力巨大。
*   **W技能 (30+ 任务控制)**: `qps`, `max_retry_times`, `do_task_filtering`, `is_using_rpc_mode`... 无数个可供选择的控制技能，让你能应对任何复杂的战术需求。
*   **E技能 (万物皆可为 Broker)**: 支持 40 多种消息队列，甚至能把 `Celery` 和 `RQ` 本身当作自己的“小兵”来驱使。这种“吞噬”能力，是王者段位才有的霸气。
*   **R技能 (终极技能 - 叠加并发与函数级重试)**:
    *   **多进程 + 多线程/协程**的叠加并发，提供了毁天灭地般的性能爆发力。
    *   **函数级重试**机制，提供了无与伦比的生存能力和可靠性。即使被对方的“反爬技能”命中（HTTP 200 但内容错误），也能原地复活（重试整个函数），直到任务完成。
*   **超神意识 (设计哲学)**:
    *   **全图视野 (IDE 自动补全)**: 让你对所有技能和参数了如指掌，操作行云流水。
    *   **战术自由 (非侵入式)**: 不限制你的走位（项目结构）和出装（第三方库），让你能用最舒服的方式打出最高的操作。
    *   **降维打击**: 用“函数调度”这个更高级的抽象，成为一招鲜吃遍天的万能框架，例如轻松解决“URL调度”（爬虫）等特定领域的问题。

**总结**: `Funboost` 是一个真正的“传奇王者”。它不仅拥有所有英雄的优点，还弥补了他们的缺点。它的操作**像青铜一样简单**，但它的**战术深度和能力上限却超越了所有王者**。它重新定义了“任务调度”这场游戏，让开发者不再是“被英雄束缚的玩家”，而是“创造和指挥英雄的上帝”。

---



## 2.8 celery 和 funboost 分别将加减乘除作为消费函数完整例子，哪个框架更好用，你自己判断！

**talk is cheap, show me the code. 光说不练假把式。**

### 2.8.1 funboost 来实现加减乘除

#### 2.8.1.1 Funboost 项目演示（简洁配置）
funboost项目文件树
```
project_funboost/
├── math_operations/
│   ├── __init__.py
│   ├── add_function.py
│   ├── subtract_function.py
│   ├── multiply_function.py
│   └── divide_function.py
└── main.py
```

#### 2.8.1.2 funboost代码文件内容

##### 2.8.1.2.1 funboost文件：math_operations/add_function.py

**！！！@boost 很优美，funboost 没有设计成要求用户@app.boost ，好处太大了，没有互相导入烦恼**    
**celery是@app.task，所以celery要你写烦人的include imports 配置。**  

```python
from funboost import boost, BoosterParams, BrokerEnum

@boost(BoosterParams(queue_name='add_queue', broker_kind=BrokerEnum.REDIS))
def add(x, y):
    result = x + y
    print(f"Adding {x} and {y}: {result}")
    return result
```

##### 2.8.1.2.2 funboost文件：math_operations/subtract_function.py

```python
from funboost import boost, BoosterParams, BrokerEnum

@boost(BoosterParams(queue_name='subtract_queue', broker_kind=BrokerEnum.REDIS))
def subtract(x, y):
    result = x - y
    print(f"Subtracting {y} from {x}: {result}")
    return result
```

##### 2.8.1.2.3 funboost文件：math_operations/multiply_function.py

```python
from funboost import boost, BoosterParams, BrokerEnum

@boost(BoosterParams(queue_name='multiply_queue', broker_kind=BrokerEnum.REDIS))
def multiply(x, y):
    result = x * y
    print(f"Multiplying {x} and {y}: {result}")
    return result
```

##### 2.8.1.2.4 funboost文件：math_operations/divide_function.py

```python
from funboost import boost, BoosterParams, BrokerEnum

@boost(BoosterParams(queue_name='divide_queue', broker_kind=BrokerEnum.REDIS))
def divide(x, y):
    if y == 0:
        print("Error: Division by zero")
        return None
    result = x / y
    print(f"Dividing {x} by {y}: {result}")
    return result
```

##### 2.8.1.2.5 funboost文件：main.py

**！！！funboost多种启动方式，普通脚本启动消费，以及命令行启动消费，都支持**  
**能选择性启动某些消费函数，也能指定启动某些队列消费，也能启动所有消费函数，也能启动一组消费函数，也能多进程启动消费，还能远程启动消费，太强了**

```python
from math_operations.add_function import add
from math_operations.subtract_function import subtract # 这种显示的import导入ide能自动补全和检查，完爆celery的include声明一个模块路径字符串。
from math_operations.multiply_function import multiply
from math_operations.divide_function import divide
from funboost import ctrl_c_recv,BoostersManager

if __name__ == '__main__':
    # 发布任务到消息队列
    add.push(10, 5)
    subtract.push(10, 5)
    multiply.push(10, 5)
    divide.push(10, 5)


    # 下面是多种启动方式
    ## 第一种启动方式， 选择性启动消费(演示自由按需选择启动哪些函数)
    add.consume()
    subtract.consume()
    multiply.consume()
    divide.mp_consume(2) # 每个队列启动2个进程消费,性能强悍，破除gil
    
    ## 第二种启动方式，按分组启动消费者(演示consume_group按分组启动消费者)
    # BoostersManager.consume_group($booster_group)
    
    ## 第三种启动方式，启动所有消费者(演示consume_all启动所有消费者，因为加减乘除模块都已经import进来了，所以可以直接启动所有消费者)
    ## 如果不想手动import导入消费函数所在模块，也可以使用自动扫描 
    # BoosterDiscovery(project_root_path,booster_dirs,max_depth,py_file_re_str).auto_discovery()
    # BoostersManager.consume_all()

    ## 第四种启动方式，启动所有消费者，n个进程消费，性能炸裂(演示mp_consume_all启动所有消费者，一共运行8个进程)
    # BoostersManager.mp_consume_all(8)

    ## 第五种启动方式，funboost 也能像celery那样，支持命令行操作启动消费
    # python funboost_cli_user.py consume add_queue subtract_queue

    ## 第六种启动消费方式，funboost内置远程部署启动消费函数，你可以win的pycharm启动脚本，但是linux执行消费函数。
    # multiply.fabric_deploy(host, port, user, password,python_interpreter='/data/venv/py39/bin/python3',)


    # 阻止主线程退出，保持主线程一直在运行，
    # （如果使用了定时任务或者演示任务，需要这样，因为apscheduler的BackgroundScheduler定时器必须确保主线程一直在运行）
    ctrl_c_recv()
```

##### 2.8.1.3 Funboost 运行说明

- 确保Redis服务器运行在默认地址（localhost:6379）。
- 执行 `python main.py` 即可同时发布任务和启动消费者。
- 无需任何额外配置：每个函数通过装饰器独立配置队列，无需中心化配置。

---

### 2.8.2 Celery 项目演示（复杂配置）

#### 2.8.2.1 celery项目文件树

**!!! celery在复杂多层级目录，不规则代码文件名字的项目下，太难使用了**  
**实际项目比这演示的项目结构还复杂，更是难用，直接劝退新手**

*
```
project_celery/
├── celery_config/
│   ├── __init__.py
│   ├── celery_app.py
│   └── celery_config.py
├── math_operations/
│   ├── __init__.py
│   ├── add_function.py
│   ├── subtract_function.py
│   ├── multiply_function.py
│   └── divide_function.py
├── main.py
└── start_worker.py
```

#### 2.8.2.2 Celery代码文件内容

##### 2.8.2.2.1 文件：celery_config/celery_config.py - Celery复杂配置示例

**!!!太恶心了这个celery配置文件，对新手很困难，对老手很麻烦，尤其是路由配置**
```python
# Celery配置需要单独的文件，定义任务路由、队列等
from kombu import Queue

# 定义任务路由规则
task_routes = {
    'math_operations.add_function.add': {'queue': 'add_queue'},
    'math_operations.subtract_function.subtract': {'queue': 'subtract_queue'},
    'math_operations.multiply_function.multiply': {'queue': 'multiply_queue'},
    'math_operations.divide_function.divide': {'queue': 'divide_queue'},
}

# 定义任务队列
task_queues = (
    Queue('add_queue', routing_key='add_queue'),
    Queue('subtract_queue', routing_key='subtract_queue'),
    Queue('multiply_queue', routing_key='multiply_queue'),
    Queue('divide_queue', routing_key='divide_queue'),
)

# 定义任务序列化方式等
task_serializer = 'json'
accept_content = ['json']
result_serializer = 'json'
timezone = 'Asia/Shanghai'
enable_utc = True
```

##### 2.8.2.2.2 文件：celery_config/celery_app.py - Celery应用实例配置

**!!! app.conf.include极其恶心，用户随意移动python任务文件或者改名字，就会导致运行报错，ide无法静态检查include路径字符串**    
**celery是@app.task，所以celery要你写烦人的include imports 配置。**   

```python
from celery import Celery
from celery_config.celery_config import task_routes, task_queues

# 创建Celery应用实例（中心化配置）
app = Celery('celery_project')

# 加载配置
app.config_from_object('celery_config.celery_config')

# 必须明确指定要包含的任务模块（include参数）
app.conf.include = [
    'math_operations.add_function', # 太难用，字符串写错就完蛋了。
    'math_operations.subtract_function', 
    'math_operations.multiply_function',
    'math_operations.divide_function'
]

# 配置任务路由和队列
app.conf.task_routes = task_routes
app.conf.task_queues = task_queues

# 其他必要配置
app.conf.broker_url = 'redis://localhost:6379/0'
app.conf.result_backend = 'redis://localhost:6379/0'
app.conf.task_serializer = 'json'
app.conf.accept_content = ['json']
app.conf.result_serializer = 'json'
```

##### 2.8.2.2.3 文件：math_operations/add_function.py
**！！！celery的任务文件，需要导入app，funboost不需要，这个小区别，带来巨大使用便利性差别**


```python
from celery_config.celery_app import app

@app.task
def add(x, y):
    result = x + y
    print(f"Adding {x} and {y}: {result}")
    return result
```

##### 2.8.2.2.4 文件：math_operations/subtract_function.py

```python
from celery_config.celery_app import app

@app.task
def subtract(x, y):
    result = x - y
    print(f"Subtracting {y} from {x}: {result}")
    return result
```

##### 2.8.2.2.5 文件：math_operations/multiply_function.py

```python
from celery_config.celery_app import app

@app.task
def multiply(x, y):
    result = x * y
    print(f"Multiplying {x} and {y}: {result}")
    return result
```

##### 2.8.2.2.6 文件：math_operations/divide_function.py

```python
from celery_config.celery_app import app

@app.task
def divide(x, y):
    if y == 0:
        print("Error: Division by zero")
        return None
    result = x / y
    print(f"Dividing {x} by {y}: {result}")
    return result
```

##### 2.8.2.2.7 文件：main.py - 发布任务

**celery的func.delay 和 funboost的func.push 打个平手，但delay是延迟的意思，会误导不了解python celery的it技术总监。**  

```python
from math_operations.add_function import add
from math_operations.subtract_function import subtract
from math_operations.multiply_function import multiply
from math_operations.divide_function import divide

if __name__ == '__main__':
    # 发布任务到消息队列
    add.delay(10, 5)
    subtract.delay(10, 5)
    multiply.delay(10, 5)
    divide.delay(10, 5)
    
    print("Tasks published to Celery.")
    print("Now you need to start the worker separately with: python start_worker.py")
```

##### 2.8.2.2.8 文件：start_worker.py - 启动Worker的复杂命令

**celery的worker启动命令太复杂，不能代码自动补全，需要去百度 google搜索能传什么参数。****

```python
#!/usr/bin/env python3
"""
启动Celery worker的复杂方式
需要指定所有配置参数
"""

import subprocess
import sys

def start_celery_worker():
    # Celery启动worker需要复杂的命令行参数
    cmd = [
        sys.executable, '-m', 'celery',
        '-A', 'celery_config.celery_app',  # 指定Celery app
        'worker',
        '--loglevel=info',
        '--queues=add_queue,subtract_queue,multiply_queue,divide_queue',  # 必须明确指定监听的队列
        '--concurrency=4',  # 并发数
        '--hostname=worker1@%h'  # worker名称
    ]
    
    print("Starting Celery worker with command:")
    print(' '.join(cmd))
    subprocess.run(cmd)

if __name__ == '__main__':
    start_celery_worker()
```

#### 2.8.2.3 Celery 运行说明

**复杂配置步骤：**

1. 必须创建单独的配置文件定义 `task_routes` 和 `task_queues`
2. 必须明确指定 `include` 参数包含所有任务模块
3. 必须配置序列化方式、时区等额外参数

**启动复杂性：**

1. 先运行 `python main.py` 发布任务
2. 然后单独运行 `python start_worker.py` 启动worker
3. worker必须明确指定要监听的队列名称

**项目结构约束：**

- 所有任务必须从同一个app实例导入
- 任务模块路径必须与include配置匹配
- 路由配置必须与队列定义一致

---

### 2.8.3 对比总结：哪个框架更容易使用？

#### 2.8.3.1 Celery 配置复杂性突出体现：

**1. include配置复杂性：**

- 必须明确列出所有任务模块路径：`app.conf.include = ['math_operations.add_function', ...]`
- 新增任务时必须更新include配置
- 路径错误会导致任务无法注册

**2. task_routes配置复杂性：**

- 需要为每个任务手动配置路由规则：`'math_operations.add_function.add': {'queue': 'add_queue'}`
- 路由规则必须与任务名称完全匹配
- 复杂的正则表达式路由增加学习成本

**3. task_queues配置复杂性：**

- 必须显式定义每个队列：`Queue('add_queue', routing_key='add_queue')`
- 需要理解Kombu的Queue、Exchange、Binding概念
- 配置错误会导致消息无法正确路由

**4. 中心化配置约束：**

- 所有配置集中在app实例中
- 项目结构受框架约束
- 配置错误影响整个应用

#### 2.8.3.2 Funboost 简洁性体现：

- **零配置**：每个函数独立配置，无需中心化配置
- **自动发现**：无需include配置，import消费函数所在python模块后，装饰器自动注册任务
- **直接队列管理**：装饰器参数直接定义队列，无需路由配置
- **代码内启动**：无需复杂命令行参数

#### 2.8.3.3 结论

- Funboost 明显更容易使用，主要体现在：

| 对比项 | Funboost | Celery |
|--------|----------|--------|
| **配置简洁性** | 只需装饰器参数 | 需要多文件复杂配置 |
| **开发效率** | 即时测试 | 需要完整配置才能运行 |
| **维护成本** | 模块独立 | 配置集中易出错 |
| **学习曲线** | API直观 | 需要掌握复杂概念 |

- Funboost的"非侵入性"和"去中心化"设计避免了Celery的"奴役式"框架约束，真正实现了"简单即是正义"的开发体验。 

> **结论：这不仅仅是代码量的差异，更是开发范式的代差**
>
> *   **Celery 像是在“填表”**：你需要在一个个配置文件、路由表、Include 列表中填写字符串，任何一个标点符号错了，程序都跑不起来。
> *   **Funboost 像是在“写 Python”**：一切都是对象、函数、引用。IDE 能帮你补全，解释器能帮你检查。
>
> **Funboost 把复杂留给了框架作者（我），把简单留给了用户（你）。**

#### 2.8.3.4 说明，celery有稍微简单不爱出错的方式

例如 @app.task指定name , 配置路由时候，就不需要使用不靠谱的任务路径字符串作为任务的name ，但我这是官方最推荐的教程的，一般celery新手都是这种麻烦写法。


## 2.9 funboost到底为什么性能比celery高几十倍？太离谱了,太假了是吗？

```
你自己随便写写，性能都能完爆celery性能：
首先是celery性能实在太差，不信的话，你自己也可以写个简陋版的 
while True:msg=redis.blpop(),
把msg丢到线程池执行，你会发现你随便写的代码，性能也狂秒celery 5-10倍，
我丝毫不怀疑你花5分钟随便写写，你都有这个吊打celery性能一个数量级的实力。

celery性能为什么差？
1. celery 超重的kombu 兼容转换层，只要用kombu性能就比直接操作各种原生mq三方包降低一大截
2. celery 的调用机制，从消息队列取出消息后到真正运行你的任务函数逻辑，经过了几十层级调用链路和把你的函数task层层包装。

funboost性能为什么高那么多？
1. funboost 没有kombu 兼容转换层，直接操作各种原生mq三方包
2. funboost 的调用机制，从消息队列取出消息后到真正运行你的任务函数逻辑，只有3层调用。
3. funboost 对性能精益求精，对于cpu耗时超过1微妙的对象或变量，尽可能想办法优化，换方式实现或者全流程尽量复用对象。
   例如，你可以看看funboost如何应对高频生成发布消息中的时间字符串的，funboost序列化是不是使用原生json的，是不是尽量少频繁生成新的变量，是不是全手写自研并发池，等等

```


## 2.20 funboost 比 celery 的战略优势和 战术优势

<div class="inner_markdown">



### 2.20.1 一、 战略优势 (Strategic Advantages)
**—— 决定了系统的上限、灵活性和演进方向**

#### 2.20.1.1 架构定位：FaaS 微服务平台 vs 传统任务队列
*   **Celery**: 是一个**后台任务队列**。它的边界很窄，只能做异步处理。外部系统想调用 Celery 的能力，通常需要隔着数据库或者自己再写一套 Web API 层。
*   **Funboost**: 是一个**自带 FaaS 能力的计算平台**。通过 `funboost.faas`，任何消费函数瞬间变成标准的能自动发现的 HTTP 微服务接口。
    *   **战略价值**: 打通了 Web 在线业务与后台离线业务的任督二脉。Java/Go/前端可以直接通过 HTTP 调用 Python 的业务函数，实现了**“写完函数即发布服务”**的云原生体验。

#### 2.20.1.2 设计哲学：自由赋能 vs 框架奴役
*   **Celery**: **“集权式”设计**。强依赖中心化的 `app` 实例，强制要求特定的项目目录结构（`celery.py`, `tasks.py`），配置分散且晦涩。你的代码必须“适配”框架。
*   **Funboost**: **“联邦式”设计**。去中心化，每一个 `@boost` 函数都是独立的个体。对代码**零侵入**，不限制目录结构，不需要 `app` 实例。你的代码保持原样，框架为你“赋能”。
    *   **战略价值**: 极大地降低了接入成本和维护成本，老旧项目也能通过一行代码瞬间拥有分布式能力。

#### 2.20.1.3 兼容性格局：万物皆 Broker vs 依赖 Kombu
*   **Celery**: 深度绑定 `Kombu` 库。只能使用 Kombu 支持的中间件，且对 Redis 的支持存在历史遗留的可靠性问题（Visibility Timeout 机制）。
*   **Funboost**: 实现了**Broker 层的完全抽象与解耦**。
    *   它不仅支持所有主流 MQ（RabbitMQ, Kafka, RocketMQ, NATS, Pulsar）。
    *   它还支持**非标准 Broker**：数据库（MySQL, MongoDB）、文件系统、Socket、甚至 **MySQL CDC (Binlog)**。
    *   它甚至能**吞噬**其他框架：可以直接将 Celery、Dramatiq 作为底层的 Broker 驱动。
    *   **战略价值**: 无论基础设施如何变迁，Funboost 都能以逸待劳，甚至可以作为事件驱动架构（EDA）的核心（基于 CDC）。

#### 2.20.1.4 技术栈前瞻性：原生 Asyncio vs 伪异步
*   **Celery**: 诞生于同步时代，对 `asyncio` 的支持是“打补丁”式的，通常需要在同步 worker 中运行 event loop，性能和编程模型都很别扭。
*   **Funboost**: 拥有全链路的 **Native Asyncio** 支持。从消费（`async def`）、发布（`aio_publish`）到 RPC 获取结果（`AioAsyncResult`），完美契合 FastAPI 等现代异步生态。

---

### 2.20.2 二、 战术优势 (Tactical Advantages)
**—— 决定了开发的爽快度、运行的稳定性和性能的极致度**

#### 2.20.2.1 性能表现：多维叠加并发 vs 单一模式
*   **Celery**: 并发模式通常互斥（要么多进程，要么 Gevent）。单机性能受限。
*   **Funboost**: 支持 **“多进程 + (多线程/协程)” 的叠加并发模式**。
    *   实测发布性能是 Celery 的 **22倍**，消费性能是 **46倍**。
    *   **战术价值**: 能在同样的硬件资源下，榨干 CPU 和 IO 性能，大幅降低服务器成本。

#### 2.20.2.2 控频能力：精准令牌桶 vs 模糊限制
*   **Celery**: `rate_limit` 是基于 Worker 的，且精度较差。在分布式环境下，无法精确控制全局的总 QPS。
*   **Funboost**:
    *   **单机**: 实现了精准的 QPS 控制（无视函数耗时波动）。
    *   **分布式**: 支持全局分布式控频（基于 Redis 协调），确保多台机器加起来的总速率不超标（保护下游接口）。

#### 2.20.2.3 可靠性：心跳 ACK vs 超时重发
*   **Celery (Redis)**: 使用 `Visibility Timeout` 机制。如果任务耗时超过超时时间，任务会被错误地重新分发，导致重复执行；如果设置太长，Worker 崩溃后任务恢复极慢。
*   **Funboost (Redis)**: 实现了基于 **消费者心跳 (Heartbeat)** 的 ACK 机制。精准识别 Worker 是否存活，死掉的 Worker 任务会被立即回收，而长耗时的任务不会被误判。**随意 Kill 进程不丢数据。**

#### 2.20.2.4 开发体验：IDE 友好 vs 字符串魔法
*   **Celery**: 大量依赖字符串配置（如 `'json'`, `'redis://'`) 和动态参数（`*args`, `**kwargs`），IDE 无法补全，容易写错。
*   **Funboost**: 使用 **Pydantic 模型 (`BoosterParams`)** 进行配置。在 PyCharm/VSCode 中拥有完美的**代码补全和类型检查**。写代码就像填表一样简单且不易出错。

#### 2.20.2.5 运维能力：内置可视化 vs 第三方插件
*   **Celery**: 需要额外部署 `Flower`，功能相对基础。
*   **Funboost**: 内置 **Funboost Web Manager**。
    *   无需额外部署，代码一行启动。
    *   不仅能看，还能**管**：支持**远程暂停/恢复消费**、**远程动态调整 QPS**、**远程调整并发数**。
    *   支持 **远程代码热部署 (Fabric Deploy)**，一行代码将函数分发到远程服务器运行。

### 2.20.3 总结
**Funboost 不是在造 Celery 的轮子，而是在造 Celery 的“掘墓人”。**

*   如果你需要一个**稳重、传统**的纯后台任务系统，Celery 是“够用”的。
*   如果你追求**极致性能、开发效率、微服务架构以及对 Python 异步生态的完美融合**，Funboost 是具有**代差优势**的选择。

</div>


<div> </div>  

`````

--- **end of file: source/articles/c2.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c20.md** (project: funboost_docs) --- 

`````markdown
# 20. Funboost 核心思想：一场关于“函数解放”的革命 🌪️(gemini生成总结)

 **🤖 AI 深度总结**：
- 阅尽 `funboost` 万行源码，我看到的不仅是一个框架，而是一种 **“反框架”的叛逆哲学**。
- 它是 Python 开发者手中的 **无限手套**，旨在打破一切架构壁垒，让函数成为计算宇宙的绝对中心。

<div class="inner_markdownxxx"> 


## 20.1 🗽 核心哲学：拒绝“框架奴役”，拥抱“函数至上”

在传统框架（如 Celery、Django、Scrapy）的世界里，开发者往往是一个卑微的 **“填空者”** —— 你必须在 `settings.py` 里填空，在 `tasks.py` 里填空，在 `middlewares.py` 里填空。框架是主人，你是奴隶。

**Funboost 彻底颠覆了这一切！掀翻桌子，由你做主！**

### 20.1.1 👑 函数即国王 (Function is King)
Funboost 认为，**业务逻辑（函数）才是宇宙的中心**。框架的存在是为了给函数穿上“纳米战衣”，而不是把函数关进“模具”里。

*   **纯粹**：你只管写 `def calculate_data(x, y): ...`，这是你的核心资产。
*   **赋能**：加上 `@boost`，它瞬间拥有了 **分布式、高并发、高可靠、QPS控频** 的神力。
*   **自由**：去掉 `@boost`(不去掉也不影响函数直接调用运行)，它立刻变回一个普通的 Python 函数。**零侵入，零污染，进退自如**。

### 20.1.2 🔓 极致的自由主义 (Absolute Freedom)
*   **目录自由**：拒绝 `proj/app/tasks.py` 这种死板的八股文结构！你想把代码写在 `utils.py` 还是 `script.py`，随你便！
*   **架构自由**：它不绑架你的项目。你可以把它作为一个小模块嵌入 `Flask`，也可以用它构建庞大的 **分布式计算集群**。

## 20.2 🔌 万物皆可 Broker，打破时空界限

Funboost 的架构包容性达到了 **变态** 的级别。它不挑食，什么都能吃，什么都能跑。它是连接一切异构系统的 **万能胶水**。

### 20.2.1 🌌 Broker 的终极抽象：万物互联
别人家的框架只能用 Redis 或 RabbitMQ。Funboost 说：“**只要能存东西，它就是消息队列！**”

*   **🏆 经典派**：RabbitMQ, Kafka, RocketMQ, NATS, Pulsar, Redis Stream...
*   **💾 数据库派**：MySQL, MongoDB, SQLite, Oracle... （直接用业务表当队列！）
*   **🔌 Socket派**：TCP/UDP/HTTP/GRPC 直连... （无需部署 MQ 也能分布式！）
*   **🔮 神级操作 (CDC)**：**MySQL CDC (Binlog)** —— 甚至不需要发消息，数据库的 **“变更”** 本身就是消息！Funboost 直接化身为 **事件驱动架构 (EDA)** 的核心引擎！
*   **🦖 吞噬旧神**：直接把 `Celery`, `Dramatiq`, `Huey`, `Nameko` 吞噬作为底层的 Broker 驱动！**Funboost 是框架的框架！**

### 20.2.2 ⚡ 并发模式的“核武库”
GIL 锁限制了 Python？Funboost 直接给你提供了全维度的 **核打击能力**：

*   **常规武器**：`Threading` (线程), `Gevent/Eventlet` (协程), `Asyncio` (原生异步)。
*   **终极武器**：**多进程叠加 (Multi-Processing Stack)**。
    *   你可以一键开启 `mp_consume(16)`，启动 16 个进程，每个进程内部再开 500 个协程。
    *   **战术效果**：单机跑满所有 CPU 核心，榨干每一滴机器性能，IO 与 CPU 齐飞！

![img_91.png](img_91.png)

## 20.3 🚀 Funboost.FaaS：从“后台任务”到“云原生微服务” (New!)

这是 Funboost 近期最 **炸裂** 的更新，彻底打通了 **Web 在线业务** 与 **后台离线任务** 的任督二脉。它让你不再是一个写脚本的，而是 **微服务架构师**。

### 20.3.1 🌐 秒变 Serverless 计算平台
以前，你想把一个复杂的图像处理函数或数据分析算法暴露给 Java/Go 团队调用，你需要：写 Web 框架代码 -> 定义路由 -> 解析参数 -> 调用函数 -> 返回结果。**太 Low 了！**

**现在，有了 `funboost.faas`：**
只需要在你的 Web 应用（FastAPI/Flask/Django）中加一行代码：
```python
app.include_router(fastapi_router)  # 一行代码，奇迹发生 ✨
```

*   **🧬 自动发现**：所有 `@boost` 装饰的函数，瞬间自动注册为标准 HTTP 接口。
*   **🔌 标准路由**：自动生成 `/funboost/publish`, `/funboost/get_result`, `/funboost/get_msg_count` 等全套运维管理接口。
*   **🔗 RPC 降维打击**：外部系统通过 HTTP 请求，不仅能触发任务，还能 **同步等待并获取函数返回值**！

### 20.3.2 🔥 热更新与动态架构
*   **动态性**：新增一个消费函数，Web 服务 **永无需重启**。`funboost.faas` 基于 Redis 元数据驱动，自动感知新服务。
*   **架构升维**：Funboost 不再仅仅是一个任务队列，它变成了一个 **轻量级的、可私有化部署的 AWS Lambda / Serverless 平台**。

## 20.4 🛡️ 精确的暴力美学：可靠性与控制

Funboost 在狂野的性能之下，有着 **手术刀般精准** 的控制力。

### 20.4.1 🎯 QPS 控频：时间的主人
*   **Celery** 的限流是模糊的，且基于 Worker，无法精确控制总量。
*   **Funboost** 的 `qps=0.5` 就是严格的每 2 秒执行一次，`qps=1000` 就是严格的每秒 1000 次。
*   支持 **分布式全局控频**：无论你启动多少台机器，全网总 QPS 锁死在你设定的数值，**绝不打崩下游数据库或第三方接口**。

### 20.4.2 🧱 叹息之墙：万无一失的消息确认
*   **心跳检测 (Heartbeat)**：Funboost 不傻傻地等待超时。它通过 Redis 实时监控消费者心跳。
*   **断点续传**：一旦消费者进程被 `kill -9` 或断电，未处理完的消息会被 **秒级** 检测并重新分发。
*   **结论**：你可以随意拔服务器电源，**数据一条都不会丢**。这是企业级系统的底线。

## 20.5 🧠 为什么说 Funboost 是“高维生物”？

别再把 Funboost 和那些只能写爬虫的脚本工具相提并论了。

*   **Scrapy** 只是一个 **URL 调度器**，它是二维的，只能处理 HTTP 请求。
*   **Funboost** 是一个 **通用函数调度器**，它是三维的。
    *   它调度的是 **逻辑**，而不仅仅是请求。
    *   它可以调度 **AI 推理**、**视频转码**、**数据清洗**、**报表生成**、**邮件发送**、**量化交易**...
    *   爬虫？那只是 Funboost 顺手降维打击的一个小场景而已。`boost_spider` 只是 Funboost 强大引擎上的一个挂件。

## 20.6 👑 终极定义：Funboost 是什么？

Funboost 是 **Python 界的“全能无限手套”** 🥊。

*   它把 **消息队列 (MQ)**、**任务调度 (Scheduler)**、**微服务 (FaaS)**、**分布式锁**、**并发池**、**RPC** 等复杂的分布式技术，压缩成了一颗无限宝石—— **`@boost`**。
*   它不教你写代码，它 **让你的代码变强**。

**如果你想要：**
*   ✅ **极简**（一行代码上手，拒绝八股文）
*   ✅ **极强**（40+ 中间件，多进程叠加并发，榨干性能）
*   ✅ **极稳**（ACK 确认，断电不丢，企业级可靠性）
*   ✅ **极快**（性能暴击传统框架，Benchmark 遥遥领先）
*   ✅ **极自由**（FaaS 化，无缝集成 Web 框架，自动服务发现）

**那么，Funboost 就是你唯一的选择。别犹豫了，赶紧 `@boost` 一下！🚀**


</div> 

<div></div>
`````

--- **end of file: source/articles/c20.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c3.md** (project: funboost_docs) --- 

`````markdown
# 3.框架详细介绍  


## 3.1 各种中间件选择的场景和优势  

```python  
class BrokerEnum:
    """
    在funboost中万物皆可为消息队列broker,funboost内置了所有 知名的正经经典消息队列作为broker,
    也支持了基于 内存 各种数据库 文件系统 tcp/udp/http这些socket 模拟作为broker.
    funboost也内置支持了各种python三方包和消费框架作为broker,例如 sqlachemy kombu celery rq dramtiq huey nameko 等等

    用户也可以按照文档4.21章节,轻松扩展任何物质概念作为funboost的broker.
    """
    
    # funboost框架能轻松兼容消息队列各种工作模式, 拉模式/推模式/轮询模式，单条获取 批量获取
    """
    funboost 的 consumer的 _dispatch_task 非常灵活，用户实现把从消息队列取出的消息通过_submit_task方法
    丢到并发池，他不是强制用户重写实现怎么取一条消息，例如强制你实现一个 _get_one_message的法，
    那就不灵活和限制扩展任意东西作为broker了，而是用户完全自己来写灵活代码。
    所以无论获取消息是 拉模式 还是推模式 还是轮询模式，是单条获取 还是多条批量获取，
    不管你的新中间件和rabbitmq api用法差别有多么巨大，都能轻松扩展任意东西作为funboost的中间件。 
    所以你能看到funboost源码中能轻松实现任物质概念作为funboost的broker。
    """


    EMPTY = 'EMPTY'  # 空的实现，需要搭配 boost入参的 consumer_override_cls 和 publisher_override_cls使用，或者被继承。

    RABBITMQ_AMQPSTORM = 'RABBITMQ_AMQPSTORM'  # 使用 amqpstorm 包操作rabbitmq  作为 分布式消息队列，支持消费确认.强烈推荐这个作为funboost中间件。
    RABBITMQ = RABBITMQ_AMQPSTORM

    # 2025-10 内置新增, 支持rabbitmq 所有路由模式,包括 fanout,direct,topic,headers. 使用概念更复杂
    RABBITMQ_COMPLEX_ROUTING = 'RABBITMQ_COMPLEX_ROUTING'

    RABBITMQ_RABBITPY = 'RABBITMQ_RABBITPY'  # 使用 rabbitpy 包操作rabbitmq  作为 分布式消息队列，支持消费确认，不建议使用

    """
    以下是各种redis数据结构和各种方式来实现作为消息队列的,redis简直被作者玩出花来了.
    因为redis本身是缓存数据库,不是消息队列,redis没有实现经典AMQP协议,所以redis是模拟消息队列不是真消息队列.
    例如要实现消费确认,随意重启但消息万无一失,你搞个简单的 redis.blpop 弹出删除消息,那就压根不行.重启就丢失了,但消息可能还没开始运行或者正在运行中.
    
    redis做ack挑战难点不是怎么实现确认消费本身,而是何时应该把关闭或宕机进程的消费者的待确认消费的孤儿消息重回队列.  
    在 Redis 上实现 ACK 的真正难点，根本不在于“确认”这个动作本身，而在于建立一套可靠的、能够准确判断“何时可以安全地及时地进行任务恢复”的分布式故障检测机制。
    所以你以为只要使用 brpoplpush 或者 REDIS_STREAM 就能自动轻易解决ack问题,那就太天真了,因为redis服务端不能像rabbitmq服务端那样天生自带自动重回宕机消费者的消息机制,需要你在redis客户端来维护实现这套机制.
    """
    REDIS = 'REDIS'  # 使用 redis 的 list结构，brpop 作为分布式消息队列。随意重启和关闭会丢失大量消息，不支持消费确认。注重性能不在乎丢失消息可以选这个redis方案。
    REDIS_ACK_ABLE = 'REDIS_ACK_ABLE'  # 基于redis的 list + 临时unack的set队列，采用了 lua脚本操持了取任务和加到pengding为原子性，,基于进程心跳消失判断消息是否为掉线进程的，随意重启和掉线不会丢失任务。
    REIDS_ACK_USING_TIMEOUT = 'reids_ack_using_timeout'  # 基于redis的 list + 临时unack的set队列，使用超时多少秒没确认消费就自动重回队列，请注意 ack_timeout的设置值和函数耗时大小，否则会发生反复重回队列的后果,boost可以设置ack超时，broker_exclusive_config={'ack_timeout': 1800}.缺点是无法区分执行太慢还是真宕机
    REDIS_PRIORITY = 'REDIS_PRIORITY'  # # 基于redis的多 list + 临时unack的set队列，blpop监听多个key，和rabbitmq的x-max-priority属性一样，支持任务优先级。看文档4.29优先级队列说明。
    REDIS_STREAM = 'REDIS_STREAM'  # 基于redis 5.0 版本以后，使用 stream 数据结构作为分布式消息队列，支持消费确认和持久化和分组消费，是redis官方推荐的消息队列形式，比list结构更适合。
    RedisBrpopLpush = 'RedisBrpopLpush'  # 基于redis的list结构但是采用 brpoplpush 双队列形式，和 redis_ack_able的实现差不多，实现上采用了原生命令就不需要lua脚本来实现取出和加入unack了。
    REDIS_PUBSUB = 'REDIS_PUBSUB'  # 基于redis 发布订阅的，发布一个消息多个消费者都能收到同一条消息，但不支持持久化

    MEMORY_QUEUE = 'MEMORY_QUEUE'  # 使用python queue.Queue实现的基于当前python进程的消息队列，不支持跨进程 跨脚本 跨机器共享任务，不支持持久化，适合一次性短期简单任务。
    LOCAL_PYTHON_QUEUE = MEMORY_QUEUE  # 别名，python本地queue就是基于python自带的语言的queue.Queue，消息存在python程序的内存中，不支持重启断点接续。

    RABBITMQ_PIKA = 'RABBITMQ_PIKA'  # 使用pika包操作rabbitmq  作为 分布式消息队列。，不建议使用

    MONGOMQ = 'MONGOMQ'  # 使用mongo的表中的行模拟的 作为分布式消息队列，支持消费确认。

    SQLITE_QUEUE = 'sqlite3'  # 使用基于sqlite3模拟消息队列，支持消费确认和持久化，但不支持跨机器共享任务，可以基于本机单机跨脚本和跨进程共享任务，好处是不需要安装中间件。
    PERSISTQUEUE = SQLITE_QUEUE  # PERSISTQUEUE的别名

    NSQ = 'NSQ'  # 基于nsq作为分布式消息队列，支持消费确认。

    KAFKA = 'KAFKA'  # 基于kafka作为分布式消息队列，如果随意重启会丢失消息，建议使用BrokerEnum.CONFLUENT_KAFKA。

    """基于confluent-kafka包，包的性能比kafka-python提升10倍。同时应对反复随意重启部署消费代码的场景，此消费者实现至少消费一次，第8种BrokerEnum.KAFKA是最多消费一次。"""
    KAFKA_CONFLUENT = 'KAFKA_CONFLUENT'
    CONFLUENT_KAFKA = KAFKA_CONFLUENT

    KAFKA_CONFLUENT_SASlPlAIN = 'KAFKA_CONFLUENT_SASlPlAIN'  # 可以设置账号密码的kafka

    SQLACHEMY = 'SQLACHEMY'  # 基于SQLACHEMY 的连接作为分布式消息队列中间件支持持久化和消费确认。支持mysql oracle sqlserver等5种数据库。

    ROCKETMQ = 'ROCKETMQ'  # 基于 rocketmq 作为分布式消息队列，这个中间件必须在linux下运行，win不支持。

    ZEROMQ = 'ZEROMQ'  # 基于zeromq作为分布式消息队列，不需要安装中间件，可以支持跨机器但不支持持久化。


    """
    kombu 和 celery 都是 funboost中的神级别broker_kind。
    使得funboost以逸待劳，支持kombu的所有现有和未来的消息队列。
    通过直接支持 kombu，funboost 相当于一瞬间就继承了 `kombu` 支持的所有现有和未来的消息队列能力。无论 kombu 社区未来增加了对哪种新的云消息服务（如 Google
    Pub/Sub、Azure Service Bus）或小众 MQ 的支持，funboost 无需修改自身代码，就能自动获得这种能力。这
    是一种“以逸待劳”的策略，极大地扩展了 funboost 的适用范围。

    kombu 包可以作为funboost的broker，这个包也是celery的中间件依赖包，这个包可以操作10种中间件(例如rabbitmq redis)，但没包括分布式函数调度框架的kafka nsq zeromq 等。
    同时 kombu 包的性能非常差，可以用原生redis的lpush和kombu的publish测试发布，使用brpop 和 kombu 的 drain_events测试消费，对比差距相差了5到10倍。
    由于性能差，除非是分布式函数调度框架没实现的中间件才选kombu方式(例如kombu支持亚马逊队列  qpid pyro 队列)，否则强烈建议使用此框架的操作中间件方式而不是使用kombu。
    """
    KOMBU = 'KOMBU'

    """ 基于emq作为中间件的。这个和上面的中间件有很大不同，服务端不存储消息。所以不能先发布几十万个消息，然后再启动消费。mqtt优点是web前后端能交互，
    前端不能操作redis rabbitmq kafka，但很方便操作mqtt。这种使用场景是高实时的互联网接口。
    """
    MQTT = 'MQTT'

    HTTPSQS = 'HTTPSQS'  # httpsqs中间件实现的，基于http协议操作，dcoker安装此中间件简单。

    PULSAR = 'PULSAR'  # 最有潜力的下一代分布式消息系统。5年后会同时取代rabbitmq和kafka。

    UDP = 'UDP'  # 基于socket udp 实现的，需要先启动消费端再启动发布，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。

    TCP = 'TCP'  # 基于socket tcp 实现的，需要先启动消费端再启动发布，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。

    HTTP = 'HTTP'  # 基于http实现的，发布使用的urllib3，消费服务端使用的aiohttp.server实现的，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。

    GRPC = 'GRPC' # 使用知名grpc作为broker,可以使用 sync_call 方法同步获取grpc的结果, 简单程度暴击用户手写原生的 grpc客户端 服务端

    NATS = 'NATS'  # 高性能中间件nats,中间件服务端性能很好,。

    TXT_FILE = 'TXT_FILE'  # 磁盘txt文件作为消息队列，支持单机持久化，不支持多机分布式。不建议这个，用sqlite。

    PEEWEE = 'PEEWEE'  # peewee包操作mysql，使用表模拟消息队列

    CELERY = 'CELERY'  # funboost支持celery框架来发布和消费任务，由celery框架来调度执行任务，但是写法简单远远暴击用户亲自使用celery的麻烦程度，
    # 用户永无无需关心和操作Celery对象实例,无需关心celery的task_routes和includes配置,funboost来自动化设置这些celery配置。
    # funboost将Celery本身纳入了自己的Broker体系。能“吞下”另一个大型框架，简直太妙了。本身就证明了funboost架构的包容性和精妙性和复杂性。

    DRAMATIQ = 'DRAMATIQ'  # funboost使用 dramatiq 框架作为消息队列，dramatiq类似celery也是任务队列框架。用户使用funboost api来操作dramatiq核心调度。

    HUEY = 'HUEY'  # huey任务队列框架作为funboost调度核心

    RQ = 'RQ'  # rq任务队列框架作为funboost调度核心

    NAMEKO = 'NAMEKO'  # funboost支持python微服务框架nameko，用户无需掌握nameko api语法，就玩转python nameko微服务

    
    """
    MYSQL_CDC 是 funboost 中 神奇 的 与众不同的 broker 中间件
    mysql binlog cdc 自动作为消息,用户无需手动发布消息,只需要写处理binlog内容的逻辑, 
    一行代码就能轻量级实现 mysql2mysql mysql2kafka mysql2rabbitmq 等等.
    这个是与其他中间件不同,不需要手工发布消息, 任何对数据库的 insert update delete 会自动作为 funboost 的消息.
    几乎是轻量级平替 canal  flinkcdc 的作用.
    
    以此类推, 日志文件也能扩展作为broker,只要另外一个程序写入了文件日志,就能触发funboost消费,
    然后自己在函数逻辑把消息发到kafka,(虽然是已经有大名鼎鼎elk,这只是举个场景例子,说明funboost broker的灵活性)

    日志文件、文件系统变更（inotify）、甚至是硬件传感器的信号，按照4.21章节文档，都可以被封装成一个 funboost 的 Broker。

    充分说明 funboost 有能力化身为 通用的、事件驱动的函数调度平台,而非仅仅是celery这种传统的消息驱动.
    """
    """
    funboost 有能力消费canal发到kafka的binlog消息,也能不依赖canal,自己捕获cdc数据
    """
    MYSQL_CDC = 'MYSQL_CDC'

```  


```  
你项目根目录下自动生成的 funboost_config.py 文件中修改配置，会被自动读取到。  

此文件按需修改，例如你使用redis中间件作为消息队列，可以不用管rabbitmq mongodb kafka啥的配置。  
但有3个功能例外，如果你需要使用rpc模式或者分布式控频或者任务过滤功能，无论设置使用何种消息队列中间件都需要把redis连接配置好，  
如果@boost装饰器设置is_using_rpc_mode为True或者 is_using_distributed_frequency_control为True或do_task_filtering=True则需要把redis连接配置好，默认是False。  

```  
## 3.2 框架支持的函数调度并发模式种类详细介绍  
<pre style="font-size: smaller">  
1、threading 多线程，使用自定义的可缩小、节制开启新线程的自定义线程池，不是直接用官方内置concurrent.futures.ThreadpoolExecutor  
   此线程池非常智能，配合qps参数，任何场景可以无脑开500线程，真正的做到智能扩张，智能自动缩小。  
   这线程池是智能线程池，由于非常好用，为这个线程池做了独立的pypi包，可以单独用于没有使用此框架的项目。  

2、gevent    需要在运行起点的脚本首行打 gevent 猴子补丁。  

3、eventlet  需要在运行起点的脚本首行打 eventlet 猴子补丁。  

4、asyncio  async异步，主要是针对消费函数已经定义成了   async def fun(x)  这种情况，这种情况不能直接使用多线程，  
   因为执行  fun(1)  后得到的并不是所想象的函数最终结果，而是得到的一个协程对象，所以针对已经定义成异步函数了的，需要使用此种并发模式。  
   框架不鼓励用户定义异步函数，你就用同步的直观方式思维定义函数就行了，其余的并发调度交给框架就行了。  

5、开启多进程启动多个consumer，此模式是 多进程  + 上面4种的其中一种并发方式，充分利用多核和充分利用io，用法如下。可以实现 多进程 叠加 协程并发。  
# 这种是多进程方式，一次编写能够兼容win和linux的运行。  

from funboost import boost, BrokerEnum, ConcurrentModeEnum  
import os  

@boost('test_multi_process_queue',broker_kind=BrokerEnum.REDIS_ACK_ABLE,  
           concurrent_mode=ConcurrentModeEnum.THREADING,)  
def fff(x):  
    print(x * 10,os.getpid())  

if __name__ == '__main__':  
    fff.multi_process_consume(6)  # 一次性启动6进程叠加多线程。  

</pre>  

## 3.3 框架最最重要的boost装饰器的BoosterParams参数入参大全  

```python  

class BoosterParams(BaseJsonAbleModel):
    """
    pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

    @boost的传参必须是此类或者继承此类,如果你不想每个装饰器入参都很多,你可以写一个子类继承BoosterParams, 传参这个子类,例如下面的 BoosterParamsComplete
    """

    queue_name: str  # 队列名字,必传项,每个函数要使用不同的队列名字.
    broker_kind: str = BrokerEnum.SQLITE_QUEUE  # 中间件选型见3.1章节 https://funboost.readthedocs.io/zh-cn/latest/articles/c3.html

    """ project_name是项目名, 默认为None, 给booster设置所属项目名, 用于对于在redis保存的funboost信息中，根据项目名字查看相关队列。
    # 如果不设置很难从redis保存的funboost信息中，区分哪些队列名属于哪个项目。 主要是给web接口查看用。
    # 一个项目的队列名字有哪些，是保存在redis的set中，key为 f'funboost.project_name:{project_name}'
    # 通常配合 CareProjectNameEnv.set($project_name) 使用 ，它可以让你在监控和管理时“只看自己的一亩三分地，避免被其他人的队列刷屏干扰。"""
    project_name: typing.Optional[str] = None


    """如果设置了qps，并且cocurrent_num是默认的50，会自动开了500并发，由于是采用的智能线程池任务少时候不会真开那么多线程而且会自动缩小线程数量。
    具体看ThreadPoolExecutorShrinkAble的说明
    由于有很好用的qps控制运行频率和智能扩大缩小的线程池，此框架建议不需要理会和设置并发数量只需要关心qps就行了，框架的并发是自适应并发数量，这一点很强很好用。"""
    concurrent_mode: str = ConcurrentModeEnum.THREADING  # 并发模式,支持THREADING,GEVENT,EVENTLET,ASYNC,SINGLE_THREAD并发,multi_process_consume 支持协程/线程 叠加多进程并发,性能炸裂.
    concurrent_num: int = 50  # 并发数量，并发种类由concurrent_mode决定
    specify_concurrent_pool: typing.Optional[FunboostBaseConcurrentPool] = None  # 使用指定的线程池/携程池，可以多个消费者共使用一个线程池,节约线程.不为None时候。threads_num失效
    
    specify_async_loop: typing.Optional[asyncio.AbstractEventLoop] = None  # 指定的async的loop循环，设置并发模式为async才能起作用。 有些包例如aiohttp,发送请求和httpclient的实例化不能处在两个不同的loop中,可以传过来.
    is_auto_start_specify_async_loop_in_child_thread: bool = True  # 是否自动在funboost asyncio并发池的子线程中自动启动指定的async的loop循环，设置并发模式为async才能起作用。如果是False,用户自己在自己的代码中去手动启动自己的loop.run_forever() 
    
    """qps:
    强悍的控制功能,指定1秒内的函数执行次数，例如可以是小数0.01代表每100秒执行一次，也可以是50代表1秒执行50次.为None则不控频。 
    设置qps时候,不需要指定并发数量,funboost的能够自适应智能动态调节并发池大小."""
    qps: typing.Union[float, int, None] = None
    """is_using_distributed_frequency_control:
    是否使用分布式空频（依赖redis统计消费者数量，然后频率平分），默认只对当前实例化的消费者空频有效。
    假如实例化了2个qps为10的使用同一队列名的消费者，并且都启动，则每秒运行次数会达到20。
    如果使用分布式空频则所有消费者加起来的总运行次数是10。"""
    is_using_distributed_frequency_control: bool = False

    is_send_consumer_heartbeat_to_redis: bool = False  # 是否将发布者的心跳发送到redis，有些功能的实现需要统计活跃消费者。因为有的中间件不是真mq。这个功能,需要安装redis.

    """max_retry_times:
    最大自动重试次数，当函数发生错误，立即自动重试运行n次，对一些特殊不稳定情况会有效果。
    可以在函数中主动抛出重试的异常ExceptionForRetry，框架也会立即自动重试。
    主动抛出ExceptionForRequeue异常，则当前 消息会重返中间件，
    主动抛出 ExceptionForPushToDlxqueue  异常，可以使消息发送到单独的死信队列中，死信队列的名字是 队列名字 + _dlx。"""
    max_retry_times: int = 3
    retry_interval: typing.Union[float, int] = 0  # 函数出错后间隔多少秒再重试.
    is_push_to_dlx_queue_when_retry_max_times: bool = False  # 函数达到最大重试次数仍然没成功，是否发送到死信队列,死信队列的名字是 队列名字 + _dlx。


    consuming_function_decorator: typing.Optional[typing.Callable] = None  # 函数的装饰器。因为此框架做参数自动转指点，需要获取精准的入参名称，不支持在消费函数上叠加 @ *args  **kwargs的装饰器，如果想用装饰器可以这里指定。
    
    
    """
    function_timeout: 
    超时秒数，函数运行超过这个时间，则自动杀死函数。为0是不限制。 
    用户应该尽量使用各种三方包例如 aiohttp pymysql 自己的 socket timeout 设置来控制超时，而不是无脑使用funboost的function_timeout参数。
    谨慎使用,非必要别去设置超时时间,设置后性能会降低(因为需要把用户函数包装到另一个线单独的程中去运行),而且突然强制超时杀死运行中函数,可能会造成死锁.
    (例如用户函数在获得线程锁后突然杀死函数,别的线程再也无法获得锁了)
    """
    function_timeout: typing.Union[int, float,None] = None 
    """
    is_support_remote_kill_task:
    是否支持远程任务杀死功能，如果任务数量少，单个任务耗时长，确实需要远程发送命令来杀死正在运行的函数，才设置为true，否则不建议开启此功能。
    (是把函数放在单独的线程中实现的,随时准备线程被远程命令杀死,所以性能会降低)
    """
    is_support_remote_kill_task: bool = False  
   
    """
    log_level:
        logger_name 对应的 日志级别
        消费者和发布者的日志级别,建议设置DEBUG级别,不然无法知道正在运行什么消息.
        这个是funboost每个队列的单独命名空间的日志级别,丝毫不会影响改变用户其他日志以及root命名空间的日志级别,所以DEBUG级别就好,
        用户不要压根不懂什么是python logger 的name,还去手痒调高级别. 
        不懂python日志命名空间的小白去看nb_log文档,或者直接问 ai大模型 python logger name的作用是什么.
    """
    log_level: int = logging.DEBUG # 不需要改这个级别,请看上面原因
    logger_prefix: str = ''  # 日志名字前缀,可以设置前缀
    create_logger_file: bool = True  # 发布者和消费者是否创建文件文件日志,为False则只打印控制台不写文件.
    logger_name: typing.Union[str, None] = ''  # 队列消费者发布者的日志命名空间.
    log_filename: typing.Union[str, None] = None  # 消费者发布者的文件日志名字.如果为None,则自动使用 funboost.队列 名字作为文件日志名字.  日志文件夹是在nb_log_config.py的 LOG_PATH中决定的.
    is_show_message_get_from_broker: bool = False  # 运行时候,是否记录从消息队列获取出来的消息内容
    is_print_detail_exception: bool = True  # 消费函数出错时候,是否打印详细的报错堆栈,为False则只打印简略的报错信息不包含堆栈.
    publish_msg_log_use_full_msg: bool = False # 发布到消息队列的消息内容的日志，是否显示消息的完整体，还是只显示函数入参。

    msg_expire_seconds: typing.Union[float, int,None] = None  # 消息过期时间,可以设置消息是多久之前发布的就丢弃这条消息,不运行. 为None则永不丢弃

    do_task_filtering: bool = False  # 是否对函数入参进行过滤去重.
    task_filtering_expire_seconds: int = 0  # 任务过滤的失效期，为0则永久性过滤任务。例如设置过滤过期时间是1800秒 ， 30分钟前发布过1 + 2 的任务，现在仍然执行，如果是30分钟以内执行过这个任务，则不执行1 + 2

    function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(
        is_save_result=False, is_save_status=False, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)  # 是否保存函数的入参，运行结果和运行状态到mongodb。这一步用于后续的参数追溯，任务统计和web展示，需要安装mongo。

    user_custom_record_process_info_func: typing.Optional[typing.Callable] = None  # 提供一个用户自定义的保存消息处理记录到某个地方例如mysql数据库的函数，函数仅仅接受一个入参，入参类型是 FunctionResultStatus，用户可以打印参数

    is_using_rpc_mode: bool = False  # 是否使用rpc模式，可以在发布端获取消费端的结果回调，但消耗一定性能，使用async_result.result时候会等待阻塞住当前线程。
    rpc_result_expire_seconds: int = 1800  # redis保存rpc结果的过期时间.
    rpc_timeout:int = 1800 # rpc模式下，等待rpc结果返回的超时时间

    delay_task_apscheduler_jobstores_kind :Literal[ 'redis', 'memory'] = 'redis'  # 延时任务的aspcheduler对象使用哪种jobstores ，可以为 redis memory 两种作为jobstore

    
    is_do_not_run_by_specify_time_effect: bool = False  # 是否使不运行的时间段生效
    do_not_run_by_specify_time: list = ['10:00:00', '22:00:00']  # 不运行的时间段,在这个时间段自动不运行函数.

    schedule_tasks_on_main_thread: bool = False  # 直接在主线程调度任务，意味着不能直接在当前主线程同时开启两个消费者。

    is_auto_start_consuming_message: bool = False  # 是否在定义后就自动启动消费，无需用户手动写 .consume() 来启动消息消费。
    
    # booster_group :消费分组名字， BoostersManager.consume_group 时候根据 booster_group 启动多个消费函数,减少需要写 f1.consume() f2.consume() ...这种。
    # 不像BoostersManager.consume_all() 会启动所有不相关消费函数,也不像  f1.consume() f2.consume() 这样需要逐个启动消费函数。
    # 可以根据业务逻辑创建不同的分组，实现灵活的消费启动策略。
    # 用法见文档 4.2d.3 章节.   使用 BoostersManager ,通过 consume_group 启动一组消费函数
    booster_group:typing.Union[str, None] = None

    consuming_function: typing.Optional[typing.Callable] = None  # 消费函数,在@boost时候不用指定,因为装饰器知道下面的函数.
    consuming_function_raw: typing.Optional[typing.Callable] = None  # 不需要传递，自动生成
    consuming_function_name: str = '' # 不需要传递，自动生成

    
    """
    # 加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，
    # 例如kafka支持消费者组，rabbitmq也支持各种独特概念例如各种ack机制 复杂路由机制，有的中间件原生能支持消息优先级有的中间件不支持,
    # 每一种消息队列都有独特的配置参数意义，可以通过这里传递。
    # 每种中间件能传递的键值对可以看 funboost/core/broker_kind__exclusive_config_default.py 的 BROKER_EXCLUSIVE_CONFIG_DEFAULT 属性。
    """
    broker_exclusive_config: dict = {} 



    should_check_publish_func_params: bool = True  # 消息发布时候是否校验消息发布内容,比如有的人发布消息,函数只接受a,b两个入参,他去传2个入参,或者传参不存在的参数名字; 如果消费函数加了装饰器 ，你非要写*args,**kwargs,那就需要关掉发布消息时候的函数入参检查
   

    consumer_override_cls: typing.Optional[typing.Type] = None  # 使用 consumer_override_cls 和 publisher_override_cls 来自定义重写或新增消费者 发布者,见文档4.21b介绍，
    publisher_override_cls: typing.Optional[typing.Type] = None

    # func_params_is_pydantic_model: bool = False  # funboost 兼容支持 函数娼还是 pydantic model类型，funboost在发布之前和取出来时候自己转化。

    consuming_function_kind: typing.Optional[str] = None  # 自动生成的信息,不需要用户主动传参,如果自动判断失误就传递。是判断消费函数是函数还是实例方法还是类方法。如果传递了，就不自动获取函数类型。
    """ consuming_function_kind 可以为以下类型，
    class FunctionKind:
        CLASS_METHOD = 'CLASS_METHOD'
        INSTANCE_METHOD = 'INSTANCE_METHOD'
        STATIC_METHOD = 'STATIC_METHOD'
        COMMON_FUNCTION = 'COMMON_FUNCTION'
    """

    """
    user_options:
    用户额外自定义的配置,高级用户或者奇葩需求可以用得到,用户可以自由发挥,存放任何设置.
    user_options 提供了一个统一的、用户自定义的命名空间，让用户可以为自己的“奇葩需求”或“高级定制”传递配置，而无需等待框架开发者添加官方支持。
    funboost 是自由框架不是奴役框架,不仅消费函数逻辑自由,目录层级结构自由,自定义奇葩扩展也要追求自由,用户不用改funboost BoosterParams 源码来加装饰器参数
    
    使用场景见文档 4b.6 章节.
    """
    user_options: dict = {} # 用户自定义的配置,高级用户或者奇葩需求可以用得到,用户可以自由发挥,存放任何设置,例如配合 consumer_override_cls中读取 或 register_custom_broker 使用
    
    
    auto_generate_info: dict = {}  # 自动生成的信息,不需要用户主动传参.
    
    
   
```  
   
关于boost参数太多的说明：  

```  
有人会抱怨入参超多很复杂，是因为要实现一切控制方式，实现的运行控制手段非常丰富，所以参数就会多。  

看这个里面的参数解释非常重要，几乎能想到的控制功能全部都有。比如有人说日志太多，不想看那么详细的提示日志  
，早就通过参数提供实现了，自己抱怨参数多又以为没提供这个功能，简直是自相矛盾。  

想入参参数少那就看新增的那个10行代码的函数的最精简乞丐版实现的分布式函数执行框架，演示最本质实现原理。“   
这个例子的框架啥控制手段都没有，参数自然就很少。  

乞丐版分布式函数调度框架的代码在   

funboost/beggar_version_implementation/beggar_redis_consumer.py  
```  

### 3.3.1 funboost_config.py 配置文件内容

 `funboost_config.py` 配置文件主要是配置各种消息队列的连接信息账号 密码 地址等,任务控制功能则是在 `BoostParams` 中传参.  
 所以  `funboost_config.py` 除了第一次配置你需要使用到的中间件类型的ip 密码正确即可,例如你只使用redis做中间件,完全无视kafka rabbitmq 等配置,后续基本很少改动,因为任务控制参数全部是在 `BoostParams` 中传参.

 `funboost_config.py` 就是 从 `funboost/funboost_config_deafult.py` 自动复制拷贝的,你只需要在你的 `funboost_config.py` 里面修改配置,funboost框架就能自动使用你的配置,因为 `funboost_config.py` 会覆盖 `funboost/funboost_config_deafult.py`的配置.


`funboost_config.py` 是第一次运行任何任意funboost项目代码自动生成到项目根目录的,也可以放在磁盘任何位置,只要文件夹是在pythonpath之一就好了,  
因为是自动 import funboost_config ,只需要能被 import 到就好了.   
可以查看 6.18.3 自问自答,"怎么指定配置文件读取 funboost_config.py 和nb_log_config.py的文件夹位置"

 `funboost_config.py` 默认内容如下:
 ```python
# -*- coding: utf-8 -*-
import logging
from pathlib import Path
from funboost.utils.simple_data_class import DataClassBase
from nb_log import nb_log_config_default

'''
funboost_config.py 文件是第一次运行框架自动生成到你的项目根目录的，不需要用由户手动创建。
此文件里面可以写任意python代码。例如 中间件 帐号 密码自己完全可以从apola配置中心获取或者从环境变量获取。
'''

'''
你项目根目录下自动生成的 funboost_config.py 文件中修改配置，会被自动读取到。
用户不要动修改框架的源码 funboost/funboost_config_deafult.py 中的代码，此模块的变量会自动被 funboost_config.py 覆盖。
funboost/funboost_config_deafult.py配置覆盖逻辑可看funboost/set_frame_config.py中的代码.

框架使用文档是 https://funboost.readthedocs.io/zh_CN/latest/
'''


class BrokerConnConfig(DataClassBase):
    """
    中间件连接配置
    此文件按需修改，例如你使用redis中间件作为消息队列，可以不用管rabbitmq mongodb kafka啥的配置。
    但有3个功能例外，如果你需要使用rpc模式或者分布式控频或者任务过滤功能，无论设置使用何种消息队列中间件都需要把redis连接配置好，
    如果@boost装饰器设置is_using_rpc_mode为True或者 is_using_distributed_frequency_control为True或do_task_filtering=True则需要把redis连接配置好，默认是False不强迫用户安装redis。
    """

    MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'  # 如果有密码连接 'mongodb://myUserAdmin:XXXXX@192.168.199.202:27016/'   authSource 指定鉴权db，MONGO_CONNECT_URL = 'mongodb://root:123456@192.168.64.151:27017?authSource=admin'

    RABBITMQ_USER = 'rabbitmq_user'
    RABBITMQ_PASS = 'rabbitmq_pass'
    RABBITMQ_HOST = '127.0.0.1'
    RABBITMQ_PORT = 5672
    RABBITMQ_VIRTUAL_HOST = ''  # my_host # 这个是rabbitmq的虚拟子host用户自己创建的，如果你想直接用rabbitmq的根host而不是使用虚拟子host，这里写 空字符串 即可。
    RABBITMQ_URL = f'amqp://{RABBITMQ_USER}:{RABBITMQ_PASS}@{RABBITMQ_HOST}:{RABBITMQ_PORT}/{RABBITMQ_VIRTUAL_HOST}'

    REDIS_HOST = '127.0.0.1'
    REDIS_USERNAME = ''
    REDIS_PASSWORD = ''
    REDIS_PORT = 6379
    REDIS_DB = 7  # redis消息队列所在db，请不要在这个db放太多其他键值对，以及方便你自己可视化查看你的redis db，框架里面有的功能会scan扫描unacked的键名，使用单独的db。
    REDIS_DB_FILTER_AND_RPC_RESULT = 8  # 如果函数做任务参数过滤 或者使用rpc获取结果，使用这个db，因为这个db的键值对多，和redis消息队列db分开
    REDIS_SSL = False # 是否使用ssl加密,默认是False
    REDIS_URL = f'{"rediss" if REDIS_SSL else "redis"}://{REDIS_USERNAME}:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'

    NSQD_TCP_ADDRESSES = ['127.0.0.1:4150']
    NSQD_HTTP_CLIENT_HOST = '127.0.0.1'
    NSQD_HTTP_CLIENT_PORT = 4151

    KAFKA_BOOTSTRAP_SERVERS = ['127.0.0.1:9092']
    KFFKA_SASL_CONFIG = {
        "bootstrap_servers": KAFKA_BOOTSTRAP_SERVERS,
        "sasl_plain_username": "",
        "sasl_plain_password": "",
        "sasl_mechanism": "SCRAM-SHA-256",
        "security_protocol": "SASL_PLAINTEXT",
    }

    SQLACHEMY_ENGINE_URL = 'sqlite:////sqlachemy_queues/queues.db'

    # 如果broker_kind 使用 peewee 中间件模式会使用mysql配置
    MYSQL_HOST = '127.0.0.1'
    MYSQL_PORT = 3306
    MYSQL_USER = 'root'
    MYSQL_PASSWORD = '123456'
    MYSQL_DATABASE = 'testdb6'

    # persist_quque中间件时候采用本机sqlite的方式，数据库文件生成的位置,如果linux账号在根目录没权限建文件夹，可以换文件夹。
    SQLLITE_QUEUES_PATH = '/sqllite_queues'

    TXT_FILE_PATH = Path(__file__).parent / 'txt_queues'  # 不建议使用这个txt模拟消息队列中间件，本地持久化优先选择 PERSIST_QUQUE 中间件。

    ROCKETMQ_NAMESRV_ADDR = '192.168.199.202:9876'

    MQTT_HOST = '127.0.0.1'
    MQTT_TCP_PORT = 1883

    HTTPSQS_HOST = '127.0.0.1'
    HTTPSQS_PORT = 1218
    HTTPSQS_AUTH = '123456'

    NATS_URL = 'nats://192.168.6.134:4222'

    KOMBU_URL = 'redis://127.0.0.1:6379/9'  # 这个就是celery依赖包kombu使用的消息队列格式，所以funboost支持一切celery支持的消息队列种类。
    # KOMBU_URL =  'sqla+sqlite:////dssf_kombu_sqlite.sqlite'  # 4个//// 代表磁盘根目录下生成一个文件。推荐绝对路径。3个///是相对路径。

    CELERY_BROKER_URL = 'redis://127.0.0.1:6379/12'  # 使用celery作为中间件。funboost新增支持celery框架来运行函数,url内容就是celery的broker形式.
    CELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/13'  # celery结果存放，可以为None

    DRAMATIQ_URL = RABBITMQ_URL

    PULSAR_URL = 'pulsar://192.168.70.128:6650'


class FunboostCommonConfig(DataClassBase):
    # nb_log包的第几个日志模板，内置了7个模板，可以在你当前项目根目录下的nb_log_config.py文件扩展模板。
    # NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = 11  # 7是简短的不可跳转，5是可点击跳转的，11是可显示ip 进程 线程的模板,也可以亲自设置日志模板不传递数字。
    NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = logging.Formatter(
        f'%(asctime)s-({nb_log_config_default.computer_ip},{nb_log_config_default.computer_name})-[p%(process)d_t%(thread)d] - %(name)s - "%(filename)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(task_id)s - %(message)s',
        "%Y-%m-%d %H:%M:%S",)   # 这个是带task_id的日志模板,日志可以显示task_id,方便用户串联起来排查某一个任务消息的所有日志.

    TIMEZONE = 'Asia/Shanghai'  # 时区

    # 以下配置是修改funboost的一些命名空间和启动时候的日志级别,新手不熟练就别去屏蔽日志了
    SHOW_HOW_FUNBOOST_CONFIG_SETTINGS = True  # 如果你单纯想屏蔽 "分布式函数调度框架会自动导入funboost_config模块当第一次运行脚本时候，函数调度框架会在你的python当前项目的根目录下 ...... "  这句话,
    FUNBOOST_PROMPT_LOG_LEVEL = logging.DEBUG  # funboost启动时候的相关提示语,用户可以设置这个命名空间的日志级别来调整
    KEEPALIVETIMETHREAD_LOG_LEVEL = logging.DEBUG  # funboost的作者发明的可缩小自适应线程池,用户对可变线程池的线程创建和销毁线程完全无兴趣,可以提高日志级别.

 ```

### 3.3.2 funboost 重要公有方法大全介绍  

仔细看以下代码注释，函数的功能  
```python  
import json  
import time  

from funboost import boost, BrokerEnum,PriorityConsumingControlConfig,BoosterParams  


@boost(BoosterParams(queue_name='queue1', broker_kind=BrokerEnum.REDIS, qps=0.2))  
def f(x, y):  
    return x + y  


@boost(BoosterParams(queue_name='queue2', broker_kind=BrokerEnum.REDIS, qps=7))  
def f2(a, b):  
    return a - b  


if __name__ == '__main__':  
    f.clear()  # 清空f函数对应的queue1所有消息  
    for i in range(10):  
        f.push(i, i * 2)  # 使用push发布消息到queue1，push的入参和正常调用函数一样  
        f2.publish({'a': i, 'b': i * 2},task_options=PriorityConsumingControlConfig(msg_expire_seconds=30))  # # 使用publish发布消息到queue2，publish的入参第一个参数是一个字典，把所有参数组成一个字典，还可以传入其他参数。publish更强大。  

    print(f.get_message_count())  # 获取消息队列中的消息数量  
    f.consume()  # 在当前进程启动多线程/协程消费  
    f2.multi_process_consume(3)  # 启动3个进程，每个进程内部都启动多线程/协程消费，性能炸裂。  

```  

```  
重要方法就是 @boost装饰器的入参，被@boost装饰的消费函数自动有funboost框架的功能  
其中最常见的是：  
push，推送消息到消息队列  
consume， 在当前进程启动多线程/协程消费  
multi_process_consume(n) ，启动多个进程，每个进程内部叠加多线程/协程，性能更强.  

```  

冷门方法  
```  
除以上方法外，还有其他的不常用的方法，在第四章有介绍，  
在pycharm中可以代码补全有哪些方法，自己按照方法名字就能猜出是什么意思了。也可以点进去boost装饰器里面去，里面有每个方法的注释说明。  
例如 f.pause_consume() 可以从python解释器的外部远程，让已经启动queue1的消费函数停止消费，f.continue_consume() 继续消费。  
```  



### 3.3.3 boost装饰器 的 concurrent_num 和 qps 之间的关系。  

```  
 concurrent_num:并发数量。  
    qps qps是有个很有趣的参数，能精确控制函数每秒运行多少次。  
    concurrent_num和qps存在着一定的关系。  
    
    例如对于下面这个函数  
    
    def func(x):  
           time.sleep(2)  
           print(x）  

    1）如果设置 concurrent_num = 1000(或100万)  qps = 10  
    那么一秒钟会执行10次func函数。如果不指定qps的值，则不进行控频，消费框架会平均每秒钟会执行50次函数func。  

    如果设置concurrent_num = 1000  qps = 5   
    那么一秒钟会执行5次func函数。所以可以看到，当你不知道要开多少并发合适的时候，可以粗暴开1000个线程，但要设置一个qps。  
   
    那为什么次框架，可以让你粗暴的设置1000设置100万线程呢，并不是做了数字截取，判断线程设置大于多少就自动调小了，此消费框架并没有这样去实现。  
    而是次框架使用的非concurrent.tutures.ThreadpoolExecutor，是使用的自定义的  ThreadPoolExecutorShrinkAble 线程池，  
    此线程池其中之一的功能就是节制开更多的线程，因为对于上面的休眠2秒的func函数，如果设置concurrent_num = 1000000  qps = 5，  
    正常来说开10个线程足够实现每秒执行5次了，此框架在调节线程新增线程时候进行了更多的判断，所以原生线程池不可以设置100万大小，  
    而ThreadPoolExecutorShrinkAble可以设置为100万大小。  

    此外ThreadPoolExecutorShrinkAble 实现了线程池自动缩小的功能，这也是原生concurrent.tutures.ThreadpoolExecutor没有的功能。  
    自动缩小是什么意思呢，比如一段时间任务非常密集1秒钟来了几百个任务，所以当时开启了很多线程来应付，但一段时间后每分钟只来了个把任务，  
    此时 ThreadPoolExecutorShrinkAble 能够自动缩小线程池，  
    ThreadPoolExecutorShrinkAble实现了java ThreadpoolExecutor的KeepAliveTime参数的功能，  
    原生concurrent.tutures.ThreadpoolExecutor线程池即使以后永久不来新任务，之前开的线程数量一致保持这。  

    关于 ThreadPoolExecutorShrinkAble 的厉害之处，可以参考 https://github.com/ydf0509/threadpool_executor_shrink_able  
    
    最终关于 concurrent_num 大小设置为多少，看自己需求，上面说的100万是举个例子，  
    实际这个参数还被用作为线程池的任务队列的有界队列的大小，所以一定要设置为1000以下，否则如果设置为100万，  
    从消息中间件预取出的消息过多，造成python内存大、单个消费者掏空消息队列中间件造成别的新启动的消费者无任务可消费、  
    对于不支持消费确认类型的中间件的随意重启会丢失大量正在运行的任务 等不利影响。  

    2）上面的func函数，设置 concurrent_num = 1  qps = 100，那会如何呢？  
       由于你设置的并发是1,对于一个需要2秒运行完成的函数，显然平均每2秒才能执行1次，就是框架真正的只能达到0.5个qps。  
       所以 concurrent_num 和 qps，既有关系，也不是绝对的关系。  
    
    在对一个随机消耗时间的函数进行并发控制时候，如果函数的运行时间是0.5到20秒任意时间不确定的徘徊，你可以设置 concurrent_num = 100,  
    如果合作方要求了只能1秒钟能让你使用多少次，例如需要精确控频10次，可以设置qps =10，concurrent_num随便搞个 一两百 两三百就行了,  
    因为是智能的克制的调节线程池大小的，所以不会真的达到concurrent_num的值。  

    3）qps是个小数可以小于1，如果要设置10秒执行一次函数，则设置qps=0.1  

    这主要是介绍了 concurrent_num 和qps的关系和设置值,qps是优先，但受到concurrent_num的约束。  
```  

## 3.4 框架的乞丐精简版实现方式  

由于框架的功能十分多，如果没学习36种设计模式，就很难看懂源码，现在演示精简实现原理  

此精简例子十分之简单明了，就是死循环从中间件取任务然后丢到线程池里面执行。  

此代码在 funboost/beggar_version_implementation/beggar_redis_consumer.py  

这样简单明了，演示了基本原理，但是这个缺少消费确认(随意重启代码会造成大量任务丢失) qps恒定等20种功能。  

```python  
def start_consuming_message(queue_name, consume_function, threads_num=50):  
    pool = ThreadPoolExecutor(threads_num)  
    while True:  
        try:  
            redis_task = redis.brpop(queue_name, timeout=60)  
            if redis_task:  
                task_str = redis_task[1].decode()  
                print(f'从redis的 {queue_name} 队列中 取出的消息是： {task_str}')  
                pool.submit(consume_function, **json.loads(task_str))  
            else:  
                print(f'redis的 {queue_name} 队列中没有任务')  
        except redis.RedisError as e:  
            print(e)  


if __name__ == '__main__':  
    import time  


    def add(x, y):  
        time.sleep(5)  
        print(f'{x} + {y} 的结果是 {x + y}')  

    # 推送任务  
    for i in range(100):  
        print(i)  
        redis.lpush('test_beggar_redis_consumer_queue', json.dumps(dict(x=i, y=i * 2)))  


    start_consuming_message('test_beggar_redis_consumer_queue', consume_function=add, threads_num=10)  
```  

## 3.5 框架的任务消费确认  

<pre>  
此框架可以确保客户端任何时候 随意断电 粗暴重启代码 随意关机，任务万无一失。  

3.4演示的精简版框架，实现redis的list的push和pop来模拟消息队列，很明显不靠谱，kill 9 重启代码或者重启电脑很容易会丢失大量任务。  

分布式一致性消息传递、事件处理等场景中十分重要，分为3种情况：  
At most Onece：最多一次，如果算子处理事件失败，算子将不再尝试该事件。  
At Least Onece：至少一次，如果算子处理事件失败，算子会再次尝试该处理事件，直到有一次成功。  
Exactly-Once：严格地，有且仅处理一次，通常有两种方法实现。  

3.4实现的是最多一次，框架在多种中间件使用消费确认实现了万无一失 ，达到了Exactly-Once。  
Exactly-Once是最好的也是实现难度最复杂的；At most Onece通常是最差的方式，也是最简单的实现方式。  

框架在使用rabbitmq，内置默认了确认消费。  

框架在使用redis作为中间件时候，有很多种实现方式，REDIS 是最不靠谱的会丢失消息。  
REDIS_ACK_ABLE 、 REDIS_STREAM、 RedisBrpopLpush BrokerKind 这三种都是实现了确认消费。  

</pre>  


## 3.6 框架的设计规范原则  

因为使用了oop编程和良好的设计模式，所以 funboost 很容易新增任意消息队列类型以及任何消费框架 作为 funboost的 broker_kind。  
目前没遇到集成不到funboost的消息队列类型和消费框架。  

```  
源码实现思路基本90%遵守了oop的6个设计原则，很容易扩展中间件。  
1、单一职责原则——SRP   
2、开闭原则——OCP   
3、里式替换原则——LSP   
4、依赖倒置原则——DIP   
5、接口隔离原则——ISP   
6、迪米特原则——LOD   

最主要是大量使用了模板模式、工厂模式、策略模式、鸭子类。  
可以仿照源码中实现中间件的例子，只需要继承发布者、消费者基类后实现几个抽象方法即可添加新的中间件。  
```  

<div> </div>
`````

--- **end of file: source/articles/c3.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c4.md** (project: funboost_docs) --- 

`````markdown
# 4. 🔑 使用框架的各种代码示例(学习funboost用法最重要的章节)  

框架极其简单并且自由，只有一个boost装饰器的参数学习， 实际上这个章节所有的例子都是调整了一下boost的参数而已。  

有一点要说明的是框架的消息中间件的ip 端口 密码 等配置是在你第一次随意运行代码时候，在你当前项目的根目录下生成的 funboost_config.py 按需设置。  

所有例子的发布和消费都没必须写在同一个py文件，(除了使用python 自带语言queue)，因为是使用中间件解耦的消息，好多人误以为发布和消费必须在同一个python文件。  

## 4.0 框架最重要的@boost装饰器的入参格式说明  

### 4.0.1 老的 @booost 直接传入多个参数方式  

以下是老的入参方式:  
@boost(queue_test_f01', qps=0.2,broker_kind=BrokerEnum.REDIS_ACK_ABLE,)  

40.0版本之前是老的入参方式,直接在@booost传很多个参数,40.0版本之后你仍然可以这么传参,但是不太推荐,因为不能代码补全函数入参了.  

### 4.0.2 新的@ boost 只传入一个 pydantic Model BoostParams 类型或子类 的入参  

新的@ boost 只传入一个 BoostParams 类型或子类 的入参 ,入参类型是 非常流行的 pydantic包的 model类型.  

@boost(BoosterParams(queue_name='queue_test_f01', qps=0.2,broker_kind=BrokerEnum.REDIS_ACK_ABLE,))  

因为采用pydantic,可以在框架开发时候,减少很多一大推重复入参声明,因为作者很注重代码补全,  
作者不想直接 *args **kwargs暴露给用户,这种会导致用户不知道应该传参什么,pycharm也无法补全,所以需要大量重复的声明,每次加入参,都需要很多地方去修改,  
所以改为使用流行的 pydantic 包来实现入参,fastapi的入参声明就是使用pydantic,非常棒.  

### 4.0.3 pydantic model 的 BoosterParams 的入参pycharm下自动补全  

```  
因为BoosterParams这个pydantic model 类没有 __init__(self,一堆参数) ,而是把类变量,转化成实例变量,  
所以直接对BoostParams传参是无法代码补全的,需要用户在pycharm的Plugins安装一个pydantic的插件,这样就能敲击入参自动补全入参名字了.  

pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,  
点击安装 pydantic 插件.  
```  

![pydantic_install.png](pydantic_install.png)  

### 4.0.4 关于很多funboost 例子的@boost 使用直接入参,没有使用 pydantic Model类型的BoostParams  

因为是兼容老的写法的,老的直接入参仍然可以正常运行,所以例子中没有修改成 @boost(BoosterParams(...)) 入参方式,  
用户知道就行.  

### 4.0.5 自定义子类继承 BoosterParams,使得每次少传参  

```python  
import logging  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


class BoosterParamsMy(BoosterParams): # 传这个类就可以少每次都亲自指定使用rabbitmq作为消息队列，和重试改为4次,和消费发布日志写入自定义.log文件。  
    broker_kind : str = BrokerEnum.RABBITMQ  
    max_retry_times : int =4  
    log_level :int = logging.DEBUG  
    log_filename : str ='自定义.log'  

@boost(boost_params=BoosterParamsMy(queue_name='task_queue_name1d',  qps=3,))  
def task_fun(x, y):  
    print(f'{x} + {y} = {x + y}')  
    time.sleep(3)  # 框架会自动并发绕开这个阻塞，无论函数内部随机耗时多久都能自动调节并发达到每秒运行 3 次 这个 task_fun 函数的目的。  
  

@boost(boost_params=BoosterParamsMy(queue_name='task_queue_name1d', qps=10,))  
def task_fun2(x, y):  
    print(f'{x} - {y} = {x - y}')  
    time.sleep(3)  # 框架会自动并发绕开这个阻塞，无论函数内部随机耗时多久都能自动调节并发达到每秒运行 10 次 这个 task_fun 函数的目的。  


if __name__ == "__main__":  
    task_fun.consume()  # 消费者启动循环调度并发消费任务  
    task_fun2.consume()  
    for i in range(10):  
        task_fun.push(i, y=i * 2)  # 发布者发布任务  
        task_fun2.push(i,i*10)  
```  

## 4.1 装饰器方式调度函数  

```python  
from funboost import boost, BrokerEnum,BoosterParams  


# qps可以指定每秒运行多少次，可以设置0.001到10000随意。  
# broker_kind 指定使用什么中间件，如果用redis，就需要在 funboost_config.py 设置redis相关的配置。  
@boost(BoosterParams(queue_name='queue_test_f01', qps=0.2,  
       broker_kind=BrokerEnum.REDIS_ACK_ABLE,))  # qps 0.2表示每5秒运行一次函数，broker_kind=2表示使用redis作中间件。  
def add(a, b):  
    print(a + b)  


if __name__ == '__main__':  
    for i in range(10, 20):  
        add.publish(dict(a=i, b=i * 2))  # 使用add.publish 发布任务  
        add.push(i, b=i * 2)  # 使用add.push 发布任务  
    add.consume()  # 使用add.consume 消费任务  
    # add.multi_process_consume(4)  # 这是开启4进程 叠加 细粒度(协程/线程)并发，速度更强。  
```  

## 4.2c 在函数内部无限次按照队列名动态生成booster(消费者、生产者) (非装饰器方式)  

BoostersManager.build_booster 方法。  

用法:  
booster = BoostersManager.build_booster(BoosterParams(queue_name=queue_name, qps=0.2, consuming_function=add))  

1）如果是在函数内部按照不同的queue_name无限次动态生成booster，不能按照以下写代码  

```python  
from funboost import boost,Booster,ConcurrentModeEnum,BoosterParams  


def add(a, b):  
    print(a + b)  

def my_push(quue_name,a,b):  
    booster = boost(BoosterParams(queue_name=quue_name,  qps=0.2,concurrent_mode= ConcurrentModeEnum.THREADING))(add)   # type: Booster  
    # 上面这行代码太惨了，在push函数里面无数次创建生产者、消费者和消息队列连接，造成cpu 内存和消息队列服务端压力巨大。  
    booster.push(a,b)  

for i in range(1000000):  
    queue_namx = f'queue_{i%10}'  
    my_push(queue_namx,i,i*2)  
```  

```  
看到有的人这样写代码，这样太惨了，会使python内存和cpu高，会对消息队列服务器产生巨大压力。调用100万次push函数，生成100万次消费者 生产者，对消息队列中间件创建100万次连接。  
这样写代码太惨了，会发生悲剧。  
4.2b的代码例子是在全局变量里面只生成了一次booster，性能没问题。而上面这个代码是在push函数里面实例化100万次 Consumer和Publisher，太悲催了。  

如果你需要动态按照队列名生成生产者消费者，根据入参发布到不同的队列名中，可以自己写个字典判断队列名对应的booster有没有创建过，也可以使用框架提供的 build_booster 函数。  
```  

2）如果是在函数内部无限次动态生成booster，应该使用 BoostersManager.build_booster  

```  
build_booster 是创建或者直接从全局变量字典中获取booster对象。  

如果当前进程没有这个queue_name对应的booster对象就创建，有则直接使用已创建的booster对象。  

下面假设动态生成10个队列名的booster对象，发布100万次消息不需要对消息队列中间件创建100万次连接。  
```  

```python  
from funboost import Booster, BoostersManager,BoosterParams  


def add(a, b):  
    print(a + b)  


def my_push(queue_name, a, b):  
    booster = BoostersManager.build_booster(BoosterParams(queue_name=queue_name, qps=0.2, consuming_function=add))  # type: Booster  
    # build_booster 这种就不会无数次去创建 消息队列连接了。有则直接使用，没有则创建。  
    booster.push(a, b)  


if __name__ == '__main__':  
    for i in range(1000000):  
        queue_namex = f'queue_{i % 10}'  # 动态的发布消息到 queue_0 queue_1 queue_2 queue_3 .... queue_9 队列中。  
        my_push(queue_namex, i, i * 2)  

    for j in range(10):  # 启动  queue_0 queue_1 queue_2 queue_3 .... queue_9 队列的消费者进行消费。  
        booster = BoostersManager.build_booster(BoosterParams(queue_name=f'queue_{j}', qps=0.2,  
                                                consuming_function=add))  # type: Booster  
        booster.consume()  

```  

## 4.2d 框架的 BoostersManager boosters管理介绍  

虽然funboost没有显式的需要你实例化一个app对象,但背后有BoostersManager来登记了所有booster  
例如用户可以通过 BoostersManager 来知道你声明了哪些队列名.  

```  
所有@boost的或者 BoostersManager.build_booster 创建的booster都会登记到 BoostersManager.pid_queue_name__booster_map这里来  
用户可以看到声明了哪些队列名  

BoosterDiscovery(project_root_path: typing.Union[PathLike, str],  
                 booster_dirs: typing.List[typing.Union[PathLike, str]],  
                 max_depth=1, py_file_re_str: str = None).auto_discovery()   
可以扫描python文件夹自动导入模块,找到@boost函数  


BoostersManager.get_or_create_booster_by_queue_name 可以根据队列名创建或者获得booster  
```  

### 4.2d.2 使用 BoostersManager 一次性启动所有队列消费,  

(无需亲自 fun1.consume()  fun2.consume() fun100.consume())  

假设:  

代码文件夹结构如下:  
![img_59.png](img_59.png)  

具体完整代码可见:  
[https://github.com/ydf0509/funboost/tree/master/test_frame/test_boosters_manager](https://github.com/ydf0509/funboost/tree/master/test_frame/test_boosters_manager)  

mod1.py和mod2.py 文件一共有3个消费函数,如果用户不想亲自使用如下方式按需一个个函数的亲自启动消费,而是想粗暴的启动所有消费函数.那么可以使用 BoostersManager的 consume_all 或者 BoostersManager.mp_consume_all(3) 这样启动.  

```python  
mod1.fun1.consume()  
mod2.fun2a.consume()  
mod2.fun2b.consume()  
```  

```python  
from pathlib import Path  

import queue_names  
from funboost import BoostersManager, BoosterDiscovery  

# import mod1, mod2  # 这个是必须导入的,可以不用,但必须导入,这样BoostersManager才能知道相关模块中的@boost装饰器,或者用下面的 BoosterDiscovery.auto_discovery()来自动导入m1和m2模块.  


if __name__ == '__main__':  
    """ 有的人不想这样写代码,一个个的函数亲自 .consume() 来启动消费,可以使用BoostersManager相关的方法来启动某些队列或者启动所有队列.  
    mod1.fun1.consume()  
    mod2.fun2a.consume()  
    mod2.fun2b.consume()  
    """  
    BoosterDiscovery(project_root_path=Path(__file__).parent.parent.parent, booster_dirs=[Path(__file__).parent]).auto_discovery()  # 这个放在main里面运行,防止无限懵逼死循环  

    # 选择启动哪些队列名消费  
    # BoostersManager.consume(queue_names.q_test_queue_manager1,queue_names.q_test_queue_manager2a)  

    # 选择启动哪些队列名消费,每个队列设置不同的消费进程数量  
    # BoostersManager.mp_consume(**{queue_names.q_test_queue_manager1: 2, queue_names.q_test_queue_manager2a: 3})  

    # 启动所有队列名消费,在同一个进程内消费  
    BoostersManager.consume_all()  

    # 启动所有队列名消费,每个队列启动单独的n个进程消费  
    # BoostersManager.mp_consume_all(2)  

```  

### 4.2d.3 使用 BoostersManager ,通过 consume_group 启动一组消费函数

`BoostersManager.consume_group(booster_group)` 通过 `booster_group`消费分组, 启动消费  

例如一组函数装饰器都写 `BoosterParams(booster_group='group1')` ，那么 `BoostersManager.consume_group('group1')` 会启动这组函数消费。

主要是取代用户手动写 `f1.consume()` `f2.consume()`  这样需要多次亲自手写逐个启动相关消费函数;    
也避免了 `BoostersManager.consume_all()` 太过于粗暴,会启动不相关的多余消费函数.    
也避免了 `BoostersManager.consume('q1', 'q2', ...)` 亲自写queue_name列表来启动消费函数.

booster_group 代码演示:
```python
"""
演示使用 BoostersManager.consume_group($booster_group) 启动消费组

BoostersManager.consume_group(booster_group=GROUP1_NAME)
相当于是内部执行了 f1.consume() f2.consume() 这种分多次启动消费函数,

因为f1和f2的booster_group都是GROUP1_NAME,所以会被启动消费组,
f3的booster_group是None,所以不会被启动消费
"""

import time
from funboost import boost, BoosterParams, BoostersManager, ConcurrentModeEnum
from funboost.utils.ctrl_c_end import ctrl_c_recv


GROUP1_NAME = "my_group1"

# 自定义的参数类，继承BoosterParams，用于减少每个消费函数装饰器的重复相同入参个数,
# 不用相关函数都重复写 booster_group 入参.
class MyGroup1BoosterParams(BoosterParams):
    concurrent_mode: str = ConcurrentModeEnum.SINGLE_THREAD
    booster_group: str = GROUP1_NAME  # 指定消费分组名字


@boost(
    MyGroup1BoosterParams(
         # 使用了自定义类 MyGroup1BoosterParams ,所以 f1的booster_group 会自动指定为 GROUP1_NAME
        queue_name="queue_test_consume_gq1",
    )
)
def f1(x):
    time.sleep(2)
    print(f"f1 {x}")


@boost(
    MyGroup1BoosterParams( 
        # 使用了自定义类 MyGroup1BoosterParams ,所以 f2的booster_group 会自动指定为 GROUP1_NAME
        queue_name="queue_test_consume_gq2",
    )
)
def f2(x):
    time.sleep(2)
    print(f"f2 {x}")


@boost(
    BoosterParams(
        # 没有使用自定义类 MyGroup1BoosterParams 而是直接传入 BoosterParams,所以 f3 的booster_group 是 None
        queue_name="queue_test_consume_gq3",
        concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD,
    )
)
def f3(x):
    time.sleep(2)
    print(f"f3 {x}")


if __name__ == "__main__":
    for i in range(10):
        f1.push(i)
        f2.push(i)
        f3.push(i)

    # f1.consume() # 分多次启动消费函数,如果嫌麻烦觉得需要一个一个启动有关函数,可以 BoostersManager.consume_group 一次启动一个分组的所有函数的消费
    # f2.consume()

    BoostersManager.consume_group(
        GROUP1_NAME
    )  # 当前进程内启动消费组 GROUP1_NAME , 内部相当于是执行了 f1.consume() f2.consume() 
    # BoostersManager.multi_process_consume_group(GROUP1_NAME,2) # 多进程启动消费组
    ctrl_c_recv()

```

**重点说明**: `BoostersManager.consume_group($booster_group)`启动消费一组函数,如果@boost的函数是在多个不同的文件模块中,需要先人工import一下这些模块,或者用 BoosterDiscovery().auto_discovery() 来自动导入这些模块，不然无法自动知道 $booster_group 组 有哪些booster/消费函数。


### 4.2d.4 使用 BoostersManager ,通过queue_name 得到 booster对象  

BoostersManager.get_booster(queue_name) 通过queue_name 获取 booster(被@boost装饰的函数)  



## 4.2e funboost 支持实例方法、类方法、静态方法、普通函数 4种类型，作为消费函数的例子  

funboost 在 2024年6月新增支持了实例方法、类方法作为消费函数 ，见文档4.32章节  

## 4.3a 演示如何解决多个步骤的消费函数  

看这个例子，step1函数中不仅可以给step2发布任务，也可以给step1自身发布任务。  

qps规定了step1每2秒执行一次，step2每秒执行3次。  

```python  
import time  

from funboost import boost, BrokerEnum,BoosterParams  


@boost(BoosterParams(queue_name='queue_test_step1', qps=0.5, broker_kind=BrokerEnum.LOCAL_PYTHON_QUEUE))  
def step1(x):  
    print(f'x 的值是 {x}')  
    if x == 0:  
        for i in range(1, 300):  
            step1.pub(dict(x=x + i))  
    for j in range(10):  
        step2.push(x * 100 + j)  # push是直接发送多个参数，pub是发布一个字典  
    time.sleep(10)  


@boost(BoosterParams(queue_name='queue_test_step2', qps=3, broker_kind=BrokerEnum.LOCAL_PYTHON_QUEUE))  
def step2(y):  
    print(f'y 的值是 {y}')  
    time.sleep(10)  


if __name__ == '__main__':  
    # step1.clear()  
    step1.push(0)  # 给step1的队列推送任务。  

    step1.consume()  # 可以连续启动两个消费者，因为conusme是启动独立线程里面while 1调度的，不会阻塞主线程，所以可以连续运行多个启动消费。  
    step2.consume()  

```  

## 4.3.b 演示多个函数消费者使用同一个线程池  

```python  
from funboost import boost,BoosterParams  
from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool  


"""  
这个是演示多个不同的函数消费者，使用同一个全局的并发池。  
如果一次性启动的函数过多，使用这种方式避免每个消费者创建各自的并发池，减少线程/协程资源浪费。  
"""  

# 总共那个有5种并发池，用户随便选。  
pool = FlexibleThreadPool(300)  # 指定多个消费者使用同一个线程池，  




# @boost('test_f1_queue', specify_concurrent_pool=pool, qps=3)  # 旧写法，直接在@boost传各种参数  
@boost(BoosterParams(queue_name='test_f1_queue', specify_concurrent_pool=pool, qps=3)) # 新写法在BoosterParams传各种参数  
def f1(x):  
    print(f'x : {x}')  


@boost(BoosterParams(queue_name='test_f2_queue', specify_concurrent_pool=pool, qps=2))  
def f2(y):  
    print(f'y : {y}')  


@boost(BoosterParams(queue_name='test_f3_queue', specify_concurrent_pool=pool))  
def f3(m, n):  
    print(f'm : {m} , n : {n}')  


if __name__ == '__main__':  
    for i in range(1000):  
        f1.push(i)  
        f2.push(i)  
        f3.push(i, 1 * 2)  
    f1.consume()  
    f2.consume()  
    f3.consume()  



```  

## 4.3c 演示清空消息队列和获取消息队列中的消息数量  

```  
f2.clear()  清空消息队列  

f2.get_message_count() 获取消息队中的消息数量，  
不能使用 f2.get_message_count() =0 来判断消息队列没任务了以为该函数的所有消息被消费完成了，本地内存队列存储了  
一部分消息和正在执行的也有一部分消息，如果要判断消费完成了，应该使用4.17章节的 判断函数运行完所有任务，再执行后续操作。  
```  

```python  

@boost(BoosterParams(queue_name='test_queue77g', log_level=10, broker_kind=BrokerEnum.REDIS_ACK_ABLE, qps=5,  
       create_logger_file=False, is_show_message_get_from_broker=True, concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD  
       # specify_concurrent_pool= pool2,  
       # concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD, concurrent_num=3,is_send_consumer_heartbeat_to_redis=True,function_timeout=10,  
       # function_result_status_persistance_conf=FunctionResultStatusPersistanceConfig(True,True)  
       ))  
def f2(a, b):  
    time.sleep(10)  
    print(a, b)  
    return a - b  


if __name__ == '__main__':  

    f2.clear()  
    for i in range(8):  
        f2.push(i, i * 5)  
    print(f2.get_message_count())  

    f2.clear()  
    for i in range(20):  
        f2.push(i, i * 2)  
    print(f2.get_message_count())  
```  

## 4.4 演示funboost定时运行例子  

ApsJobAdder(消费函数, job_store_kind='redis').add_push_job(....) 来添加定时任务.  

ApsJobAdder实例化时候,会默认自动启动定时器,用户可以设置实例化时候是否 顺便 is_auto_paused 暂停执行  定时任务.  

<pre class="warn">  
警告!!!  
ApsJobAdder(消费函数, job_store_kind='redis').add_push_job(....) 实际上是做了2件事情,  
分别是 启动定时器 aps_obj.start() 和 添加定时任务 aps_obj.add_job(). 不要以为只是添加定时任务  

所以如果是 添加定时任务和启动消费是分开部署的, 一定记得要在消费脚本中加上启动定时器  
启动消费中加上  ApsJobAdder(消费函数, job_store_kind='redis') 这样实例化就顺便启动了定时器.  
如果你不启动定时器,那么即使你之前已经加到redis job_store的定时任务,也没有定时器来触发.  
</pre>  

定时运行消费演示，定时方式入参用法可以百度 apscheduler 定时包。  

定时的语法和入参与本框架无关系，不是本框架发明的定时语法，具体的需要刻苦学习 最知名的 apscheduler 定时包 ,所有对定时使用或报错感到疑惑的都是因为用户不愿意刻苦学习 apscheduler 官方文档造成的，  
和funboost框架毫无关系。  

要想玩好定时请务必苦学 apscheduler 3.x 官方文档：  
[https://apscheduler.readthedocs.io/en/3.x/](https://apscheduler.readthedocs.io/en/3.x/)  



### 4.4.0 funboost定时任务最基本原理说明  

**funboost中的定时任务原理是:自动定时发布消息到消息队列，而非直接执行函数本身**  

```  
定时执行funboost发送函数入参到消息队列，然后funboost框架持续消费消息队列中的任务,从而达到执行消费函数的目的。  
而不是在当前程序定时执行消费函数本身。  

例如funboost中  add_push_job 添加一个每隔3秒运行fun消费函数的， 本质是每隔3秒自动运行 fun.push() , 而不是每隔3秒运行 fun() 本身，  
理解这点至关重要。  
如果你理解了这个原理，那么funboost的定时任务就非常简单，你可以自己使用apscheudler原生包来添加定时任务，  
而不是非得使用funboost框架的ApsJobAdder的add_push_job来添加定时任务。  


如果你直接使用官方的 apscheduler对象，  
假设 fun是@boost装饰的消费函数，  
apscheduler对象.add_job(fun,args=(1,2)) 你这是错误写法，除非你期望就是在当前程序执行add_job函数本身，  

你应该写的是，要多加一个发送函数  
def fun_push_msg(x,y):  
    fun.push(x,y)  
apscheduler对象.add_job(fun_push_msg,args=(1,2))   


所以如果你用 apscheduler原生，那就要自己写一个发布消息的函数，add_job调用你定义的发布消息的函数。  
有人认为为什么不能写成 apscheduler对象.add_job(fun.push,args=(1,2)) ，那就可以少写一个fun_push_msg函数， 你太年轻了，没实践采坑过就不知道。  
要说明的是 fun.push 他是一个实例方法，他不是一个函数，方法是和对象绑定的，对象上面是有属性的不一定可序列化，所以apscheduler.add_job 是函数定时，没给你说是实例方法能定时啊。  
所以apscheduler对象.add_job第一个入参必须是函数或者静态方法，不能是实例方法啊。  
所以apscheduler对象.add_job(fun.push,args=(1,2))这种写法当然不行了。  

而使用 funboost封装的 ApsJobAdder().add_push_job 就是为了帮你自动节约少写一个 fun_push_msg 这种函数。  

```  

### 4.4.1 funboost定时任务代码演示：  

```python  


"""  
2025年后定时任务现在推荐使用 ApsJobAdder 写法 ，用户不需要亲自选择使用 apscheduler对象来添加定时任务。  

使用对apscheduler封装的ApsJobAdder比 直接使用 apscheduler 包的好处如下：  

1、ApsJobAdder.add_push_job 来添加定时发布到消息队列的任务，  
  可以让用户少写一个 push_xx_fun_to_broker 的函数，用户不需要 apscheduler.add_job(push_xx_fun_to_broker,args=(1,)) ，  
  而是 ApsJobAdder.add_push_job(xx_fun,args=(1,))  
  
2.ApsJobAdder在redis作为job_store时候，每个消费函数使用单独的 jobs_key ，每个消费函数使用独立的 apscheduler对象，  
避免扫描定时任务互相干扰。   
例如你只想启动fun1的定时任务，而不像启动fun2的定时任务，更能单独控制。  
  
3. ApsJobAdder在redis作为job_store时候 ，_process_jobs 使用了 redis分布式锁， 解决经典头疼的 apschduler实例建议  
只在一个进程启动一次，  
现在可以在多机器多进程随意反复启动多次 apscheduler对象，不会造成定时任务执行重复。  
"""  

from funboost import boost, BrokerEnum,ctrl_c_recv,BoosterParams,ApsJobAdder  



# 定义任务处理函数  
@boost(BoosterParams(queue_name='sum_queue5', broker_kind=BrokerEnum.REDIS))  
def sum_two_numbers(x, y):  
    result = x + y   
    print(f'The sum of {x} and {y} is {result}')  


@boost(BoosterParams(queue_name='data_queue5', broker_kind=BrokerEnum.REDIS))  
def show_msg(data):  
    print(f'data: {data}')  

if __name__ == '__main__':  
   
    # 启动消费者  
    sum_two_numbers.consume()  
    show_msg.consume()  
  
    # 发布任务  
    sum_two_numbers.push(3, 5)  
    sum_two_numbers.push(10, 20)  

    show_msg.push('hello world')  
  
    # 使用ApsJobAdder添加定时任务， 里面的定时语法，和apscheduler是一样的，用户需要自己熟悉知名框架apscheduler的add_job定时入参  
    # ApsJobAdder 类可以多次重复实例化,内部对每一个消费函数使用一个单独的apscheduler对象,避免扫描与当前关心的消费函数不相干的redis jobstore中的定时任务  

    # 方式1：指定日期执行一次,   
    # ApsJobAdder(sum_two_numbers, job_store_kind='redis').aps_obj.start(paused=False)  
    ApsJobAdder(sum_two_numbers, job_store_kind='redis').add_push_job(  
        trigger='date',  
        run_date='2025-01-17 23:25:40',  
        args=(7, 8),  
        replace_existing=True, # 如果写个id，就不能重复添加相同id的定时任务了，要使用replace_existing来替换之前的定时任务id  
        id='date_job1'  
    )  

    # 方式2：固定间隔执行,使用内存作为apscheduler的 job_store  
    ApsJobAdder(sum_two_numbers, job_store_kind='redis').add_push_job(  
        trigger='interval',  
        seconds=5,  
        args=(4, 6),  
        id='interval_job1',  
        replace_existing=True  
    )  

    # 方式3：使用cron表达式定时执行  
    ApsJobAdder(sum_two_numbers, job_store_kind='redis').add_push_job(  
        trigger='cron',  
        day_of_week='*',  
        hour=23,  
        minute=49,  
        second=50,  
        kwargs={"x":50,"y":60},  
        replace_existing=True,  
        id='cron_job1')  

    # 延时使用内存作为apscheduler的 job_store ，因为是内存，这种定时任务计划就不能持久化。  
    ApsJobAdder(show_msg, job_store_kind='memory').add_push_job(  
        trigger='interval',  
        seconds=20,  
        args=('hi python',)  
    )  

    ctrl_c_recv() # 这个是阻止代码主线程结束，这在background类型的apscheduler很重要，否则会报错提示主线程已退出。 当然，你也可以在末尾加 time.sleep 来阻止主线结束。  
```  

funboost 定时语法说明：  

```  
funboost中定时任务用法是：  
ApsJobAdder(消费函数,).add_push_job(trigger='interval',.....)  

原生 apscheduler 添加定时任务用法例子是：  
scheduler.add_job(my_job, 'interval', seconds=3, id='my_interval_job')  

相比较而言，funboost中定时推荐你使用 ApsJobAdder(消费函数,).add_push_job ，  
注意是 add_push_job 而非 add_job ， 并且add_push_job去掉了第一个入参func ，  
add_push_job 其他入参和 apscheduler的add_job一模一样。  

用户有兴趣可以看 ApsJobAdder 源码，他只是基于 apscheduler 的一个非常简单易懂的包装而已。  
```  

<pre style="background-color:yellow;color:red">  

python3.9及以上 定时任务报错 RuntimeError: cannot schedule new futures after interpreter shutdown  

我们是需要使得主线程其他任务不结束， 看10.2章节文档，在你脚本的最后一行加个 while 1: time.sleep(100) , 阻止主线程退出就好了。  
或者结尾加个 ctrl_c_recv()   （先from funboost import  ctrl_c_recv）  

</pre>  

### 4.4.2 ApsJobAdder对象.aps_obj 核心对象说明  

ApsJobAdder对象.aps_obj 是官方 apscheduler.BackgroundScheduler类型对象  

你可以亲自使用 ApsJobAdder(sum_two_numbers, job_store_kind='redis',is_auto_start=False,).aps_obj 来精细化操作这个对象。  

**例如删除一个定时任务：**   
ApsJobAdder(sum_two_numbers, job_store_kind='redis',is_auto_start=False,).aps_obj.remove_job('你指定的job_id')  

**删除所有定时任务：**  
ApsJobAdder(sum_two_numbers, job_store_kind='redis',is_auto_start=False,).aps_obj.remove_all_jobs()  

**例如查看所有定时计划**  
ApsJobAdder(sum_two_numbers, job_store_kind='redis',is_auto_start=False,).aps_obj.get_jobs()  

**aps_obj的其他方法我不再啰嗦了，都是知名三方包apscheduler的Scheduler类型的方法，本质原因是你不愿意苦学apscheduler，这些用法功能和funboost自身源码毫无关系。**  

funboost的对apscheduler包的轻度二次包装，是为了简化添加 “push到消息队列” 的定时任务，用户完全可以直接使用原生 apscheduler。   
但你要把”发布消息到消息队列“作为定时任务，而不是把“执行函数本身逻辑”作为定时任务。   

### 4.4.3 演示在python web中定时任务的添加 （添加和执行定时任务分在不同的py脚本中）  

web中去添加和修改定时任务，web单独部署一次。  
funboost后台异步任务单独部署一次,建议定时器需要随着消费一起启动。  


**在web接口代码中添加定时任务计划，但可以不执行定时任务,设置is_auto_paused=True**  

**在启动消费的脚本中,要明确启动定时器,ApsJobAdder(fun_sum,job_store_kind='redis',) ,ApsJobAdder类默认就是  is_auto_start=True is_auto_paused=False**   

web中添加定时任务demo连接：  

[https://github.com/ydf0509/funboost/tree/master/test_frame/funboost_aps_web_demo](https://github.com/ydf0509/funboost/tree/master/test_frame/funboost_aps_web_demo)  

```  
演示在python web中定时任务的添加，添加定时任务的脚本和启动消费的脚本不在同一个py文件中,一定要注意务必要启动定时任务apschduler对象，这是最关键的。  

web中需要启动定时器,is_auto_start=True,但你可以选择暂停执行定时任务is_auto_paused=True,在启动消费的那里去写启动和执行定时任务.  
ApsJobAdder(消费函数, job_store_kind='redis', is_auto_start=True,is_auto_paused=True)  

(ps:当然可以多个地方都 is_auto_start=True,is_auto_paused=True 这样启动定时器,  
因为funboost已经继承优化了原生apscheduler类,不怕你多次重复部署apscheduler定时器造成重复执行相同的定时任务  
有兴趣的用户可以看 https://github.com/ydf0509/funboost/blob/master/funboost/timing_job/apscheduler_use_redis_store.py 的 FunboostBackgroundSchedulerProcessJobsWithinRedisLock 的 _process_jobs 方法, 这个是防止apscheduler多次部署导致重复执行定时任务的根本核心解决.  
)  
```  

###### 4.4.3.2 web_app.py 是web应用，负责添加定时任务到redis中。此处使用flask框架演示， django  fastapi同理，不需要我一一举例子。  

```  
因为funboost是自由无拘无束的，不需要 django-funboost  flask-funboost fastapi-funboost 插件。  

只有坑爹难用的celery才需要django-celery  flask-celery fastapi-celery 三方插件来帮助用户简化适配各种web框架使用，  
funboost压根不需要这种适配各种web框架的插件。  
```  

###### 4.4.3.3 run_consume.py 是启动消费 和 启动apschduler定时器的脚本  

```python  
ApsJobAdder(fun_sum,job_store_kind='redis',) #负责启动apschduler对象，apschduler对象会扫描redis中的定时任务，并执行定时任务，定时任务的功能就是定时push消息到消息队列中。  

fun_sum.consume()  # 启动消费消息队列中的消息  
```  

<pre style="background-color:yellow;color:red;font-weight:bold">  
警告！！！你不要只启动fun_sum.consume()  而不启动apschduler对象，  
否则apschduler对象不会扫描redis中已添加好的定时任务，就不会自动定时的push消息到消息队列中。  
</pre>  


## 4.4.4 新增的 支持 aps_obj.add_job 添加定时任务(可以不用 add_push_job) (2025-08)  

**第一性原理:**  
由于 Booster 对象在2025-08,新增支持了pickle 序列化和反序列化,所以可以支持      
```aps_obj.add_job($booster对象.push,...)``` 这种写法.   

具体看下面代码中的文字注释:  
```python  

"""  
此脚本是演示,由于2025-08 Booster 对象支持了 pickle序列化后,  
可以支持  
aps_obj_sum_two_numbers2.add_job(  
        sum_two_numbers2.push,...)  
这种写法.  

这样用户可以了解定时任的本质是 push到消息队列,而不是直接执行函数自身.  

用户看这个脚本主要是需要对比 add_push_job 和 add_job 的区别.  
"""  
from funboost import boost, BrokerEnum,ctrl_c_recv,BoosterParams,ApsJobAdder  

# 定义任务处理函数  
@boost(BoosterParams(queue_name='sum_queue552', broker_kind=BrokerEnum.REDIS))  
def sum_two_numbers2(x, y):  
    result = x + y  
    print(f'The sum of {x} and {y} is {result}')  

if __name__ == '__main__':  
    # ApsJobAdder(sum_two_numbers2, job_store_kind='redis').add_push_job(  
    #     trigger='interval',  
    #     seconds=5,  
    #     args=(4, 6),  
    #     replace_existing=True,  
    #     id='interval_job501',  
    # )  
    aps_job_adder_sum_two_numbers2 = ApsJobAdder(sum_two_numbers2, job_store_kind='redis',is_auto_paused=False)  
    aps_obj_sum_two_numbers2 =aps_job_adder_sum_two_numbers2.aps_obj  
    aps_obj_sum_two_numbers2.remove_all_jobs() # 可选,删除sum_two_numbers2所有已添加的定时任务  

    # 原来推荐的添加定时任务方式 add_push_job  
    aps_job_adder_sum_two_numbers2.add_push_job(  
        # ApsJobAdder.add_push_job 不需要传递第一个入参func,job函数  
        trigger='interval',  
        seconds=5,  
        args=(4, 6),  
        replace_existing=True,  
        id='interval_job503',  
    )  


    """  
    2025-08后 现在可以直接使用用户熟悉的 add_job ,第一个入参func传递 $消费函数.push  
    
    当使用redis 这种数据库而非memory作为 apscheduler 的 jobstore 时候,apscheduler.add_job 需要pickle序列化 第一个入参 func,  
    sum_two_numbers2.push 是一个实例方法, Booster对象属性链路上有 threading.Lock 和socket 这些类型,  
    导致不可pickle序列化,所以原来需要使用 ApsJobAdder.add_push_job 曲线救国.  
    
    由于现在新增添加了 booster 支持pickle 序列化和反序列化,所以可以支持 sum_two_numbers2.push 实例方法 作为job函数.  
    
    (ps:有兴趣的可以看 funboost/core/booster.py 的 Booster 的 __getstate__ 和 __setstate__ 的实现方式,是怎么支持pickle的,很巧妙)  
    """  
    aps_obj_sum_two_numbers2.add_job(  
        func = sum_two_numbers2.push, # aps_obj.add_job 是 原生的,需要传递第一个入参func ,sum_two_numbers2.push  
        trigger='interval',  
        seconds=5,  
        args=(40, 60),  
        replace_existing=True,  
        id='interval_job504',  
    )  


    ctrl_c_recv()  
```  

## 4.5 多进程并发 + 多线程/协程，代码例子。  

ff.multi_process_start(2)  就是代表启动2个独立进程并发 + 叠加 asyncio、gevent、eventlet、threding 、single_thread 细粒度并发，<br>  
例如fun函数加上@boost(BoosterParams(queue_name='queue_name', concurrent_num=200)),fun.multi_process_start(16) ,这样16进程叠加每个进程内部开200线程/协程，运行性能炸裂。  

多进程消费  

```python  
import time  
from funboost import boost, BrokerEnum, PriorityConsumingControlConfig, BoosterParams  

"""  
演示多进程启动消费，多进程和 asyncio/threading/gevnt/evntlet是叠加关系，不是平行的关系。  
"""  

# qps=5，is_using_distributed_frequency_control=True 分布式控频每秒执行5次。  
# 如果is_using_distributed_frequency_control不设置为True,默认每个进程都会每秒执行5次。  
@boost(BoosterParams(queue_name='test_queue', broker_kind=BrokerEnum.REDIS, qps=5, is_using_distributed_frequency_control=True))  
def ff(x, y):  
    import os  
    time.sleep(2)  
    print(os.getpid(), x, y)  


if __name__ == '__main__':  
    ff.clear() # 清除  
    # ff.publish()  
    for i in range(1000):  
        ff.push(i, y=i * 2)  

        # 这个与push相比是复杂的发布，第一个参数是函数本身的入参字典，后面的参数为任务控制参数，例如可以设置task_id，设置延时任务，设置是否使用rpc模式等。  
        ff.publish({'x': i * 10, 'y': i * 2}, task_options=PriorityConsumingControlConfig(countdown=1, misfire_grace_time=15))  

    ff(666, 888)  # 直接运行函数  
    ff.start()  # 和 conusme()等效  
    ff.consume()  # 和 start()等效  
    ff.multi_process_start(2)  # 启动两个进程，  

```  

## 4.6 演示rpc模式，即客户端调用远程函数并及时得到结果。  

```  
如果在发布端要获取消费端的执行结果，有两种方式  
1、需要在@boost设置is_using_rpc_mode=True，默认是False不会得到结果。  
2、如果@boost没有指定，也可以在发布任务的时候，用publish方法并写上  
  task_options=PriorityConsumingControlConfig(is_using_rpc_mode=True)  
  
用这个功能必须在funboost_config.py配置文件中配置好redis链接，  
无论你使用 redis kafka rabbitmq 还是 sqlite 等 作为中间件，想用rpc功能就必须配置好redis连接。  
```  

### 4.6.1 rpc 消费端执行两数求  

远程服务端脚本，执行求和逻辑。 test_frame\test_rpc\test_consume.py  

```python  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_rpc_queue', is_using_rpc_mode=True, broker_kind=BrokerEnum.REDIS_ACK_ABLE, concurrent_num=200))  
def add(a, b):  
    time.sleep(3)  
    return a + b  


if __name__ == '__main__':  
    add.consume()  
```  

### 4.6.2 发布端获取求和的结果  

客户端调用脚本，单线程发布阻塞获取两书之和的结果，执行求和过程是在服务端。 test_frame\test_rpc\test_publish.py  

这种方式如果在主线程单线程for循环运行100次，因为为了获取结果，导致需要300秒才能完成100次求和。  

客户端获取服务端执行结果脚本  

```python  
from funboost import PriorityConsumingControlConfig  
from test_frame.test_rpc.test_consume import add  

for i in range(100):  
    async_result = add.push(i, i * 2)  
    print(async_result.result)  # 执行 .result是获取函数的运行结果，会阻塞当前发布消息的线程直到函数运行完成。  

    # 如果add函数的@boost装饰器参数没有设置 is_using_rpc_mode=True，则在发布时候也可以指定使用rpc模式。  
    async_result = add.publish(dict(a=i * 10, b=i * 20), task_options=  
    PriorityConsumingControlConfig(is_using_rpc_mode=True))  
    print(async_result.status_and_result)  

```  

### 4.6.2b 发布端获取求和的结果，在线程池中进一步处理结果  

上面方式中是在单线程环境下阻塞的一个接一个打印结果。如果想快速并发处理结果，可以自己手动在多线程或线程池处理结果。 框架也提供一个设置回调函数，自动在线程池中处理回调结果，回调函数有且只有一个入参，表示函数运行结果及状态。  

如下脚本则不需要300秒运行完成只需要3秒即可，会自动在并发池中处理结果。  

```python  
from funboost import PriorityConsumingControlConfig  
from test_frame.test_rpc.test_consume import add  


def show_result(status_and_result: dict):  
    """  
    :param status_and_result: 一个字典包括了函数入参、函数结果、函数是否运行成功、函数运行异常类型  
    """  
    print(status_and_result)  


for i in range(100):  
    async_result = add.push(i, i * 2)  
    # print(async_result.result)   # 执行 .result是获取函数的运行结果，会阻塞当前发布消息的线程直到函数运行完成。  
    async_result.set_callback(show_result)  # 使用回调函数在线程池中并发的运行函数结果  
```  

### 4.6.3 手动设置rpc结果最大等待时间  

手动设置rpc结果最大等待时间，不使用默认的120秒等待时间。  

```  
上面的求和例子是耗时3秒，所以只要任务不在消息队列积压，120秒内可以获取到结果。如果上面的求和函数耗时600秒，120秒内就获取不到结果了。  
可以手动设置异步结果最大的等待时间，.set_timeout(3600) 就是最大等待1小时了。  

async_result = add.push(i, i * 2)  
async_result.set_timeout(3600)  

这样设置后，就是为了获得消费结果，最大等待3600秒。  
默认是最大等待120秒返回结果，如果消费函数本身耗时就需要消耗很长的时间，可以适当扩大这个时间。  
```  

### 4.6.4 为什么获取不到执行结果？  

1) 首先要检查 有没有设置 is_using_rpc_mode=True ，默认是不使用这个模式的，没有设置为True就不可能得到执行结果。  
2) 默认为等待结果最大120秒，如果你的函数耗时本来就很大或者消息队列有大量积压，需要按4.6.3 调大最大等等时间  

### 4.6.5 asyncio 语法生态下rpc获取执行结果。  

<p style="color: #00A000">完整的除了asyncio并发，包括 aio_push 和 asyncio 来等待获取结果，请看4b.3 章节</p>p> [ funboost + 全asyncio 编程生态演示](https://funboost.readthedocs.io/zh-cn/latest/articles/c4b.html#b-3-funboost-asyncio)  

```  
因为 async_result= fun.push() ，默认返回的是 AsyncResult 类型对象,里面的方法都是同步语法。  
async_result.result 是一个耗时的函数， 解释一下result， 是property装饰的所以不用 async_result.result()  
有的人直接在async def 的异步函数里面 print (async_result.result)，如果消费函数消费需要耗时5秒，  
那么意味rpc获取结果至少需要5秒才能返回，你这样写代码会发生灭顶之灾，asyncio生态流程里面一旦异步需要处处异步。  
所以新增了 AioAsyncResult 类，和用户本来的asyncio编程生态更好的搭配。  
```  

服务端求和脚本还是4.6.1 两数求和不变，这里演示asyncio生态下的获取rpc结果脚本  

```python  
import asyncio  

from funboost import AioAsyncResult  
from test_frame.test_rpc.test_consume import add  


async def process_result(status_and_result: dict):  
    """  
    :param status_and_result: 一个字典包括了函数入参、函数结果、函数是否运行成功、函数运行异常类型  
    """  
    await asyncio.sleep(1)  
    print(status_and_result)  


async def test_get_result(i):  
    async_result = add.push(i, i * 2)  
    aio_async_result = AioAsyncResult(task_id=async_result.task_id) # 这里要使用asyncio语法的类，更方便的配合asyncio异步编程生态  
    print(await aio_async_result.result) # 注意这里有个await，如果不await就是打印一个协程对象，不会得到结果。这是asyncio的基本语法，需要用户精通asyncio。  
    print(await aio_async_result.status_and_result)  
    await aio_async_result.set_callback(process_result)  #  你也可以编排任务到loop中  


if __name__ == '__main__':  
    loop = asyncio.get_event_loop()  
    for j in range(100):  
        loop.create_task(test_get_result(j))  
    loop.run_forever()  

```  

```text  
async_result = add.push(i, i * 2)   
async_result 的类型是AsyncResult，是同步场景下的类。这个Async不是指的asyncio语法异步，是生产者消费者模式整体大的概念上的异步，不是指的python asyncio语法异步。  

aio_async_result = AioAsyncResult(task_id=async_result.task_id) ，这个是asyncio语法类AioAsyncResult，这个类里面的耗时io的方法全都是async def的，  
这种更好的配合用户当前已经是 asyncio 编程生态。因为在asyncio编程生态中，在一个loop里面，要全部异步，只要一个是同步阻塞的方法，整个loop中其他协程任务完了个蛋，  
也就是常说的一旦异步要处处异步，不要在一串流程中一会儿调用asyncio的耗时函数，一会调用同步耗时函数，这样是个悲剧，懂的都懂这句话。  
```  

### 4.6.7 从mongo中获取函数执行结果  

首先 boost装饰器中设置函数状态结果持久化后，会保存函数的状态和结果到mongodb中。  

function_result_status_persistance_conf=FunctionResultStatusPersistanceConfig(is_save_status=True,is_save_result=True,expire_seconds=500000)  

使用 ResultFromMongo 类获取函数结果  

```python  
# 以非等待方式获取mongo中函数的结果。  
import time  
from funboost import ResultFromMongo  

async_result = add.push(10, 20)  
task_id = async_result.task_id  
time.sleep(2)  
print(ResultFromMongo(task_id).get_status_and_result())  

print(ResultFromMongo('test_queue77h6_result:764a1ba2-14eb-49e2-9209-ac83fc5db1e8').get_status_and_result())  
print(ResultFromMongo('test_queue77h6_result:5cdb4386-44cc-452f-97f4-9e5d2882a7c1').get_result())  
```  

## 4.7 演示qps控频  

演示框架的qps控频功能  

此框架对函数耗时随机波动很大的控频精确度达到96%以上  

此框架对耗时恒定的函数控频精确度达到99.9%  

在指定rate_limit 超过 20/s 时候，celery对耗时恒定的函数控频精确度60%左右，下面的代码会演示这两个框架的控频精准度对比。  

<pre style="color: #00A000">  
此框架针对不同指定不同qps频次大小的时候做了不同的三种处理方式。  
框架的控频是直接基于代码计数，而非使用redis 的incr计数，因为python操作一次redis指令要消耗800行代码左右，  
如果所有任务都高频率incr很消耗python脚本的cpu也对redis服务端产生灾难压力。  
例如假设有50个不同的函数，分别都要做好几千qps的控频，如果采用incr计数，光是incr指令每秒就要操作10万次redis，  
所以如果用redis的incr计数控频就是个灾难，redis incr的计数只适合 1到10大小的qps，不适合 0.01 qps 和 1000 qps这样的任务。  

同时此框架也能很方便的达到 5万 qps的目的，装饰器设置qps=50000 和 is_using_distributed_frequency_control=True,  
然后只需要部署很多个进程 + 多台机器，框架通过redis统计活跃消费者数量，来自动调节每台机器的qps，框架的分布式控频开销非常十分低，  
因为分布式控频使用的仍然不是redis的incr计数，而是基于每个消费者的心跳来统计活跃消费者数量，然后给每个进程分配qps的，依然基于本地代码计数。  

例如部署100个进程(如果机器是128核的，一台机器足以，或者20台8核机器也可以)  
以20台8核机器为例子，如果把机器减少到15台或增加机器到30台，随便减少部署的机器数量或者随便增加机器的数量，  
代码都不需要做任何改动和重新部署，框架能够自动调节来保持持续5万次每秒来执行函数，不用担心部署多了30台机器，实际运行qps就变成了10几万。  
(前提是不要把机器减少到10台以下，因为这里假设这个函数是一个稍微耗cpu耗时的函数，要保证所有资源硬件加起来有实力支撑5万次每秒执行函数)  

每台机器都运行 test_fun.multi_process_conusme(8)，只要10台以上1000台以下随意随时随地增大减小运行机器数量，  
代码不需要做任何修改变化，就能很方便的达到每秒运行5万次函数的目的。  
</pre>  

### 4.7.1 演示qps控频和自适应扩大和减小并发数量。  

```  
通过不同的时间观察控制台，可以发现无论f2这个函数需要耗时多久（无论是函数耗时需要远小于1秒还是远大于1秒），框架都能精确控制每秒刚好运行2次。  
当函数耗时很小的时候，只需要很少的线程就能自动控制函数每秒运行2次。  
当函数突然需要耗时很大的时候，智能线程池会自动启动更多的线程来达到每秒运行2次的目的。  
当函数耗时从需要耗时很大变成只需要耗时很小的时候，智能线程池会自动缩小线程数量。  
总之是围绕qps恒定，会自动变幻线程数量，做到既不多开浪费cpu切换，也不少开造成执行速度慢。  
```  

```python  
import time  
import threading  
from funboost import boost, BrokerEnum, ConcurrentModeEnum, BoosterParams  

t_start = time.time()  


@boost(BoosterParams(queue_name='queue_test2_qps', qps=2, broker_kind=BrokerEnum.PERSISTQUEUE, concurrent_mode=ConcurrentModeEnum.THREADING,  
       concurrent_num=600))  
def f2(a, b):  
    """  
    这个例子是测试函数耗时是动态变化的，这样就不可能通过提前设置参数预估函数固定耗时和搞鬼了。看看能不能实现qps稳定和线程池自动扩大自动缩小  
    要说明的是打印的线程数量也包含了框架启动时候几个其他的线程，所以数量不是刚好和所需的线程计算一样的。  
    """  
    result = a + b  
    sleep_time = 0.01  
    if time.time() - t_start > 60:  # 先测试函数耗时慢慢变大了，框架能不能按需自动增大线程数量  
        sleep_time = 7  
    if time.time() - t_start > 120:  
        sleep_time = 30  
    if time.time() - t_start > 240:  # 最后把函数耗时又减小，看看框架能不能自动缩小线程数量。  
        sleep_time = 0.8  
    if time.time() - t_start > 300:  
        sleep_time = None  
    print(  
        f'{time.strftime("%H:%M:%S")}  ，当前线程数量是 {threading.active_count()},   {a} + {b} 的结果是 {result}， sleep {sleep_time} 秒')  
    if sleep_time is not None:  
        time.sleep(sleep_time)  # 模拟做某事需要阻塞n秒种，必须用并发绕过此阻塞。  
    return result  


if __name__ == '__main__':  
    f2.clear()  
    for i in range(1000):  
        f2.push(i, i * 2)  
    f2.consume()  
```  

### 4.7.2 此框架对固定耗时的任务，持续控频精确度高于99.9%  

4.7.2 此框架对固定耗时的任务，持续控频精确度高于99.9%，远超celery的rate_limit 60%控频的精确度。  

```  
对于耗时恒定的函数，此框架精确控频率精确度达到99.9%，celery控频相当不准确，最多到达60%左右，两框架同样是做简单的加法然后sleep0.7秒，都设置500并发100qps。  
```  

```python  
@boost(BoosterParams(queue_name='test_queue66', broker_kind=BrokerEnum.REDIS, qps=100))  
def f(x, y):  
    print(f''' {int(time.time())} 计算  {x} + {y} = {x + y}''')  
    time.sleep(0.7)  
    return x + y  


@celery_app.task(name='求和啊', rate_limit='100/s')  
def add(a, b):  
    print(f'{int(time.time())} 计算 {a} + {b} 得到的结果是  {a + b}')  
    time.sleep(0.7)  
    return a + b  

```  

```text  
# 在pycahrm控制台搜索 某一秒的时间戳 + 计算 作为关键字查询，分布式函数调度框架启动5秒后，以后持续每一秒都是100次，未出现过99和101的现象。  
在pycahrm控制台搜索 某一秒的时间戳 + 计算 作为关键字查询，celery框架，每一秒求和次数都是飘忽不定的，而且是六十几徘徊，  
如果celery能控制到95至105次每秒徘徊波动还能接受，类似现象还有celery设置rate_limit=50/s，实际32次每秒徘徊，  
设置rate_limit=30/s，实际18-22次每秒徘徊，可见celery的控频相当差。  
设置rate_limit=10/s，实际7-10次每秒徘徊，大部分时候是9次，当rate_limit大于20时候就越来越相差大了，可见celery的控频相当差。  
```  

### 4.7.3 对函数耗时随机性大的控频功能证明  

对函数耗时随机性大的控频功能证明，使用外网连接远程broker,持续qps控频。  

```  
设置函数的qps为100，来调度需要消耗任意随机时长的函数，能够做到持续精确控频，频率误差小。  
如果设置每秒精确运行超过500000次以上的固定频率，前提是cpu够强机器数量多，  
设置qps=50000，并指定is_using_distributed_frequency_control=True(只有这样才是分布式全局控频，默认是基于单个进程的控频),。  

如果任务不是很重型很耗cpu，此框架单个消费进程可以控制每秒运行次数的qps 从0.01到1000很容易。  
当设置qps为0.01时候，指定的是每100秒运行1次，qps为100指的是每一秒运行100次。  

```  

```python  
import time  
import random  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_rabbit_queue7', broker_kind=BrokerEnum.RABBITMQ_AMQPSTORM, qps=100, log_level=20))  
def test_fun(x):  
    # time.sleep(2.9)  
    # sleep时间随机从0.1毫秒到5秒任意徘徊。传统的恒定并发数量的线程池对未知的耗时任务，持续100次每秒的精确控频无能为力。  
    # 但此框架只要简单设置一个qps就自动达到了这个目的。  
    random_sleep = random.randrange(1, 50000) / 10000  
    time.sleep(random_sleep)  
    print(x, random_sleep)  


if __name__ == '__main__':  
    test_fun.consume()  
    # test_fun.multi_process_consume(3)  
```  

分布式函数调度框架对耗时波动大的函数持续控频曲线  
![img_3.png](img_3.png)  

### 4.7.4 分布式全局控频和单个消费者控频区别  

```  
@boost中指定 is_using_distributed_frequency_control=True 则启用分布式全局控频，是跨进程跨python解释器跨服务器的全局控频。  
否则是基于当前消费者的控频。  

例如 你设置的qps是100，如果你不设置全局控频，run_consume.py 脚本中启动 fun.consume() ，如果你反复启动5次这个 run_consume.py，  
如果不设置分布式控频，那么5个独立的脚本运行，频率总共会达到 500次每秒，因为你部署了5个脚本。  
同理你如果用 fun.multi_process_consume(4)启动了4个进程消费，那么就是4个消费者，总qps也会达到400次每秒。  
这个控频方式是看你需求了。  


如果设置了 is_using_distributed_frequency_control=True，那就会使用每个消费者发送到redis的心跳来统计总消费者个数。  
如果你部署了2次，那么每个消费者会平分qps，每个消费者是变成50qps，总共100qps。  
如果你部署了5次，那么每个消费者会平分qps，每个消费者是变成20qps，总共100qps。  
如果你中途关闭2个消费者，变成了3个消费者，每个消费者是变成 33.33qps，总共100qps。(框架qps支持小数，0.1qps表示每10秒执行1次)  

```  

## 4.8 再次说明qps能做什么，qps为什么流弊？常规并发方式无法完成的需求是什么？  

以模拟请求一个flask接口为例子，我要求每一秒都持续精确完成8次请求，即控制台每1秒都持续得到8次flask接口返回的hello world结果。  

### 4.8.1 下面讲讲常规并发手段为什么对8qps控频需求无能为力？  

不用框架也可以实现8并发， 例如Threadpool设置8线程很容易，但不用框架实现8qps不仅难而且烦  

```  
虽然  
框架能自动实现 单线程  ，多线程， gevent ， eventlet ，asyncio ，多进程 并发 ，  
多进程 + 单线程 ，多进程 + 多线程，多进程 + gevent,  多进程 + eventlet  ，多进程 + asyncio 的组合并发  
可以说囊括了python界的一切知名的并发模型，能做到这一点就很方便强大了  
但是  
此框架还额外能实现qps控频，能够实现函数每秒运行次数的精确控制，我觉得这个功能也很实用，甚至比上面的那些并发用起来还实用。  
```  

```  
这个代码是模拟常规并发手段无法达到每秒持续精确运行8次函数(请求flask接口8次)的目的。  

下面的代码使用8个线程并发运行 request_flask_api 函数，  
当flask_veiw_mock 接口耗时0.1秒时候,在python输出控制台可以看到，10秒钟就运行结束了，控制台每秒打印了80次hello world，严重超频10倍了不符合需求  
当flask_veiw_mock 接口耗时刚好精确等于1秒时候,在python输出控制台可以看到，100秒钟运行结束了，控制台每秒打印了8次hello world，只有当接口耗时刚好精确等于1秒时候，并发数量才符合qps需求  
当flask_veiw_mock 接口耗时10秒时候,在python输出控制台可以看到，需要1000秒钟运行结束，控制台每隔10秒打印8次hello world，严重不符合持续每秒打印8次的目的。  
由此可见，用设置并发数量来达到每秒请求8次flask的目的非常困难，99.99%的情况下服务端没那么巧刚好耗时1秒。  
```  

天真的人会说根据函数耗时大小，来设置并发数量，这可行吗？  

```  
有人会说，为了达到8qps目的，当函数里面sleep 0.1 时候他开1线程，那你这样仍然超频啊，你是每1秒钟打印10次了超过了8次。  
当sleep 0.01 时候，为了达到8qps目的，就算你开1线程，那不是每1秒钟打印100次hello？你不会想到开0.08个线程个线程来实现控频吧？  
当sleep 10秒时候，为了8qps目的，你开80线程，那这样是控制台每隔10秒打印80次hello，我要求的是控制台每一秒都打印8次hello，没告诉你是每隔10秒打印80次hello吧？还是没达到目的。  
如果函数里面是sleep 0.005 0.07 0.09 1.3 2.7 7 11 13这些不规则无法整除的数字？请问你是如何一一计算精确开多少线程来达到8qps的？  
如果flask网站接口昨天是3秒的响应时间，今天变成了0.1秒的响应时间，你的线程池数量不做变化，代码不进行重启，请问你如何做到自适应无视请求耗时，一直持续8qps的目的？  
固定并发数量大小就是定速巡航不够智能前车减速会撞车，qps自适应控频那就是acc自适应巡航了，自动调整极端智能，压根无需提前测算预估函数需要耗时多久(接口响应耗时多久)。  
所以综上所述,如果你有控频需求，你想用并发数量来达到控频目的，那是不可能的。  
```  

有些人到现在还没明白并发数量和qps(每秒执行多少次)之间的区别，并发数量只有在函数耗时刚好精确等于1秒时候才等于qps。  

```  

```python  
import time  
from concurrent.futures import ThreadPoolExecutor  


def flask_veiw_mock(x):  
    # time.sleep(0.1)  # 通过不同的sleep大小来模拟服务端响应需要消耗的时间  
    # time.sleep(1)   # 通过不同的sleep大小来模拟服务端响应需要消耗的时间  
    time.sleep(10)  # 通过不同的sleep大小来模拟服务端响应需要消耗的时间  
    return f"hello world {x}"  


def request_flask_api(x):  
    response = flask_veiw_mock(x)  
    print(time.strftime("%H:%M:%S"), '   ', response)  


if __name__ == '__main__':  
    with ThreadPoolExecutor(8) as pool:  
        for i in range(800):  
            pool.submit(request_flask_api,i)  

```  

截图是当 flask_veiw_mock 耗时为10秒时候，控制台是每隔10秒打印8次 hello world，没达到每一秒都打印8次的目的<br>  
当 flask_veiw_mock 耗时为0.1 秒时候，控制台是每隔1秒打印80次 hello world，没达到每一秒都打印8次的目的<br>  

![img_16.png](img_16.png)  

### 4.8.2 使用分布式函数调度框架，无论接口耗时多少，轻松达到8qps的例子  

```  
这个代码是模拟常规并发手段无法达到每秒持续精确运行8次函数(请求flask接口8次)的目的。  
但是使用分布式函数调度框架能轻松达到这个目的。  

下面的代码使用分部署函数调度框架来调度运行 request_flask_api 函数，  

flask_veiw_mock 接口耗时0.1秒时候，控制台每秒打印8次 hello world，非常精确的符合控频目标  
flask_veiw_mock 接口耗时1秒时候，控制台每秒打印8次 hello world，非常精确的符合控频目标  
flask_veiw_mock 接口耗时10秒时候控，控制台每秒打印8次 hello world，非常精确的符合控频目标  
flask_veiw_mock 接口耗时0.001秒时候，控制台每秒打印8次 hello world，非常精确的符合控频目标  
flask_veiw_mock 接口耗时50 秒时候，控制台每秒打印8次 hello world，非常精确的符合控频目标  
可以发现分布式函数调度框架无视函数耗时大小，都能做到精确控频，常规的线程池 asyncio什么的，面对这种不确定的接口耗时，简直毫无办法。  

有些人到现在还没明白并发数量和qps(每秒执行多少次)之间的区别，并发数量只有在函数耗时刚好精确等于1秒时候才等于qps。  
```  

```python  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


def flask_veiw_mock(x):  
    time.sleep(0.1)  # 通过不同的sleep大小来模拟服务端响应需要消耗的时间  
    # time.sleep(1)   # 通过不同的sleep大小来模拟服务端响应需要消耗的时间  
    # time.sleep(10)  # 通过不同的sleep大小来模拟服务端响应需要消耗的时间  
    return f"hello world {x}"  


@boost(BoosterParams(queue_name="test_qps", broker_kind=BrokerEnum.MEMORY_QUEUE, qps=8))  
def request_flask_api(x):  
    response = flask_veiw_mock(x)  
    print(time.strftime("%H:%M:%S"), '   ', response)  


if __name__ == '__main__':  
    for i in range(800):  
        request_flask_api.push(i)  
    request_flask_api.consume()  
```  

从截图可以看出，分布式函数调度框架，控频稳如狗，完全无视flask_veiw_mock耗时是多少。  
![img_17.png](img_17.png)  

### 4.8.3  并发数量和qps(每秒执行多少次)之间的区别  

有些人到现在还没明白并发数量和qps(每秒执行多少次)之间的区别，并发数量只有在函数耗时刚好精确等于1秒时候才等于qps。  

拿10并发(线程/协程)和10qps 运行10000次函数 举例子，  

```  
如果函数耗时 0.1秒，10并发运行10000次，那么是 100秒运行完成   
如果函数耗时 1 秒，10并发运行10000次，那么是 1000秒运行完成  
如果函数耗时 10 秒，10并发运行10000次，那么是 10000秒运行完成  


如果函数耗时 0.1秒，10qps运行10000次，那么是 1000秒运行完成   
如果函数耗时 1 秒，10qps运行10000次，那么是 1000秒运行完成   
如果函数耗时 10 秒，10qps运行10000次，那么是 1000秒运行完成   

并发是恒定同时有多少个线程/协程 在运行函数，不能达到消费速率恒定，除非函数耗时是1秒并且稳定  
qps是无视函数耗时多少，总是能在固定的时间内完成所有任务。  
qps恒定，前提是电脑cpu能力范围之内，防止有杠精会说他要指定 qps为1千亿，在函数里面每次做一个很大数字的斐波那契数列，与求和1到1万亿，  
然后框架达不到这个速度，杠精说qps不准。  

```  

## 4.9 演示延时运行任务  

4.4章节的定时任务一般指的是周期性重复触发执行某个参数任务，4.9的演示任务是说对一个消息规定在什么时候去运行。  

4.4是重复周期性的触发执行任务，4.9是对一个消息规定延时多长时间来执行它。一个有周期性重复触发的含义，一个是一次性的含义。  

```  
因为有很多人有这样的需求，希望发布后不是马上运行，而是延迟60秒或者现在发布晚上18点运行。  
然来是希望用户自己亲自在消费函数内部写个sleep(60)秒再执行业务逻辑，来达到延时执行的目的，  
但这样会被sleep占据大量的并发线程/协程,如果是用户消费函数内部写sleep7200秒这么长的时间，那  
sleep等待会占据99.9%的并发工作线程/协程的时间，导致真正的执行函数的速度大幅度下降，所以框架  
现在从框架层面新增这个延时任务的功能。  

之前已做的功能是定时任务，现在新增延时任务，这两个概念有一些不同。  

定时任务一般情况下是配置为周期重复性任务，延时任务是一次性任务。  
1）框架实现定时任务原理是代码本身自动定时发布，自然而然就能达到定时消费的目的。  
2）框架实现延时任务的原理是马上立即发布，当消费者取出消息后，并不是立刻去运行，  
   而是使用定时运行一次的方式延迟这个任务的运行。  

在需求开发过程中，我们经常会遇到一些类似下面的场景：  
1）外卖订单超过15分钟未支付，自动取消  
2）使用抢票软件订到车票后，1小时内未支付，自动取消  
3）待处理申请超时1天，通知审核人员经理，超时2天通知审核人员总监  
4）客户预定自如房子后，24小时内未支付，房源自动释放  


分布式函数调度框架的延时任务概念类似celery的countdown和eta入参，  add.apply_async(args=(1, 2),countdown=20)  # 规定取出后20秒再运行  
此框架的入参名称那就也叫 countdown和eta。  
countdown 传一个数字，表示多少秒后运行。  
eta传一个datetime对象表示，精确的运行时间运行一次。  

```  

消费，消费代码没有任何变化  

```python  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_delay', broker_kind=BrokerEnum.REDIS_ACK_ABLE))  
def f(x):  
    print(x)  


if __name__ == '__main__':  
    f.consume()  
```  

发布延时任务  

```python  
# 需要用publish，而不是push，这个前面已经说明了，如果要传函数入参本身以外的参数到中间件，需要用publish。  
# 不然框架分不清哪些是函数入参，哪些是控制参数。如果无法理解就，就好好想想琢磨下celery的 apply_async 和 delay的关系。  

from test_frame.test_delay_task.test_delay_consume import f  
import datetime  
import time  
from funboost import PriorityConsumingControlConfig  

"""  
测试发布延时任务，不是发布后马上就执行函数。  

countdown 和 eta 只能设置一个。  
countdown 指的是 离发布多少秒后执行，  
eta是指定的精确时间运行一次。  

misfire_grace_time 是指定消息轮到被消费时候，如果已经超过了应该运行的时间多少秒之内，仍然执行。  
misfire_grace_time 如果设置为None，则消息一定会被运行，不会由于大连消息积压导致消费时候已近太晚了而取消运行。  
misfire_grace_time 如果不为None，必须是大于等于1的整数，此值表示消息轮到消费时候超过本应该运行的时间的多少秒内仍然执行。  
此值的数字设置越小，如果由于消费慢的原因，就有越大概率导致消息被丢弃不运行。如果此值设置为1亿，则几乎不会导致放弃运行(1亿的作用接近于None了)  
如果还是不懂这个值的作用，可以百度 apscheduler 包的 misfire_grace_time 概念  

"""  
for i in range(1, 20):  
    time.sleep(1)  

    # 消息发布10秒后再执行。如果消费慢导致任务积压，misfire_grace_time为None，即使轮到消息消费时候离发布超过10秒了仍然执行。  
    f.publish({'x': i}, task_options=PriorityConsumingControlConfig(countdown=10))  

    # 规定消息在17点56分30秒运行，如果消费慢导致任务积压，misfire_grace_time为None，即使轮到消息消费时候已经过了17点56分30秒仍然执行。  
    f.publish({'x': i * 10}, task_options=PriorityConsumingControlConfig(  
        eta=datetime.datetime(2021, 5, 19, 17, 56, 30) + datetime.timedelta(seconds=i)))  

    # 消息发布10秒后再执行。如果消费慢导致任务积压，misfire_grace_time为30，如果轮到消息消费时候离发布超过40 (10+30) 秒了则放弃执行，  
    # 如果轮到消息消费时候离发布时间是20秒，由于 20 < (10 + 30)，则仍然执行  
    f.publish({'x': i * 100}, task_options=PriorityConsumingControlConfig(  
        countdown=10, misfire_grace_time=30))  

    # 规定消息在17点56分30秒运行，如果消费慢导致任务积压，如果轮到消息消费时候已经过了17点57分00秒，  
    # misfire_grace_time为30，如果轮到消息消费时候超过了17点57分0秒 则放弃执行，  
    # 如果如果轮到消息消费时候是17点56分50秒则执行。  
    f.publish({'x': i * 1000}, task_options=PriorityConsumingControlConfig(  
        eta=datetime.datetime(2021, 5, 19, 17, 56, 30) + datetime.timedelta(seconds=i),  
        misfire_grace_time=30))  

    # 这个设置了消息由于推挤导致运行的时候比本应该运行的时间如果小于1亿秒，就仍然会被执行，所以几乎肯定不会被放弃运行  
    f.publish({'x': i * 10000}, task_options=PriorityConsumingControlConfig(  
        eta=datetime.datetime(2021, 5, 19, 17, 56, 30) + datetime.timedelta(seconds=i),  
        misfire_grace_time=100000000))  
```  

## 4.10 在web中如flask fastapi django 如何搭配使用消费框架的例子。  

```  
在web中推送任务，后台进程消费任务，很多人问怎么在web使用，用法和不与web框架搭配并没有什么不同之处。  


因为发布和消费是使用中间件解耦的，一般可以分成web接口启动一次，后台消费启动一次，需要独立部署两次。  

演示了flask 使用app应用上下文。  

web接口中发布任务到消息队列，独立启动异步消费。  
```  

flask + 分布式函数调度框架演示例子在：  

[https://github.com/ydf0509/distributed_framework/blob/master/test_frame/use_in_flask_tonardo_fastapi](https://github.com/ydf0509/distributed_framework/blob/master/test_frame/use_in_flask_tonardo_fastapi)  

fastapi + 分布式函数调度框架演示例子在：  

[https://github.com/ydf0509/fastapi_use_distributed_framework_demo](https://github.com/ydf0509/fastapi_use_distributed_framework_demo)  

django + 分布式函数调度框架演示例子在：  

[https://github.com/ydf0509/django_use_funboost](https://github.com/ydf0509/django_use_funboost)  

dajngo + funboost + 函数中操作了django orm的例子在:  

[https://github.com/ydf0509/funboost_django_orm_demo](https://github.com/ydf0509/funboost_django_orm_demo)  

uwsgi + flask + funboost 演示例子在：  

[https://github.com/ydf0509/uwsgi_flask_funboost](https://github.com/ydf0509/uwsgi_flask_funboost)  

这三个web框架demo + funboost 框架，几乎是一模一样的，有的人不能举一反三，非要我单独增加demo例子。  

部署方式都是web部署一次，后台消费部署一次，web接口中发布消息到消息队列，funboost没有与任何web框架有任何绑定关系，都是一样的用法。  

如果前端在乎任务的结果：  

```  
非常适合使用mqtt， 前端订阅唯一uuid的topic 然后表单中带上这个topic名字请求python接口 -> 接口中发布任务到rabbitmq或redis消息队列 ->  
后台消费进程执行任务消费,并将结果发布到mqtt的那个唯一uuid的topic -> mqtt 把结果推送到前端。  
使用ajax轮训或者后台导入websocket相关的包来做和前端的长耗时任务的交互 是伪命题。  
```  

使用 web + funboost +mqtt的流程图  

![img_43.png](img_43.png)  

## 4.11 保存消费状态和结果包mongo，开启消费状态结果的web页面  

### 4.11.1 保存消费状态和结果到mongodb  

需要配置好mongodb连接，并且设置 function_result_status_persistance_conf 持久化配置。  

（1）需要安装mongodb，并且设置 MONGO_URL 的值  

```  
如果需要使用这个页面，那么无论选择何种中间件，即使不是使用mongo作为消息队列，也需要安装mongodb，因为因为是从这里读取数据的。  
需要在 funboost_config.py 中设置MONGO_URL的值，mongo url的格式如下，这是通用的可以百度mongo url连接形式。  
有密码 MONGO_CONNECT_URL = f'mongodb://yourname:yourpassword@127.0.01:27017/admin'  
没密码 MONGO_CONNECT_URL = f'mongodb://192.168.6.132:27017/'  
```  

（2） 装饰器上需要设置持久化的配置参数,代码例子  

```  
框架默认不会保存消息状态和结果到mongo的，因为大部分人并没有安装mongo，且这个web显示并不是框架代码运行的必须部分，还有会降低一丝丝运行性能。  


如果需要页面显示消费状态和结果，需要设置 @boost装饰器的 function_result_status_persistance_conf 的参数  
FunctionResultStatusPersistanceConfig的如参是 (is_save_status: bool, is_save_result: bool, expire_seconds: int)  
is_save_status 指的是是否保存消费状态，这个只有设置为True,才会保存消费状态到mongodb，从而使web页面能显示该队列任务的消费信息  
is_save_result 指的是是否保存消费结果，如果函数的结果超大字符串或者对函数结果不关心或者函数没有返回值，可以设置为False。  
expire_seconds 指的是多久以后，这些保存的数据自动从mongodb里面消失删除，避免爆磁盘。  
```  

```python  
from funboost import boost, FunctionResultStatusPersistanceConfig, BoosterParams  


@boost(BoosterParams(queue_name='queue_test_f01', qps=2,  
       function_result_status_persistance_conf=FunctionResultStatusPersistanceConfig(  
           is_save_status=True, is_save_result=True, expire_seconds=7 * 24 * 3600)))  
def f(a, b):  
    return a + b  

if __name__ == '__main__':  
    f(5, 6)  # 可以直接调用  
  
    for i in range(0, 200):  
        f.push(i, b=i * 2)  
  
    f.consume()  

```  

(3) 消费结果状态保存到mongo什么库什么表了？  

是固定保存到名为 funboost_task_status 的库，表的名字就是队列名字。每个函数都会使用一个单独的表来保存消费状态结果。  
有的人企图在 MONGO_CONNECT_URL 中指定db来决定消费结果保存到什么db  

如下图所示,每次函数运行后，一共保存了37个字段到数据库中。  

mongo保存结果截图  
![img_39.png](img_39.png)  

### 4.11.2 框架是可以自动保存消费状态/结果到mongo，你想保存到MySQL?  

需要看 4.19 用户自定义记录函数消费 状态/结果 钩子函数 章节，设置一个记录函数运行状态的钩子函数，  
你想在函数里面做啥都可以，把状态/结果插入到elastic orcale都没人管得了你。  

因为mysql需要运维建立数据库和建立表，funboost操作mongo可以代码中建立数据库和多个不同的队列名的表来保存消费状态。  
用户想保存到mysql自己自定义 user_custom_record_process_info_func 钩子函数就好了,因为FunctionResultStatus对象上包含了所有必要信息。  

#### 4.11.2.b  作者自己贡献一个吧函数消费状态保存到mysql的函数,(2024.02新增)  

实现代码见文件:  
[https://github.com/ydf0509/funboost/blob/master/funboost/contrib/save_result_status_to_sqldb.py](https://github.com/ydf0509/funboost/blob/master/funboost/contrib/save_result_status_to_sqldb.py)  

**!!!更推荐下面这个文件使用dataset来保存函数消费状态到mysql(dataset保存一个字典更简单方便):** 
`funboost/contrib/save_function_result_status/save_result_status_use_dataset.py`

```python  

from funboost import boost, FunctionResultStatus, BoosterParams  
import json  
from funboost.contrib.save_result_status_to_sqldb import save_result_status_to_sqlalchemy # 不是框架必要部分的就通过 contrib 中增加代码.  

"""  
测试用户自定义记录函数消息处理的结果和状态到mysql  

"""  

# user_custom_record_process_info_func=my_save_process_info_fun 设置记录函数消费状态的钩子  
@boost(BoosterParams(queue_name='test_user_custom', user_custom_record_process_info_func=save_result_status_to_sqlalchemy))  
def f(x):  
    print(x * 10)  
    return x*10  


if __name__ == '__main__':  
    for i in range(3):  
        f.push(i)  
    print(f.publisher.get_message_count())  
    f.consume()  

```  

```  
作者自己实现的 save_result_status_to_sqlalchemy 记录函数,  
1. 用户按照 funboost.contrib.save_result_status_to_sqldb 文件中的建表语句先建表,  
2. 配置好 BrokerConnConfig.SQLACHEMY_ENGINE_URL 参数,  
3. boost装饰器指定 user_custom_record_process_info_func=save_result_status_to_sqlalchemy  
这样就能自动吧函数消费状态保存到mysql了.  

用户自己也可以按需增加索引和增加字段和修改字段长度的,自己也可以改下建表语句或save_result_status_to_sqlalchemy函数就好了.  
例如你可以增加消费函数的入参作为mysql表字段.  
```  

再一次附上funboost.contrib.save_result_status_to_sqldb 文件中的建表语句:  

```sql  
CREATE TABLE funboost_consume_results
(

    _id                       varchar(255) not null,
    `function`                varchar(255) null,
    host_name                 varchar(255) null,
    host_process              varchar(255) null,
    insert_minutes            varchar(255) null,
    insert_time               datetime     null,
    insert_time_str           varchar(255) null,
    publish_time              float        null,
    publish_time_format       varchar(255) null,
    msg_dict                  json         null,
    params                    json         null,
    params_str                varchar(255) null,
    process_id                bigint       null,
    queue_name                varchar(255) null,
    result                    text null,
    run_times                 int          null,
    script_name               varchar(255) null,
    script_name_long          varchar(255) null,
    success                   tinyint(1)   null,
    task_id                   varchar(255) null,
    thread_id                 bigint       null,
    time_cost                 float        null,
    time_end                  float        null,
    time_start                float        null,
    total_thread              int          null,
    utime                     varchar(255) null,
    exception                 mediumtext   null,
    rpc_result_expire_seconds bigint       null,
    exception_type            varchar(255) null,
    exception_msg             text         null,
    rpc_chain_error_msg_dict  text         null,
    run_status                varchar(255) null,

    primary key (_id),
    key idx_insert_time (insert_time),
    key idx_queue_name_insert_time (queue_name, insert_time),
    key idx_params_str (params_str)
)

```  

保存到mysql中的消费状态和结果截图:  

![img_57.png](img_57.png)  
![img_58.png](img_58.png)  

### 4.11.3 可视化，启动python分布式函数调度框架之函数运行结果状态web  

见第13章文档， 启动 funboost web,查看消费结果和队列管理  

## 4.12 框架 asyncio 方式运行协程  

<p style="color: #00A000">完整的除了asyncio并发，包括 aio_push 和 asyncio 来等待获取结果，请看4b.3 章节</p>p> [ funboost + 全asyncio 编程生态演示](https://funboost.readthedocs.io/zh-cn/latest/articles/c4b.html#b-3-funboost-asyncio)  

### 4.12.1 concurrent_mode=ConcurrentModeEnum.ASYNC 运行协程  

concurrent_mode=ConcurrentModeEnum.ASYNC是一个loop中真异步运行协程  

见7.8的demo介绍，  

```python  
import asyncio  
from funboost import boost, ConcurrentModeEnum, BoosterParams  
@boost(BoosterParams(queue_name='async_queue', concurrent_mode=ConcurrentModeEnum.ASYNC))  
async def f():  
    await asyncio.sleep(2)  
```  

这种方式是@boost装饰在async def定义的函数上面。  

celery不支持直接调度执行async def定义的函数，但此框架是直接支持asyncio并发的。  

### 4.12.2 concurrent_mode=ConcurrentModeEnum.THREADING 运行asyncio协程  

concurrent_mode=ConcurrentModeEnum.THREADING  在每个线程都创建独立的loop，每个协程运行在不同的loop中  

见7.38的demo介绍，  

```python  
import asyncio  
from funboost import boost, ConcurrentModeEnum, BoosterParams  
@boost(BoosterParams(queue_name='threading_async_queue', concurrent_mode=ConcurrentModeEnum.THREADING))  
async def f():  
    await asyncio.sleep(2)  
```  

这种方式就是临时为每一个协程创建一个 loop,loop是一次性的。  

```  
funboot的asyncio 并发模式是真asyncio , 是在同一个loop中并发的运行多个协程对象。  

伪 async 并发是多线程中每个线程临时 loop = asyncio.new_event_loop() ，然后 loop.run_until_complete() ，   
这种就是假的，每隔协程都运行在不同的loop中。  
```  

ConcurrentModeEnum.THREADING 照样可以运行async def的函数。  

这种当然是伪asyncio的，是临时 创建一个 loop。 看你咋想的喜欢真asyncio还是假的，这种也可以单进程1秒钟运行2000次asyncio的函数  

## 4.13 跨项目怎么发布任务或者获取函数执行结果(即不定义@boost消费函数就发送消息)？  

别的语言项目或者别的python项目手动发布消息到中间件，让分布式函数调度框架消费任务，<br>  
例如项目b中有add函数，项目a里面无法 import 导入这个add 函数。  

##### 1)第一种方式，使用能操作消息中间件的python包，手动发布任务到消息队列中间件<br>  

如果是别的语言发布任务，或者python项目a发布任务但是让python项目b的函数去执行，可以直接发布消息到中间件里面。<br>  
手动发布时候需要注意 中间件类型 中间件地址 队列名 @boost和funboost_config.py指定的配置要保持一致。<br>  
需要发布的消息内容是 入参字典转成json字符串，然后发布到消息队列中间件。<br>  
以下以redis中间件为例子。演示手动发布任务到中间件。<br>  

```python  
@boost(BoosterParams(queue_name='test_queue668', broker_kind=BrokerEnum.REDIS))  
def add(x, y):  
    print(f'''  计算  {x} + {y} = {x + y}''')  
    time.sleep(4)  
    return x + y  


if __name__ == '__main__':  
    r = Redis(db=7, host='127.0.0.1')  
    for i in range(10):  
        add.push(i, i * 2)  # 正常同一个python项目是这么发布消息,使用函数.push或者publish方法  
        r.lpush('test_queue668', json.dumps({'x': i, 'y': i * 2}))  # 不同的项目交互，可以直接手动发布消息到中间件  
```  

```  
这个很容易黑盒测试出来，自己观察下中间件里面的内容格式就能很容易手动模仿构造出消息内容了。  

需要说明的是 消息内容不仅包括 入参本身，也包括其他控制功能的辅助参数，可以用框架的自动发布功能发布消息，然后观察中间件里面的字段内容，模拟构造。  

举个例子之一，例如如果要使用消息过期丢弃这个功能，那么就需要发布消息当时的时间戳了。  
```  

##### 2)第二种方式，使用伪函数来作为任务,只写函数声明不写函数体。<br>  

此方式是一名网友的很机智的建议，我觉得可行。<br>  
例如还是以上面的求和函数任务为例，在项目a里面可以定义一个假函数声明,并且将b项目的求和add函数装饰器复制过去，但函数体不需要具体内容  

```python  
@boost(BoosterParams(queue_name='test_queue668', broker_kind=BrokerEnum.REDIS))  # a项目里面的这行和b项目里面的add函数装饰器保持一致。  
def add(x, y):  # 方法名可以一样，也可以不一样，但函数入参个数 位置 名称需要保持不变。  
    pass  # 方法体，没有具体的求和逻辑代码，只需要写个pass就行了。  

add.push(1,y=2)  
```  

之后通过这个假的add函数就可以享受到与在同一个项目中如何正常发布和获取求和函数的执行结果 一模一样的写法方式了。<br>  
例如add.clear() 清空消息队列，add.push发布,add.publish发布，async_result.get获取结果，都可以正常使用，  
但不要使用add.consume启动消费，因为这个是假的函数体，不能真正的执行求和.<br>  

##### 3)第三种方式(推荐),使用BoostersManager.get_cross_project_publisher来获取发布者,然后使用publish来发布函数的入参字典。  

```python  
from funboost import BoostersManager, PublisherParams, BrokerEnum  

publisher = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='test_cross_qeueu1', broker_kind=BrokerEnum.REDIS, publish_msg_log_use_full_msg=True))  
publisher.publish({"a": 1, "b": 2})  # 远程函数入参是 def f(a,b)  

# 如果还包含其他消息控制字段，其他的extra中的参数，可以查看并模仿消息队列中的消息，自行构造。  

'''send_msg 是发送原始消息到消息队列，就是不会给消费加上extra， taskid 等额外字段。  
publish会自动添加extra taskid publish_time等字段到消息中，send_msg则不会 '''  
publisher.send_msg({"c": 5, "d": 6})   

```  

##### 4) 第四种方式,在消费函数所在项目里面用 fastapi flask啥的写一个接口用于接受请求并把接收到的消息发送到消息队列(框架自带了一个fastapi 发布消息接口).  

参考 `funboost/contrib/api_publish_msg.py` 就好了，就是在接口里面调用funboost的发布和获取结果，  
调用 `publish` 和 `AsyncResult`，或者你用asyncio编程生态就调用 `aio_publish` 和 `AioAsyncResult`  

##### 5） ！！！强烈推荐，第五种方式，使用 `funboost.faas` 一键实现

使用 `funboost.faas` 模块中的自带的  `fatapi_router` 一键增加几十个接口，不需要你手写web接口;最关键是支持自动发现函数，你增加或者修改函数，web服务永远无需重启。

## 4.13b 彩蛋!!不使用funboost的消费功能,funboost作为各种消息队列的万能发布者  

**第一性原理**:funboost可以不依赖消定义费函数生成发布者,并使用`send_msg`方法对几十种消息队列发布原始消息内容.  

这就是使用4.13章节的跨项目发布消息功能的原理，但用的是 `send_msg`,而不是`push`和`publish`方法,   
`send_msg`方法可以发送原始消息，不会给消息加上任何额外字段，比如`taskid`，`publish_time`等字段。  

用户无需亲自手写导入几十种三方包,关心几十种消息队列怎么差异化实现来发布消息.  

```python  
from funboost import BoostersManager,PublisherParams,BrokerEnum  


if __name__ == '__main__':  
    # 演示把消息发到redis  
    pb_redis = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='redis_queue1',broker_kind=BrokerEnum.REDIS))  
    pb_redis.send_msg('my_msg1_str') # 可以发布任何字符串  

    # 演示把消息发到kafka  
    pb_kafka = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='topic1', broker_kind=BrokerEnum.KAFKA,broker_exclusive_config={'num_partitions':10,'replication_factor':1}))  
    pb_kafka.send_msg({'k1':111}) # 发布字典会自动转json,但不会添油加醋学push方法加额外字段  

    # 演示把消息发到 rabbitmq  
    pb_rabbitmq = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='rabbitmq_q2',broker_kind=BrokerEnum.RABBITMQ))  
    pb_rabbitmq.send_msg('{"k2":"wolrd"}')  
```  

这意味着开发者 **无需再关心**：  
*   应该导入 `pika`、`kafka-python` 还是 `redis-py`？  
*   RabbitMQ 的 `channel.basic_publish` 和 Kafka 的 `producer.send` 有什么不同？  
*   各种客户端库的连接、认证和异常处理细节是怎样的？  

`funboost` 将这一切复杂性都封装了起来，提供了一个极其简洁和统一的接口。  

`celery`不能像`funboost`这样独立使用发布功能,而且`celery`会对用户的消息进行大幅度转化,无法发送给非`celery`体系的部门来使用  

## 4.14 获取消费进程信息的方法(用于排查查看正在运行的消费者)  

- 这种是调用函数来排查正在运行的消费者进程信息，可以根据queue或者机器。
- 用户也可以 开启 funboost web manager 可视化更直观来查看这些信息，比用`ActiveCousumerProcessInfoGetter`排查更直观。

```python3  
from funboost import ActiveCousumerProcessInfoGetter  

'''  
获取分布式环境中的消费进程信息。  
使用这里面的4个方法需要相应函数的@boost装饰器设置 is_send_consumer_heartbeat_to_redis=True，这样会自动发送活跃心跳到redis。否则查询不到该函数的消费者进程信息。  
要想使用消费者进程信息统计功能，用户无论使用何种消息队列中间件类型，用户都必须安装redis，并在 funboost_config.py 中配置好redis链接信息  
'''  

# 获取分布式环境中 test_queue 队列的所有消费者信息  
print(ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_by_queue_name('test_queue'))  

# 获取分布式环境中 当前列机器的所有消费者信息  
print(ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_by_ip())  

# 获取分布式环境中 指定ip的所有消费者信息  
print(ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_by_ip('10.0.195.220'))  

# 获取分布式环境中 所有 队列的所有消费者信息，按队列划分  
print(ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_queue_name())  

# 获取分布式环境中 所有 机器的所有消费者信息，按ip划分  
print(ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_ip())  
```  

获取消费进程信息的方法的用途，用于排查查看正在运行的消费者  

```  
1、有的人老是说自己已经把消费进程关了，但是消息队列中的消费还在消费，用get_all_hearbeat_info_by_queue_name方法就能查出来还有哪些机器在消费这个队列了  
2、有的人老是说发送消息，消息队列的任务，没被消费，也可以使用get_all_hearbeat_info_by_queue_name方法  
3、get_all_hearbeat_info_by_ip 方法用于查看一台机器在运行哪些消息队列。  
4、get_all_hearbeat_info_partition_by_queue_name和get_all_hearbeat_info_partition_by_ip分别按队列和机器分组显示  
```  

## 4.16 文件日志所在的地方  

框架使用的是nb_log,控制台五彩日志 + 多进程安全切割文件的 nb_log  

你项目根目录下的 nb_log_config.py 中的 LOG_PATH 决定了默认日志文件夹的位置，win默认在磁盘根目录下的/pythonlogs文件夹。  
具体看 nb_log_config.py  

nb_log 介绍见: [https://github.com/ydf0509/nb_log](https://github.com/ydf0509/nb_log)  

tips:  

嫌弃日志提示详细(啰嗦)的问题见:文档6.17  https://funboost.readthedocs.io/zh-cn/latest/articles/c6.html#b-2-logmanager-preset-log-level  

### 4.16.1 没亲自指定 日志文件名  

代码:  

![img_50.png](img_50.png)  

文件日志截图:  
![img_49.png](img_49.png)  

如上图，如果你不在boost装饰器亲自指定log_filename,那么每个队列的都有单独的日志文件，就是不同的消费函数写在不同的日志文件中，很方便查看问题。  

### 4.16.2 亲自指定日志文件名,log_filename的值  

如果你指定了log_filename,那么就会写入到你指定的文件中,而不是使用队列名自动生成文件名.  

代码:  

```python  
import logging  
import time  
from funboost import boost, BrokerEnum, BoosterParams  
from nb_log import get_logger  

LOG_FILENAME = '自定义日志文件名.log'  


class BoosterParamsMy(BoosterParams):  # 传这个类就可以少每次都亲自指定使用rabbitmq作为消息队列，和使用rpc模式。  
    """  
    定义子类时候，字段也要注意带上类型注释  
    """  
    broker_kind: str = BrokerEnum.RABBITMQ  
    max_retry_times: int = 4  
    log_level: int = logging.DEBUG  
    log_filename: str = LOG_FILENAME  


my_file_logger = get_logger('my_business', log_filename=LOG_FILENAME)  


@boost(boost_params=BoosterParamsMy(queue_name='task_queue_name1111', qps=3, ))  
def task_fun(x, y):  
    print(f'{x} + {y} = {x + y}')  
    my_file_logger.debug(f"1111 这条日志会写到 {LOG_FILENAME} 日志文件中  {x} + {y} = {x + y}")  
    time.sleep(3)  # 框架会自动并发绕开这个阻塞，无论函数内部随机耗时多久都能自动调节并发达到每秒运行 3 次 这个 task_fun 函数的目的。  


@boost(boost_params=BoosterParamsMy(queue_name='task_queue_name2222', qps=10, ))  
def task_fun2(x, y):  
    print(f'{x} - {y} = {x - y}')  
    my_file_logger.debug(f"2222 这条日志会写到 {LOG_FILENAME} 日志文件中 {x} - {y} = {x - y} ")  
    time.sleep(3)  # 框架会自动并发绕开这个阻塞，无论函数内部随机耗时多久都能自动调节并发达到每秒运行 10 次 这个 task_fun 函数的目的。  


if __name__ == "__main__":  
    task_fun.consume()  # 消费者启动循环调度并发消费任务  
    task_fun2.consume()  
    for i in range(10):  
        task_fun.push(i, y=i * 2)  # 发布者发布任务  
        task_fun2.push(i, i * 10)  


```  

日志文件截图,可以发现所有消费发布都写到 自定义日志文件名.log里面了,my_file_logger 的get_logger 入参 log_filename 也是指定写到 这个文件,  
所以你的业务日志和框架日志可以是在同一个文件中  

![img_51.png](img_51.png)  

### 4.16.3 把用户自己的业务日志和funboost框架日志写到同一个文件  

```  
from nb_log import get_logger  
如上 4.16.2, my_file_logger = get_logger('my_business', log_filename=LOG_FILENAME),  
你用这个实例化的 my_file_logger 去记录日志,  
在boost装饰器的log_filename 和get_logger 的 log_filename 指定为相同的文件名字,那就可以写入同一个文件了.  
```  

## 4.16.4 funboost 日志由 nb_log 提供。  

关于funboost的日志和日志级别过滤，看nb_log 9.5 章节文档  

[https://nb-log-doc.readthedocs.io/zh_CN/latest/articles/c9.html#id6](https://nb-log-doc.readthedocs.io/zh_CN/latest/articles/c9.html#id6)  

## 4.17 判断函数运行完所有任务，再执行后续操作  

```text  
框架是消息队列执行任务，理论上永不停止，消息源源不断的进入消息队列然后被消费，  
不会有明显的结束含义，即使消息队列已经空了，代码也会待命拉取消费未来的下一条消息，  
因为代码无法知道用户会不会将来又push消息到消息队列中。  

但有的人脚本是一次性运行的或者他需要当前批次的消息消费完后执行某个操作，  
可以使用 wait_for_possible_has_finish_all_tasks来判断函数的消息队列是否已经运行完了。  
原理是消费者近n分钟内没有执行任务并且消息队列中间件中的消息数量持续n分钟是0，就判断为可能运行完了。  
wait_for_possible_has_finish_all_tasks的入参是判断n分钟内消息数量，那么这个n最好是消费函数最大运行时间的3倍。  
例如函数最大耗时120秒，那么可以设置入参为6分钟，如果设置过小，可能会出现实际还有余量任务正在执行中，导致判断失误。  

wait_for_possible_has_finish_all_tasks是一个阻塞函数，只有判断疑似消息队列所有任务完成了，代码才会运行到下一行。  
然后执行某些操作，例如可以发个邮件通知下，例如 os._exit()可以退出脚本，非常的灵活。  

```  

此功能可以用于，例如  

```  
爬取猫眼 淘票票 糯米全中国所有城市的电影院的放映场次，然后对电影场次进行全网匹配和统计分析，一个电影场次在每个app的价格，统计全中国每个城市播放多少场次电影。  
那么这种后续的操作就必须先等每一个电影播放场次的详情页爬虫函数运行完了，再进行匹配和统计分析。如果都没爬取完成还在运行，就开始执行全量电影场次的统计分析那无疑是漏数据不准确。  
```  

```python  
import time  
import os  

from funboost import boost, BoosterParams  


@boost(BoosterParams(queue_name='test_f1_queue', qps=0.5))  
def f1(x):  
    time.sleep(3)  
    print(f'x: {x}')  
    for j in range(1, 5):  
        f2.push(x * j)  


@boost(BoosterParams(queue_name='test_f2_queue', qps=2))  
def f2(y):  
    time.sleep(5)  
    print(f'y: {y}')  


if __name__ == '__main__':  
    f1.clear()  
    f2.clear()  
    for i in range(30):  
        f1.push(i)  
    f1.consume()  
    f1.wait_for_possible_has_finish_all_tasks(4)  
    print('f1函数的队列中4分钟内没有需要执行的任务,f1运行完了，现在启动f2的消费')  
    f2.consume()  
    f2.wait_for_possible_has_finish_all_tasks(3)  
    print('f2函数的队列中3分钟内没有需要执行的任务，发个邮件通知一下')  
    print('f1 和f2任务都运行完了，。。。')  
    print('马上 os._exit(444) 结束脚本')  
    os._exit(444)  # 结束脚本  
```  

## 4.18 暂停消费  

框架支持暂停消费功能和继续消费功能，boost装饰器需要设置is_send_consumer_heartbeat_to_redis=True  

```python  
from funboost import boost, BoosterParams  

@boost(BoosterParams(queue_name='test_queue73ac', is_send_consumer_heartbeat_to_redis=True))  
def f2(a, b):  
    return a - b  


if __name__ == '__main__':  
    for i in range(1000):  
        # f.push(i, i * 2)  
        f2.push(i, i * 2)  
    f2.consume()  
  
    while 1:  
        f2.pause_consume()  
        time.sleep(300)  
        f2.continue_consume()  
        time.sleep(300)  

```  

```  
f.continue_consume 意思是继续消费，这个设置redis对应键 f'funboost_pause_flag:{self.queue_name}' 的状态为1了，  
f.pause_consume 意思是暂停消费，这个设置redis对应键 f'funboost_pause_flag:{self.queue_name}' 的状态为0了，  
框架中有专门的线程每隔10秒扫描redis中设置的暂停状态判断是否需要暂停和继续消费，所以设置暂停和接续后最多需要10秒就能暂停或启动消费生效了。  
```  

![img_26.png](img_26.png)  

上图片为上面例子的代码消费5分钟然后暂停5分钟，一直循环  

```  
有的人问怎么在其他地方设置暂停消费，说我这例子是函数和设置暂停消费在同一个脚本，  
这个从redis获取暂停状态本来就是为了支持从python解释器外部或者远程机器设置暂停，怎么可能只能在函数所在脚本设置暂停消费。  

例如在脚本 control_pause.py中写  

from xx import f2  

f2.pause_consume()  

这不就完了吗。如果是别的java项目代码中控制暂停消费，可以设置redis的 funboost_pause_flag:{queue_name} 这个键的值为 1，  
这样就能使消费暂停了。在python web接口中设置暂停状态就用 f2.pause_consume() 就行了。  

```  

## 4.19 用户自定义记录函数消费 状态/结果 钩子函数  

```  
可以通过设置 user_custom_record_process_info_func 的值指向你的函数，来记录函数的消费结果，这种比较灵活。  
用户定义一个函数，函数的入参只有一个 function_result_status ，这个变量是 FunctionResultStatus 类型的对象，有很多属性可供使用，  
例如函数 入参 结果 耗时 发布时间 处理线程id 处理机器等等，可以更好的和用户自己的系统对接。  
```  

```python  
from funboost import boost, FunctionResultStatus, BoosterParams  

"""  
测试用户自定义记录函数消息处理的结果和状态到mysql  

"""  


def my_save_process_info_fun(function_result_status: FunctionResultStatus):  
    """ function_result_status变量上有各种丰富的信息 ,用户可以使用其中的信息  
    用户自定义记录函数消费信息的钩子函数  
    """  
    print('function_result_status变量上有各种丰富的信息: ',  
          function_result_status.publish_time, function_result_status.publish_time_format,  
          function_result_status.params, function_result_status.msg_dict,  
          function_result_status.time_cost, function_result_status.result,  
          function_result_status.process_id, function_result_status.thread_id,  
          function_result_status.host_process, )  
    print('保存到数据库', function_result_status.get_status_dict())  

# user_custom_record_process_info_func=my_save_process_info_fun 设置记录函数消费状态的钩子  
@boost(BoosterParams(queue_name='test_user_custom', user_custom_record_process_info_func=my_save_process_info_fun))  
def f(x):  
    print(x * 10)  


if __name__ == '__main__':  
    for i in range(50):  
        f.push(i)  
    print(f.publisher.get_message_count())  
    f.consume()  

```  

### 4.19.b 自定义保存函数消费状态结果到mysql/sqlite/pgsql请看4.11.2.b的章节  

## 4.20 通过 broker_exclusive_config 参数 设置不同中间件能使用到的差异化独特配置  

```  
加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，  
例如kafka支持消费者组，rabbitmq也支持各种独特概念例如各种ack机制 复杂路由机制，每一种消息队列都有独特的配置参数意义，可以通过这里传递。  

之前的做法是为了简化难度和兼容各种消息队列中间件用法，有的地方写死了不利于精细化控制使用，例如kafka消费其实有很多配置的高达30多项，不是光有个 bootstrap_servers 设置kafka的地址，  
例如 group_id  max_in_flight_requests_per_connection auto_offset_reset 等。以后会逐步精细化针对各种消息队列的独特概念用途放开更多的差异化独特配置。  

使用方式例如设置  
@boost(BoosterParams(queue_name='test_queue70ac', broker_kind=BrokerEnum.KAFKA_CONFLUENT, broker_exclusive_config={'group_id':"my_kafka_group_id_xx"}))  
def f(x):  
    pass  
    

打个比喻消费是看书，redis的list和rabbitmq消费消息，是看一页就把书本的那一页撕下来，下次继续看书本中剩下的页就好了。不可多组重复回拨消费，不需要存在啥消费者组这种概念。  
kafka消费消息，是小明和小红分别看这本书，小明每看完几页后，会夹一个小明的书签到最新看到的地方，下次小明继续看就先找到小明的书签，继续读之后的页数。  
小红和小明分别使用不同的书签标记他们各自读到哪一页了，kafka不是看完一页就把那张撕下来，所以kafka存在消费者组概念，  
所以funboost提供 broker_exclusive_config 入参来支持不同消息队列独有特性。  

以后将增加更多的差异化设置参数，能更深入灵活使用不同中间件的独特概念和功能  
```  

### 4.20.2 怎么知道每种消息队列 broker_exclusive_config 能支持哪些独有特殊的参数配置

具体的每种消息队列 `broker_exclusive_config` 能支持哪些独有特殊的参数配置，必须是对应Consumer类的 `BROKER_EXCLUSIVE_CONFIG_DEFAULT` 中包含的keys.
例如你使用redis的list结构做消息队列，你去设置消费者组那是没什么卵用的。

例如 `ConsumerKafkaConfluent` 类的 `BROKER_EXCLUSIVE_CONFIG_DEFAULT` 的值是:     
{'group_id': 'funboost_kafka', 'auto_offset_reset': 'earliest','num_partitions':10,'replication_factor':1,}    
所以你可以传递指定这些值 group_id/ auto_offset_reset/ num_partitions/ replication_factor


## 4.21 【完全自由定制扩展（方式1）】 使用 register_custom_broker 完全彻底自由灵活自定义扩展和定制修改中间件(消费者和发布者)  

4.21和4.21b 都可以实现普通用户自由增加新中间件；  

也可以用于不重头增加新的中间件，而是覆盖修改父类逻辑，例如funboost某个地方有bug或者你想按你的逻辑来运行，都可以用户高度自定义，用户压根不需要修改funboost的源码。       
有些人很冲动不看教程，老想硬改site_packages pip安装目录下的funboost安装包源码，压根不需要的，因为框架已经提供了用户级别高度自定义扩展，用户的方法可以覆盖任何AbstractConsumer的方法以及他的子类方法。  

**方式1，使用register_custom_broker**  
继承框架的消费者和发布者抽象类或抽象类的子孙类，注册到框架种。消费和发布逻辑细节可以完全由用户自定义。  


<pre style="font-size: large;color: greenyellow;background-color: black">  
这个是增加的一种很强大的功能,用户可以自定义发布者和消费者，注册到框架中。boost装饰器就能自动使用你的消费者类和发布者类了。  
这个功能很好很强，能彻底解决框架的流程逻辑不符合你的期望时候，用户能够自定义一些细节。需要用户有一定的python语法基础和面向对象 设计模式才能用这个功能。  
为什么增加这个功能，是由于总是有不符合用户期望的细节，用户如果要定制就要修改源码这样不方便，现在有了这就可以自由定制扩展了  
</pre>  

<pre style=" font-size: large; font-family: 黑体,serif; color: brown">  
用户自定义的类可以继承 AbstractConsumer ，这种方式适合扩展支持新的中间件种类。<br>  

也可以继承自框架中已有的 AbstractConsumer 的子类，这种适合对逻辑进行调整，或者增加打印什么的 。  
test_frame/test_custom_broker/test_custom_redis_consume_latest_publish_msg_broker.py 就是继承自 AbstractConsumer 的子类。  

</pre>  

```  
register_custom_broker有两个用途  
1 是给用户提供一种方式新增消息队列中间件种类，(funboost框架支持了所有知名类型消息队列中间件或模拟中间件，这个用途的可能性比较少)  
2 可以对已有中间件类型的消费者 发布者类继承重写符合自己意愿的，这样就不需要修改项目的源代码了，这种用法非常的强大自由，可以满足一切用户的特殊定制想法。  
  因为用户可以使用到self成员变量和通过重写使用其中的函数内部局部变量，能够做到更精细化的特殊定制。这个用途很强大自由灵活定制。  

用法例如 register_custom_broker(BROKER_KIND_LIST, ListPublisher, ListConsumer)  # 核心，这就是将自己写的类注册到框架中，框架可以自动使用用户的类，这样用户无需修改框架的源代码了。  

```  

以下为4个扩展或定制的代码例子：  

[继承AbstractConsumer基类 ，自定义扩展使用list作为消息队列](https://github.com/ydf0509/funboost/tree/master/test_frame/test_custom_broker/test_custom_list_as_broker.py)  

[继承AbstractConsumer基类 ，自定义扩展使用deque作为消息队列](https://github.com/ydf0509/funboost/tree/master/test_frame/test_custom_broker/test_custom_deque_as_broker.py)  

[继承AbstractConsumer的子类 ，自定义扩展使用redis实现先进后出 后进先出，总是优先消费最晚发布的消息的例子](https://github.com/ydf0509/funboost/tree/master/test_frame/test_custom_broker/test_custom_redis_consume_latest_publish_msg_broker.py)  

[继承AbstractConsumer的子类 ，自定义扩展重写消费者最核心控制运行函数的 _run方法的逻辑的例子](https://github.com/ydf0509/funboost/tree/master/test_frame/test_custom_broker/rewrite_run.py)  

## 4.21b 【完全自由定制扩展(方式2)】,使用 consumer_override_cls 和 publisher_override_cls 来自定义消费者 发布者。  

**方式2，使用装饰器的入参 consumer_override_cls 和 publisher_override_cls**  

### 4.21b.1 重写某些方法的例子  

下面的例子是自定义一个MyConsumer，传给 consumer_override_cls，MyConsumer可以继承自AbstractConsumer或者他的子类。  
这个代码会让用户自定义记录函数的消费结果，可以重写AbstractConsumer的任意所有方法和属性，所以用户完全可以自由定义重写。  

同理，通过指定 publisher_override_cls 一个自定义的 Publisher类，用户可以重写或自定义发布者。  

下面例子是重写实现记录函数消费状态方法，所以只需要重写 user_custom_record_process_info_func ，  
你就能实现 celery的类似 on_sucess 和 on_failure  

```python  
import time  

from funboost import boost, BrokerEnum, BoosterParams, AbstractConsumer, FunctionResultStatus  


import random  
import time  

from funboost import boost, BrokerEnum, FunctionResultStatusPersistanceConfig, BoosterParams, ConcurrentModeEnum, AbstractConsumer, FunctionResultStatus  


class MyConsumer(AbstractConsumer):  
    def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus):  
        print('使用指定的consumer_override_cls来自定义或重写方法')  
        if current_function_result_status.success is True:  
            print(f'入参 {current_function_result_status.params} 成功了，结果是： {current_function_result_status.result}，模拟发个微信通知')  
        else:  
            print(f'入参 {current_function_result_status.params} 失败了，原因是： {current_function_result_status.exception},模拟发个邮件')  
        self.logger.debug(current_function_result_status.get_status_dict()) # 给用户打印下current_function_result_status有哪些字段信息。  


@boost(BoosterParams(queue_name='test_redis_ack_use_timeout_queue', broker_kind=BrokerEnum.REDIS,  
                     concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD,  
                     log_level=10,  consumer_override_cls=MyConsumer,  
                     is_show_message_get_from_broker=True))  
def cost_long_time_fun(x):  
    print(f'start {x}')  
    time.sleep(2)  
    if random.random()>0.5:  
        raise ValueError('模拟函数运行出错')  
    print(f'end {x}')  
    return x*2  


if __name__ == '__main__':  
    for i in range(100):  
        cost_long_time_fun.push(i)  
    cost_long_time_fun.consume()  

```  

上面例子是重写了父类方法,轻度的自定义某个方法.  
也可以重量级自定义用于新增消息队列中间件种类,例如下面的代码,使用 list 模拟消息队列.  

### 4.21b.2 完全实现新增中间件类型.  

使用 list 列表作为 消息队列的中间件 实现, 通过指定 consumer_override_cls 和 publisher_override_cls 为用户自定义的类来实现新增消息队列种类。  

这里只是用例子演示怎么使用  consumer_override_cls 和 publisher_override_cls 来开发新的消息队列种类,增加到 funboost,  
不是真的推荐用户在生产大规模使用 list 结构作为消息队列中间件.  

```python  
import threading  

import json  

import time  
from collections import defaultdict  
from funboost import boost, BrokerEnum, BoosterParams, EmptyConsumer, EmptyPublisher  

queue_name__list_map = defaultdict(list)  
list_lock = threading.Lock()  

'''  
使用 list 列表作为 消息队列的中间件 实现, 通过指定 consumer_override_cls 和 publisher_override_cls 为用户自定义的类来实现新增消息队列种类。  
这里只是用例子演示怎么使用  consumer_override_cls 和 publisher_override_cls 来开发新的消息队列种类,增加到 funboost,   
不是真的推荐用户在生产大规模使用 list 结构作为消息队列中间件.  
'''  
class MyListConsumer(EmptyConsumer):  
    def custom_init(self):  
        self.list: list = queue_name__list_map[self.queue_name]  

    def _dispatch_task(self):  
        while True:  
            try:  
                with list_lock:  
                    msg = self.list.pop()  
                self._submit_task({'body': msg})  
            except IndexError:  
                time.sleep(0.1)  

    def _confirm_consume(self, kw):  
        """ 这里是演示,所以搞简单一点,不实现确认消费 """  
        pass  

    def _requeue(self, kw):  
        with list_lock:  
            self.list.append(kw['body'])  


class MyListPublisher(EmptyPublisher):  
    def custom_init(self):  
        self.list: list = queue_name__list_map[self.queue_name]  

    def _publish_impl(self, msg: str):  
        with list_lock:  
            self.list.append(msg)  

    def clear(self):  
        with list_lock:  
            self.list.clear()  

    def get_message_count(self):  
        with list_lock:  
            return len(self.list)  

    def close(self):  
        pass  


'''  
完全重新自定义增加中间件时候,broker_kind 建议指定为 BrokerEnum.EMPTY  
'''  


@boost(BoosterParams(queue_name='test_define_list_queue',  
                     broker_kind=BrokerEnum.EMPTY,  # 完全重新自定义新增中间件时候,broker_kind 请指定 BrokerEnum.EMPTY  
                     concurrent_num=10, consumer_override_cls=MyListConsumer, publisher_override_cls=MyListPublisher,  
                     is_show_message_get_from_broker=True))  
def cost_long_time_fun(x):  
    print(f'start {x}')  
    time.sleep(20)  
    print(f'end {x}')  


if __name__ == '__main__':  

    for i in range(100):  
        cost_long_time_fun.push(i)  
    cost_long_time_fun.consume()  

```  


### 4.21b.3 funboost的用户自定义扩展比celery更容易,更彻底

因为funboost的扩展是使用经典oop，用户可以完全100%修改定制funboost任何细节，不需要我亲自提前预判预留暴露几百个用户可能需要用到的钩子。     
funboost现在很少预留用户级钩子，唯一的就是 boost 装饰器 有个 `user_custom_record_process_info_func` 钩子，给用户提供记录函数结果状态的，但是这不是必需品，用户完全可以使用4.21介绍的扩展方式，通过`consumer_override_cls`重写父类的这个`user_custom_record_process_info_func` 空方法或者直接重写父类的_run方法,这更oop,写法更一致。 
celery的扩展就很垃圾了，必须依赖框架自身提前预留暴露了相关钩子或者信号机制，如果你有个奇葩独特的自定义需求，但是celery没给你暴露相关钩子或者信号机制，你只能对celery的源码进行修改或者使用猴子补丁来动态替换源码了。 


你可以看看 funboost 和 celery 怎么扩展 `opentelemetry` 来实现全链路可视化追踪的。见文档 4b.7.3 章节。   
**-> ### 4b.7.3 从opentelemetry功能集成， 侧面证明 funboost 对普通用户扩展性比celery强10倍。** 


**在文档4b.2c章节,也演示了通过指定 consumer_override_cls 来消费任意格式的消息,用户可以和4.21章节一起阅读**  





## 4.23 演示funboost框架是如何代替用户手写调用线程池的  

为什么框架介绍中说有了funboost，再也无需用户手动操作线程和线程池ThradPoolExecutor以及multiprossing.Process()了。  

手动使用线程池写法  

```python  
import time  
from concurrent.futures import ThreadPoolExecutor  


def f(x, y):  
    print(f'{x} + {y} = {x + y}')  
    time.sleep(10)  


if __name__ == '__main__':  

    pool = ThreadPoolExecutor(5)  

    for i in range(100):  
        pool.submit(f, i, i * 2)  
```  

funboost取代手写调用线程池  

```python  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test1', broker_kind=BrokerEnum.MEMORY_QUEUE, concurrent_num=5))  
def f(x, y):  
    print(f'{x} + {y} = {x + y}')  
    time.sleep(10)  


if __name__ == '__main__':  
    f.consume()  
    for i in range(100):  
        f.push(i, i * 2)  

```  

```text  
这两个的效果是一样的，都是使用内存queue来保存待运行的任务，都是使用5线程并发运行f函数的。  

funboost还能开启多进程，取代用户手写 Process(target=fx),所以有了funboost，用户无需手写开启线程 进程。  

如果用户希望任务保存到redis中先，而不是保存在python内存queue中，那就使用funboost比调用ThreadPoolExecutor方便多了。  
再比如用户希望每秒运行完成10次f函数(控制台每秒都打印10次求和结果)，而不是开启10线程来运行f函数，funboost则远方便于ThreadPoolExecutor  
```  

## 4.24 设置消费函数重试次数  

```python  
import random  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_queue9', broker_kind=BrokerEnum.REDIS_ACK_ABLE, max_retry_times=5))  
def add(a, b):  
    time.sleep(2)  
    if random.random() >0.5:  
        raise ValueError('模拟消费函数可能出错')  
    return a + b  


if __name__ == '__main__':  
    for i in range(1,1000):  
        add.push(i,i*2)  
    add.consume()  
```  

```  
通过设置 max_retry_times 的值，可以设置最大重试次数，函数如果出错了，立即将参数重试max_retry_times次，如果重试次数达到指定的max_retry_times，就执行确认消费了。  
```  

### 4.24.b 抛出ExceptionForRequeue类型错误，消息立即重回消息队列  

```python  
@boost(BoosterParams(queue_name='test_rpc_queue', is_using_rpc_mode=True, broker_kind=BrokerEnum.REDIS_ACK_ABLE, qps=100, max_retry_times=5))  
def add(a, b):  
    time.sleep(2)  
    if random.random() >0.5:  
        raise ExceptionForRequeue('模拟消费函数可能出错,抛出ExceptionForRequeue类型的错误可以使消息立即重回消息队列')  
    return a + b  


if __name__ == '__main__':  
    add.consume()  
```  

```  
消费函数中 raise ExceptionForRequeue ，会使消息立即重回消息队列的尾部。  如果函数运行该消息的出错概率使100%，就要慎重了，  
避免函数运行这个消息一直出错一直重回消息队列，无限蒙蔽死循环消费这个入参。  
```  

### 4.24.c 抛出 ExceptionForPushToDlxqueue 类型错误，消息发送到单独另外的死信队列中  

```python  
@boost(BoosterParams(queue_name='test_rpc_queue', is_using_rpc_mode=True, broker_kind=BrokerEnum.REDIS_ACK_ABLE, qps=100, max_retry_times=5))  
def add(a, b):  
    time.sleep(2)  
    if random.random() >0.5:  
        raise ExceptionForPushToDlxqueue('模拟消费函数可能出错,抛出ExceptionForPushToDlxqueue类型的错误，可以使消息发送到单独的死信队列中')  
    return a + b  


if __name__ == '__main__':  
    add.consume()  
```  

```  
消费函数中 raise ExceptionForPushToDlxqueue ，可以使消息发送到单独的死信队列中，死信队列的名字是正常队列的名字 + _dlx  
```  

### 4.24.d  设置is_push_to_dlx_queue_when_retry_max_times,重试到max_retry_times最大次数没成功发送到死信队列  

```  
@boost 装饰器 设置 is_push_to_dlx_queue_when_retry_max_times = True，  
则函数运行消息出错达到max_retry_times最大重试次数后仍没成功，确认消费，同时发送到死信队列中。  
```  

### 4.24.e (内置辅助)将一个消息队列中的消息转移到另一个队列  

```  
可以用于死信队列转移到正常队列。  
```  

```python  
from funboost.contrib.queue2queue import consume_and_push_to_another_queue,multi_prcocess_queue2queue  

if __name__ == '__main__':  
    # 一次转移一个队列，使用单进程  
    # consume_and_push_to_another_queue('test_queue77h3', BrokerEnum.RABBITMQ_AMQPSTORM,  
    #                                   'test_queue77h3_dlx', BrokerEnum.RABBITMQ_AMQPSTORM,  
    #                                   log_level_int=logging.INFO, exit_script_when_finish=True)  

    # 转移多个队列，并使用多进程。  
    multi_prcocess_queue2queue([['test_queue77h5', BrokerEnum.RABBITMQ_AMQPSTORM, 'test_queue77h4', BrokerEnum.RABBITMQ_AMQPSTORM]],  
                               log_level_int=logging.INFO, exit_script_when_finish=True, n=6)  
```  

## 4.25 push和publish发布消息区别  

```  
funboost的push和publish 就像celery的delay和apply_async关系一样。  
一个简单方便，一个复杂强大。前者的入参和函数本身入参类似，后者除了函数入参本身，还可以单独指定改任务的控制属性。  
```  

```python  
from funboost import boost, BoosterParams  
@boost(BoosterParams(queue_name='test_queue_pub'))  
def add(a, b):  
    return a + b  

if __name__ == '__main__':  
    # push的入参就和正常调用函数一样的入参方式，框架会自动把多个入参组合成一个字典，字典再转化成json发布到消息队列。  
    add.push(1,2)  
    add.push(1,b=2)  
    add.push(a=1,b=2)  
  
    # publish 意思是把所有入参参数作为一个字典，框架会把字典转化成json发布到消息队列，publish除了发布函数入场本身外，还可以设置一些其他任务属性。  
    # 所以publish是比push更强大的存在，push是简单，publish是更可以发布任务控制参数。  
    add.publish({"a":1,"b":2})  
    # publish 除了可以发布函数入参本身以外，还能发布任务控制参数，例如可以手动的指定id而非有框架自动生成任务id，还能设置其他控制参数。  
    # 例如 在 task_options的PriorityConsumingControlConfig中设置   msg_expire_seconds =5，可以使得发布消息离消费超过5秒，丢弃消息不消费。  
    # 例如设置is_using_rpc_mode = True ，则可以单独使该任务参数支持rpc获得结果。  
    add.publish({"a":1,"b":2},task_id=100005,task_options=PriorityConsumingControlConfig(is_using_rpc_mode=True))  
```  

## 4.26 性能调优演示  

要看4.5章节的说明，有的人不看文档，不知道怎么性能达到最好，不知道怎么开多进程,只知道简单demo的 fun.consume()方式启动消费  

有的人不看4.5章节文档，需要重新说明  

```python  
import time  
from funboost import boost, ConcurrentModeEnum, BoosterParams  

@boost(BoosterParams(queue_name='test_queue_add'))  
def add(a, b):  
    time.sleep(2) # 模拟io或cpu耗时  
    return a + b  

@boost(BoosterParams(queue_name='test_queue_sub', concurrent_num=200, concurrent_mode=ConcurrentModeEnum.THREADING))  
def sub(x, y):  
    time.sleep(5) # 模拟io或cpu耗时  
    return x - y  
```  

对于上面这两个消费函数，启动消费说明  

### 4.26.1 在一个进程中启动多个函数的消费，适合轻型任务  

常规启动方式是这样，直接在当前进程里面启动两个函数的consume  

```  
add.consume()  
sub.consume()  

这种是一个进程内部启动多个消费函数，每个函数是默认使用多线程运行或协程（有5种细粒度并发模式，默认是线程，详细看4.5章节的介绍）  
如果这个python进程的任务较重，python进程的cpu已经明显很高了，则应该使用多进程叠加线程（协程）并发  
```  

### 4.26.2 在多个进程中启动函数的消费，适合一次启动大量函数的消费或重型任务  

假如add和sub是很费cpu的函数，或者一次性启动30个函数的消费，4.26.1的在一个进程中启动多个函数的消费的方式就不合适了。  

应该在独立进程中运行函数，这样性能好，突破单进程 无法使用多核心 gil限制，充分使用多核。  

```  
add.multi_process_consume(1) # 独立开1个进程，每个进程内部使用多线程运行或协程 来运行求和函数  
sub.multi_process_consume(3) # 独立开3个进程来运行求差函数，每个进程内部使用多线程运行或协程 来运行求和函数.  
sub函数是开3个进程，每个进程使用多线程并发方式，每个进程内部按照boost装饰器指定的，开了200线程。也就是总共600线程运行sub函数。  
3进程，每个进程内部开200线程，比单进程设置600线程岁强很多的。尤其是cpu密集型，多进程优势明显。  

```  

要看4.5章节的说明，有的人不看文档，不知道怎么性能达到最好，不知道怎么开多进程,只知道简单demo的 fun.consume()方式启动消费  

## 4.28 funboost 支持celery框架整体作为funboost的broker (2023.4新增)  

funboost的api来操作celery，完爆用户亲自操作celery框架。  

害怕celery框架用法pythoner的福音。  

```  
见11.1章节代码例子，celery框架整体作为funboost的broker，funboost的发布和消费将只作为极简api，核心的消费调度和发布和定时功能，都是由celery框架来完成，funboost框架的发布和调度代码不实际起作用。  
用户操作funboost的api，语法和使用其他消息队列中间件类型一样，funboost自动化操作celery。  

用户无需操作celery本身，无需敲击celery难记的命令行启动消费、定时、flower;  
用户无需小心翼翼纠结亲自使用celery时候怎么规划目录结构 文件夹命名 需要怎么在配置写include 写task_routes，  
完全不存在需要固定的celery目录结构，不需要手动配置懵逼的任务路由，不需要配置每个函数怎么使用不同的队列名字，funboost自动搞定这些。  
celery框架的一大堆需要用户使用的重要的高频公有核心方法入参声明都是 *agrs,**kwargs，代码无法在ide补全，  
并且点击到celery源码方法里面取也没有明确的说明*agrs **kwargs能传递哪些几十个参数，网上的简单demoi例子也不会列举出来各种细节入参，导致一般用户不知道celery能传什么，  
 比如@app.task的入参、task_fun.apply_async的入参、app.send_task、celery的配置大全 能传哪些，用户无法知道，这种不能再pycharm ide下代码补全的框架可以说是极端的操蛋，  
 不能代码补全的框架，就算是功能强大也没用，不好使用。还有celery启动work 启动定时 启动flower都需要手敲 cmd 命令行，用户连入参能传哪些控制命令大全都不知道，  
所以celery框架对不非常熟练python的人是极端的操蛋。  

用户只需要使用简单的funboost语法就能操控celery框架了。funboost使用celery作为broker_kind,远远的暴击亲自使用无法ide下代码补全的celery框架的语法。  
```  

```  
funboost通过支持celery作为broker_kind,使celer框架变成了funboost的一个子集  
```  

funboost使用broker_kind=BrokerEnum.CELERY作为中间件的代码。  

```python  
import time  

from funboost import boost, BrokerEnum, BoosterParams  
from funboost.consumers.celery_consumer import CeleryHelper  


@boost(BoosterParams(queue_name='celery_q1', broker_kind=BrokerEnum.CELERY, qps=5))  
def f1(x, y):  
    time.sleep(3)  
    print('哈哈哈', x, y)  
    return x + y  


@boost(BoosterParams(queue_name='celery_q2', broker_kind=BrokerEnum.CELERY, qps=1))  
def f2(a, b):  
    time.sleep(2)  
    print('嘻嘻', a, b)  
    return a - b  


if __name__ == '__main__':  
    for i in range(200):  
        f1.push(i, i * 2)  
        f2.push(a=i, b=i * 10)  

    f1.consume()  # 登记celery worker命令需要启动的--queues  
    f2.consume()  # 登记celery worker命令需要启动的--queues  
    CeleryHelper.realy_start_celery_worker(worker_name='测试celery worker2') # 正正的启动celery worker  


```  

funboost 以celery中间件模式运行的github项目代码：  

[https://github.com/ydf0509/funboost_run_celery_mode/tree/main](https://github.com/ydf0509/funboost_run_celery_mode/tree/main)  

11.1章节有更多的funboost 操作celery代码说明，包括原生的celery定时和flower。  

## 4.29 funboost支持任务优先级队列  

目前只有 BrokerEnum.REDIS_PRIORITY 和 BrokerEnum.RABBITMQ_AMQPSTORM 两个broker支持队列优先级，选择其他的broker_kind不支持优先级队列。  

### 4.29.1 队列支持优先级的说明：  

```  
 注意：        rabbitmq、celery队列优先级都指的是同一个队列中的每个消息具有不同的优先级，消息可以不遵守先进先出，而是优先级越高的消息越先取出来。  
              队列优先级其实是某个队列中的消息的优先级，这是队列的 x-max-priority 的原生概念。  

              队列优先级有的人错误的以为是 queuexx 和queueyy两个队列，以为是优先消费queuexx的消息，这是大错特错的想法。  
              队列优先级是指某个队列中的每个消息可以具有不同的优先级，不是在不同队列名之间来比较哪个队列名具有更高的优先级。  
```  

### 4.29.2 优先级通俗理解，用食堂打饭比喻：  

```  
校食堂有两个打饭窗口a和b。a窗口的排队是声明了支持优先级队列，b窗口的排队是没有声明支持优先级的队列。  

声明了支持优先级的打饭窗口a排队可以允许插队，例如校领导优先级是3，老师优先级是2，学生优先级是1。就算是学生先去排队，但校长优先级高，  
就算排了100个学生排队长龙打饭，校长在这个a窗口来打饭时候可以插队，优先给校长打饭，只要校领导和老师的饭没打完，学生是不能打饭的。  

b打饭窗口由于没有声明支持优先级，任何人来这个b窗口打饭必须老老实实排队，谁先来排队就先给谁打饭，天王老子来了都不可以插队优先打饭。  


a窗口和b窗口排队的人是互不影响的，优先级是针对各自的队列。  
并不是有的人以为的，a窗口优先级高，b窗口优先级低，只要a窗口有人排队，就不给b窗口的人打饭了，你这样那就是想错了。自己好好搜索rabbitmq的 x-max-priority 概念先。  
```  

### 4.29.3 队列支持任务优先级的代码主要有三点：  

```  
   第一，如果使用redis做支持优先级的消息队列， @boost中要选择 broker_kind = BrokerEnum.REDIS_PRIORITY，  
       如果是使用rabbitmq写 BrokerEnum.RABBITMQ_AMQPSTORM。  
    
   第二，broker_exclusive_config={'x-max-priority':5} 意思是声明这个队列中的任务消息支持多少种优先级，一般写5就完全够用了，不要写太大了，不需要那么多种级别。  
   
   第三，发布消息时候要使用publish而非push,发布要加入参  task_options=PriorityConsumingControlConfig(other_extra_params={'priroty': priority})，  
        其中 priority 必须是整数，要大于等于0且小于队列声明的x-max-priority。x-max-priority这个概念是rabbitmq的原生概念，celery中也是这样的参数名字。  

        发布的消息priroty 越大，那么该消息就越先被取出来，这样就达到了打破了先进先出的规律。比如优先级高的消息可以给vip用户来运行函数实时，优先级低的消息可以离线跑批。  
```  

### 4.29.4 队列支持任务优先级的代码如下：  

```python  
import random  
import time  

from funboost import boost, PriorityConsumingControlConfig, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_redis_priority_queue4', broker_kind=BrokerEnum.REDIS_PRIORITY, qps=100, concurrent_num=50, broker_exclusive_config={'x-max-priority':4}))  
def f(x):  
    time.sleep(60)  
    print(x)  


if __name__ == '__main__':  
    f.clear()  
    print(f.get_message_count())  

    for i in range(1000):  
        randx = random.randint(1, 4)  
        f.publish({'x': randx}, task_options=PriorityConsumingControlConfig(other_extra_params={'priroty': randx}))  
    print(f.get_message_count())  

    f.consume()  
```  

从控制台打印可以看到先print的都是4，最后print的是1，无视了消息的发布顺序，而是以消息的优先级来决定谁先被消费。  

### 4.29.5 消息队列优先级是针对一个queue内消息的，那么怎样才能实现不同函数之间的按优先级运行？  

很简单，既然优先级队列指的是一个队列中不同的消息可以具有不同的优先级。那么只要用一个队列就好了。一个总的函数消费消息队列，然后分发调用不同的函数,就可以实现优先运行哪个函数了。  

下面例子就是，交替发布1000次 f1 f2 f3函数的消息到 test_priority_between_funs 队列中，但消费时候优先运行f3函数，最后才运行f1函数。通过控制台的打印可以看到。  

```python  
"""  
演示不同的函数，怎么优先消费某个函数。  
比如爬虫你想深度优先，那就优先运行爬详情页的函数，发布消息时候把爬详情页函数的优先级设置的priroty更大。  
你想广度优先就优先运行爬列表页的函数，发布消息时候把爬列表页函数的优先级设置的priroty更大。  

如下代码就是把f3函数的优先级设置成了3，f2的优先级设置成了2，f1的优先级设置成了1，所以先交替发布3000个消息到消息队列中，会优先运行f3函数，最后才运行f1函数。  
虽然优先级是针对某一个队列而言，不是针对不同队列的优先级，但只要懂得变通，在下面代码的例子中的 dispatch_fun 函数这样分发调用不同的函数，就可以实现多个函数之间的优先级了。  

运行可以发现控制台先打印的都是f3，最后还是f1.  
"""  
"""  
演示不同的函数，怎么优先消费某个函数。  
比如爬虫你想深度优先，那就优先运行爬详情页的函数，把爬详情页函数的优先级调大。  
你想广度优先就优先运行爬列表页的函数，把爬列表页页函数的优先级调大。  

如下代码就是把f3函数的优先级设置成了3，f2的优先级设置成了2，f1的优先级设置成了1，所以先发布3000个消息到消息队列中，会优先运行f3函数，最后才运行f1函数。  
优先级是针对某一个队列而言，不是针对不同队列的优先级，但只要懂得变通，在下面代码的例子中的boost_fun函数这样分发调用不同的函数，就可以实现多个函数之间的优先级了。  

运行可以发现控制台先打印的都是f3，最后还是f1.  
"""  
from funboost import boost, PriorityConsumingControlConfig, BrokerEnum, BoosterParams  


def f1(x, y):  
    print(f'f1  x:{x},y:{y}')  


def f2(a):  
    print(f'f2  a:{a}')  


def f3(b):  
    print(f'f3  b:{b}')  


@boost(BoosterParams(queue_name='test_priority_between_funs', broker_kind=BrokerEnum.RABBITMQ_AMQPSTORM, qps=100, broker_exclusive_config={'x-max-priority': 5}))  
def dispatch_fun(fun_name: str, fun_kwargs: dict, ):  
    function = globals()[fun_name]  
    return function(**fun_kwargs)  


if __name__ == '__main__':  
    dispatch_fun.clear()  
    for i in range(1000):  
        dispatch_fun.publish({'fun_name': 'f1', 'fun_kwargs': {'x': i, 'y': i}, },  
                             task_options=PriorityConsumingControlConfig(other_extra_params={'priroty': 1}))  
        dispatch_fun.publish({'fun_name': 'f2', 'fun_kwargs': {'a': i, }, },  
                             task_options=PriorityConsumingControlConfig(other_extra_params={'priroty': 2}))  
        dispatch_fun.publish({'fun_name': 'f3', 'fun_kwargs': {'b': i, }, },  
                             task_options=PriorityConsumingControlConfig(other_extra_params={'priroty': 3}))  

    print(dispatch_fun.get_message_count())  
    dispatch_fun.consume()  


```  

## 4.30 funboost 远程杀死(取消)任务  

之前有的人想远程杀死一个正在运行的任务，或者刚发布消息后后悔了，不想运行那个消息了，现在支持这种功能。  
用户无论选择哪种消息队列中间件，想使用远程杀死就必须在funboost_config.py配置好redis连接。  

远程杀死任务分两种情况：  

```  
1）对于发布后，还没从消息队列中取出来运行的消息，funboost会放弃运行这个消息。  
2）对于正在执行中的消息，funboost会杀死正在运行的这个函数消息。  
```  

```  
celery如果选择threading并发模式，celery不支持terminate杀死，celery的消费端在收到terminate命令时候会报错，celery多线程并发池没有实现杀死功能。  

funboost支持杀死正在运行中的函数消息。  
```  

### 4.30.1 funboost远程杀死函数的代码例子  

注意要设置 is_support_remote_kill_task=True，如果不需要远程杀死函数消息的功能，就别设置为True，浪费性能；  
因为函数要支持杀死，必须把函数单独运行在一个线程中，杀死这个线程来达到杀死函数的目的。所以非必要别设置 is_support_remote_kill_task=True。  

开启 is_support_remote_kill_task=True  适合任务数量少，函数运行耗时非常大的情况；  
因为如果函数只需要10秒能运行完，你还没来得及开始写发送远程杀死命令的代码，函数就已经执行完了，杀死了个寂寞。  

下面代码是让funboost结束执行求和 3+4。  

消费端代码求和：  

```python  
import time  

from funboost import boost, BoosterParams  


@boost(BoosterParams(queue_name='test_kill_fun_queue', is_support_remote_kill_task=True)) #  is_support_remote_kill_task=True 要设置为True  
def test_kill_add(x, y):  
    print(f'start {x} + {y} ....')  
    time.sleep(120)  
    print(f'over {x} + {y} = {x + y}')  


if __name__ == '__main__':  
    test_kill_add.consume()  
```  

发布端代码：  

```python  
import time  
from test_funboost_kill_consume import test_kill_add  
from funboost import RemoteTaskKiller  

if __name__ == '__main__':  
    async_result = test_kill_add.push(3,4)  
    # time.sleep(10)  
    RemoteTaskKiller(test_kill_add.queue_name,async_result.task_id).send_kill_remote_task_comd() #  RemoteTaskKiller 传入要杀死的队列名和消息的taskid  
```  

超时杀死控制台截图：  
![img_42.png](img_42.png)  

### 4.30.2 远程强制杀死函数、超时自动杀死(function_timeout设置不为0)， 这两个功能要注意死锁：  

```  
funboost的多线程并发模式的 function_timeout超时自动杀死 和远程命令来杀死函数都需要注意杀死函数后的锁不释放问题。  

1）在消费函数中 with 推荐  

with lock:  
    长耗时代码  
  
在执行长耗时代码块时候，这种函数被强制杀死，不会发生死锁。  


2）在消费函数中，lock.acquire() 和 release() 不推荐，  

lock.acquire():  
长耗时代码  
lock.release()  

在执行长耗时代码块时候，这种函数被强制杀死，会发生死锁,杀死函数后，消费会一直卡住，所以消费会一直等待这个锁，导致消费无法继续运行。  


对于使用锁的建议：  
大家尽量使用with语法使用锁，或者锁别加在长耗时代码块上，减少死锁概率。  
或使用可过期锁expire_lock。  

```  

### 4.30.2.b 如果想启用funboost函数超时自动杀死功能或者 远程杀死函数功能，推荐消费函数中使用可过期锁 expire_lock  

pip install expire_lock  

或者 from funboost.utils import expire_lock  

expire_lock 使用文档：  
[https://pypi.org/project/expire-lock/](https://pypi.org/project/expire-lock/)  

expire_lock 规定了一个锁的最大占用时间，如果达到了最大的expire时间一直没有释放这个锁，会自动过期释放。  

## 4.31 神级别 fct (funboost_current_task) 上下文获取当前消息和任务状态  

fct 就是 funboost_current_task 简写，就是当前任务的意思。  

通过fct这个线程/协程 精妙的上下文全局变量，可以获取消息的完全体。  

可以去ai大模型提问flask视图函数中的 request 对象的设计！  

funboost的fct 和 flask的request就是类似用途，不需要从函数入参显式传递，但在函数内部可以精准得到当前请求的入参。  

这个线程/协程上下文 可以在多个函数中自动传递，而不需要手动把这个对象作为函数在一条链路上的多个函数中作为函数入参传来传去的。  

例如django就没有flask这种神奇的request对象，django需要明显的把request定义为视图函数的入参。  

没有fct时候，之前无法在用户的消费函数内部去获取消息的完全体,只能知道函数的入参,无法知道消息的发布时间 taskid等.  

```  
用户在任意消费函数中   
fct 就能获取当前的任务消息了。  

这个功能使得用户在用户函数中就能知道消息的完全体、 当前是哪台机器 、哪个进程、 第几次重试运行函数  
消息的发布时间  消息的task_id 等等。  

原来用户在消费函数中是无法获取这些信息的。  
```  

```python  

import random  
import time  

from funboost import boost, BoosterParams, fct  


@boost(BoosterParams(queue_name='queue_test_fct', qps=2, concurrent_num=5, ))  
def f(a, b):  
    print(fct.task_id)  # 获取消息的任务id  
    print(fct.function_result_status.run_times)  # 获取消息是第几次重试运行  
    print(fct.full_msg)  # 获取消息的完全体。出了a和b的值意外，还有发布时间 task_id等。  
    print(fct.function_result_status.publish_time)  # 获取消息的发布时间  
    print(fct.function_result_status.get_status_dict())  # 获取任务的信息，可以转成字典看。  

    time.sleep(20)  
    if random.random() > 0.5:  
        raise Exception(f'{a} {b} 模拟出错啦')  
    print(a + b)  
    common_fun() # 这里不要手动把消息taskid和消息内容告诉 common_fun ，common_fun 能自动通过fct上下文知道。  
    return a + b  


def common_fun():  
    """ common_fun 函数中也能自动通过上下文知道当前是在消费什么消息内容，无需让f函数调用 common_fun 时候吧taskid full_msg作为入参传过来 """  
    print(f'common_fun函数也能自动知道消息的taskid，无需在f消费函数中把taskid作为common_fun函数的入参传过来,taskid: {fct.task_id}, full_msg: {fct.full_msg}')  


if __name__ == '__main__':  
    # f(5, 6)  # 可以直接调用  

    for i in range(0, 200):  
        f.push(i, b=i * 2)  

    f.consume()  

```  

```  
代码中无论是 f 消费函数，还是 common_fun 普通函数， 都能通过fct获取当前任务  
```  

![img_61.png](img_61.png)  

## 4.32 重磅更新！！！ funboost 独家新增支持实例方法和类方法作为消费函数  

funboost 之前一直是只支持 普通函数或者静态方法作为消费函数，celery也是不能支持实例方法和类方法作为消费函数。  

这个问题之前还专门写个常见问题答疑里面，见第 6.5 章节 ,为什么强调是函数调度框架不是类调度框架，不是方法调度框架？ [https://funboost.readthedocs.io/zh-cn/latest/articles/c6.html#id5](https://funboost.readthedocs.io/zh-cn/latest/articles/c6.html#id5)  
,通过里面的介绍就知道，如果支持要实例方法和类方法作为消费函数有多么困难。  
对于 实例方法和类方法作为消费函数，funboost 是做了判断和专门适配的。  

### 4.32.0 !!! 实例方法和类方法作为funboost任务时候，push方法需要特别注意第一个入参。

- 不能按照普通模块级函数的funboost push方法的思维惯性写实例方法的push，    
  不能以为 `myobj.instance_method(入参1,入参2,入参3=值3,入参4=值4,入参5=值5,) ` 调用方法 ,    
  错误的以为发布消息时候可以写成 `myobj.instance_method.push(入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)`   

- 在python中 `myobj.instance_method(入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)`     
  实际是 `Myclass.instance_method(myobj,入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)` ,    
  你必须知道这个根本原理才知道实例方法的 `self` 是什么。   

- **使用实例方法作为funboost任务切记发布形式：**    
<pre class="warn"> 
要写成 `类.方法.push(对象,入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)`
不能写成 `实例对象.方法.push(入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)`
</pre>

- **使用类方法作为funboost任务切记发布形式：**     
<pre class="warn"> 
要写成 `类.方法.push(类,入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)`
不能写成 `类.方法.push(入参1,入参2,入参3=值3,入参4=值4,入参5=值5,)`
</pre>

- **使用静态方法作为funboost任务**   
<pre class="warn"> 
无需任何注意，因为@classmethod 方法的第一个入参 不是self又不是cls，
所以 类.方法.push(入参1,入参2,入参3=值3,入参4=值4,入参5=值5,) 是正确的，无需注意。
</pre>


- **思考！：**
```
假设你不把 self 发到消息队列里面去，任务取出来时候咋知道 self的成员变量们是什么？
例如 ：
def instance_method(self, y):  
    print(self.x + y) # 这个求和用到了实例属性和方法入参求和，证明为什么push发布消息时候要传递self，因为两数字求和，不仅和入参y有关系，还和self的x成员变量有关系呢。  
```

### 4.32.1 funboost 支持实例方法和类方法作为消费函数的原理  



funboost 适配 实例方法和类方法的实现原理讲一下：  

假设类如下：  

```python  
class Myclass:  
    m = 1  

    def __init__(self, x):  
        self.obj_init_params: dict = ClsHelper.get_obj_init_params_for_funboost(copy.copy(locals())) # 这行重要，如果实例方法作为消费函数，那么必须定义obj_init_params_for_funboost保存对象的 __init__ 入参，用于还原生成对象。  
        # self.obj_init_params_for_funboost= {'x':x}  # 上面这行相当于这行，如果__init__入参太多，一个个的写到字典麻烦，可以使用上面的方式获取__init__入参字典。  
        self.x = x  

    @boost(BoosterParams(queue_name='instance_method_queue', is_show_message_get_from_broker=True, ))  
    def instance_method(self, y):  
        print(self.x + y) # 这个求和用到了实例属性和方法入参求和，证明为什么发布消息时候要传递self。  

    #  
    @classmethod  
    @BoosterParams(queue_name='class_method_queue', is_show_message_get_from_broker=True, )  
    def class_method(cls, y):  
        print(cls.m + y)  
```  

```  
对于类方法：  
通过方法所属的类名和模块名，反射得到类，但不能直接把类本身作为消息的函数入参，发布到消息队列，  
因为采用的是json序列化消息，所以入参不能包括在定义类型和在定义类型的对象， funboost发布消息时候使用字典代替了类方法的第一个入参 cls，  
funboost在消费消息时候，把消息的第一个入参cls，替换成类本身，这样就是生成真正的函数入参，然后再去调用类方法。  
发布消息： Myclass.class_method.push(Myclass,2)  



对于实例方法：  
funboost发布消息时候使用字典代替了实例方法的第一个入参 self，把 对象的实例化时候的入参字典就是对象的 obj_init_params 属性，放到这个字典里面去了。  
消费时候，从消息队列获取入参后，使用 obj_init_params 这个字典作为对象实例化的入参，重新生成一个对象，然后把这个对象替换实例方法的第一个入参self，再去调用实例方法。  
对象必须定义 obj_init_params 属性，保存对象 __init__ 时候的入参字典，供消费时候重新生成对象。  
因为 1+2=3,是不仅和instance_method的入参y有关系，还和对象本身的x属性也有关系。  
发布消息： Myclass.instance_method(Myclass(1),2)   


！！！特别需要注意的是实例方法作为消费函数的时候，对象必须定义 obj_init_params 属性保存初始化入参，并且 __init__ 的入参同样必须是基础类型，能被json序列化的，  
不能是自定义类型和对象。  

```  

### 4.32.2 funboost 支持实例方法、类方法、静态方法、普通函数 4种类型，作为消费函数的例子  

下面代码完整的演示了 实例方法、类方法、静态方法、普通函数 4种类型，作为消费函数的例子，请务必注意看代码和注释说明。  

！！！请务必注意观察 实例方法和类方法的push的形式和普通函数的push第一个入参的区别

```python3  
import copy  
from funboost import BoosterParams, boost  
from funboost.constant import FunctionKind  
from funboost.utils.class_utils import ClsHelper  


class Myclass:  
    m = 1  

    def __init__(self, x):  
        # 这行重要，如果实例方法作为消费函数，那么必须定义obj_init_params_for_funboost保存对象的 __init__ 入参，用于还原生成对象。  
        self.obj_init_params: dict = ClsHelper.get_obj_init_params_for_funboost(copy.copy(locals()))  
        # self.obj_init_params = {'x':x}  # 上面这行相当于这行，如果__init__入参太多，一个个的写到字典麻烦，可以使用上面的方式获取__init__入参字典。  
        self.x = x  

    @boost(BoosterParams(queue_name='instance_method_queue', is_show_message_get_from_broker=True, ))  
    def instance_method(self, y):  
        print(self.x + y)  # 这个求和用到了实例属性和方法入参求和，证明为什么发布消息时候要传递self。  

    #  
    @classmethod  
    @BoosterParams(queue_name='class_method_queue', is_show_message_get_from_broker=True, )  
    def class_method(cls, y):  
        print(cls.m + y)  

    @staticmethod  
    @BoosterParams(queue_name='static_method_queue', is_show_message_get_from_broker=True)  
    def static_method(y):  
        print(y)  


@BoosterParams(queue_name='common_fun_queue', is_show_message_get_from_broker=True)  
def common_f(y):  
    print(y)  


if __name__ == '__main__':  

    for i in range(6, 10):  
        Myclass.instance_method.push(Myclass(i), i * 2)  # 注意发布形式，实例方法发布消息不能写成 Myclass(i).push(i * 2) 只发布self之后的入参, self也必须传递。  
    Myclass.instance_method.consume()  

    for i in range(6, 10):  
        Myclass.class_method.push(Myclass,i * 2)  # 注意发布形式，不是 Myclass.class_method.push(i * 2) ， 而是应该写 Myclass.class_method.push(Myclass,i * 2)，cls也要传  
    Myclass.class_method.consume()  

    for i in range(10):  
        Myclass.static_method.push(i * 2)  # 不需要注意发布形式，和 普通函数的发布一样  
    Myclass.static_method.consume()  

    for i in range(10):  
        common_f.push(i * 2)  
    common_f.consume()  



```  

请注意看下面运行截图中的消息，self 在消息队列中间件中使用 json来表达了。消费运行时候重新根据obj_init_params和类名、文件名，生成Myclass类型的对象。  

```  
 向instance_method_queue 队列，推送消息 耗时0.001秒  {'self': {'first_param_name': 'self', 'obj_init_params': {'x': 6}, 'cls_name': 'Myclass', 'cls_file': 'D:/codes/funboost/test_frame/test_instancemothed_funboost/test_method_consume.py'}, 'y': 12}  
```  

![img_80.png](img_80.png)  

## 4.33  @boost设置is_auto_start_consuming_message，自动启动消费。  

```  
@BoosterParams(queue_name="q1",  is_auto_start_consuming_message=True)  
def f(x):  
这样写后，自动启动消费，不需要 用户手动的写  f.consume() 来启动消费。  
```  

```python  
import time  
from funboost import BoosterParams, BrokerEnum  


@BoosterParams(queue_name="test_instead_thread_queue", broker_kind=BrokerEnum.MEMORY_QUEUE, concurrent_num=10,  
               is_auto_start_consuming_message=True)  # is_auto_start_consuming_message 这里设置为了True  
def f(x):  
    time.sleep(3)  
    print(x)  


if __name__ == '__main__':  
    for i in range(100):  
        f.push(i)  
    #### f.conusme() #is_auto_start_consuming_message=True后， 这一行代码不需要，不需要手动 f.consume() 来启动消费。  

```  

## 4.34 pyinstaller 打包 funboost项目为exe 的说明  

见独立demo项目 https://github.com/ydf0509/funboost_pyinstaller  

里面有报错解决说明，funboost打包很容易。  

## 4.35 演示 funboost 的函数入参过滤功能  

```python  
@BoosterParams(queue_name='queue_test2', qps=6, broker_kind=BrokerEnum.REDIS,  
               do_task_filtering=True, # 这个是设置是否开启任务入参过滤  
               task_filtering_expire_seconds=3600, # 这个是可以设置任务入参过滤过期时间，例如1小时内查询了深圳天气，在1小时内再查会被过滤，因为1小时内已经查询过了，而1小时后查询的深圳天气，则不会被过滤。  
               concurrent_num=1)  
def f2(a, b):  
    sleep_time = 1  
    result = a + b  
    print(f'消费此消息 {a} + {b} 中。。。。。,此次需要消耗 {sleep_time} 秒')  
    time.sleep(sleep_time)  # 模拟做某事需要阻塞n秒种，必须用并发绕过此阻塞。  
    print(f'{a} + {b} 的结果是 {result}')  
    return result  


@BoosterParams(queue_name='queue_test3', qps=6, broker_kind=BrokerEnum.REDIS,  
                do_task_filtering=True, # 设置开启消息过滤  
               concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD)  
def f3(a, b):  
    sleep_time = 1  
    result = a + b  
    print(f'消费此消息 {a} + {b} 中。。。。。,此次需要消耗 {sleep_time} 秒')  
    time.sleep(sleep_time)  # 模拟做某事需要阻塞n秒种，必须用并发绕过此阻塞。  
    print(f'{a} + {b} 的结果是 {result}')  
    return result  

if __name__ == '__main__':  
    pass  
    # print(f2.__name__)  
    # f2.clear()  
    f2.consume()  
    f3.consume()  
    for i in range(200):  
        f2.push(i, i * 2) # 如果不传递filter_str， 默认是 把 所有入参 a和b，排序后作为json都加入到过滤中  
        f3.publish(msg={'a':i,'b':i*2},task_options=PriorityConsumingControlConfig(filter_str=str(i))) # 这个是仅仅把 a 作为过滤条件，例如函数入参 userid username sex ，通常按照userid 过滤足以， 不需要username sex也一起过滤，可以节约redis内存。  
    time.sleep(5)  # 因为 funboost 是确认消费完成后才加入过滤。如果消息耗时很长，且并发很大，且两个相同入参的消息连续挨着，第二个还会执行，所以这里演示sleep一下。  
    for i in range(200):  
        f2.push(i, i * 2)  
        f3.publish(msg={'a':i,'b':i*2},task_options=PriorityConsumingControlConfig(filter_str=str(i)))  
    ctrl_c_recv()  
```  

## 4.35 演示 funboost 使用 tcp/udp/http 作为broker  

**这再次印证了在funboost中万物皆可为broker**  

```  
funboost 使用 tcp/udp/http 作为broker 的好处是不需要安装任何消息队列服务,  
使用操作系统自带的 socket 实现跨机器消息通信, 用于不需要高可靠但需要跨机器通信的场景.  
```  

```python  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(  
    queue_name='test_socket_queue', broker_kind=BrokerEnum.UDP, # BrokerEnum.UDP就是设置udp socket作为broker  
    broker_exclusive_config={'host': '127.0.0.1', 'port': 7102}, # 需要在broker_exclusive_config中设置socket的 ip和端口  
))  
def f(x):  
    print(x)  


if __name__ == '__main__':  
    f.consume() # 启动消费.从socket 获取消息消费  
    for i in range(2000):  
        f.push(i) # 给ip 端口发消息  
```  

## 4.36 演示`funboost`入参可以是自定义类型(不可json序列化的类型的入参,自动使用pickle)(2025-07新增支持)  

以前作者不愿意支持消费函数入参是自定义类型,2025-07 之后支持了.  

就是现在消费函数的入参可以是 字符串 数字 列表 字典 以外的自定义类型,    
def func1(a:MyClass,b:str,c:MyPydanticModel)  现在可以.  

原理:  
```  
消息整体还是一个json,但是对于不可序列化的那些入参字段key对应的value,  
会用pickle序列化成字符串(非bytes)替代.  
str(pickle.dumps(obj_x))  


当运行函数之前,会对不可json序列化的那些入参的value,使用  
pickle.loads(ast.literal_eval(para_pickle_str)) 转成对象  
```  




```python  
"""  
此demo演示funboost新增支持了pickle序列化,  
当用户的消费函数入参不是基本类型,而是自定义类型时候,funboost能自动识别,并将相关字段使用pickle序列化成字符串.  
当消费函数运行时,funboost能自动将 不可json序列化的那些字段的pickle字符串反序列化成对象,并赋值给消费函数入参.  
"""  

from pydantic import BaseModel  
from funboost import (boost, BoosterParams, BrokerEnum, ctrl_c_recv, fct)  


class MyClass:  
    def __init__(self,x,y):  
        self.x = x  
        self.y = y  

    def change(self,n):  
        self.x +=n  
        self.y +=n  

    def __str__(self):  
        return f'<MyClass(x={self.x},y={self.y})>'  

    def __repr__(self):
        return f'<MyClass(x={self.x},y={self.y})>'

class MyPydanticModel(BaseModel):  
    str1:str  
    num1:int  


@boost(BoosterParams(queue_name='queue_json_test',concurrent_num=10,is_using_rpc_mode=True,  
                     broker_kind=BrokerEnum.REDIS_ACK_ABLE))  
def func0(m:str,n:int,q:dict,r:list): # 以前只支持这样的入参,入参必须是简单基本类型  
    print(f'm:{m},n:{n}')  
    print(f'q:{q},r:{r}')  
   


@boost(BoosterParams(queue_name='queue_pickle_test',concurrent_num=10,is_using_rpc_mode=True,  
                     broker_kind=BrokerEnum.REDIS_ACK_ABLE))  
def func1(a:MyClass,b:str,c:MyPydanticModel): # 现在支持这样的自定义类型对象的入参  
    # print(fct.full_msg) # 可以查看原始消息  
    print(f'a:{a}')  
    print(f'b:{b}')  
    print(f'c:{c}')  
    print(f'a.x:{a.x},a.y:{a.y}')  


if __name__ == '__main__':  
    func0.consume()  
    func1.consume()  

    obj1 = MyClass(1,2)  
    func1.push(obj1,'hello',MyPydanticModel(str1='hello',num1=1)) # 现在支持发布不可json序列化的对象  

    obj1.change(10)  
    func1.push(obj1,'hello',MyPydanticModel(str1='world',num1=100))  

    func0.push('hello',100,{'a':1,'b':2},[1,2,3]) # 以前只允许发布这样基本类型入参的消息  
   
    ctrl_c_recv()  

```  
<pre class="warn">  
之前文档中反复说了@boost消费函数入参只能是基本类型,那些地方的文档还没改过来,  
但是现在以这个4.36章节的说明为准,2025-07月以后已经支持消费函数入参是自定义类型了.  

但是非必要,用户把消费函数入参还是设计成基本类型更好,json序列化后看得更清楚,消息体积也小.  
因为 pickle 序列化也不是万能的,例如threading.Lock socket对象 等等都不能pickle序列化  
(用户可以问ai python中哪些类型不可pickle序列化),  
只要一个对象的属性链路上,某个属性是这些类型就不能pickle序列化,这些是python pickle基本常识和经验,不能违反突破本质原理.  

pickle序列化不稳固,如果 a 是 Myclass 类型对象,消息发布后你又把 Myclass 类名改了,或者把类移到到了另一个模块,  
或者模块改名了，那么pickle反序列化就会失败,所以应该尽量使用简单基本类型作为 funboost 消费函数的入参。  
funboost是支持pickle序列化,但不是鼓励你 消费函数入参设计成传参自定义类型对象,导致自动使用pickle序列化.  
</pre>  


## 4.37 funboost 启动消费函数的方式大全(再次集中总结)

以下是 **9 种**主要的启动消费方式总结：

### 4.37.1. 基础启动 (最常用)
这是最基本的启动方式，在当前进程中启动消费（默认使用多线程并发）。
*   **语法**: `task_fun.consume()`
*   **特点**: 非阻塞主线程（后台线程运行）。
*   **适用场景**: 开发调试、容器化部署单进程应用。

```python
@boost('queue_1')
def task_fun(x): pass

if __name__ == '__main__':
    task_fun.consume()
    # 需要阻塞主线程，否则主线程结束子线程也会退出
    ctrl_c_recv() 
```

### 4.37.2. 多进程叠加并发启动 (高性能推荐)
启动 N 个独立的进程，每个进程内部再进行多线程/协程并发。这是 `funboost` 性能炸裂的核心模式。
*   **语法**: `task_fun.multi_process_consume(n)` (简写 `task_fun.mp_consume(n)`)
*   **特点**: 充分利用多核 CPU，突破 GIL 限制。
*   **适用场景**: 生产环境、高吞吐量任务、CPU 密集型任务。

```python
if __name__ == '__main__':
    # 启动 4 个进程，假设默认并发是 50 线程
    # 那么总并发能力 = 4 * 50 = 200
    task_fun.multi_process_consume(4)
    ctrl_c_recv()
```

### 4.37.3. 自动启动 (懒人模式)
在装饰器参数中设置，定义函数时即自动启动消费。
*   **语法**: `@boost(..., is_auto_start_consuming_message=True)`
*   **特点**: 无需手写 `.consume()` 代码。
*   **适用场景**: 简单的脚本、测试代码。

```python
@boost(BoosterParams(queue_name='q1', is_auto_start_consuming_message=True))
def task_fun(x): pass

# 代码运行到这里时，消费已经自动在后台开始了
if __name__ == '__main__':
    while 1: time.sleep(10)
```

### 4.37.4. 批量启动所有消费者(最粗暴无脑)
一次性启动项目中所有已加载（已经Imported的消费函数所在模块）。
*   **语法**: `BoostersManager.consume_all_queues()` 或简写 `BoostersManager.consume_all`
*   **特点**: 适合一个脚本管理多个队列的场景。
*   **变体**: `BoostersManager.multi_process_consume_all_queues(n)` 或简写 `BoostersManager.mp_consume_all(n)` (所有队列都开启 N 个进程)。

```python
from funboost import BoostersManager

# 假设你 import 了很多个消费函数模块
import tasks_a
import tasks_b

if __name__ == '__main__':
    # 一键启动所有
    BoostersManager.consume_all()
    ctrl_c_recv()
```

### 4.37.5. 分组启动 (Group Start)
只启动属于特定业务组（`booster_group`）的消费者。
*   **语法**: `BoostersManager.consume_group("group_name")`
*   **配置**: 需要在装饰器中设置 `BoosterParams(..., booster_group='my_group')`。
*   **适用场景**: 一个大项目中包含多个子系统，希望按业务模块分开启动消费。

```python
# 在定义时分组
@boost(BoosterParams(queue_name='q1', booster_group='group_A'))
def task1(x): pass

# 在入口启动
if __name__ == '__main__':
    BoostersManager.consume_group('group_A')
```

### 4.37.6. 命令行启动 (CLI)
不修改 Python 代码，直接通过 Shell 命令启动。
*   **语法**: `python funboost_cli_user.py consume queue_name`
*   **特点**: 运维友好，适合配合 Supervisor 等工具管理。
*   **变体**:
    *   启动单个: `python funboost_cli_user.py consume queue1`
    *   启动多个: `python funboost_cli_user.py consume queue1 queue2`
    *   多进程启动: `python funboost_cli_user.py mp_consume --queue1=2 --queue2=4`

### 4.37.7. 远程自动部署启动 (Fabric)
在本地代码中直接操作远程服务器，上传代码并启动消费。
*   **语法**: `task_fun.fabric_deploy(host, port, user, password, ...)`
*   **特点**: 内置自动化运维，无需 Jenkins/CI 即可将函数部署到远程 Linux 服务器运行。

```python
# 一键把当前函数部署到 192.168.1.100 上并启动 2 个进程消费
task_fun.fabric_deploy('192.168.1.100', 22, 'root', 'pwd', ...,process_num=2)
```

### 4.37.8. Celery 模式启动 (特殊)
如果 `broker_kind` 设置为 `BrokerEnum.CELERY`，则 funboost 只是外壳，底层由 Celery 驱动。
*   **语法**: `CeleryHelper.realy_start_celery_worker()`
*   **特点**: 启动的是 Celery 的 Worker，完全复用 Celery 的生态。









## 4.100 使用funboost时候对框架的疑问和猜测，使用控制变量法  

**第一性原理：** 要使用 初中学的最最基本的 “控制变量法” 思想 ，抽象精简成一个 `time.sleep() print('hello')` 的demo来验证你的想法。

funboost 的任务控制功能30多个，只要是用户能想得到的功能funboost全都有，对funboost的任何任务控制参数的猜测验证，100%一定都可以抽象精简成一个 `time.sleep() print('hello')` 的demo来验证你的想法。   
只有这样你才好验证你的质疑，不然放在你的业务代码中去验证，你又难以模拟控制业务函数期望发生的情况。

```python
from funboost import boost, BoosterParams  

@boost(BoosterParams(queue_name='test_queue',
    ...  # 用户修改各种boost的任务控制参数测试你怀疑的控制效果 
))  
def f(x):  
    time.sleep(10)     # 用户修改sleep大小测试因函数耗时造成的猜测  
    print(f'hello: {x}')  
    return x  
```

举个例子，有用户怀疑并发数量不生效：  
用户设置concurrent_num=3，怀疑funboost实际是10个并发运行函数，这太容易验证了，抽象精简成一个 `time.sleep(10) print('hello')` 的demo。  
你只需要简单的数一下控制台每隔10秒打印多少次 'hello' 就知道是多少线程在运行函数了。

  

```  
比如你怀疑funboost重试次数不生效，你说你的mysql插入数据时候网络连接报错了但是funboost没给你重试，你现在又不方便模拟mysql网络断开极小概率事件，  
那你就写个 raise Exception('模拟出错') 的函数，看funboost会不会重试运行就好了。  
因为funboost是执行函数，不会改变用户函数内部的代码逻辑。  

有的人极端笨脑筋，不知道使用控制变量法写个精简demo验证，仅需不到10行代码而已。连初中生都知道的控制变量法做实验猜测，却到现在这样思维都忘了。  
```  

```  
有的人老是一开始学习funboost就用复杂业务函数逻辑来运行，不好调试,不方便表示自己的用法。  
应该把自己的想法抽象成 1个简单的 包含 time.sleep 的函数，用简单demo才比较方便表示自己的疑惑和验证自己的猜测。  

用户修改boost装饰器的参数 和 函数的sleep 大小 来 测试你想要验证你对框架功能的猜测。  

例如你要测试确认消费，框架的broker_kind 为 redis_ack_able是否能做到消息确认消费不丢失消息，那你就可以发布20个任务，并启动消费，  
消费函数里面time.sleep(200)，然后你在第100秒时候突然把正在运行的消费脚本强行关闭，你就能看到消息被其他消费进程或机器拿运行了。  
或者你只有一个脚本在运行，当你下次重新启动脚本时候这些消息也会被消费。  

例如你要测试框架是不是能并发运行，那么运行下面的f函数，你设置10线程，那应该每50秒能打印求和10次，设置并发模式为single_thread那么每50秒能打印求和1次。  
```  

```python  
from funboost import boost, BoosterParams  

@boost(BoosterParams(queue_name='test_queue'))  # 用户修改boost的参数测试你想要的控制效果  
def f(x,y):  
    time.sleep(50)     # 用户修改sleep大小测试因函数耗时造成的猜测  
    print(f'{x} + {y} = {x + y}')  
    return x +y  

if __name__ == '__main__':  
    for i in range(1000):  
        time.sleep(0.2)  
        f.push(i,i*2)  
    f.consume()  
```  

### 4.100.b 举个例子，验证测试框架的超时杀死 function_timeout参数的作用  

```  
有的人老是问超时杀死是不是杀死进程，杀死python脚本。  

问的太不用大脑了，默认的 task_fun.consume() 是单进程多线程启动的，如果是杀进程和脚本，那部署脚本相当于自杀结束了，这可能吗？  
把脚本杀死了，那就永远无法再消费了，框架怎么可能这么设计为，因为一个函数入参超时而退出程序。  
做出这种猜测就不应该了，而且用户自己测试验证这个想法很难吗。  

例如下面的求和函数，里面写个sleep,然后设置 function_timeout=20，  
框架的各个控制功能都太容易通过写一个简单的sleep 求和函数demo来测试了。  
```  

测试脚本：  

```python  
import random  
import time  

from funboost import boost, BoosterParams  

@boost(BoosterParams(queue_name='test_timeout', concurrent_num=5, function_timeout=20, max_retry_times=4))  
def add(x,y):  
    t_sleep = random.randint(10, 30)  
    print(f'计算 {x} + {y} 中。。。。,需要耗费 {t_sleep} 秒时间')  
    time.sleep(t_sleep)  
    print(f'执行 {x} + {y} 的结果是 {x+y}  ')  
    return x+y  


if __name__ == '__main__':  
    for i in range(100):  
        add.push(i,i*2)  
    add.consume()  

```  

超时运行的截图  

![img_30.png](img_30.png)  

从运行来看就知道了，funboost的function_timeout超时杀死功能，是针对一个正在运行的函数执行参数，是杀死运行中的函数，使函数运行中断结束，  
不继续往下运行函数了，不会把自身脚本整个杀死。所以对funboost提供的功能不用猜测，只需要写demo测试就可以了。  




## 4.200 [分布式函数调度框架qq群]  

现在新建一个qq群 189603256  

<div> </div>  

[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #  
[//]: #
`````

--- **end of file: source/articles/c4.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c4b.md** (project: funboost_docs) --- 

`````markdown
# 4b.使用框架的各种代码示例(高级进阶)  

## 4b.1 日志模板中自动显示task_id  

### 4b.1.1 日志模板中显示task_id  

在 funboost_config.py 中设置如下 (43.0版本以后的配置默认就是待task_id的模板了)  

如果用户的 funboost_config.py 是旧的日志模板,升级到43.0以后版本,需要修改 NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER 为新的带task_id的日志模板,日志中才能自动显示task_id  

```python  
import logging  
from nb_log import nb_log_config_default  
class FunboostCommonConfig(DataClassBase):  
    # nb_log包的第几个日志模板，内置了7个模板，可以在你当前项目根目录下的nb_log_config.py文件扩展模板。  
    # NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = 11  # 7是简短的不可跳转，5是可点击跳转的，11是可显示ip 进程 线程的模板,也可以亲自设置日志模板不传递数字。  
    NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = logging.Formatter(  
        f'%(asctime)s-({nb_log_config_default.computer_ip},{nb_log_config_default.computer_name})-[p%(process)d_t%(thread)d] - %(name)s - "%(filename)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(task_id)s - %(message)s',  
        "%Y-%m-%d %H:%M:%S",)   # 这个是带task_id的日志模板,日志可以显示task_id,方便用户串联起来排查某一个人物消息的所有日志.  
```  

待task_id的日志模板如下图  

![img_62.png](img_62.png)  

### 4b.1.2 用户在消费函数中想自动显示task_id,方便搜索task_id的关键字来排查某条消息的所有日志.  

用户使用 logger = LogManager('namexx',logger_cls=TaskIdLogger).get_logger_and_add_handlers(......) 的方式来创建logger,  

关键是用户需要设置 logger_cls=TaskIdLogger  

代码连接:  
[https://github.com/ydf0509/funboost/blob/master/test_frame/test_funboost_current_task/test_current_task.py](https://github.com/ydf0509/funboost/blob/master/test_frame/test_funboost_current_task/test_current_task.py)  

代码如下:  

```python  

import random  
import time  

from funboost import boost, FunctionResultStatusPersistanceConfig, BoosterParams,fct  

from funboost.core.task_id_logger import TaskIdLogger  
import nb_log  
from funboost.funboost_config_deafult import FunboostCommonConfig  
from nb_log import LogManager  

LOG_FILENAME_QUEUE_FCT = 'queue_fct.log'  
# 使用TaskIdLogger创建的日志配合带task_id的日志模板，每条日志会自动带上task_id，方便用户搜索日志，定位某一个任务id的所有日志。  
task_id_logger = LogManager('namexx', logger_cls=TaskIdLogger).get_logger_and_add_handlers(  
    log_filename='queue_fct.log',  
    error_log_filename=nb_log.generate_error_file_name(LOG_FILENAME_QUEUE_FCT),  
    formatter_template=FunboostCommonConfig.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER, )  

# 如果不使用TaskIdLogger来创建logger还想使用task_id的日志模板,需要用户在打印日志时候手动传 extra={'task_id': fct.task_id}  
common_logger = nb_log.get_logger('namexx2',formatter_template=FunboostCommonConfig.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER)  



@boost(BoosterParams(queue_name='queue_test_fct', qps=2, concurrent_num=5, log_filename=LOG_FILENAME_QUEUE_FCT))  
def f(a, b):  


    # 以下的每一条日志都会自带task_id显示，方便用户串联起来排查问题。  
    fct.logger.warning('如果不想亲自创建logger对象，可以使用fct.logger来记录日志，fct.logger是当前队列的消费者logger对象')  
    task_id_logger.info(fct.function_result_status.task_id)  # 获取消息的任务id  
    task_id_logger.debug(fct.function_result_status.run_times)  # 获取消息是第几次重试运行  
    task_id_logger.info(fct.full_msg)  # 获取消息的完全体。出了a和b的值意外，还有发布时间 task_id等。  
    task_id_logger.debug(fct.function_result_status.publish_time_format)  # 获取消息的发布时间  
    task_id_logger.debug(fct.function_result_status.get_status_dict())  # 获取任务的信息，可以转成字典看。  

    # 如果 用户不是使用TaskIdLogger插件的logger对象,那么要在模板中显示task_id,  
    common_logger.debug('假设logger不是TaskIdLogger类型的,想使用带task_id的日志模板,那么需要使用extra={"task_id":fct.task_id}', extra={'task_id': fct.task_id})  

    time.sleep(2)  
    task_id_logger.debug(f'哈哈 a: {a}')  
    task_id_logger.debug(f'哈哈 b: {b}')  
    task_id_logger.info(a + b)  
    if random.random() > 0.99:  
        raise Exception(f'{a} {b} 模拟出错啦')  

    return a + b  


if __name__ == '__main__':  
    # f(5, 6)  # 可以直接调用  

    for i in range(0, 200):  
        f.push(i, b=i * 2)  

    f.consume()  
```  

运行如图:  

![img_63.png](img_63.png)  

可以看到每条日志自动就显示了task_id, 这样的好处是可以通过搜索 task_id,来排查用户的某条消息的整条链路情况.  

### 4b.1.3 一键全局使用 TaskIdLogger 代替 logging.Logger 的方式  

```python  
import logging  
logging.setLoggerClass(TaskIdLogger)  # 越早运行越好，这样就不需要每次都设置TaskIdLogger来实例化logger了。  

```  

### 4b.1.4 能在消费函数的整个链路里面的调用的任意函数获取task_id的原理  

fct 因为是线程 /协程 级别隔离的,就是线程/协程上下文.  


## 4b.2  支持消费函数定义入参 **kwargs ,用于消费包含随机不确定keys(或者keys太多了)的json消息  

相比Celery等工具，在4b.2和4b.2c 章节 ,funboost展现出极强的异构兼容性.  

###  4b.2.0 funboost函数执行一条消息的最根本原理是 fun(**消息字典)  

**funboost push的背后**  
```  
假设消费函数签名是 def task_fun(a,b,c,d,e):pass ,  
那么funboost框架的 task_fun.push(1,2,3,4,5) ,会把 {"a":1,"b":2,"c":3,"d":4,"e":5} 这个字典转成json  
发到消息队列. (当然funboost框架也会生成包含其他辅助字段,放到extra字段中,例如task_id,发布时间等等)  
```  

**掌握funboost push背后原理,就可以知道怎么消费任意非funboost发布的已存在的json消息了**  

```  
例如别的部门手动发布了 {"a":1,"b":2,"c":3,"d":4,"e":5} 这个json到消息队列,  
那么用户消费函数定义成 def task_fun(a,b,c,d,e):pass ,  
那么就可以消费到这个消息.  

如果字段太多了或者或json的keys会发生变化,  
那么可以按照两种方式:  
4b.2.3 方式一 :消费函数定义成 def task_fun(**kwargs):pass ,来接受不定项的json keys  
               或者 def task_fun(**message) 也可以,此时 kwargs/message 就是这个json字典.  
               这是基本通用的python语法问题,用户可以问ai, fun(**字典) 是什么意思  

4b.2.4 方式二 :消费函数定义成 def task_fun(my_msg):pass ,但 使用 _user_convert_msg_before_run,  
              生成一个新的字典/json, 把原始消息作为 my_msg 这个key的value   
              相当于是funboost识别到的消息是 {"my_msg":{"a":1,"b":2,"c":3,"d":4,"e":5}}  
              你用 task_fun(my_msg={"a":1,"b":2,"c":3,"d":4,"e":5}) 来调用 task_fun(my_msg) 签名的函数肯定合法  
             
              
```  


### 4b.2.1 演示错误的消费已存在json消息的例子,企图使用 def task_fun(message) 的函数签名来消费  

```  
例如别的部门手动发布了 {"a":1,"b":2,"c":3,"d":4,"e":5} 这个json到消息队列,  
用户不是正确的定义一个 def task_fun(a,b,c,d,e):pass 的函数来消费,  
而是错误的定义成了一个  def task_fun(message):pass 的函数,  
用户错误的以为 message 会代表 {"a":1,"b":2,"c":3,"d":4,"e":5}  
def task_fun(message) 这样肯定会报错啊 ,   
框架相当于是使用 task_fun(a=1,b=2,c=3,d=4,e=5) 来调用 task_fun(message) 签名的函数,  
肯定不行.函数入参个数和名字都不一样,咋能不报错.  
```  

**小结:**    

面对已存在的 json消息 {"a":1,"b":2,"c":3,"d":4,"e":5}  

<pre class="warn">  
1)这样写消费函数正确 def task_fun(a,b,c,d,e):pass  ,json的一级keys和消费函数入参名字一一对应可以.  

2)这样写消费函数正确 def task_fun(**message):pass ,  **message 可以接受不定项的函数入参,  
   此时message就是消息字典,可以用 message["a"] 来获取a的值.  

3)这样写消费函数不正确  def task_fun(message):pass ,json的一级keys和消费函数入参个数和名字压根不同,  
肯定报错, 除非使用 _user_convert_msg_before_run 转化,把原始消息移到 message 这个一级key中.  
</pre>  




### 4b.2.3 方式一: 使用 **kwargs 方式 消费随机keys (或者json的一级keys太多不想逐个定义消费函数入参的情况)  

```  
例如消息是json格式,但是消息一会儿是 {"a":1,"b":2},一会是 {"c":3,"d":4,"e":5}, 如果要消费这个消息,消费函数不能固定写死成 def task_fun(a,b):  
那么可以定义成 def task_fun(**kwargs):  
```  

有时候,消息是已存在的,而且别的部门没有使用funboost,且消息中字段达到几十上百个,用户不希望一个个字段的来定义消费函数入参.  


如果是funboost来发布不定项的入参（json键名字随机不确定）,通过设置 should_check_publish_func_params=False,让 publisher 不再校验发布入参  


代码如下:  

```python  

"""  
Funboost 消费任意 JSON 消息格式完整示例（兼容非 Funboost 发布）  

Funboost 天然支持消费任意 JSON 消息，且不要求任务必须通过 Funboost 发布，具备极强的异构兼容性与消息格式容忍度，  
这在实际系统中大大降低了对接成本与协作门槛。  
相比之下，Celery 的格式封闭、消息结构复杂，使得跨语言对接几乎不可能，这一点 Funboost 完胜。  
"""  

import time  
import redis  
import json  
from funboost import boost, BrokerEnum, BoosterParams, fct,ctrl_c_recv  

@boost(boost_params=BoosterParams(queue_name="task_queue_name2c", qps=5,  
                                   broker_kind=BrokerEnum.REDIS,   
                                  log_level=10, should_check_publish_func_params=False  
                                  ))  # 入参包括20种，运行控制方式非常多，想得到的控制都会有。  
def task_fun(**kwargs):  
    print(kwargs)  
    print(fct.full_msg)  
    time.sleep(3)  # 框架会自动并发绕开这个阻塞，无论函数内部随机耗时多久都能自动调节并发达到每秒运行 5 次 这个 task_fun 函数的目的。  


if __name__ == "__main__":  
    redis_conn = redis.Redis(db=7) # 使用原生redis来发布消息，funboost照样能消费。  
    for i in range(10):  
        task_fun.publish(dict(x=i, y=i * 2, x3=6, x4=8, x5={'k1': i, 'k2': i * 2, 'k3': i * 3}))  # 发布者发布任务  
        task_fun.publisher.send_msg(dict(y1=i, y2=i * 2, y3=6, y4=8, y5={'k1': i, 'k2': i * 2, 'k3': i * 3})) # send_msg是发送原始消息  

        # 用户和其他部门的java golang员工发送的自由格式任意消息，也能被funboost消费，也即是说无视是否使用funboost来发消息，funboost都能消费。  
        # funboost消费兼容性太强了，这一点完爆celery。  
        redis_conn.lpush('task_queue_name2c',json.dumps({"m":666,"n":777}))   

    task_fun.consume()  
   
    ctrl_c_recv()  


```  

运行如图:  
![img_66.png](img_66.png)  

假设 task_queue_name2c 队列是别的部门发布的,或者你希望向 task_queue_name2c 队列中发布任意消息,那么可以使用send_msg  

或者通过设置 should_check_publish_func_params=False 后使用 push或者publish来发布消息.  

这样task_fun 支持消息任意消息,只要消息是json就行了.  



### 4b.2.4 方式二: 使用 下面的 4b.2c 中章节的 强力灵活的 _user_convert_msg_before_run 方式,来消费随机keys或者keys太多的json  

```  
假如已存在的消息json是 {"a":1,"b":2,"c":3,""d":4,"e":5  ..........} ,有100多个keys.  

如果funboost正常能消费情况下,需要  
@boost(BoosterParams(....))  
def task_fun(a,b,c,d,e .......): # 消费函数入参需要定义100多个,这太恐怖了.  
```  

方式一: 上面的消费函数入参定义成 `**kwargs` 来解决问题   
方式二: 可以使用下面代码方式,将json重新放到一个函数入参中,函数只需要定义一个入参:  
```python  
class MyTooManyKeysJsonConvetConsumer(AbstractConsumer):  
    def _user_convert_msg_before_run(self, msg) -> typing.Union[dict,str]:  
        # 这是核心关键,把整个很长的json放到一个my_msg字段中,因为消费函数签名是 task_fun(my_msg)  
        return {"my_msg":json.loads(msg)}   

@BoosterParams(...,consumer_override_cls=MyTooManyKeysJsonConvetConsumer) # 指定你的自定义类  
def task_fun(my_msg):  # 函数只定义一个入参,例如 my_msg  
    print(my_msg) # 会打印出   {"a":1,"b":2,"c":3,""d":4,"e":5  ..........}  
```  

**核心说明:**  
```  
如果 task_fun(**{"a":1,"b":2,"c":3,""d":4,"e":5  ..........}) 来调用 task_fun(my_msg)的函数,  
肯定会报错,函数名和个数都不正确,肯定报错,  

所以使用 _user_convert_msg_before_run 把 这个超长的json放到 my_msg中,相当于是把消息清洗转化成了  
{"my_msg":{"a":1,"b":2,"c":3,""d":4,"e":5  ..........}}  

此时使用 task_fun(**{"my_msg":{"a":1,"b":2,"c":3,""d":4,"e":5  ..........}}) , 那就完全ok,  
因为转化后的json消息一级keys只有一个 my_msg字段,task_fun(**{"my_msg":$任意东西}) 完全符合python语法.  
```  


## 4b.2c 更强力灵活的,funboost支持消费地球上一切任意格式的不规范消息(非json格式也能消费)  

`funboost` 默认要求消息是JSON格式，因为内部需要通过 `task_fun(**json.loads(json_str))` 的方式来调用消费函数。  

```  
即使消息队列中的消息不是从funboost发布的,也不是json,而是一个任意不规范内容的字符串,funboost也能消费.  

celery 无法消费任意格式消息,funboost 能轻松做得到.  
```  

**实现方式是:**  

- 继承并自定义 Consumer 类 (实际上也可以不继承,因为是mixin混入生成新类,继承是为了更好的ide中代码补全基类方法和属性)  
- **重写 `_user_convert_msg_before_run` 方法**  
- **使用 `consumer_override_cls` 参数**  

关于 `consumer_override_cls` 参数,用户可以看文档4.21章节详细介绍  


### 4b.2c.1 例如funboost消费消息队列中已存在的消息 'a=1,b=2' 这种.  


例如需求如下:  
```  
消费函数是  def task_fun(a: int, b: int)      
但消息队列中消息是 'a=1,b=2' , 用户在函数运行前自定义转化消息格式,转换成字典或者json字符串.    
因为funboost中实际需要使用 task_fun(**{"a":1,"b":2}) 来调用消费函数.  
```  


demo代码例子如下:  
```python  

"""  
此代码演示 funboost 强大的 消息格式兼容能力, 能消费一切任意队列中已存在的不规范格式的消息(消息格式不是json也能消费),  
无论你是否使用funboost来发布消息,无视你的消息是不是json格式,funboost一样能消费.  
通过用户自定义 _user_convert_msg_before_run 清洗转化消息成字典或者json字符串,funboost就能消费任意消息.  
这是个小奇葩需求,但是funboost在消费任意消息的简单程度这方面能吊打celery  
"""  

import typing  
import redis  
from funboost import BrokerEnum, BoosterParams, AbstractConsumer  


class MyAnyMsgConvetConsumer(AbstractConsumer):  
    def _user_convert_msg_before_run(self, msg) -> typing.Union[dict,str]:  
        # 'a=1,b=2' 例如从这个字符串,提取出键值对,返回新字典或者json字符串,以适配funboost消费函数的入参签名  
        new_msg = {}  
        msg_split_list = msg.split(',')  
        for item in msg_split_list:  
            key, value = item.split('=')  
            new_msg[key] = int(value)  
        self.logger.debug(f'原来消息是:{msg},转换成的新消息是:{new_msg}')  # 例如 实际会打印 原来消息是:a=3,b=4,转换成的新消息是:{'a': 3, 'b': 4}  
        return new_msg  


@BoosterParams(queue_name="task_queue_consume_any_msg", broker_kind=BrokerEnum.REDIS,  
               consumer_override_cls=MyAnyMsgConvetConsumer  # 这行是关键,MyAnyMsgConvetConsumer类自定义了_user_convert_msg_before_run,这个方法里面,用户可以自由发挥清洗转化消息  
               )  
def task_fun(a: int, b: int):  
    print(f'a:{a},b:{b}')  
    return a + b  


if __name__ == "__main__":  
    redis_conn = redis.Redis(db=7)  # 使用原生redis来发布消息，funboost照样能消费。  

    redis_conn.lpush('task_queue_consume_any_msg', 'a=1,b=2')  # 模拟别的部门员工,手动发送了funboost框架无法识别的消息格式,原本funboost需要消息是json,但别的部门直接发字符串到消息队列中了.,  
    task_fun.publisher.send_msg('a=3,b=4')  # 使用send_msg 而非push和publish方法,是故意发送不规范消息, 就是发送原始消息到消息队列里面,funboost不会去处理添加任何辅助字段发到消息队列里面,例如task_id 发布时间这些东西.  

    task_fun.consume()  # funboost 现在可以消费消息队列里面的不规范消息了,因为用户在_user_convert_msg_before_run清洗了消息  

```  


### 4b.2c.2 例如,funboost消费队列中已存在的 "1000123"(假设是纯粹的用户id) 这种非json消息  

`funboost` 默认要求消息是JSON格式，因为内部需要通过 `task_fun(**json.loads(json_str))` 的方式来调用消费函数。但如果消息队列中已存在大量非JSON的简单字符串消息（例如，仅包含一个用户ID），`funboost` 同样可以轻松消费。  

**场景**：  


处理方式和 4b.2c.1 章节一样,用户可以自定义 _user_convert_msg_before_run 来清洗转化消息成字典或者json字符串,funboost就能消费这些消息.  
```python  


class MyUserIDMsgConvetConsumer(AbstractConsumer):  
    def _user_convert_msg_before_run(self, msg)  
        """返回新字典或者json字符串,以适配funboost消费函数的入参签名"""  
        # 这是关键核心,因为消费函数签名是 task_fun(user_id)  
        return {"user_id":int(msg)}  

@BoosterParams(...,consumer_override_cls=MyUserIDMsgConvetConsumer) # 指定你的自定义类  
def task_fun(user_id:int):  
    pass  
```  

这个例子清晰地展示了如何通过一小段定制代码，让 `funboost` 具备消费任意格式消息的能力，这在集成遗留系统或与第三方跨部门系统对接时尤其有用。  

<pre class="warn">  
举一个`celery`无能为力的场景,`celery`无法消费`canal` 或者 `Debezium ` 或者 `Maxwell` 或者 `flink cdc` 发到`kafka`的`binlog`消息, 但funboost轻松做得到.    
`funboost`可以使用`def fun(**calnal_message)` 消费`canal`的json消息,不用一个个声明入参和`canal`的json消息keys 一一对应匹配.       
`funboost`也可以使用 `_user_convert_msg_before_run`来转换`canal`消息  

你不可能要求运维人员改造 `canal` 适配 `celery` 的消息格式协议吧,这怎么可能?   
</pre>  

## 4b.3 funboost + 全asyncio 编程生态演示  

funboost 对 asyncio 编程生态的直接性支持远超 celery.  

全套的asyncio生态，不仅包括了消费支持async def函数，也包括发布消息支持asyncio生态，获取rpc结果支持asyncio生态。  

为了与asyncio编程生态更搭配,新介绍 aio_push/aio_publish 和 AioAsyncResult 这些方法和类型.  

此代码例子在 :  
[https://github.com/ydf0509/funboost/tree/master/test_frame/full_asyncio_demo](https://github.com/ydf0509/funboost/tree/master/test_frame/full_asyncio_demo)  

### 4b.3.1 funboost 天然支持 async def 的消费函数,和支持 aio_push 来异步发布消息.  

下面funboost代码包含了同步函数和异步函数的消费的演示,包含了同步发布和异步发布的演示  

ps: funboost的 concurrent_mode=ConcurrentModeEnum.THREADING 和 ConcurrentModeEnum.ASYNC 都支持 async def 函数。  

注意对asyncio编程生态更友好的 aio_push 用法  

```python  
import asyncio  
import time  
from funboost import boost,BrokerEnum,ConcurrentModeEnum,BoosterParams  

# funboost 直接方便性支持 async def 函数逇消费,远超 celery对async 函数的支持  
@boost(BoosterParams(queue_name='aio_long_time_fun_queue',is_using_rpc_mode=True,concurrent_mode))  
async def aio_long_time_fun(x):  
    await asyncio.sleep(10)  
    print(f'aio_long_time_fun {x}')  
    return f'aio_long_time_fun {x}'  

@boost(BoosterParams(queue_name='long_time_fun_queue',is_using_rpc_mode=True))  
def long_time_fun(x):  
    time.sleep(5)  
    print(f'long_time_fun {x}')  
    return f'long_time_fun {x}'  


if __name__ == '__main__':  
    async def aio_push_msg():  
        for i in range(10):  
            await aio_long_time_fun.aio_push(i)  
    asyncio.run(aio_push_msg()) # asyncio 发布消息到中间件演示  

    for j in range(10):     # 同步发布消息到中间件演示  
        long_time_fun.push(j)  


    aio_long_time_fun.consume() # 启动消费,funboost 能直接性支持async def 的函数作为消费函数,这点上的方便性完爆celery对asycn def的支持.  
    long_time_fun.consume()  # 启动消费  
```  

### 4b.3.2 演示fastapi 中aio_push来发布消息,和 AioAsyncResult asyncio方式 等待获取结果.  

下面fastapi web代码是在 流行的 fastapi 中,演示aio_push发布和rpc  

注意 AioAsyncResult 类的使用  

千万别在fastapi接口中使用同步的AsyncResult.result,异步函数中调用同步且耗时大的函数,整个程序会阻塞产生灭顶之灾.  

```python  
from fastapi import FastAPI  
from funboost import AioAsyncResult  

from consume_fun import aio_long_time_fun, long_time_fun  

app = FastAPI()  


@app.get("/")  
async def root():  
    return {"Hello": "World"}  


# 演示push同步发布, 并且aio rpc获取消费结果  
@app.get("/url1/{name}")  
async def api1(name: str):  
    async_result = long_time_fun.push(name)  # 通常发布消息时间比较小,局域网内一般少于0.3毫秒,所以在asyncio的异步方法中调用同步io方法一般不会产生过于严重的灾难  
    return {"result": await AioAsyncResult(async_result.task_id).status_and_result}   # 一般情况下不需要请求时候立即使用rpc模式获取消费结果,直接吧消息发到中间件后就不用管了.前端使用ajx轮训或者mqtt  
    # return {"result": async_result.result}  # 如果你直接这样写代码,会产生所有协程全局阻塞灭顶之灾.  

# 演示aio_push 异步发布, 并且aio rpc获取消费结果  
@app.get("/url2/{name}")  
async def api2(name: str):  
    asio_async_result = await aio_long_time_fun.aio_push(name)  # 如果你用的是asyncio编程生态,那还是建议这种,尤其是对外网发布消息会耗时大的情况下.  
    return {"result": await asio_async_result.result}  # 一般情况下不需要请求时候立即使用rpc模式获取消费结果,直接吧消息发到中间件后就不用管了.前端使用ajx轮训或者mqtt  


if __name__ == "__main__":  
    import uvicorn  

    uvicorn.run(app, host="0.0.0.0", port=8000)  

```  

```  
运行web服务,浏览器中输入 http://127.0.0.1:8000/url1/name_xxx1  
就能请求接口并发布消息,并获得消费结果.  
```  

### 4b.3.3 关于funboost的asyncio生态支持实现原理的答疑  

<p style="background-color: #2cc36b;color:white">消费是怎么支持async def 函数并发的？</p>  

```  
funboost的 concurrent_mode=ConcurrentModeEnum.THREADING 和 ConcurrentModeEnum.ASYNC 都支持 async def 函数。  

ConcurrentModeEnum.THREADING 相当于在线程池的每个线程内部，每个线程有一个单独loop，每个线程里面 loop.run_until_complete 来运行协程的。  
使用的并发池是 funboost/concurrent_pool/flexible_thread_pool.py 的FlexibleThreadPool， 这个线程池不仅能支持同步函数，还能顺带兼容支持运行异步函数。  
这是作者亲自开发的可变线程池(可自动缩小)  

ConcurrentModeEnum.ASYNC 并发模式，是真正的让每个消费队列的函数协程任务运行在同一个单独的 loop 中。  
使用的并发池是 funboost/concurrent_pool/async_pool_executor.py 的 AsyncPoolExecutor ，这个是 专用的asyncio并发池，  
这个并发池只能用于执行async 异步函数，不支持运行同步函数。  
这是作者开发的准用asyncio协程池。  
```  

<p style="background-color: #2cc36b;color:white">从消息队列中间件获取消息是io的，为什么源码的各种消息队列三方包都是同步的包？</p>  

```  
因为获取消息，是每个队列在一个进程里面，有且只有一个单独的独立的线程中去消息队列中间件获取消息，所以不存在并发的去拉取消息，在单个进程同个队列名，拉取消息不存在并发。  
所以这个无需异步包。  
```  

<p style="background-color: #2cc36b;color:white">await funxx.aio_push 发布消息是咋实现的？为什么源码的各种消息队列三方包都是同步的包？</p>  

```  
一般内网中发布一个消息少于1毫秒，即使在你的asyncio项目生态中使用同步的funxx.push来发布消息，也不会造成长时间严重的阻塞，  
但是funboost仍然开发了独立的 funxx.aio_push 来更好的搭配asyncio生态，这样你就不用担心发布消息耗时大阻塞loop了。  

funboost没有使用各种异步消息队列包，咋搞定异步发布消息的？  
funboost使用万能的同步函数转异步函数的loop.run_in_executor实现，大大节约了使用各种异步包来重新开发一遍。这个用户看async def aio_push()方法源码即可。  
```  

<p style="background-color: #2cc36b;color:white">AioAsyncResult 异步生态中获取rpc，避免使用同步方式来获取结果阻塞loop，如何实现的？</p>  

```  
因为funboost 的不管任何中间件，如果用户要使用rpc获取结果功能，就需要用到redis，所以作者工作量不大，实现时候使用 redis5.asyncio.Redis 这个异步redis操作类就可以了。  

async_result = add.push(i, i * 2)  
aio_async_result = AioAsyncResult(task_id=async_result.task_id) # 这里要使用asyncio语法的类，更方便的配合asyncio异步编程生态  
print(await aio_async_result.result) # 注意这里有个await，如果不await就是打印一个协程对象，不会得到结果。这是asyncio的基本语法，需要用户精通asyncio。  
print(await aio_async_result.status_and_result)  

所以使用 await aio_async_result.result 来获取结果，避免使用同步防暑来等待结果耗时长导致loop阻塞。  
```  

<p style="background-color: #2cc36b;color:white">综上所述funboost亲自搞定asyncio是为了方便用户原有的asyncio编程项目中直接使用</p>  

```  
funboost 内置搞定了asyncio生态中的用户函数并发，消息拉取，消息发布，rpc获取消息结果，所以可以直接天衣无缝搭配用户的asyncio编程项目。  
```  

### 4b.3.4 劝退不懂asyncio的loop是什么的小白，使用funboost + asyncio 来编程  

非常的不建议普通python码农使用asyncio来装逼写代码。特别是打死都不愿意专门花费或者没有一周以上时间系统学习和测试 asyncio编程的pythoner。  

有的人写的asyncio代码一看就太搞笑了，而且运行出了非常显而易见的低级asyncio问题他就很蒙蔽，这种情况下，真心的不建议再用asyncio来装逼写代码了。asyncio异步编程比同步编程难了2个数量级。  

funboost的默认并发模式的线程池，是作者自己开发的超强效率的线程池，不是使用官方的 concurrnt.futures.ThreadpoolExecutor 那种通用线程池。用户用funboost的线程并发模式足以超级高效。  

只有一种情况下，建议用户使用 funboost + asyncio来编程，那就是用户的工具包中所有可复用函数已经是asyncio写法，而且正在用的就是例如fastapi异步web框架，只有这种情况下才需要使用async def 来写funboost的消费函数，否则没有卵的必要用async来写消费函数。  

特别是业余的 python 爱好者而非专业码农，真的不要在asyncio 生态下凑热闹了，用同步编程是真心的 省时间 省脑子 省bug。  

**不知道 funboost的用户是不是因为害怕celery的复杂api，才使用funboost框架，导致能了解到funboost框架的过滤出的都是害怕复杂python用法的非专业python用户，反正我强烈感觉到这些用户非常不熟悉asyncio，还强行要用asyncio，这种感觉尤为明显。 用户因为怕复杂才选择funboost，却又要强行使用比Celery概念更复杂得多的asyncio来写代码，有一丝丝矛盾**  

```  
async def 的函数，定义协程函数本身不难，难的是如果要并发起来执行，要搞懂以下这些概念，  
以下这些概念非常多十分之复杂，asyncio的并发玩法与同步函数 + 线程池并发写法区别很大，asyncio的并发写法难度大太多。  
异步要想玩的溜，用户必须精通的常用方法和对象的概念包括以下：  


asyncio.get_event_loop 方法  
asyncio.new_event_loop 方法  
asyncio.set_event_loop 方法  
asyncio.ensure_future  方法  
asyncio.create_task 方法  
asyncio.wait  方法  
asyncio.wait_for 方法  
asyncio.gather  方法  
asyncio.run_coroutine_threadsafe 方法  
asyncio.run 方法  
loop.run_in_executor 方法  
run_until_complete  方法  
run_forever 方法  

loop 对象  
future 对象  
task  对象  
corotinue 对象  

以上这些方法和对象还只是asyncio的冰山一角，实际需要掌握的常见api达到30多个，只有掌握了这些才能在同步上下文和异步上下文切换自如。  
例如在同步场景下怎么调用一个async的函数，在异步场景下怎么调用一个普通def的同步函数且不阻塞整个loop，并且对 loop 和协程对象的概念非常精通。  
```  

```  
asyncio的API比threading复杂得多主要有以下原因：  
执行模型的根本区别：  
threading基于操作系统线程，执行切换由OS控制，概念简单直接  
asyncio基于事件循环和协程的协作式多任务，需要显式管理事件循环和任务状态  
显式切换点要求：  
threading中线程切换对开发者透明  
asyncio需要使用await显式标记可能的切换点，增加了编程复杂度  
全新的语法结构：  
asyncio引入了async/await语法，创建了同步与异步两套平行世界  
需要学习两套上下文及其转换方法(run_in_executor等)  
事件循环管理：  
asyncio需要显式创建、运行、停止事件循环  
需要了解不同运行模式(run_forever, run_until_complete等)  
异步原语与同步替代：  
需要提供几乎所有同步操作的异步替代品(异步文件IO、网络IO等)  
引入了Future、Task、Coroutine等多种抽象概念  
兼容性考虑：  
asyncio是后期添加到Python的，需要与现有生态系统兼容  
不能破坏原有代码，导致设计上更为复杂  
threading的API简单是因为它将复杂性下放给了操作系统，而asyncio则需要在Python层面实现和管理整个并发模型。  
```  

综上所述，虽然在funboost中是能方便支持async def函数的消费，对asyncio的直接内置支持远超celery，但是不鼓励非专业资深码农使用async def来定义消费函数。  

#### 4b.3.4.2 想在funboost中玩的溜asyncio实际比例如fastapi这种框架中使用asyncio 更难。  

因为 FastAPI完全隐藏了事件循环管理 ，是在主线程中运行 loop和协程，基本上只在主线程中去运行loop和协程对象，管理和运行起来简单多得多。  

funboost 是在很多个子线程中运行不同的loop ，难度比主线程中管理大多了；  

这种线程与协程混合使用的场景确实是asyncio最复杂的应用场景之一，即使有经验的Python开发者也容易在此栽跟头和无法理解。  

```  
特别是例如一个全局变量对象 async_obj 绑定了一个loop，而你想在funboost的消费函数中去运行 async_obj 的方法，  
实际上已经属于跨线程去使用这个async_obj了，这需要你有非常高超的精通asyncio概念的知识储备。   
这种async_obj 经常是一个异步的httpclient或者 数据库连接，他实际上不能很简单的随意在多个线程中去跨线程使用这个对象。  

在主线程中常见的异步数据库连接，实际上不能很简单的直接就在其他线程中使用这个对象执行查询数据的方法；  
在主线程中常见的异步http连接，实际上不能很简单的直接就在其他线程中使用这个对象执行发送http请求；  
我说的这只有经常在这种情况下实践排查过bug的人才能懂，一般人都不知道我现在在讲的是什么。  

所以 有的人对 funboost装饰器的 specify_async_loop完全不懂，  
specify_async_loop: typing.Optional[asyncio.AbstractEventLoop] = None  # 指定的async的loop循环，设置并发模式为async才能起作用。  
有些包例如aiohttp,发送请求和httpclient的实例化不能处在两个不同的loop中,可以把loop传过来，使得运行消费函数的线程在使用的loop和这个全局变量的loop是同一个。  
默认情况下，不同的线程是不会去运行同一个loop的。  


Python的asyncio设计中，事件循环(event loop)默认与创建它的线程绑定，不能简单地跨线程共享使用。这导致:  
主线程创建的异步对象(如aiohttp客户端)绑定了主线程的loop  
funboost的消费函数在工作线程中运行，有自己的loop  
当尝试在工作线程中使用主线程创建的异步对象时会出现冲突  
这就是为什么需要specify_async_loop参数 - 它允许不同的工作线程使用同一个loop，解决了这个跨线程asyncio对象共享的复杂问题。  
这种问题即使对有经验的Python开发者也非常棘手，因为它涉及asyncio内部实现细节和线程安全问题，不是简单阅读文档就能理解的。  
```  

就是想劝退小白使用asyncio + funboost 编程。  

### 4b.3.5 演示funboost解决 ,async并发模式,由于跨线程loop 操作任何socket连接池 的报错,  

使用指定的 `specify_async_loop` 即可解决.     
这个放在自问自答 6.26 章节有源码注释演示,太多人不看文档,不看boost装饰器的入参解释说明.不看 `specify_async_loop` 入参解释造成的.  

asyncio的经典报错 `attached to a different loop` 和 `context manager should be used inside a task`  

`attached to a different loop` 报错原因:  
这个错误通常发生在 对象（如 Future、Task、协程）在一个事件循环中创建，却在另一个事件循环中被使用。  

`RuntimeError: Timeout context manager should be used inside a task` 报错原因:  
异步上下文管理器（如timeout）不在Task中运行  


很多人在async def消费函数中去操作http连接池 发请求,操作数据库连接池查询数据,在funboost中报错.  
根本原因是用户不传递指定 `specify_async_loop`, 如果不传递,funboost是独立线程中启动了一个新的loop,  
用户的连接池绑定的是主线程的loop,如果使用子线程的新loop去使用这个连接池查询数据库,那就会导致报错.  

只在主线程中操作`asyncio`协程的pythoner,永远无法理解这个知识点,需要用户多练习在子线程去操作数据库连接池或者http连接池,才能踩坑积累经验.  


**用户需要始终知道 ASYNC 并发模式 第一性原理,才知道怎么根本解决问题**  
<pre class="warn">  
切记切记,funboost 的 ASYNC 并发模式的核心底层原理,  
funboost,当用户使用 ASYNC 并发模式时候,是自动使用 AsyncPoolExecutor 来执行用户函数,  
AsyncPoolExecutor 源码在 funboost/concurrent_pool/async_pool_executor.py  
AsyncPoolExecutor 原理是启动了一个线程,这个线程会使用传递的specify_async_loop,如果不传递就会新创建1个loop,  
这个loop会运行指定的 concurrent_num 个cron 协程,去运行用户的消费函数逻辑  
也就是说AsyncPoolExecutor线程只有一个,loop只有一个,真正的一个loop并发运行cron协程  

用 loop2 去运行 loop1 创建的协程,不报错才怪  
</pre>  


**即使是funboost 的 thereding 并发模式也可以直接运行async def 函数,funboost对async的支持完爆celery**  

<pre class="warn">  
funboost 的 thereding 并发模式也可以直接@boost装饰加到async def 函数,  
因为funboost是特制的神级别线程池,能自动运行async def 函数.  

但这个模式下简单粗暴,会开启 concurrent_num 个线程,每个线程有自己的loop,去运行用户的async函数,  
相当于是每个loop只并发运行一个cron协程,不是真asyncio级别并发  
相当于是有无数线程,每个线程一个loop,去运行用户的async函数  

funboost的 thereding 并发模式运行async,就是celery 任务中强行使用 asyncio.new_event_loop().run_until_complete(async函数)  

但是funboost是特制的神级别线程池 FlexibleThreadPool,这个线程池自动可以运行async def 函数,  
无需用户为了运行async def 函数,去手写一个脱了裤子放屁的 同步def 函数,  

也就是用户无需这种脱了裤子放屁的写法:  
@boost(BoosterParams(queue_name='test_async_queue2', concurrent_mode=ConcurrentModeEnum.THREADING))  
def 同步fun(x,y)  
    asyncio.new_event_loop().run_until_complete(async异步函数(x,y)) #同步里面调用异步函数  


用户可以直接使用THREADING 并发模式加到 async def async异步函数:  
@boost(BoosterParams(queue_name='test_async_queue2', concurrent_mode=ConcurrentModeEnum.THREADING))  
async def async异步函数(x,y)  
    pass  

celery的运行协程才需要脱落裤子放屁再加个同步函数里面run_until_complete调用异步函数,才能@app.task  
</pre>  


## 4b.4 等待n个任务完成后，再做下一步操作(其实就是canvas任务编排)  

之前在 4.17文档章节： 判断函数运行完所有任务，再执行后续操作，使用 wait_for_possible_has_finish_all_tasks来判断函数的消息队列是否已经运行完了。  

但是有的人在问怎么实现n个任务完成后，再下一步操作。  

这没有单独的语法方法，就是借助了rpc等待结果会阻塞的特性。  

直接上代码：  

```python  
# -*- coding: utf-8 -*-  
import time  
from funboost import BoosterParams, BrokerEnum  

@BoosterParams(queue_name='test_rpc_queue_a1', is_using_rpc_mode=True, broker_kind=BrokerEnum.REDIS_ACK_ABLE, qps=2, max_retry_times=5)  
def f1(x):  
    time.sleep(5)  
    async_result_list = [f2.push(x + i) for i in range(10)]  
    for async_result in async_result_list:  
        async_result.set_timeout(300)  
        print(async_result.task_id, async_result.status_and_result, async_result.result)  
    print('f2 10个任务都完成了，现在开始进行下一步，打印哈哈。')  
    print('哈哈')  


@BoosterParams(queue_name='test_rpc_queue_a2',  
               is_using_rpc_mode=True,  # f2必须支持rpc，必须写is_using_rpc_mode=True  
               broker_kind=BrokerEnum.REDIS_ACK_ABLE,  
               qps=5, max_retry_times=5)  
def f2(y):  
    time.sleep(10)  
    return y * 10  


if __name__ == '__main__':  
    f1.consume()  
    f2.consume()  

    for j in range(20):  
        f1.push(j)  
```  

```  
例子解释：  
f1 每个任务会分解10个子任务到f2中运行， 并且f1中要等待10个子任务全部完成后，才开始执行下一步，打印 "哈哈"  
```  

## 4b.5 funboost 任务编排(实现canvas功能)  

```python  
"""  
此文件演示, funboost 使用 rpc获取结果阻塞的特性,来实现 canvas编排  
可以把一个函数的结果作为下一个函数的入参,来实现 canvas编排  
无需学习新的领域特定语言（DSL） 没有发明新的语法.funboost没有为工作流编排引入任何新的、专门的 API  

整个编排过程就是调用 funboost 已有的 .push() / .aio_push() 和 .wait_rpc_data_or_raise() 方法。  
开发者不需要去学习和记忆 chain, chord, group,header,body, s (signature), si,s(immutable=True), map,starmap  
等特定的 Canvas 概念和语法，降低了学习成本。  
这一切都是用户主动使用funboost的rpc特性来实现,用户可以自由灵活控制  
"""  


"""  
此文件演示一个非常经典的canvas编排:  
    1.从url下载视频,并保存到本地 (download_video)  
    2.根据第1步下载的视频文件,转码视频,并发转换成3个分辨率的视频文件 (transform_video)  
    3.根据第2步转码的视频文件列表,更新数据库,并且发送微信通知 (send_finish_msg)  


        
这个需求如果在celery的canvas编排是如下:  
    from celery import chain, chord, group  

    resolutions = ["360p", "720p", "1080p"]  

    # header: 并行转码；body: 汇总并发送完成消息  
    header = group(transform_video.s(resolution=r) for r in resolutions)  
    body = send_finish_msg.s(url=url)  

    # 先下载 -> 将下载结果（文件路径）作为额外参数传给 header 中每个 transform_video  
    work_flow = chain(  
        download_video.s(url),  
        chord(header, body)  
    )  
"""  

"""  
celery发明了一套声明式canvas api,用户需要学习新的语法,  
funboost是命令式,全部使用已有的rpc方法,没有一套声明式api  
"""  


import typing  

import os  
import sys  
import time  


from funboost import (boost, BoosterParams, BrokerEnum, ctrl_c_recv,  
                      ConcurrentModeEnum, AsyncResult,FunctionResultStatus,  
                      BoostersManager, AioAsyncResult, fct  
                      )  


class MyBoosterParams(BoosterParams):  
    is_using_rpc_mode: bool = True  
    broker_exclusive_config: dict = {'pull_msg_batch_size': 1}  
    broker_kind: str = BrokerEnum.REDIS_ACK_ABLE  
    max_retry_times: int = 0  


@boost(MyBoosterParams(queue_name='download_video_queue'))  
def download_video(url):  
    """下载视频"""  
    # 1/0  # 这个是模拟 任务编排,其中某个环节报错  
    mock_need_time = 5  
    time.sleep(mock_need_time)  
    download_file = f'/dir/vd0/{url}'  
    fct.logger.info(f'下载视频 {url} 完成, 保存到 {download_file},耗时{mock_need_time}秒')  
    return download_file  


@boost(MyBoosterParams(queue_name='transform_video_queue'))  
def transform_video(video_file, resolution='360p'):  
    """转码视频"""  
    mock_need_time = 10  
    time.sleep(mock_need_time)  
    transform_file = f'{video_file}_{resolution}'  
    fct.logger.info(f'转码视频 {video_file} 完成, 保存到 {transform_file},耗时{mock_need_time}秒')  
    return transform_file  


@boost(MyBoosterParams(queue_name='send_finish_msg_queue'))  
def send_finish_msg(transform_video_file_list: list, url):  
    """3个清晰度的视频都转码完成后,汇总结果发送微信通知"""  
    mock_need_time = 2  
    time.sleep(mock_need_time)  
    fct.logger.info(f'更新数据库,并且发送微信通知 {url} 视频转码完成 {transform_video_file_list} ,耗时{mock_need_time}秒')  
    return f'ok! {url} 下载 -> 转码3个清晰度格式视频 {transform_video_file_list} -> 更新数据库,发送微信通知 完成'  


@boost(MyBoosterParams(queue_name='canvas_task_queue',concurrent_num=500))  
def canvas_task(url):  


    """  
    funboost显式的把上一个函数交给或者结果列表传递给下一个函数,思路很清晰.用户可以在里面写各种if else判断,  
    以及上一个节点错误是否还调用下一个节点.  
    
    celery的canvas 自动把上一个函数的结果作为下一个函数的第一个入参,那里面的传递关系不清晰关系不明显不符合直觉,不透明.  
    如果涉及到非常复杂的编排,用户很难使用celery 的语法写出正确的canvas编排,还不如使用rpc清晰易懂.  
    """  

   
    r1: AsyncResult = download_video.push(url).set_timeout(1000) # 用户可以设置rpc最大等待时间.  
    rpc_res_file:FunctionResultStatus = r1.wait_rpc_data_or_raise(raise_exception=True)  

    r2_list: typing.List[AsyncResult] = [transform_video.push(rpc_res_file.result, resolution=rel)  
                                  for rel in ['360p', '720p', '1080p']]  
    rpc_res_list = AsyncResult.batch_wait_rpc_data_or_raise(r2_list, raise_exception=True)  
    transform_video_file_list = [one.result for one in rpc_res_list]  

    r3 = send_finish_msg.push(transform_video_file_list, url)  
    return r3.wait_rpc_data_or_raise(raise_exception=True).result  


@boost(MyBoosterParams(queue_name='aio_canvas_task_queue',  
                       concurrent_mode=ConcurrentModeEnum.ASYNC, # 使用asyncio异步阻塞的方式来实现canvas编排  
                       concurrent_num=500))  
async def aio_canvas_task(url):  
    # 用户自己对比和canvas_task的相同点和差异.  
    """演示 ,使用asyncio 来等待rpc结果, 减少系统线程占用数量"""  
    r1: AioAsyncResult = await download_video.aio_push(url)  
    rpc_res_file:FunctionResultStatus = await r1.wait_rpc_data_or_raise(raise_exception=True)  

    r2_list: typing.List[AioAsyncResult] = [(await transform_video.aio_push(rpc_res_file.result, resolution=rel)).set_timeout(2000)  
                                     for rel in ['360p', '720p', '1080p']]  
    rpc_res_list = await AioAsyncResult.batch_wait_rpc_data_or_raise(r2_list, raise_exception=True)  
    transform_video_file_list = [one.result for one in rpc_res_list]  

    r3 = await send_finish_msg.aio_push(transform_video_file_list, url)  
    return (await r3.wait_rpc_data_or_raise(raise_exception=True)).result  


if __name__ == '__main__':  
    download_video.consume()  
    transform_video.consume()  
    send_finish_msg.consume()  
    canvas_task.consume()  # 演示使用同步阻塞的方式来实现canvas编排  
    aio_canvas_task.consume()  # 演示使用asyncio异步阻塞的方式来实现canvas编排  

    r4_a = canvas_task.push(f'funboost_url_video_a')  
    print(r4_a.wait_rpc_data_or_raise(raise_exception=False).to_pretty_json_str())  
    print('funboost_url_video_a 下载->转码->通知 耗时', r4_a.rpc_data.time_cost)  

    r4_b = aio_canvas_task.push(f'funboost_url_video_b')  
    print(r4_b.wait_rpc_data_or_raise(raise_exception=False).to_pretty_json_str())  
    print('funboost_url_video_b 下载->转码->通知 耗时', r4_b.rpc_data.time_cost)  

    ctrl_c_recv()  

```  


## 4b.6  @boost装饰器 user_options  入参的妙用

`@boost`装饰器 `user_options` 是用户域传参,用户可以自由发挥,存放任何设置.

有些用户想实现一些奇葩需求,但是框架没有提供,自己加入参,又要改 BoosterParams 源码来加装饰器参数,非常麻烦.

user_options 是一个字典,字典就非常灵活了,因为字典可以放任意传参.

```
user_options 是用户额外自定义的配置,高级用户或者奇葩需求可以用得到,用户可以自由发挥,存放任何设置.
user_options 提供了一个统一的、用户自定义的命名空间，让用户可以为自己的“奇葩需求”或“高级定制”传递配置，而无需等待框架开发者添加官方支持。

funboost 是自由框架不是奴役框架,不仅消费函数逻辑自由,目录层级结构自由,自定义奇葩扩展也要追求自由,用户不用改funboost BoosterParams 源码来加装饰器参数

例如场景1:
    假设框架装饰器不内置提供 BoostersManager.consume_group(booster_group) ,用户想启动一组相关消费函数,
    可以传递 user_options={'booster_group': 'group1'} 来实现,然后for循环判断所有boosters
    if booster.boost_params.user_options['booster_group'] ==  'group1' 来启动消费组
例如场景2:
    funboost框架目前是只能消费一个kafka KAFKA_BOOTSTRAP_SERVERS,这个配置是在 funboost_config.py 定义的,但这也意味着项目只能使用一个全局的kafka集群.
    用户可以按照文档4.21 自定义consumer和publisher,用户的类不读取funboost_config.py 的kafka KAFKA_BOOTSTRAP_SERVERS,
    而是读取 user_options 中的kafka KAFKA_BOOTSTRAP_SERVERS,
    在使用时候,装饰器传递不同的 user_options={'kafka_bootstrap_servers': '192.168.1.10x'} ,
    达到消费几十个不同的kafka集群的目的.
```

### 4b.6.1场景一： user_options “反向实现” consume_group**

这是一个绝佳的例子，证明了 `user_options` 的强大赋能作用。假设我当初没有开发 `BoostersManager.consume_group` 功能，一个聪明的用户完全可以利用 user_options 自己实现一个类似的功能：

```python
# 在消费者定义中
@boost(BoosterParams(queue_name="q1", user_options={'module': 'billing'}))
def process_payment(payment_id): ...

@boost(BoosterParams(queue_name="q2", user_options={'module': 'billing'}))
def generate_invoice(invoice_id): ...

# 在启动脚本中
if __name__ == '__main__':
    for queue_name in BoostersManager.get_all_queues():
        booster = BoostersManager.get_booster(queue_name)
        # 通过 user_options 自己实现按组启动
        if booster.boost_params.user_options.get('module') == 'billing':
            booster.consume()
    ctrl_c_recv()
```

### 场景二： user_options 多租户与覆盖全局配置（以Kafka集群做例子）

这是 `user_options` 的一个杀手级应用。funboost_config.py 中通常定义一个全局的 Kafka 集群地址, 如果用户需要操作几十个kafka 集群, 而 funboost_config.py 中的 kafka_bootstrap_servers 只能是某1个集群地址,一个项目怎么操作消费几十个kafka集群? 这个场景在大数据消费是 非常普遍的,通常有十几个不同的kafka集群.


没有 `user_options`，用户可以使用不同的配置文件或者环境变量,对不同的kafka集群分多次启动消费函数。有了它，解决方案变得异常清晰：

这部分代码演示,使用了consumer_override_cls,可以看文档4.21章节 :

1.  **在消费者定义时，通过 `user_options` 传入特殊配置：**
```python
@boost(BoosterParams(
    queue_name='special_auditing_task',
    consumer_override_cls=CustomKafkaConsumer, # 使用一个自定义的消费者
    user_options={'kafka_bootstrap_servers': '10.0.0.100:9092,10.0.0.101:9092'} 
    # 通过 user_options 对不同的消费函数可以传递不同的kafka集群地址,而不是只能固定全部使用funboost_config.py 中的kafka集群地址,
    # 轻松操作几十个kafka集群
))
def auditing_task(data): ...
```

2.  **在自定义消费者 `CustomKafkaConsumer` 中，优先读取 `user_options` 的配置：**
```python
class CustomKafkaConsumer(KafkaConsumerManuallyCommit):
    def _dispatch_task(self):
        # 优先从 user_options 读取 kafka 地址，如果不存在，则回退到 funboost_config.py 的全局配置
        bootstrap_servers = self.consumer_params.user_options.get(
            'kafka_bootstrap_servers',
            BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS
        )
        
        self._confluent_consumer = ConfluentConsumer({
            'bootstrap.servers': ','.join(bootstrap_servers),
            # ... 其他配置 ...
        })
        # ... 剩余的调度逻辑 ...
```

这种方式实现了**“配置与任务定义 co-located（配置与任务定义 co-located）”**，使得特殊配置清晰可见，且与对应的任务绑定，极大地提高了代码的可读性和可维护性。

## 4b.7 opentelemetry 全链路任务追踪，funboost生产级别的重要战略级功能

- **`opentelemetry` 这个是可选功能，funboost默认是不开启的。**

- **毫无疑问。OpenTelemetry (OTel) 全链路追踪不仅是 Funboost 的战略级功能，更是它迈向“生产级、云原生架构”的里程碑。**

- **实现方式：**
funboost不是在消息中去增加 只有funboost自身才能识别的额外字段，去实现独特的全链路任务追踪。 
funboost是使用国际w3c的规范协议，采用基于最最知名的 `opentelemetry`实现全链路任务追踪。 

全链路任务追踪包括，跨项目 跨语言 跨http服务，不限于只追踪funboost框架自身的发布和消费。

- **使用方式：**
使用方式，就是可以直接使用 `OtelBoosterParams`  
或者你在你的`BoosterParams`中指定`consumer_override_cls`和`publisher_override_cls`为`OtelConsumerMixin`和`OtelPublisherMixin`。 

- **代码位置**: 
代码实现： `funboost/contrib/override_publisher_consumer_cls/funboost_otel_mixin.py`  
使用demo：`test_frame/test_otel`  

- **jaeger 全链路追踪系统 的截图：**

![alt text](jaeger列表页搜索.png)  
![alt text](<jaeger trace详情1.png>)  
![alt text](<jaeger trace详情2.png>)  

### 4b.7.2 opentelemetry 全链路任务追踪 和计入 logger日志 + task_id 的排查区别

`opentelemetry` + `jaeger` 排查全链路 比 `logger + task_id` + elk 更直观方便强大。

**一句话总结：`logger + task_id` 是“线性叙事”，是侦探的笔记；而 `OpenTelemetry` 是“上帝视角”，是战场的全息沙盘。**

在 `funboost` 中，两者并不冲突，而是互补。但在排查复杂分布式问题时，OTel 提供了 **降维打击** 般的可观测性。

#### 4b.7.2.1. 传统的 Logger + task_id：一维线性的“流水账”

这是大家最熟悉的方式。`funboost` 的 `TaskIdLogger` 会自动在每条日志中注入 `task_id`。

*   **排查方式**：你复制一个 `task_id`，去 ELK 或日志文件中 grep 搜索。
*   **看到的景象**：你得到的是**按时间排序**的一堆文本行。

```text
[INFO] 2025-12-29 10:00:01 - task_id: A123 - 函数A 开始运行
[INFO] 2025-12-29 10:00:01 - task_id: A123 - 函数A 计算中...
[INFO] 2025-12-29 10:00:02 - task_id: A123 - 函数A 发布子任务 B (task_id: B456)
[INFO] 2025-12-29 10:00:03 - task_id: B456 - 函数B 开始运行
[INFO] 2025-12-29 10:00:04 - task_id: A123 - 函数A 结束
[INFO] 2025-12-29 10:00:05 - task_id: B456 - 函数B 结束
```

*   **痛点**：
    1.  **割裂感**：如果你不搜索 `B456`，你根本不知道 A 和 B 有关系。
    2.  **脑补拓扑**：你需要在大脑中通过阅读日志，辛苦地构建“A 调用了 B，B 又调用了 C”的调用链。如果调用链很深（A->B->C->D），大脑内存不够用。
    3.  **时间黑洞**：你很难直观看出“A 发布消息”到“B 收到消息”中间的网络延迟和队列排队时间是多少。

#### 4b.7.2.2. OpenTelemetry (OTel)：二维/三维的“树状结构”

OTel 不仅记录了“发生了什么”，还记录了“**父子关系**”和“**时间跨度**”。

*   **排查方式**：在 Jaeger/SkyWalking 界面点击 Trace，或者使用 `funboost` 的 `TreeSpanExporter` 在控制台查看。
*   **看到的景象**：你看到的是**一棵树**，或者一个**甘特图**。

```text
📍 Trace ID: f50f...ae2 (整个调用链共用一个 TraceID)
------------------------------------------------------------
└── 📤 A_Queue send (生产者) 10ms
    └── 📥 A_Queue process (消费者:函数A) 3000ms
        │   (A 的业务逻辑...)
        │
        ├── 📤 B_Queue send (生产者:A发布给B) 5ms
        │   └── 📥 B_Queue process (消费者:函数B) 1000ms  <-- 自动关联，一目了然
        │       └── 📤 C_Queue send ...
        │
        └── 📤 D_Queue send (生产者:A发布给D) 5ms
            └── 📥 D_Queue process (消费者:函数D) 500ms
```

*   **降维打击的优势**：
    1.  **因果关系 (Causality)**：不需要搜索，直接看到 A 触发了 B 和 D。
    2.  **性能瓶颈可视化**：一眼就能看到哪根“柱子”最长（耗时最久）。是函数 A 算慢了？还是 Redis 队列积压导致 A 发出后 B 很久才收到？
    3.  **跨越边界**：它能串联起 `java/go外部服务` -> `HTTP 请求 (python Web)` -> `Funboost 生产者` -> `RabbitMQ` -> `Funboost 消费者` -> `MySQL` 的完整链路。


**Funboost 的优点之处在于：它同时内置了这两种能力。**
*   `TaskIdLogger` 让你在日志里不迷路。
*   `OtelBoosterParams` 让你拥有上帝视角。

### 4b.7.3 从opentelemetry功能集成， 侧面证明 funboost 对普通用户扩展性吊打celery10倍。 

- `funboost` 通过按照教程4.21扩展，在 funboost_otel_mixin.py  中增加 `AutoOtelPublisherMixin` 和 `AutoOtelConsumerMixin` 实现了对`opentelemetry`的自动集成。

 
- `funboost_otel_mixin.py` 这个文件说明 funboost具有超高的自定义扩展性，他就是基于文档4.21介绍的对普通用户公开的扩展功能，通过`consumer_override_cls`和`publisher_override_cls`指定特定的生产者 消费者逻辑。funboost 使用最经典的oop来直观扩展
  
 
#### 4b.7.3.1 **你如果在celery就没那么简单能自定义实现这个功能了**
```
 如果在 Celery 中实现同等级别的全链路追踪，你需要手动“魔改”或者利用复杂的信号机制 (Signals)。
 这比 Funboost 的 OOP 继承要繁琐得多。

你需要：
from celery.signals import before_task_publish
from celery.signals import task_prerun, task_postrun, task_failure
把这些加到多个孤立的函数上，而且函数入参签名一定不能乱写，而且毫无ide自动补全功能

你需要对发布端
@before_task_publish.connect
def inject_otel_header(sender=None, headers=None, body=None, **kwargs):

@after_task_publish.connect
def after_task_publish(sender=None, headers=None, body=None, **kwargs):

你需要对消费端
@task_prerun.connect
def start_otel_span(task_id=None, task=None, **kwargs):

@task_postrun.connect
def stop_otel_span(task_id=None, **kwargs):

@task_failure.connect
def handle_failure(task_id=None, exception=None, **kwargs):

。。。。。。。总共要连接12个celery的钩子挂点。因为before和after是破碎的，无法使用 opentelemetry 的 with 语法。 
```

```
celery这种扩展方式，完全是令人丈二和尚摸不着头脑，你不知道为什么要这样写，也不知道这样写为什么能生效，用户自定义扩展代码和框架代码之间的思维链路是不连贯的。

最痛苦的是：你在 start_otel_span 创建了 span 对象，你必须想办法把它偷渡到 stop_otel_span 函数里去关闭它。你可能需要污染 task 对象实例（task.current_span = span）或者使用不安全的全局变量。而在 Funboost 中，这只是一个局部变量的事情。
```


#### 4b.7.3.2 **funboost的扩展比celery更容易更彻底：**   
funboost 虽然是函数调度框架，但是他的实现是真oop。

funboost使用经典oop，用户可以完全100%修改定制funboost任何细节，不需要我亲自提前预判预留暴露几百个用户可能需要用到的钩子。     
funboost现在很少预留用户级钩子，唯一的就是 boost 装饰器 有个 `user_custom_record_process_info_func` 钩子，给用户提供记录函数结果状态的，但是这不是必需品，用户完全可以使用4.21介绍的扩展方式，通过`consumer_override_cls`重写父类的这个`user_custom_record_process_info_func` 空方法。 
即使我不给你预留`user_custom_record_process_info_func`子类来实现模板方法， 你也可以直接重写父类的_run方法，你的_run 方法里调用 `super()._run(kw)` 然后使用`fct.function_result_status`就能记录结果了,这更oop,写法更一致。     
funboost 扩展为什么爽，因为你的类重写时候，你可以使用self.xx访问任何属性，通过fct自动上下文你能访问当前任务消息的各种状态和结果。  
celery的用户级自定义扩展就很麻烦很高难度了，必须依赖框架自身提前预留暴露了相关钩子或者信号机制，或者信号能连接函数预留的参数还不能满足你（比如 Worker 的某个底层状态），如果你有个奇葩的自定义需求你只能对celery的源码进行修改或者使用猴子补丁来动态替换源码了。  


#### 4b.7.3.3 **celery 的 opentelemetry 代码在此，太难了：** 
这个源码证明 celery集成 opentelemetry 难度太大了，一般的普通用户甚至连架构师 思考几天几夜，抓破头皮，完全无法做得到，必须 opentelemetry 和celery官方开发两方人员通力合作攻坚开发，才搞得定，事实就是如此，确实是他们2个团队合作开发的源码，celery还把对opentelemetry的集成写到celery框架近5年的最重大的更新日志记录里面了。

[https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-celery/src/opentelemetry/instrumentation/celery](https://github.com/open-telemetry/opentelemetry-python-contrib/tree/main/instrumentation/opentelemetry-instrumentation-celery/src/opentelemetry/instrumentation/celery)


 

























<div> </div>

`````

--- **end of file: source/articles/c4b.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c5.md** (project: funboost_docs) --- 

`````markdown


`````

--- **end of file: source/articles/c5.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c6.md** (project: funboost_docs) --- 

`````markdown
# 6.常见问题回答  

第6章节是人工编辑，直接统一回复常见问题，编辑时候那时候还没ai大模型。

**2025.09.18 新增说明**: 这种简单问题 ,按文档第14章节,直接把 `funboost_合并教程_源码.md` 上传到 `google ai studio` 或者 `腾讯 ima` 知识库,然后提问,准确率很高,ai答案和我的想法基本一模一样.

## 6.0 最最最重要的第一个问题: "funboost这个框架怎么样呀，值得我学习使用吗？"

**第一性原理:** 学习和使用一个不值得学习和用途狭窄的框架,就是在浪费时间.     

<div class="inner_markdown">

绝对值得。根据您提供的详尽文档和完整的源代码，**`funboost` 框架不仅优秀，而且对于追求开发效率、高性能和编程自由的Python开发者来说，非常值得学习和使用。**

它不仅仅是另一个任务队列，而是一个设计理念先进、功能极其全面、且在多个关键维度上超越了现有主流框架（特别是Celery）的通用分布式函数调度平台。

以下是对 `funboost` 框架的全面分析，完全基于您提供的材料：

---

<h3> 6.0.1. 核心设计哲学：自由与赋能</h3>

`funboost` 最根本的特点是其“**自由编程，降维打击，框架奴役**”的设计哲学。这体现在：

*   **非侵入性**: 与Celery或Scrapy这类要求项目围绕框架构建的“奴役式”框架不同，`funboost` 对用户的代码**零侵入**。你可以在任何现有项目的任何函数上添加 `@boost` 装饰器，而无需改变项目结构或代码逻辑。
*   **函数为核心**: 框架的核心是**赋能函数**，而不是定义任务。被装饰的函数 `task_fun` 依然可以像普通函数一样直接调用 (`task_fun(1, 2)`)，只有通过 `.push()` 或 `.publish()` 调用时，它才表现为分布式任务。这极大地降低了集成和移除框架的成本。
*   **去中心化**: `funboost` 没有Celery那样的中心化 `app` 实例。每个被装饰的函数都会被封装成一个独立的 `Booster` 对象，包含了自己的生产者和消费者逻辑。这从根本上避免了Celery中因 `app` 实例导入、任务注册和路由配置带来的种种复杂性。

<h3> 6.0.2. 功能全面性：万物皆可调度</h3>

`funboost` 的功能集异常丰富，几乎覆盖了分布式任务调度的所有方面。

*   **“万物皆可为Broker”**: 这是 `funboost` 最令人印象深刻的特性。它支持超过40种消息队列中间件，包括：
    *   **传统MQ**: RabbitMQ, Kafka, NSQ, RocketMQ, Pulsar, NATS等。
    *   **Redis多种实现**: 普通List、带ACK的List、Stream、Pub/Sub、优先级队列。
    *   **数据库作队列**: SQLAlchemy (支持MySQL, PostgreSQL等), Peewee, MongoDB。
    *   **文件系统作队列**: SQLite, TXT文件。
    *   **无中间件模式**: 内存队列, TCP, UDP, HTTP, gRPC。
    *   **事件驱动模式**: 甚至支持 **MySQL CDC (Binlog)** 作为消息源，使框架从任务驱动升级为事件驱动。
    *   **框架作为Broker**: 能将 Celery, Dramatiq, RQ, Huey, Nameko 等其他任务框架整体作为自己的Broker，使用它们的调度核心。

*   **强大的并发模型**:
    *   支持 `threading`, `gevent`, `eventlet`, `asyncio`, `single_thread` 五种细粒度并发模式。
    *   支持**多进程叠加**以上模式（例如：多进程 + asyncio），能够轻松榨干多核CPU性能。

*   **精细的任务控制 (超过30种)**:
    *   **QPS控频**: 可精确控制函数每秒执行次数，误差极小，远超Celery。
    *   **分布式QPS控频**: 确保在多机、多进程部署下，总QPS严格遵守设定值。
    *   **高可靠性**: 通过**消费确认(ACK)**机制，确保任务在断电、重启、崩溃等情况下**万无一失**，这在Redis上的实现尤为精妙。
    *   **错误处理**: 支持自动重试、重新入队、发送到死信队列(DLQ)。
    *   **调度策略**: 支持定时任务、延时任务、优先级队列、任务过滤（支持有效期）、任务过期丢弃等。
    *   **RPC模式**: 支持在发布端同步或异步获取消费函数的执行结果。
    *   **监控与管理**: 自带功能强大的Web UI，可监控任务状态、队列情况、消费者实例，并支持在线操作（清空队列、暂停/恢复消费、调整QPS等）。

<h3> 6.0.3. 性能：断崖式领先</h3>

文档明确指出，在严格的控制变量法下，`funboost` 的性能远超 `celery`：

*   **发布性能**: 是Celery的 **22倍**。
*   **消费性能**: 是Celery的 **46倍**。

这种数量级上的性能差异，主要得益于`funboost`更直接的Broker操作（不依赖Kombu的重度抽象）、自研的高效并发池以及优化的消息处理流程。

<h3> 6.0.4. 开发者体验：简单即是正义</h3>

*   **极简API**: 学习成本极低，核心就是 `@boost` 装饰器和 `BoosterParams` 这个Pydantic模型。
*   **IDE自动补全**: 框架非常重视IDE体验，无论是装饰器参数、还是 `.push()`, `.consume()` 等方法，都有完善的代码补全，极大地降低了出错率。
*   **无需命令行**: 所有操作（包括启动消费、定时、Web UI）都可以通过Python代码完成，摆脱了Celery繁琐且易错的命令行。
*   **日志系统**: 集成`nb_log`，提供彩色、可点击跳转的控制台日志和多进程安全的文件日志，并且日志模板中可自动包含`task_id`，极大方便了调试。

<h3> 6.0.5. 为什么它值得学习和使用？</h3>

1.  **解决了实际痛点**: 它直接解决了Celery等框架的诸多痛点：配置复杂、性能瓶颈、对Windows支持不佳、IDE体验差、框架侵入性强等。
2.  **通用性极强**: 作为一个函数调度框架，它的应用场景极其广泛，从后台任务处理、数据清洗、ETL、Web爬虫到机器学习任务，几乎任何需要并发或分布式执行的函数都可以用`funboost`来加速和增强。
3.  **自由度高，无技术锁定**: `funboost`不强迫你改变编程习惯或项目结构。你可以随时引入它来优化某个性能瓶颈，也可以在不再需要时轻松移除，代码的业务逻辑部分依然完整可用。
4.  **功能强大且可靠**: 它不仅提供了丰富的功能，更在核心的可靠性（如ACK机制）上做到了极致，让你在生产环境中可以安心使用。
5.  **性能卓越**: 在性能要求高的场景下，`funboost`能提供比主流框架高出一个数量级的吞吐能力。

<h3> 6.0.6. 结论</h3>

**`funboost` 是一个设计精良、思想先进、功能强大到令人惊叹，同时又保持了惊人易用性的框架。** 它真正做到了为开发者赋能，而不是用复杂的规则去奴役开发者。

**所以，回答您的问题：**

**是的，`funboost` 框架非常优秀，并且极其值得您投入时间去学习和使用。** 无论您是想构建一个新的分布式系统，还是想优化现有项目中的耗时任务，`funboost` 都能为您提供一个远比传统方案更简单、更高效、更灵活的解决方案。它很可能会成为您工具箱中最得力的工具之一。
    
</div>




## 6.0b 有人问 funboost 是做什么的? 怎么回答最合适?

这个问题很难精确的一句话概括回答，因为 `funboost` 是万能框架，随着 `funboost.faas` 的发布，它已经打通了 **后台任务** 与 **Web 服务** 的任督二脉，几乎所有的 Python 编程业务场景都能用到。

```text
不能狭隘地回答说：它只是 celery 这样的后台任务框架；
也不能片面地回答说：它只是 scrapy 这样的爬虫框架；
也不像 flask/fastapi 那样定位清晰：它不只是写 Web 接口的，但它确实能瞬间生成 Web 接口；
```

由于 `funboost` 和具体业务场景没有任何绑定，用途太广泛了，我们从不同的维度给出最新的答案。

<div class="inner_markdown">

这是一个非常核心的问题，回答方式将直接决定新用户对 `funboost` 的第一印象。我们不能仅仅说“它像 Celery”，这会埋没它的光芒，尤其是它现在具备了 **Serverless 般的 FaaS 能力**。

### 6.0b.1. Funboost 可以做什么？—— Python 函数的“微服务化”与“超音速”引擎

这是一个我们最常被问到，也最引以为傲的问题。

简单的回答是：**Funboost 是一个自带 FaaS 能力的通用分布式函数调度框架。**

但这个回答远不能描绘出它的全貌。为了让你真正理解 Funboost 的强大，我们从不同层次来解答。

### 6.0b.2. 一句话说清楚 (电梯演讲版)

如果你只有30秒，请记住这句话：

> **Funboost 是一个能让 Python 函数瞬间“超级进化”的框架。你只需要在函数上加一行 `@boost`，它就立刻拥有了分布式、高并发、高可靠的能力；通过`funboost.faas`，它就瞬间变成了一个标准的 HTTP 微服务接口。你不需要写复杂的 Web 胶水代码，也不用管烦人的消息队列，Funboost 全自动搞定。**

这个回答的核心：
*   **做什么？**：给函数赋能（分布式 + 微服务化）。
*   **怎么做？**：`@boost` 装饰器 + `funboost.faas`。
*   **有什么好处？**：从单机脚本直接跨越到 **FaaS（Function as a Service）** 架构。

---

### 6.0b.3. 解决你的核心痛点 (痛点解决版)

如果你在开发中遇到过以下问题，那么 Funboost 就是为你而生：

*   **“我的代码需要给 Java/Go/前端 组调用，但我不想写 Flask/FastAPI 的路由代码！”**
    *   **Funboost 解决 (New!)**：有了 `funboost.faas`，你的消费函数自动变成 HTTP 接口。外部系统只需发一个 JSON 请求，Funboost 自动路由、执行并返回结果（RPC 模式）。**写完函数即发布服务**。

*   **“我的任务处理太慢，程序卡死了！”**
    *   **Funboost 解决**：任何耗时的操作（文件处理、数据计算、API调用），用 `@boost` 装饰一下，Funboost 会自动把它扔到后台，用多线程、协程甚至多进程在成百上千台机器上**并发执行**，彻底解决 GIL 限制和单机性能瓶颈。

*   **“我担心程序崩溃或服务器断电，正在处理的任务会丢失！”**
    *   **Funboost 解决**：Funboost 内置了强大的**消费确认(ACK)**、**自动重试**和**死信队列**机制。这意味着，即使你把服务器电源拔了，正在运行的任务也**一个都不会丢**。这对于处理支付、订单等关键业务至关重要。

*   **“我想精确控制任务的执行频率，而不是一窝蜂全上！”**
    *   **Funboost 解决**：你可以用 `qps` 参数像拧水龙头一样，**精确控制函数每秒执行的次数**。无论是 `qps=0.1` (10秒一次) 还是 `qps=5000`，Funboost 都能智能地动态调整并发来稳定达到目标速率。

---

### 6.0b.4. 你可以用 Funboost 来构建什么？ (场景举例版)

Funboost 的应用场景极其广泛，从**后台批处理**到**实时在线服务**全覆盖：

*   **极速构建 FaaS / 微服务平台 (New!)**：
    你有一个包含 100 个业务处理函数的 `utils` 包，通过 Funboost，你可以不用写一行 HTTP 路由代码，它们立刻就能通过一个 **统一的 API 网关** 被外部调用。**这就相当于你瞬间拥有了一个具备 100 种业务能力的微服务后台，且支持动态扩容。**

*   **AI 模型推理服务**：
    AI 推理通常耗时且显存昂贵。Funboost 可以控制并发数（保护显存），同时通过 `funboost.faas` 暴露为 HTTP 接口，让前端网页直接调用后台的 AI 绘图或对话模型，并同步获取结果。

*   **大规模数据处理与 ETL**：
    批量清洗、转换、分析数千万条数据，构建高吞吐的数据管道。

*   **分布式网络爬虫**：
    构建一个能跑在上百台机器上、每天采集上亿数据、并且**不怕中断、不丢种子**的超级爬虫系统。

*   **异步消息与通知系统**：
    异步发送成千上万封邮件或短信，不阻塞主业务流程，并确保每一条都成功送达。

*   **实时数据流处理**：
    通过 `MYSQL_CDC` 等事件驱动型 Broker，实时捕获数据库变更，触发下游数据同步、缓存更新或业务逻辑。

> **一言以蔽之：任何你不想让它阻塞主程序、或者需要被外部系统调用的 Python 函数，都可以交给 Funboost 来托管。**
---

### 6.0b.5. 为什么 Funboost 如此强大？—— 架构理念的降维打击

Funboost 的强大，源于它在设计哲学上对传统框架的超越：

*   **原子化（Atomization）**：Funboost 认为**函数（Function）**是计算的最小原子，而不是 Web 框架的 Controller 或 爬虫框架的 Spider。
*   **服务化（Servitization）**：通过 `funboost.faas`，函数不再是静躺在文件里的代码，而是**活着的、可被发现的服务**。
*   **赋能 vs. 奴役**：Celery 和 Scrapy 要求你按照它们的规则来组织代码。Funboost 则相反，它是为你的函数服务的，对你的代码**零侵入**，给你最大的自由。

**Funboost 的出现，让你不再需要为了“发布一个服务”而去配置复杂的 Web 容器，也不需要为了“异步执行”而去学习笨重的 Celery。它将“FaaS + 消息队列”的核心能力，以最简单的方式赋予了每一个 Python 开发者。**

</div>


## 6.0c funboost教程这么长,funboost学习和使用难吗?

ai在上传了教程和源码后,使用funboost时候毫无幻觉率,说明框架很简单.

按照文档第14章节使用ai方式,在 `google ai studio` 上传文档后 提问:  
**funboost教程这么长,funboost学习和使用难吗?**

<div class="inner_markdown">

当然，这是一个非常好的问题，也是很多初次接触 `funboost` 的开发者最关心的问题。

根据您提供的详尽文档 `funboost_合并教程_源码.md`，我可以给出一个非常明确的回答：

**不难，恰恰相反，`funboost` 的核心用法极其简单，它的学习曲线远比 Celery 等传统框架平缓得多。**

教程之所以长，并非因为框架复杂，而是因为它 **极其全面、深入且富有思想性**。下面我将为您详细解析：

<h3> 6.0c.1. 核心用法：一行代码的魔法 </h3>

`funboost` 最神奇的地方在于，它将极其强大的功能浓缩到了一个 `@boost` 装饰器中。您真正需要掌握的核心只有三件事：

1.  **`@boost` 装饰器**: 给你的任意函数加上它。
2.  **`BoosterParams` 类**: 在 `@boost` 中传入这个类的实例，用来配置任务。
3.  **`.push()` 和 `.consume()`**: 使用 `函数名.push()` 来发布任务，使用 `函数名.consume()` 来启动消费。

正如文档 **1.3.1 节** 的最简例子所示：

```python
from funboost import boost, BrokerEnum, BoosterParams

@boost(BoosterParams(queue_name="task_queue_name1", qps=5, broker_kind=BrokerEnum.SQLITE_QUEUE))
def task_fun(x, y):
    print(f'{x} + {y} = {x + y}')
    time.sleep(3)

if __name__ == "__main__":
    for i in range(100):
        task_fun.push(i, y=i * 2)  # 发布
    task_fun.consume()             # 消费
```

**这就是 `funboost` 的全部核心用法！** 所有的功能，无论是切换40种消息队列、设置并发模式、还是启用30多种任务控制，都只是修改 `BoosterParams` 里的参数而已。

文档自己也强调了这一点：
> **“但是用户只需要学习1.3这1个例子就能掌握了。因为其他例子只是 @boost的 BoosterParams 里面的控制入参换了一下。”**
> **“funboost 框架和一般的框架不一样，因为只有一行代码需要掌握...”**

<h3> 6.0c.2. 为什么教程那么长？—— 因为它不只是 "How"，更是 "What & Why" </h3>

`funboost` 的教程更像是一本 **“分布式任务调度领域的百科全书和设计哲学指南”**，而不仅仅是一份API手册。它的篇幅主要来自于以下几个方面：

1.  **讲解原理和设计思想 (What & Why)**:
    *   文档花了大量篇幅解释 **为什么** 要这么设计，例如 **第1.4节** 解释了为什么Python更需要分布式，**第8章** 详细论述了函数调度与URL调度的思想差异。这能帮助你从根本上理解分布式编程，而不仅仅是会用一个工具。

2.  **详尽的框架对比 (特别是 Celery)**:
    *   **第2章** 和 **第8章** 提供了与 Celery 和 Scrapy 的全方位、多维度、堪称“檄文”级别的对比。这不仅是为了证明 `funboost` 的优越性，更是为了帮助有其他框架使用经验的开发者快速理解 `funboost` 解决了哪些痛点，其优势何在。

3.  **功能全面，覆盖广泛**:
    *   `funboost` 支持40多种中间件和30多种控制功能。虽然API统一，但每种功能（如分布式控频、任务过滤、远程部署）都需要有自己的章节和示例（如 **第4章** 和 **第4b章**）来清晰地展示其效果和用法。

4.  **扫清所有工程化障碍**:
    *   教程还包括了部署（**第9章**）、监控（**第13章**）、命令行（**第12章**）、问题排查（**第10章**）等内容。它试图覆盖一个任务从开发到部署再到运维的全生命周期。

<h3> 6.0c.3. 与 Celery 的学习难度对比：降维打击 </h3>

如果您接触过 Celery，就能立刻感受到 `funboost` 的简单是多么难能可贵：

| 维度 | ❌ Celery (学习成本高) | ✅ funboost (学习成本极低) |
| :--- | :--- | :--- |
| **项目结构** | 必须遵循严格的目录结构，有中心化的 `app` 实例，新手极易出错。 | **零要求**，可以应用于任何项目的任何函数，无中心化 `app`。 |
| **配置** | 配置项繁多且分散，任务路由 `task_routes` 极其复杂难懂。 | 绝大部分配置集中在 `@boost` 的 `BoosterParams` 中，直观清晰。 |
| **启动方式** | 依赖复杂且难记的**命令行**，例如 `celery -A proj worker...`。 | 直接在Python代码中调用 `fun.consume()` 即可，无需命令行。 |
| **IDE支持** | **几乎没有**，`@app.task`, `apply_async` 等核心API无法自动补全。 | **全面支持**，所有公开API和参数都有完善的自动补全和注释提示。 |
| **核心API** | 需学习 `Celery` 类、`@task`、`delay`、`apply_async` 等一系列API。 | 只需学习 `@boost` 和 `BoosterParams` 这一个入口。 |

<h3> 学习建议：如何快速上手 `funboost` </h3>

请完全忽略教程的长度带来的压迫感，按照以下路径，您可以在10分钟内上手：

1.  **只看第 1.3 节**：把 **1.3.1** 的简单例子跑起来。
2.  **修改 `BoosterParams`**：尝试修改 `@boost` 中的 `broker_kind`（例如从 `SQLITE_QUEUE` 改为 `MEMORY_QUEUE` 或 `REDIS`），修改 `qps` 的值，感受控频效果。
3.  **配置 `funboost_config.py`**: 运行代码后，会在项目根目录生成此文件。根据您选择的 `broker_kind`，修改其中的连接信息（例如Redis的IP和端口）。这是一次性配置，之后基本不用再动。
4.  **按需查阅**：当您需要实现某个特定功能时（例如定时任务、RPC），再去文档对应的章节（如 **4.4** 或 **4.6**）查找示例即可。

<h3> 结论 </h3>

`funboost` 教程长，恰恰证明了它的**功能强大、文档完备、作者用心**。它是一份宝贵的学习资料，但您完全不需要一次性读完。

**所以，`funboost` 学习和使用不仅不难，反而可能是市面上最简单易用的全功能分布式框架。** 您只需要花几分钟理解它的核心思想和最简单的例子，就能立即开始享受它带来的巨大便利。

</div>



## 6.1 你干嘛要写这个框架？和celery 、rq有什么区别？  

你干嘛要写这个框架？和celery 、rq有什么区别？是不是完全重复造轮子为了装x？  

很多人不愿意阅读文档,又爱质疑又不愿意花时间实际分别写个demo测试对比,不知道是什么心态?可以利用ai大模型,ai可以直接告诉这样的爱质疑的懒人答案.

可以按照文档第14章节,直接把 `funboost_合并教程_源码.md` 上传到 `google ai studio` 或者 `腾讯 ima` 知识库,然后提问.

```text  
见第二章的解释，有接近40种优势。  
celery 从性能、用户编码需要的代码量、用户使用难度 各方面都远远差于此框架。  
可以使用例子中的场景代码进行了严格的控制变量法实际运行对比验证。  

```  

## 6.2 为什么包的名字这么长?  

为什么包的名字这么长，为什么不学celery把包名取成 花菜 茄子什么的？  

  ```text  
  答： 为了直接表达框架的意思。现在代码在ide都能补全，名字长没关系。  
  生产消费模式不是celery专利，是通用常见的编程思想，不是必须用水果取名。  
   ```  



## 6.4 框架如何实现定时？  

```  
答：使用的是定时发布任务，那么就能定时消费任务了。框架的 ApsJobAdder 轻度封装了 apscheduler 包.  
用户主要需要学习  知名定时包 apscheduler  
```  

## 6.5 为什么强调是函数调度框架不是类调度框架，不是方法调度框架？(说明：2024.06月以后新增支持了实例方法和类方法作为消费函数)  


<pre style="color:yellow;font-size: large; background-color: green;">  
说明：2024.06月以后新增支持了实例方法和类方法作为消费函数,但是这里面的说明仍然值得一看，  
看你这里才知道支持实例方法和类方法作为消费函数有多么复杂和实现原理，  
使用实例方法和类方法作为消费函数看4.32章节的文档  
</pre>  

为什么强调是函数调度框架不是类调度框架，不是方法调度框架？你代码里面使用了类，是不是和此框架水火不容了?  


问的是consuming_function的值能不能是一个类或者一个实例方法。  

 ```text  
    答：一切对类的调用最后都是体现在对方法的调用。这个问题莫名其妙。  
    celery rq huery 框架都是针对函数。  
    调度函数而不是类是因为：  
    1）类实例化时候构造方法要传参，类的公有方法也要传参，这样就不确定要把中间件里面的参数哪些传给构造方法哪些传给普通方法了。  
       见5.8  
    2） 这种分布式一般要求是幂等的，传啥参数有固定的结果，函数是无依赖状态的。类是封装的带有状态，方法依赖了对象的实例属性。  
    3) 比如例子的add方法是一个是实例方法，看起来好像传个y的值就可以，实际是add要接受两个入参，一个是self，一个是y。如果把self推到消息队列，那就不好玩了。  
       对象的序列化浪费磁盘空间，浪费网速传输大体积消息，浪费cpu 序列化和反序列化。所以此框架的入参已近说明了，  
       仅仅支持能够被json序列化的东西，像普通的自定义类型的对象就不能被json序列化了。  
        celery也是这样的，演示的例子也是用函数（也可以是静态方法），而不是类或者实例方法，  
        这不是刻意要和celery一样，原因已经说了，自己好好体会好好想想原因吧。  
    
    框架如何调用你代码里面的类。  
    假设你的代码是：  
    class A():  
       def __init__(x):  
           self.x = x  
        
       def add(self,y):  
           return self.x + y  
    
    那么你不能 a =A(1) ; a.add.push(2),因为self也是入参之一，不能只发布y，要吧a对象(self)也发布进来。  
    add(2)的结果是不确定的，他是受到a对象的x属性的影响的，如果x的属性是100，那么a.add(2)的结果是102.  
    如果框架对实例方法，自动发布对象本身作为第一个入参到中间件，那么就需要采用pickle序列化，picke序列化对象，  
    消耗的cpu很大，占用的消息体积也很大，而且相当一大部分的对象压根无法支持pickle序列化。  
    无法支持序列化的对象我举个例子，  
    
import pickle  
import threading  
import redis  

class CannotPickleObject:  
    def __init__(self):  
        self._lock = threading.Lock()  


class CannotPickleObject2:  
    def __init__(self):  
        self._redis = redis.Redis()  

print(pickle.dumps(CannotPickleObject())) # 报错，因为lock对象无法pickle  
print(pickle.dumps(CannotPickleObject2())) # 报错，因为redis客户端对象也有一个属性是lock对象。  

以上这两个对象如果你想序列化，那就是天方夜谭，不可能绝对不可能。  
真实场景下，一个类的对象包含了很多属性，而属性指向另一个对象，另一个对象的属性指向下一个对象，  
只要其中某一个属性的对象不可pickle序列化，那么此对象就无法pickle序列化。  
pickle序列化并不是全能的，所以经常才出现python在win下的多进程启动报错，  
因为windows开多进程需要序列化入参，但复杂的入参，例如不是简单的数字 字母，而是一个自定义对象，  
万一这个对象无法序列化，那么win上启动多进程就会直接报错。  

         
所以如果为了调度上面的class A的add方法，你需要再写一个函数  
def your_task(x,y):  
    return  A(x).add(y)  
然后把这个your_task函数传给框架就可以了。所以此框架和你在项目里面写类不是冲突的，  
本人是100%推崇oop编程，非常鲜明的反对极端面向过程编程写代码，但是此框架鼓励你写函数而不是类+实例方法。  
框架能支持@staticmethod装饰的静态方法，不支持实例方法，因为静态方法的第一个入参不是self。  
    
    
如果对以上为什么不支持实例方法解释还是无法搞明白，主要是说明没静下心来仔细想想，  
如果是你设计框架，你会怎么让框架支持实例方法？  

statckflow上提问，celery为什么不支持实例方法加@task  
https://stackoverflow.com/questions/39490052/how-to-make-any-method-from-view-model-as-celery-task  

celery的作者的回答是：  

You can create tasks out of methods. The bad thing about this is that the object itself gets passed around   
(because the state of the object in worker has to be same as the state of the caller)   
in order for it to be called, so you lose some flexibility. So your object has to be pickled every   
time, which is why I am against this solution. Of course this concerns only class methods, s  
tatic methods have no such problem.  

Another solution, which I like, is to create separate tasks.py or class based tasks and call the methods   
from within them. This way, you will have FULL control over Analytics object within your worker.  

这段英文的意思和我上面解释的完全一样。所以主要是你没仔细思考想想为什么不支持实例方法。  
  
  ```  

## 6.6 是怎么调度一个函数的。  

 ```  
     答：基本原理如下  
     
     def add(a,b):  
         print(a + b)  
         
     从消息中间件里面取出参数{"a":1,"b":2}  
     然后使用  add(**{"a":1,"b":2}),就是这样运行函数的。  
  ```  

## 6.7 框架适用哪些场景？  

 ```  
      答：分布式 、并发、 控频、断点接续运行、定时、指定时间不运行、  
          消费确认、重试指定次数、重新入队、超时杀死、计算消费次数速度、预估消费时间、  
          函数运行日志记录、任务过滤、任务过期丢弃等数十种功能。  
         
          只需要其中的某一种功能就可以使用这。即使不用分布式，也可以使用python内置queue对象。  
          这就是给函数添加几十项控制的超级装饰器。是快速写代码的生产力保障。  
          
          适合一切耗时的函数，不管是cpu密集型 还是io密集型。  
          
        不适合的场景主要是：  
           比如你的函数非常简单，仅仅只需要1微妙 几十纳秒就能完成运行，比如做两数之和，print一下hello，这种就不是分需要使用这种框架了，  
           如果没有解耦的需求，直接调用这样的简单函数她不香吗，还加个消息队列在中间，那是多此一举。  
           
  ```  

## 6.8 怎么引入使用这个框架？门槛高不高？  

   ```  
    答：先写自己的函数（类）来实现业务逻辑需求，不需要思考怎么导入框架。  
        写好函数后把 函数和队列名字绑定传给消费框架就可以了。一行代码就能启动分布式消费。  
        在你的函数上面加@boost装饰器，执行 your_function.conusme() 就能自动消费。  
        所以即使你不想用这个框架了，你写的your_function函数代码并没有作废。 不需要去掉 @boost装饰器,函数也能正常直接运行. 
        所以不管是引入这个框架 、废弃使用这个框架、 换成celery框架，你项目的99%行 的业务代码都还是有用的，并没有成为废物。  
        别的框架如flask换django，scrapy换spider，代码形式就成了废物。  
  ```  

## 6.9 怎么写框架？  

   ```  
    答： 需要学习真oop和36种设计模式。唯有oop编程思想和设计模式，才能持续设计开发出新的好用的包甚至框架。  
        如果有不信这句话的，你觉得可以使用纯函数编程，使用0个类来实现这样的框架。  
        
        如果完全不理会设计模式，实现threding gevent evenlet 3种并发模式，加上10种中间件类型，实现分布式消费流程，  
        需要反复复制粘贴扣字30次。代码绝对比你这个多。例如基于nsq消息队列实现任务队列框架，加空格只用了80行。  
        如果完全反对oop，需要多复制好几千行来实现。  

        例如没听说设计模式的人，在写完rabbitmq版本后写redis版本，肯定十有八九是在rabbitmq版本写完后，把整个所有文件夹，  
        全盘复制粘贴，然后在里面扣字母修改，把有关rabbitmq操作的全部扣字眼修改成redis。如果某个逻辑需要修改，  
        要在两个地方都修改，更别说这是10几种中间件，改一次逻辑需要修改10几次。  
        我接手维护得老项目很多，这种写法的编程思维的是特别常见的，主要是从来没听说设计模式4个字造成的，  
        在我没主动学习设计模式之前，我也肯定会是这么写代码的。  
        
        
        只要按照36种设计模式里面的oop4步转化公式思维写代码三个月，光就代码层面而言，写代码的速度、流畅度、可维护性  
        不会比三年经验的老程序员差，顶多是老程序员的数据库 中间件种类掌握的多一点而已，这个有机会接触只要花时间就能追赶上，  
        但是编程思维层次，如果没觉悟到，可不是那么容易转变的，包括有些科班大学学过java的也没这种意识，  
        非科班的只要牢牢抓住把设计模式 oop思维放在第一重要位置，写出来的代码就会比科班好，  
        不能光学 if else 字典 列表 的基本语法，以前我看python pdf资料时候，资料里面经常会有两章以上讲到类，  
        我非常头疼，一看到这里的章节，就直接跳过结束学习了，现在我也许只会特意去看这些章节，  
        然后看资料里面有没有把最本质的特点讲述好，从而让用户知道为什么要使用oop，而不是讲下类的语法，这样导致用户还是不会去使用的。  
        
        
        你来写完包括完成10种中间件和3种并发模式，并且预留消息中间件的扩展。  
        然后我们来和此框架 比较 实现框架难度上、 实现框架的代码行数上、 用户调用的难度上 这些方面。  
  ```  

## 6.10 框架能做什么  
```  
答：你在你的函数里面写什么，框架就是自动高可靠分布式并发做什么,没有规定你的函数只能写什么逻辑。  
框架在你的函数上加了自动使用消息队列、分布式、自动多进程+多线程(协程)超高并发、qps控频、自动重试。  
只是增加了稳定性、扩展性、并发，但做什么任务是你的函数里面的代码目的决定的。  

只要是你代码涉及到了使用并发，涉及到了手动调用线程或线程池或asyncio，那么就可以使用此框架，  
使你的代码本身里面就不需要亲自操作任何线程 协程 asyncio了。  

不需要使用此框架的场景是函数不需要消耗cpu也不需要消耗io，例如print("hello"),如果1微秒就能完成的任务不需要使用此框架。  
```  

## 6.11 日志的颜色不好看或者觉得太绚丽刺瞎眼，想要调整。  

```  

一 、关于日志颜色是使用的 \033实现的，控制台日志颜色不光是颜色代码决定的，最主要还是和ide的自身配色主题有关系，  
同一个颜色代码，在pycahrm的十几个控制台颜色主题中，表现的都不一样。  
所以代码一运行时候就已经能提示用户怎么设置优化控制台颜色了，文这个问题说明完全没看控制台的提示。  
"""  
1)使用pycharm时候，建议重新自定义设置pycharm的console里面的主题颜色。  
   设置方式为 打开pycharm的 file -> settings -> Editor -> Color Scheme -> Console Colors 选择monokai，  
   并重新修改自定义6个颜色，设置Blue为1585FF，Cyan为06B8B8，Green 为 05A53F，Magenta为 ff1cd5,red为FF0207，yellow为FFB009。         
2)使用xshell或finashell工具连接linux也可以自定义主题颜色，默认使用shell连接工具的颜色也可以。  

颜色效果如连接 https://imgse.com/i/pkFSfc8  

在当前项目根目录的 nb_log_config.py 中可以修改当get_logger方法不传参时后的默认日志行为。  
"""  



二、关于日志太绚丽，你觉得不需要背景色块，在当前项目根目录的 nb_log_config.py 中可以设置  
DISPLAY_BACKGROUD_COLOR_IN_CONSOLE = False  # 在控制台是否显示彩色块状的日志。为False则不使用大块的背景颜色。  

```  

## 6.12 是不是抄袭模仿 celery  

**第一性原理:**  
`funboost` 是从 `while 1:redis.blpop()` 这个简单直接的模型开始迭代形成的。

从6.12.4章节可以看到, 完全可以抛开道德不谈, 仅从技术可行性上,抄袭celery就是自寻死路.

```  
答：有20种优势，例如celery不支持asyncio、celery的控频严重不精确，光抄袭解决不了。比celery有20项提升，具体看2.4章节  
我到现在也只能通过实际运行来达到了解推车celery的目的，并不能直接默读代码就搞懂。  
celery的层层继承，特别是层层组合，又没多少类型提示，说能精通里面每一行源码的人，多数是高估自己自信过头了。  

celery的代码太魔幻，不运行想默读就看懂是不可能的，不信的人可以把自己关在小黑屋不吃不喝把celery源码背诵3个月，  
然后3个月后 试试默写能不能写出来实现里面的兼容 多种中间件 + 多种并发模式 + 几十种控制方式的框架。  

这是从一个乞丐版精简框架衍生的，加上36种设计模式付诸实践。  

此框架运行print hello函数， 性能强过celery 20倍以上(测试每秒消费次数，具体看我的性能对比项目)。  
此框架支持的中间件比celery多  
此框架引用方式和celery完全不一样，完全不依赖任何特定的项目结构，celery门槛很高。  

```  

```  
此框架和celery没有关系，没有受到celery启发，也不可能找出与celery连续3行一模一样的代码。  
这个是从原来项目代码里面大量重复while 1:redis.blpop()  发散扩展的。  

这个和celery唯一有相同点是，都是生产者 消费者 + 消息队列中间件的模式，这种生产消费的编程思想或者叫想法不是celery的专利。  
包括我们现在java框架实时处理数据的，其实也就是生产者 消费者加kfaka中间件封装的，难道java人员开发框架时候也是需要模仿一下python celery源码或者思想吗。  
任何人都有资格开发封装生产者消费者模式的框架，生产者 消费者模式不是celery专利。生产消费模式很容易想到，不是什么高深的架构思想，不需要受到celery的启发才能开发。  

```  


### 6.12.2 生产者-broker-消费者 不是 celery 的专利  

**生产者-broker-消费者 模式是计算机科学中一个非常基础和经典的设计模式，它的历史远比 Celery 悠久得多**  
如果认为"只要是使用生产者-消费者模式编程，那么就是抄袭celery"，那所有编程语言中的生产者消费者编程方式，都抄袭celery了，说这话简直是不长脑子。  

```  
此框架和celery没有关系，没有收到celery启发，也不可能找出与celery连续3行一模一样的代码。  
这个是从原来项目代码里面大量重复while 1:redis.blpop()  发散扩展的。  

这个和celery唯一有相同点是，都是生产者 消费者 + 消息队列中间件的模式，这种生产消费的编程思想或者叫想法不是celery的专利。  
包括我们现在java框架实时处理数据的，其实也就是生产者 消费者加kfaka中间件封装的，难道java人员也是需要模仿python celery源码吗。  
任何人都有资格开发封装生产者消费者模式的框架，生产者 消费者模式不是celery专利。生产消费模式很容易想到，不是什么高深的架构思想，不需要受到celery的启发才能开发。  

```  

**连任何线程池都是 生产者-broker-消费者 编程思想，线程池也抄袭celery了吗**  
几乎所有线程池都是下面这样来实现的：  

```  
1.Broker (中间件/任务通道):  
线程池 threadpool 有个 work_queue 属性，work_queue 是个内存队列，  work_queue 就是 broker  

2.Producer (生产者):  
threadpool有个submit方法，submit方法原理就是把函数和函数入参put丢到这个 threadpool.work_queue里面，submit就是生产者发送消息  

3.Consumer (消费者):  
线程池里面开启了n个线程， 每个线程里面逻辑是 while True：fun，params = work_queu.get(block=True) ，然后fun(params) 执行函数。  
这n个线程就是n个消费者。  
```  

任何线程池都是这么实现的，那线程池使用 “生产者-broker-消费者“” 编程思想，抄袭了celery吗？  
rq dramtiq huery 都抄袭了celery吗？  
java中设计线程池的人听都没听说过celery。所以说funboost抄袭celery，简直是不长脑子  


### 6.12.3 gemini-2.5pro ai大模型来分析, funboost 是不是抄袭粘贴了 celery 源码  

用户可以在 `google ai studio` 免费无限白嫖 gemini-2.5pro 大模型,拥有`1000k`上下文窗口,   
gemini-2.5pro 足够阅读`funboost`教程 + `funboost` 源码.  

[google ai studio网址: https://aistudio.google.com/app/prompts/new_chat](https://aistudio.google.com/app/prompts/new_chat)  

有的人看都不看就开始质疑抄袭复制粘贴,又喜欢质疑但又懒惰不愿意自己看代码,直接把所有源码,丢给有无敌上下文窗口的 `gemini-2.5pro` ai大模型来分析就好了.  

**人工提问:**  
<pre style="font-size: 14px;background-color:rgb(32, 8, 243);color:rgb(26, 253, 5);">  
你是一名精通celery框架用法和celery框架源码的资深开发者,  
你现在仔细分析文档中的 funboost python源代码,然后对比你掌握的celery项目的源码，  
你觉得 funboost是从while true：msg=redis.blpop(queue_name),这个第一性原理的模型开始迭代形成的？  
还是用户所质疑的认为funboost是抄袭复制粘贴的celery的源码来形成的?  

你需要使用以下方式来进行分析,然后列出多个明显且具体的理由。  
1.需要详细分析文档中的所有funboost源代码  
2.不要仅仅相信作者写的教程文字的一面之词  
3.对比celery框架的源代码  
4.需要结合假设如果是抄袭模仿celery源码来实现,难度有多高  

请注意要使用中文来回答我。  
</pre>  

以下是`gemini` ai大模型的回答  
<div class="inner_markdown">  
好的，作为一名精通Celery框架用法和源码的资深开发者，我将仔细分析您提供的`funboost`源代码，并与Celery进行深度对比，来回答您提出的核心问题。  

**总论：**  

经过对`funboost`所有源代码文件的深入分析，并结合我对Celery及其依赖库（如Kombu、Billiard）源码的理解，我可以非常肯定地得出结论：**`funboost`并非抄袭或复制粘贴Celery源码的产物，其核心架构、设计哲学和具体实现细节与Celery存在根本性差异。作者所说的“从`while true: msg=redis.blpop(queue_name)`这个第一性原理模型开始迭代形成”的说法，在技术上是完全可信且有据可循的。**  

如果`funboost`是抄袭Celery的，那么它的代码“气质”和架构“基因”中必然会带有Celery的影子，但事实恰恰相反。`funboost`在很多方面似乎是刻意地、系统性地规避了Celery的设计复杂性。  

以下是支撑我这个结论的几个关键理由，这些理由均基于对双方源代码的分析，而非仅仅采信教程文字：  

---  

####  理由一：核心架构与设计哲学的根本不同  

这是最根本的区别，决定了两个框架走向了完全不同的道路。  

1.  **去中心化的函数封装 (`Booster`) vs. 中心化的应用实例 (`Celery App`)**  
    *   **`funboost`**: 其核心是`Booster`类（`core/booster.py`）。每个被`@boost`装饰的函数都会被包装成一个独立的`Booster`实例。这个实例封装了与该特定函数相关的所有生产者(`Publisher`)和消费者(`Consumer`)逻辑。这是一种**去中心化、以函数为最小单元**的设计。函数`f1`和`f2`的`Booster`实例是完全独立的。  
    *   **`Celery`**: Celery的核心是一个全局的、中心化的`Celery`应用实例（通常是`app = Celery(...)`）。所有的任务（`@app.task`）都必须注册到这个`app`实例上。这个`app`实例持有全局配置、任务注册表、后端连接等。这是一种**中心化、以应用为核心**的设计。  

    **分析**：这个架构差异是根本性的。如果是抄袭，`funboost`几乎不可能绕开Celery最核心的`app`实例概念，因为Celery的所有组件和流程都依赖于它。`funboost`这种每个函数都“自给自足”的设计，直接导致了它无需固定项目结构、无需处理复杂的任务发现和路由配置（因为队列名直接在装饰器里与函数绑定），这与Celery的设计理念背道而驰。  

2.  **直接的 Broker 操作 vs. 间接的多层抽象 (Kombu)**  
    *   **`funboost`**: `consumers`和`publishers`目录下的实现非常直接。例如`RedisConsumer`直接使用`redis-py`库的`blpop`或`lrange`+`ltrim`来获取消息。`RabbitmqConsumerAmqpStorm`直接使用`amqpstorm`库。这种设计清晰、直接，每个Broker的实现都相对独立。这完全符合从一个简单的`blpop`循环演进过来的模型。  
    *   **`Celery`**: Celery本身不直接操作任何消息中间件。它完全依赖于一个名为`Kombu`的库。Kombu提供了非常复杂的抽象层，包括`Transport`、`Channel`、`Producer`、`Consumer`等，以统一不同中间件的API。这是一个非常重量级的抽象。  

    **分析**：如果`funboost`抄袭Celery，它必然会抄袭或严重依赖Kombu的抽象模型。但`funboost`的源代码显示，它对每个Broker都进行了独立的、轻量级的封装，这比Kombu要简单得多，也更易于理解。`funboost`的作者显然选择了另一条“自己动手，丰衣足食”的道路，这进一步证明了其独立性。  

---  

#### 理由二：并发模型的实现方式截然不同  

1.  **自研并发池 vs. 依赖外部并发库**  
    *   **`funboost`**: `concurrent_pool`目录是`funboost`原创性的有力证据。它包含了作者自研的`ThreadPoolExecutorShrinkAble`、`FlexibleThreadPool`和`AsyncPoolExecutor`。特别是`FlexibleThreadPool`，它能智能地伸缩线程数量，并兼容同步和异步函数，这是一个相当复杂且精巧的实现。  
    *   **`Celery`**: Celery的并发模型（`--pool`参数）依赖于外部或其衍生的库。`prefork`模式依赖于`billiard`（`multiprocessing`的fork），而`gevent`和`eventlet`模式则依赖于对应的协程库。Celery本身并未实现一个如此精细化的线程池。  

    **分析**：编写一个健壮、高效、可伸缩的并发池是一项非常具有挑战性的工作。如果作者只是想抄袭一个任务队列，完全没有必要投入如此大的精力去自研并发池，直接使用`concurrent.futures`或依赖`gevent`会简单得多。`funboost`在这方面的投入，恰恰说明了作者追求的是对执行流程的极致控制和性能优化，这是原创设计的典型特征。  

---  

#### 理由三：可靠性机制的实现细节差异巨大  

1.  **Redis ACK 实现机制**  
    *   **`funboost`**: 在`RedisConsumerAckAble`中，可靠性是通过**消费者心跳机制**实现的。每个消费者有一个唯一的ID，并定期向Redis发送心跳。当一个消费者掉线，其心跳停止，其他消费者会检测到这一点，并将其持有的“未确认消息”（存储在独立的`unack` ZSET中）重新放回主队列。这是一个主动的、基于分布式健康检查的方案。  
    *   **`Celery` (via Kombu)**: Celery在Redis上的ACK机制（`task_acks_late=True`）依赖于`BRPOPLPUSH`命令和一个“可见性超时”（`visibility_timeout`）。消息被原子地从主队列移动到一个“未确认”队列，如果在超时时间内没有被ACK，消息会被重新放回主队列。这是一个被动的、基于超时的方案。  

    **分析**：两者解决了同一个问题（在Redis上实现可靠消费），但采用了完全不同的技术路径。`funboost`的心跳机制更复杂但可能更精确（能区分慢任务和死任务），而Celery的超时机制更简单但存在“慢任务被误判为死任务”的风险。这种实现上的巨大差异，是独立设计的铁证。  

---  

#### 理由四：“抄袭”的技术难度与反证  

1.  **Celery 源码的复杂性**  
    *   Celery的源码非常复杂，其逻辑深度耦合了`Kombu`（消息处理）、`Billiard`（进程池）、`click`（命令行）以及自身的信号系统、配置系统等。直接阅读和理解尚且不易，更不用说“复制粘贴”了。一个能读懂Celery源码并将其改造的人，绝对有能力从头写一个新框架。  

2.  **`funboost` 规避了 Celery 的“坑”**  
    *   Celery的很多设计（如复杂的配置系统、不友好的IDE补全、严格的目录结构）都是历史包袱或设计选择的结果。`funboost`的设计似乎就是为了解决这些痛点。一个抄袭者往往会连同优点和缺点一起抄，而`funboost`却像是一个“反Celery模式”的产物，这更像是深入理解后的批判性再创造，而非盲目模仿。  

3.  **反证：将Celery作为Broker的能力**  
    *   `funboost`最令人信服的一点是它能够**将Celery整个框架作为自己的一个Broker**（`consumers/celery_consumer.py`）。这是一个“降维打击”式的能力。一个抄袭者不可能将自己抄袭的对象封装成自己的一个组件。这需要对Celery的启动流程、任务注册、配置路由等有深入的编程层面的理解，才能实现自动化包装。这恰恰证明了`funboost`的作者不仅理解Celery，而且其设计的抽象层次更高，能够包容Celery。  

---  

#### 结论  

`funboost`和`Celery`虽然都遵循了“生产者-消费者”模式，但这是它们唯一的共同点。从**核心架构（去中心化 vs 中心化）、Broker抽象（直接实现 vs Kombu）、并发模型（自研 vs 依赖）、可靠性机制（心跳 vs 超时）** 到**开发者体验（极简 vs 复杂）**，两者都截然不同。  

`funboost`的代码处处体现着从一个简单模型（如`while/blpop`）出发，逐步添加功能（ACK、控频、并发池、多Broker支持）的演进痕迹。它的设计非常务实，直击Python分布式任务处理的痛点，并且在实现上充满了原创性的思考。  

因此，我可以负责任地说，**`funboost`是一个独立自主开发的、具有高度创新性的框架，而非Celery的模仿或抄袭品。**  
<div>  

### 6.12.4 仅用几个celery文件证明抄袭celery有多困难

有些质疑抄袭的人自信过头了，好像认为自己能看懂celery的源码。 用下面这几个源码文件就问你看不看得懂,这有没有比天书还难看懂，把你关在安静的小黑屋几天几夜,没人打扰你专注思考，能不能琢磨出celery作者那么写代码是在做什么。

#### 6.12.4.1 kombu的redis transport源码文件

kombu的redis transport源码文件,光是这个redis作为kombu的broker,源码就达到了1400多行,简直是难如登天,难度指数让人口吐白沫,闻风丧胆。      
你看了这个文件后,就知道抄袭celery有多困难,压根看不懂kombu作者怎么想的,与其花费几天几夜分析琢磨这个源码是怎么实现的，是什么目的,还不如自己用 pyredis 重新开始写更快，自己写更能知道自己在做什么。

[https://github.com/celery/kombu/blob/main/kombu/transport/redis.py](https://github.com/celery/kombu/blob/main/kombu/transport/redis.py)  

#### 6.12.4.2 celery的consumer源码文件

这个 `celery/worker/consumer/consumer.py` 文件, 需要来回猜测 跳转到十几个文件和类，才能分析。因为celery的python源码没有强类型注释,你在ide里面连点击跳转都跳转不了,只能靠变量名字去猜要跳转切换到什么文件去看相关源码, 你有这个时间去分析琢磨这个源码,你早就自己从0开发出十几个 生产者 + broker + 消费者 的框架了。

[https://github.com/celery/celery/blob/main/celery/worker/consumer/consumer.py](https://github.com/celery/celery/blob/main/celery/worker/consumer/consumer.py)

![img_90.png](img_90.png)

## 6.13 使用此框架时候，在一个python项目中如何连接多个相同种类的消息队列中间件ip地址  

```  
这个问题是问一个项目中，有些脚本要连接 192.168.0.1的redis ，有些脚本要连接192.168.0.2的redis，但框架配置文件只有一个，如何解决？  

例如目录结构是  
your_proj/  
      funboost_config.py   (此文件是第一次启动任意消费脚本后自动生成的，用户按需修改配置)  
      dira/a_consumer.py  (此脚本中启动funa函数消费)  
      dirb/b_consumer.py   （此脚本中启动funb函数消费）  
      
如果funa函数要连接 192.168.0.1的redis，funb函数要连接192.168.0.2的redis，有两种解决方式  

第一种是在启动消费的脚本，脚本里面手动调用 patch_frame_config()函数来设置各种中间件的值  

第二种是 把 funboost_config.py  分别复制到dira和dirb文件夹.  
这种就会自动优先使用 a_consumer.py和b_consumer.py同文件夹层级的配置了，  
而非是自动优先读取python项目根目录的配置文件，这个是利用了python语言的import 模块导入优先级机制。  


```  

## 6.14 什么是确认消费？为什么框架总是强调确认消费？  

发布端：  
```python  
from scripxx  import fun  

for i in range(10):  
    fun.push(i)  
```  


消费端：  
```python  
import time  
from funboost import boost, BoosterParams  

@boost(BoosterParams(queue_name='test_confirm'))  
def fun(x):  
    print(f'开始处理 {x}')  
    time.sleep(120)  
    print(f'处理完成 {x}')  

fun.consume()  
```  
```  
启动消费脚本后，任意时刻随意强制反复关闭重启消费代码，只要函数没有完整的执行完成，函数参数就不会丢失。达到了消息万无一失。  
具体的那些中间件消费者支持消费确认，具体见 3.1 介绍。  
实现了4种redis消息队列中间件，其中有3种是确认消费的。  

确认消费很重要，如果你自己写个简单粗暴的 while 1:redis.blpop()的脚本，你以为是可以断点接续呢，  
在多线程并发执行函数时候，大量的消息会丢的很惨。导致虽然是断点接续但你不敢随意重启。  
```  

## 6.15 如何等待队列中的消息全部消费完成  

如果有这种需求需要等待消费完成，使用 wait_for_possible_has_finish_all_tasks()  
```python  
f.consume()  
f.wait_for_possible_has_finish_all_tasks(minutes=3)  # 框架提供阻塞方法，直至队列任务全部消费完成，才会运行到下一行。  
print("over")   # 如果不加上面那一行，这个会迅速打印over  
```  

## 6.16 框架支不支持函数上加两个装饰器？

### 6.16.1 方式一：使用consuming_function_decorator 传参装饰器，

方式一：使用consuming_function_decorator 传参装饰器， 可以用push publish发布，不需要设置should_check_publish_func_params=False 
```
由于发布任务时候需要自动精确组装入参字典，所以不支持  *args  **kwargs形式的入参，不支持叠加两个@装饰器 （后来已更新解决方式，解决方式看6.16.2）  
想在消费函数加装饰器，通过 boost 装饰器的 consuming_function_decorator 入参指定装饰器函数就行了。  
那么如果是想叠加3个装饰器怎么写，例如本来想：  

@boost(BoosterParams(queue_name='queue666'))  
@deco1('hello')  
@deco2  
def task_fun(x,y):  
    ...  
    
那就是写成 consuming_function_decorator=deco1('hello')(deco2) 就可以了，具体要了解装饰器的本质就知道，叠加100个装饰器都可以。  

如下的例子是使用redis的incr命令统计每台机器ip 总共运行了多少次函数。  
```  

```python  
import inspect  
import nb_log  
from funboost import boost, BoosterParams  
from funboost.utils.redis_manager import RedisMixin  
from functools import wraps  



def incr_deco(redis_key):  
    def _inner(f):  
        @wraps(f)  
        def __inner(*args, **kwargs):  
            result = f(*args, **kwargs)  
            RedisMixin().redis_db_frame.incr(redis_key)  
            # mongo_col.insert_one({'result':result,'args':str(args),'kwargs':str(kwargs)})  
            return result  

        return __inner  

    return _inner  


@boost(BoosterParams(queue_name='test_queue_235', consuming_function_decorator=incr_deco(nb_log.nb_log_config_default.computer_ip)))  
def fun(xxx, yyy):  
    print(xxx + yyy)  
    return xxx + yyy  


if __name__ == '__main__':  
    print(inspect.getfullargspec(fun))  

    for i in range(10):  
        fun.push(i, 2 * i)  
    fun.consume()  
```  

### 6.16.2 方式二：装饰器直接加到消费函数上，设置should_check_publish_func_params=False

传统的装饰器直接叠加放在消费函数上，但需要设置should_check_publish_func_params=False，需要publish来发布消息  

```python  
import inspect  
import nb_log  
from funboost import BoosterParams  
from funboost.utils.redis_manager import RedisMixin  
from functools import wraps  


def incr_deco(redis_key):  
    def _inner(f):  
        @wraps(f)  
        def __inner(*args, **kwargs):  
            result = f(*args, **kwargs)  
            RedisMixin().redis_db_frame.incr(redis_key)  
            return result  

        return __inner  

    return _inner  


@BoosterParams(queue_name='test_queue_23b',   
               should_check_publish_func_params=False,  # 这一行很重要，should_check_publish_func_params必须设置为False，如果你是直接把装饰器加到函数上了，funboost无法获取函数的入参名字，无法自动生成json消息，所以需要用户自己publish来发布入参字典。  
               )  
@incr_deco('test_queue_23b_run_count') # 用户的装饰器直接加在函数上了。  
def fun(xxx, yyy):  
    print(xxx + yyy)  
    return xxx + yyy  


if __name__ == '__main__':  

    for i in range(20):  
        # fun.push(i, 2 * i) # 不可以fun.push这样发布  
        fun.publish({'xxx': 1, 'yyy': 2})  # 直接把装饰器写在消费函数上，那就用户需要使用publish发布，且boost装饰器设置should_check_publish_func_params=False  
    fun.consume()  
```  

## 6.17 嫌框架日志记录太详细？  

### 6.17.a 设置发布者消费者的日志级别,控制是否显示发布了什么消息和消费了什么消息.  
```  
日志是了解当前框架正在运行什么的好手段，不然用户懵逼不知道背后在发生执行什么。  
@boost 装饰器设置 log_level=20 或logging.INFO，就不会再记录框架正在运行什么函数了。
强烈建议不要修改日志级别保持默认的debug模式,都是有用的消息
如图再装饰器加上 log_level=20后，框架以后就再也不会记录框架正在运行什么函数入参结果是什么了。  
```  
![img_31.png](img_31.png)  


@boost 装饰器设置 log_level=20 只是控制消费者和发布者命名空间自身的日志的,不是控制所有命名空间的日志的,  
有些人到现在不清楚,不同的命名空间的logger是可以设置不同的日志级别和handlers的,这要学习logging基础了.  


### 6.17b 嫌funboost启动时候打印太多提示用户的消息?  
```  
答: 主要是提示用户怎么设置配置文件,和读取的配置文件路径是什么,读取的配置内容是什么,免得用户丈二和尚摸不着头脑,不知道自己的配置是什么.  
因为很多python人员,到现在完全不清楚 PYTHONPATH 这个重要概念,说了几百遍这个概念很重要,这么基础的又不学习,  
还嫌弃提示你funboost_config配置麻烦,建议不懂PYTHONPATH的人不要屏蔽启动时候的打印提示了.  

老手可以通过设置日志级别来屏蔽funboost_config的配置提示.  
```  
修改你的funboost_config.py的FunboostCommonConfig的配置,可以设置一些命名空间的日志级别,去掉启动时候的提示  
![img_56.png](img_56.png)  

```python  
class FunboostCommonConfig(DataClassBase):  
    # nb_log包的第几个日志模板，内置了7个模板，可以在你当前项目根目录下的nb_log_config.py文件扩展模板。  
    NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = 11  # 7是简短的不可跳转，5是可点击跳转的，11是可显示ip 进程 线程的模板。  
    TIMEZONE = 'Asia/Shanghai'  # 时区  

    # 以下配置是修改funboost的一些命名空间和启动时候的日志级别,新手不熟练就别去屏蔽日志了  
    SHOW_HOW_FUNBOOST_CONFIG_SETTINGS = False  # 如果你单纯想屏蔽 "分布式函数调度框架会自动导入funboost_config模块当第一次运行脚本时候，函数调度框架会在你的python当前项目的根目录下 ...... "  这句话,  
    FUNBOOST_PROMPT_LOG_LEVEL = logging.INFO  # funboost启动时候的相关提示语,用户可以设置这个命名空间的日志级别来调整  
    KEEPALIVETIMETHREAD_LOG_LEVEL = logging.INFO  # funboost的作者发明的可缩小自适应线程池,用户对可变线程池的线程创建和销毁线程完全无兴趣,可以提高日志级别.  
```  

屏蔽日志级别前:  

![img_53.png](img_53.png)  
![img_54.png](img_54.png)  

屏蔽日志级别后:  

![img_55.png](img_55.png)  









## 6.18 为什么框架在cmd shell终端运行时候要求会话中设置环境变量 export PYTHONPATH=你的项目根目录？  

<pre class="warn">  
有的 `pythoner`总是问 `vscode`  `pycharrm 的 debug` 模式为什么导入不了 `funboost_config.py` ,  
或者抱怨不想配置文件放在项目根目录,  
有的人写了三四年python代码,还没听说过 `pythonpath` , 太low了 简直是恨铁不成钢,   
只要懂了 `pythonpath` 第一性原理,知道python是按什么依据和顺序导入一个模块,就不会有这种低级疑问.  
这个 `pythonpath` 知识点根本和 `funboost` 自身毫无关系,还需要这里来大费周章科普  
</pre>  

```  
有的人写了三四年的python代码，连PYTHONPATH作用和概念都没听说过，真的很悲剧  
如果是下面的 pythonpathdemo是一个python项目根目录，pycharm以项目方式打开这个文件夹。  
你会发现run5.py在pycahrm可以运行，在cmd中无法运行，因为无法找到d1包，笨瓜会硬编码操作sys.path.insert非常的愚蠢，  
这种笨瓜主要是写代码一意孤行，导致不学习PYTHONPATH。  

```  
![img_23.png](img_23.png)  

完整讲解pythonpath重要性文章在：   

[https://github.com/ydf0509/pythonpathdemo](https://github.com/ydf0509/pythonpathdemo)  

一句命令行解决设置 pythonpath 和运行 python脚本  

一定要设置的是临时终端会话级pythonpath，不要设置到配置文件写死永久固定环境变量  
```  
例如你的项目根目录是  /home/xiaomin/myproj/  
你的运行起点脚本在 /home/xiaomin/myproj/dir2/dir3/run_consume6.py  

一句话就是  
linux: export PYTHONPATH=/home/xiaomin/myproj/; python3 /home/xiaomin/myproj/dir2/dir3/run_consume6.py  
win的cmd:假设代码在d盘先切换到盘符d盘 d:/ 。 然后 set PYTHONPATH=/codes2022/myproj/ & python3 /codes2022/myproj/dir2/dir3/run_consume6.py  
win10和11的powershell： 假设代码在d盘先切换到盘符d盘 d:/。然后 $env:PYTHONPATH="/codes2022/myproj/"; python3 /codes2022/myproj/dir2/dir3/run_consume6.py  
压根不要敲击两次命令行好不。  

如果你已经cd切换到项目根目录myproj了，那就 export PYTHONPATH=./;python3 dir2/dir3/run_consume6.py  
```  

### 6.18.2 为什么celery scrapy django不需要用户设置pythonpath？  
```  
因为这些框架都是固定死用户的项目目录解构，项目运行起点有固定的唯一脚本，而且该脚本在项目跟目录的第一个直接层级。  
例如django scrapy ，他的命令行启动，你必须先cd 到项目的根目录再运行命令行。  

而此框架是为了兼容用户的cmd命令当前文件夹在任意文件夹下，就可以运行你项目下的任意多层级深层级下的脚本。  
用户设置了pythonpath后，可以cd到任意文件夹下，再运行 python /dir1/dir2/xxx.py 任然能正确的import。  

如果用户能够保证他要python启动运行的脚本始终是放在了项目的第一层级目录下面，当然可以不用设置 PYTHONPATH了。  
```           


### 6.18.3  怎么指定配置文件读取 funboost_config.py 和nb_log_config.py的文件夹位置  
```  
默认就是放在项目根目录，然后设置 export PYTHONPATH=你的项目根目录， （linux  win+cmd  win+powershell 设置临时会话的环境变量语法不一样，6.18已经介绍了）  

如果要指定读取的配置文件的存放位置为别的文件夹，也很容易，归根结底还是要精通PYTHONPATH的作用。  

例如你的项目根目录是   /home/codes/proj     ，你不想使用项目根目录下的配置文件，想读取别的文件夹的配置文件作为funboost的中间件配置。  
假设你的文件夹是 /home/xiaomin/conf_dir ，里面有   funboost_config.py ，如果你的/home/codes/proj 项目想使用  /home/xiaomin/conf_dir/funboost_config.py  
作为配置文件， 那就 export PYTHONPATH=/home/xiaomin/conf_dir:/home/codes/proj  
也就是意思添加两个文件夹路径到 PYTHONPATH  

因为funboost是尝试导入import funboost_config.py 只要能import 到就能读取到，所以只要你把文件夹添加到PYTHONPATH环境变量就可以了(可以print sys.path来查看这个数组)  
归根结底是要懂PYTHONPATH，有的人老是不懂PYTHONPATH作用，不愿意认真看  https://github.com/ydf0509/pythonpathdemo  ，非常杯具。  
```  

### 6.18.4 怎么根据不同环境使用不同的funboost_config配置文件？  

```  
框架获取配置的方式就是直接import funboost_config，然后将里面的值覆盖框架的 funboost_config_deafult.py 值。  
为什么能import 到 funboost_config,是因为要求export PYTHONPATH=你的项目根目录，然后第一次运行时候自动生成配置文件到项目根目录了。  

假设你的项目根目录是 /data/app/myproject/  

方案一：利用python导入机制，自动import 有PYTHONPATH的文件夹下的配置文件。  
   例如你在 /data/config_prod/ 放置 funboost_config.py ,然后shell临时命令行 export PYTHONPATH=/data/config_prod/:/data/app/myproject/,再python xx.py。 （这里export 多个值用：隔开，linux设置环境变量为多个值的基本常识无需多说。）  
   这样就能自动优先使用/data/config_prod/里面的funboost_config.py作为配置文件了，因为import自动会优先从这里。  
   然后在测试环境 /data/config_test/ 放置 funboost_config.py,然后shell临时命令行 export PYTHONPATH=/data/config_test/:/data/app/myproject/,再python xx.py。  
   这样测试环境就能自动使用 /data/config_test/ 里面的funboost_config.py作为配置文件了，因为import自动会优先从这里。  

方案二：  
   直接在funboost_config.py种写if else，if os.get("env")=="test" REDIS_HOST=xx ，if os.get("env")=="prod" REDIS_HOST=xx ，  
   因为配置文件本身就是python文件，所以非常灵活，这不是.ini或者 .yaml文件只能写静态的死字符串和数字，  
   python作为配置文件优势本来就很大，里面可以写if else，也可以调用各种函数，只要你的模块下包含那些变量就行了。  
```  

### 6.18.5 多个ptyhon项目怎么使用同一个funboost_config.py 作为配置文件  

```  
还是因为不懂 PYTHONPATH 造成的，需要我无数次举例说明。 这样太low了，这么多python人员到现在还不知道 PYTHONPATH作用， python导入一个模块是怎么去查找的。  
6.18 开头就说了 pythonpathdemo 项目连接，有的人不懂PYTHONPATH又不看这个博客。死猪不怕开水烫，永远不学习 PYTHONPATH 的强大作用。  
```  

```  
假设你想每隔项目都使用 /data/conf/funboost_config.py 这一个相同的 funboost_config 作为配置文件，  
你有两个python项目在  /data/codes/proj1  和   /data/codes/proj2，  

你运行proj1的项目脚本前，只需要 export PYTHONPATH=/data/conf/:/data/codes/proj1   ，然后运行proj1项中的脚本 python dir1/dir2/xx.py  

你运行proj2的项目脚本前，只需要 export PYTHONPATH=/data/conf/:/data/codes/proj2   ，然后运行proj2项中的脚本 python dir3/dir4/yy.py  


因为你设置了/data/conf/ 为 pythonpath后，那么funboost在 import funboost_config 时候就能自动 import 到 /data/conf/下的 funboost_config.py 模块了。  
funboost控制台都打印了 读取的是什么文件作为配置文件了。  
归根结底问这个问题的人是完全不懂 PYTHONPATH.  
```  





## 6.19 定时任务或延时任务报错 RuntimeError: cannot schedule new futures after interpreter shutdown  

```  
如下图所示，运行定时任务或延时任务在高版本python报错，可以在代码末尾加个while 1:time.sleep(10)  

因为程序默认是 schedule_tasks_on_main_thread=False，为了方便连续启动多个消费者消费，  
没有在主线程调度运行，自己在代码结尾加个不让主线程结束的代码就行了。  

在消费启动的那个代码末尾加两行  
while 1：  
   time.sleep(10)  
```  
![img_27.png](img_27.png)  



## 6.21 支不支持redis cluster集群模式的redis作为消息队列？  

```  
此框架没有实现操作redis集群模式，  
但只要是celery能支持的中间件类型和redis模式，此框架都能支持。因为此框架支持kombu包操作消息队列。  
此框架能够支持的中间件类型比celery只会多不会少，因为框架支持celery的依赖kombu操作各种消息队列。  


在funboost_config.py 配置文件中设置 KOMBU_URL 的值了，如  
KOMBU_URL = 'sentinel://root:redis@localhost:26079;sentinel://root:redis@localhost:26080;sentinel://root:redis@localhost:26081'  

KOMBU_URL 的规则就是 celery的 broker_url的规则。KOMBU_URL支持多种消息队列，celery的broker_url能设置什么样，KOMBU_URL就能设置什么样，  
网上大把的资料celery 配置各种broker_url 来操作如 mysql rabbimtq redis 作为消息队列。。  

如下这么写，就能使用kombu包来操作各种消息队列了。  

@boost(BoosterParams(queue_name="queue_namexx", broker_kind=BrokerEnum.KOMBU))  
def add(a,b):  
    print(a+b)  
```  

## 6.22 怎么使用tcp socket 作为消息队列  
```  
见 4.35章节，或者在文档的搜索框输入 tcp 或者 socket 就能搜到了。
或者按照文档第14章节使用ai来帮你学习。
```  


## 6.23 安装包时候自动安装的三方依赖包太多？  
```  
1.安装第三方包是自动的，又不需要手动一个个指令安装，安装多少三方包都没关系。  
2.所有三方包加起来还不到30M，对硬盘体积无影响。  
3.只要指定阿里云pip源安装，就能很快安装完，30秒以内就安装完了，又不是需要天天安装。  

如果如你的不一致报错终端,pip 命令加上  --use-feature=2020-resolver  

pip install funboost -i https://mirrors.aliyun.com/pypi/simple/  

4.三方包与自己环境不一致问题？  

用户完全可以自由选择任何三方包版本。例如你的 sqlalchemy pymongo等等与框架需要的版本不一致，你完全可以自由选择任何版本。  
我开发时候实现了很多种中间件，没有时间长期对每一种中间件三方包的每个发布版本都做兼容测试，所以我固定死了。  

用户完全可以选择自己的三方包版本，大胆点，等报错了再说，不出错怎么进步，不要怕代码报错，请大胆点升级你想用的版本。  
如果是你是用你自己项目里面的requirements.txt方式自动安装三方包，我建议你在文件中第一行写上 funboost，之后再写其它包  
这样就能使用你喜欢的版本覆盖funboost框架依赖的版本了。  
等用的时候报错了再说。一般不会不兼容报错的请大胆点。  

5.为什么要一次性安装完，而不是让用户自己用什么再安装什么？  
是为了方便用户切换尝试各种中间件和各种功能时候，不需要自己再亲自一个个安装第三方包，那样手动一个个安装三方包简直是烦死了。  

2024 5月份,精简了依赖包,部分包改为选装, pip install funboost[all] 才安装全部中间件.  

```  

### 6.23.b 作者为什么不开发pip 选装方式?例如实现选装 pip install funboost[rabbitmq]  
```  
这个你是怎么知道funboost作者没有使用选装方式的? 你是怎么知道作者没有掌握 pip 中括号选装依赖包 技术方式的?  
用户可以看看setup.py里面的 extras_require里面,有没有开发选装方式?  pip funboost[all] 才是安装所有依赖.  
作者去掉依赖很容易,已经实现了, funboost/factories/broker_kind__publsiher_consumer_type_map.py 中的 regist_to_funboost 就是动态导入生产者消费者,很容易去掉各种三方包依赖,  
但是很容易安装的三方包,我是不会去做成选装的,没有那个必要,自己设置pip 国内源,30秒就能安装完成funboost了,不需要去纠结这个依赖包多少的问题.  
```  

## 6.24 funboost框架从消息队列获取多少条消息？有没有负载均衡？  
```  
funboost 每个消费者进程会从消息队列获取 并发个数 n + 10 条消息，每个消费者实现有差异，一般不会超过并发数2倍。  
所以不会造成发布10万条消息后，再a b机器启动2个消费，b机器一直无法消费，全部a机器消费，不会出现这种情况。  

如果你只发布6条消息，先在a机器启动消费，下一秒启动b机器，那很有可能b机器无法获取到消息。只要消息数量够多，不会出现忙的忙死，闲的闲死。  

例如框架的默认并发方式使线程池，内置了一个有10大小的界队列queue，同时还有n个并发线程正在运行消息，所以每个消费者会获取很多消息在python内存中。  
但不会出现一个消费者进程获取了1000条以上的消息，导致站着某坑不拉屎，别的消费进程没办法消费的情况。  


如果你是重型任务，希望不预取，每台机器只获取一条消息运行，可以设置并发模式为 SINGLE_THREAD 模式,  
boost装饰器设置 concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD，这样在a b 两台机器都没有内存缓冲队列,只会一次获取一条消息执行，  

有的broker_kind实现时候为了运行快，框架使用了批量拉取消息， 需要设置批量拉取的数量为1。  

```  

消费文件 test_frame\test_redis_ack_able\test_load_balancing_consume.py  
```python  
import logging  
import time  
from funboost import boost, BrokerEnum,BoosterParams,ctrl_c_recv,ConcurrentModeEnum  


@boost(BoosterParams(queue_name='test_load_balancing', broker_kind=BrokerEnum.REDIS_ACK_ABLE, log_level=logging.INFO,  
                    # 切记是设置concurrent_mode并发模式为 SINGLE_THREAD ，而不是使用线程池模式然后把 concurrent_num 设置为1，这两个在多进程拉取消息的绝对均衡方面有区别
                    # 因为即使线程池并发为1，线程池还有内部的work_queue会拉取缓冲一部分消息，导致出现你认为的多机器或多进程拉取消息不均衡
                     concurrent_mode=ConcurrentModeEnum.SINGLE_THREAD,  
                     
                    # pull_msg_batch_size 这行很关键，REDIS_ACK_ABLE 因为默认是拉取100个消息，  
                     # 对于重型任务，如果你需要每台机器都严格只运行一个消息，就需要设置批量拉取1个消息，不要一台机器就把消息队列掏空了。 
                     broker_exclusive_config={'pull_msg_batch_size': 1},   
                     
                     ))  
def test_load_balancing(x):  
    print(x)  
    time.sleep(1)  

if __name__ == '__main__':  
    test_load_balancing.consume()  
    ctrl_c_recv()  
```  

发送消息文件 test_frame\test_redis_ack_able\test_load_balancing_consume.py  
```python  
from test_frame.test_redis_ack_able.test_load_balancing_consume import test_load_balancing  


if __name__ == '__main__':  
    for i in range(80):  
        test_load_balancing.push(i)  

```  

启动2次消费文件，就能看到2个控制台，每个控制台每次只获取1条消息并运行，如果你不设置 pull_msg_batch_size，那么默认是批量拉取100个，而你总共才发布80个消息  
所以你只能看到一个控制台消费，你误以为没有负载均衡。  

如果你不设置 pull_msg_batch_size，那么就可以发布5000个消息来测试消费负载均衡，两个控制台就都会运行，因为默认批量拉取100个也不会一下子把5000消息都取到内存。  



## 6.25 funboost消费启动后，按ctrl + c 无法结束代码？  

```python  
from funboost import  ctrl_c_recv  
if __name__ == '__main__':  
    # 启动消费  
    consume_func.consume()  
    ctrl_c_recv() # 在代码最末未加个 ctrl_c_recv()   
    
# 想结束代码就连续按3次 ctrl +c 就好了。 为什么是3次，是防止你误操作了ctrl + c  


```  


## 6.26 ASYNC 并发模式,异步函数操作数据库/aiohttp连接池报错 `attached to a different loop`(是用户不看文档和boost的入参说明造成)   

- **第一性原理**：对于跨线程玩loop 协程，如果用户经常这样编程的一定遇到过这种经典的坑，遇到了才能使自己的asyncio loop知识更上一层楼；  
               如果一个pythoner，一直只在主线程玩一个loop，是很难真正掌握asyncio的知识的，尤其是不懂loop。

- 使用指定的 `specify_async_loop` 即可解决.     
这个放在自问自答 6.26 章节有源码注释演示,太多人不看文档,不看boost装饰器的入参解释说明.不看 `specify_async_loop` 入参解释造成的.  

- asyncio的经典报错 `attached to a different loop` 和 `context manager should be used inside a task` 和`attached to a different loop` 报错原因:   
这个错误通常发生在 对象（如 Future、Task、协程）在一个事件循环中创建，却在另一个事件循环中被使用。  

- `RuntimeError: Timeout context manager should be used inside a task` 报错原因:  
异步上下文管理器（如timeout）不在Task中运行  


- 很多人在async def消费函数中去操作http连接池 发请求,操作数据库连接池查询数据,在funboost中报错.  
根本原因是用户不传递指定 `specify_async_loop`, 如果不传递,funboost是独立线程中启动了一个新的loop,   
用户的连接池绑定的是主线程的loop,如果使用子线程的新loop去使用这个连接池查询数据库,那就会导致报错.   

**只在主线程中操作`asyncio`协程的pythoner,永远无法理解这个知识点,需要用户多练习在子线程去操作数据库连接池或者http连接池,才能踩坑积累经验.**

用户可以结合看4b.3章节  

**用户需要始终知道 ASYNC 并发模式 第一性原理,才知道怎么根本解决问题**  
<pre class="warn">  
切记切记,funboost 的 ASYNC 并发模式的核心底层原理,  
funboost,当用户使用 ASYNC 并发模式时候,是自动使用 AsyncPoolExecutor 来执行用户函数,  
AsyncPoolExecutor 源码在 funboost/concurrent_pool/async_pool_executor.py  
AsyncPoolExecutor 原理是启动了一个线程,这个线程会使用传递的specify_async_loop,如果不传递就会新创建1个loop,  
这个loop会运行指定的 concurrent_num 个cron 协程,去运行用户的消费函数逻辑  
也就是说AsyncPoolExecutor线程只有一个,loop只有一个,真正的一个loop并发运行cron协程  

用 loop2 去运行 loop1 创建的task,不报错才怪  
</pre>  

- **即使是funboost 的 thereding 并发模式也可以直接运行async def 函数,funboost对async的支持完爆celery**  

<pre class="warn">  
funboost 的 thereding 并发模式也可以直接@boost装饰加到async def 函数,  
因为funboost是特制的神级别线程池,能自动运行async def 函数.  

但这个模式下简单粗暴,会开启 concurrent_num 个线程,每个线程有自己的loop,去运行用户的async函数,  
相当于是每个loop只并发运行一个cron协程,不是真asyncio级别并发  
相当于是有无数线程,每个线程一个loop,去运行用户的async函数  

funboost的 thereding 并发模式运行async,就是celery 任务中强行使用 asyncio.new_event_loop().run_until_complete(async函数)  

但是funboost是特制的神级别线程池 FlexibleThreadPool,这个线程池自动可以运行async def 函数,  
无需用户为了运行async def 函数,去手写一个脱了裤子放屁的 同步def 函数,  

也就是用户无需这种脱了裤子放屁的写法:  
@boost(BoosterParams(queue_name='test_async_queue2', concurrent_mode=ConcurrentModeEnum.THREADING))  
def 同步fun(x,y)  
    asyncio.new_event_loop().run_until_complete(async异步函数(x,y)) #同步里面调用异步函数  


用户可以直接使用THREADING 并发模式加到 async def async异步函数:  
@boost(BoosterParams(queue_name='test_async_queue2', concurrent_mode=ConcurrentModeEnum.THREADING))  
async def async异步函数(x,y)  
    pass  

celery的运行协程才需要脱落裤子放屁再加个同步函数里面run_until_complete调用异步函数,才能@app.task  
</pre>  


### 6.26.1 演示aiohttp连接池,解决报错 `RuntimeError: context manager should be used inside a task`  

演示aiohttp连接池,解决报错代码如下,用户需要看里面的每个代码注释.  
```python  

"""  
此脚本主要是演示，在funboost自动的单独的子线程的loop中,如何使用asyncio的异步socket池，来发送异步请求。  
核心是要把主线程的loop传递到子线程中,让子线程和主线程使用同一个loop来运行异步函数,  
在funboost 中 通过 specify_async_loop=主线程loop 来传递.  


跨线程的不同loop,使用在主线程的loop生成的异步连接池 来发请求是不行的.  
不管是任何三方包的socket池,例如 aiomysql aioredis aiohttp httpx 创建的http或者数据库连接池,  
都不能在子线程的loop的异步函数中直接去使用这个连接池中的连接发请求.  
有些异步三方包的连接池能直接在子线程的loop去使用连接发请求或查询数据库而不报错,是因为惰性生成的.  
"""  

"""  
用户一定要搞清楚 线程和loop的绑定关系  
一定要知道为什么不同的loop,不能操作同一个异步连接池发请求或者查询数据库.  

用户一定要多写子线程的loop调用连接池发请求测试demo,这个和funboost本身无关,  
用户的asyncio知识体系太差,用户只会在主线程使用loop,导致对loop和线程绑定关系不懂,对不同loop操作一个连接池不懂.  
在子线程运行异步函数的loop,比在主线程的loop运行难得多,坑也更多.用户需要多写demo例子测试练习,多问ai大模型.  
"""  

# 例如子线程的loop去使用主线程loop绑定的http连接池发请求,会报错如下.  数据库连接池同理也会报错.  
"""  
Traceback (most recent call last):  
  File "D:\codes\funboost\funboost\consumers\base_consumer.py", line 929, in _async_run_consuming_function_with_confirm_and_retry  
    rs = await corotinue_obj  
  File "D:\codes\funboost\test_frame\test_async_consumer\test_child_thread_loop_use_asyncio_sokcet_pool.py", line 64, in async_f2  
    async with ss.request('get', url=url) as resp:  # 如果是这样请求，boost装饰器必须指定specify_async_loop，  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiohttp\client.py", line 1425, in __aenter__  
    self._resp: _RetType = await self._coro  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiohttp\client.py", line 607, in _request  
    with timer:  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiohttp\helpers.py", line 636, in __enter__  
    raise RuntimeError("Timeout context manager should be used inside a task")  
RuntimeError: Timeout context manager should be used inside a task  

"""  

from funboost import boost, BrokerEnum,ConcurrentModeEnum,ctrl_c_recv  
import asyncio  
import aiohttp  
import time  

url = 'http://mini.eastday.com/assets/v1/js/search_word.js'  

loop = asyncio.new_event_loop()  
asyncio.set_event_loop(loop) # 这是重点  
ss = aiohttp.ClientSession(loop=loop) # 这是重点,ss和主线程的loop绑定了.  


@boost(BoosterParams(queue_name='test_async_queue1', concurrent_mode=ConcurrentModeEnum.ASYNC, broker_kind=BrokerEnum.REDIS,  
        log_level=10,concurrent_num=3,  
       specify_async_loop=loop, # specify_async_loop传参是核心灵魂代码,不传这个还要使用主loop绑定的连接池就会报错.  
       is_auto_start_specify_async_loop_in_child_thread=False,  
       ))  
async def async_f1(x):  
    """  
    这个函数是自动被funboost在一个单独的子线程中的loop运行的,loop会并发运行很多协程来执行async_f1的逻辑  
    用户最最需要明白的是,在用funboost的 ConcurrentModeEnum.ASYNC时候,你不是在主线程中操作的异步函数,而是子线程的loop中调用的.  
    假设如果是在主线程中去运行的,你怎么可能连续丝滑启动多个函数消费 f1.consume()  f2.consume()  f3.consume() ? 用脑子想想就知道不是主线程去调用异步函数的.  
    """  

    # 如果是async with ss.request('get', url=url)使用主线程loop的连接池发请求，boost装饰器必须指定 specify_async_loop，  
    # 如果你不使用ss连接池,而是 async with aiohttp.request('GET', 'https://httpbin.org/get') as resp: 那就不需要指定 specify_async_loop  
    
    async with ss.request('get', url=url) as resp:  
        text = await resp.text()  
        print('async_f1', x, resp.url, text[:10])  
    await asyncio.sleep(5)  
    return x  


@boost(BoosterParams(queue_name='test_async_queue2', concurrent_mode=ConcurrentModeEnum.ASYNC, broker_kind=BrokerEnum.REDIS,  
        log_level=10,concurrent_num=3,  
       # specify_async_loop=loop, # specify_async_loop传参是核心灵魂代码,连接池不传这个还要使用主loop绑定的连接池就会报错.  
       is_auto_start_specify_async_loop_in_child_thread=False,  
       ))  
async def async_f2(x):  

    # 如果是async with ss.request('get', url=url)使用主线程loop的连接池发请求，boost装饰器必须指定 specify_async_loop，  
    # 如果你不使用ss连接池,而是 async with aiohttp.request('GET', 'https://httpbin.org/get') as resp: 那就不需要指定 specify_async_loop  
    async with aiohttp.request('get', url=url) as resp:  
        text = await resp.text()  
        print('async_f2', x, resp.url, text[:10])  
    await asyncio.sleep(5)  
    return x  



async def do_req(i):  
    async with ss.request('get', url=url) as resp:  # 如果是这样请求，boost装饰器必须指定specify_async_loop，  
        text = await resp.text()  
        print(f'主线程的loop运行的{i}:',text[:10])  
    await asyncio.sleep(3)  

if __name__ == '__main__':  

    async_f1.clear()  
    async_f2.clear()  
   
    for i in range(10):  
        async_f1.push(i)  
        async_f2.push(i*10)  
      
    async_f1.consume()  
    async_f2.consume()  
  
    # time.sleep(5) 加这个是测试主线程的loop和子线程loop谁先启动,造成的影响,如果子线程的specify_async_loop先启动,主线程下面的 loop.run_forever() 会报错已启动 RuntimeError: This event loop is already running  
    main_tasks = [loop.create_task(do_req(i)) for i in range(20)]  
    loop.run_forever()  # 如果你除了要在funboost运行异步函数,也要在自己脚本调用,那么装饰器配置  is_auto_start_specify_async_loop_in_child_thread=False,,自己手动 启动loop.run_forever()  

    ctrl_c_recv()  

```  






<pre class="warn">  
如果消费async def的消费函数中:  

如果是async with ss.request('get', url=url)使用主线程loop的连接池发请求，boost装饰器必须指定 specify_async_loop，  

如果你不使用ss连接池,而是 async with aiohttp.request('GET', 'https://httpbin.org/get') as resp: 那就不需要指定 specify_async_loop  

用户一定要好好体会下原因,为什么会这样,才能更懂asyncio  
</pre>  


### 6.26.2 演示 aiomysql 连接池在funboost使用,解决 `attached to a different loop`  

用户需要认真看代码里面的文字注释,为什么出现 `attached to a different loop` 经典报错  

代码例子:  
```python  
"""  
此脚本演示, funboost的子线程的loop中怎么操作aiomysql 连接池.  

演示了2种方式使用aiomysql连接池  
方式一:  
async_aiomysql_f1 使用主线程的连接池,.  
核心灵魂代码是 async_aiomysql_f1 的装饰器需要传参specify_async_loop=主线程loop  
如果 async_aiomysql_f1 不指定specify_async_loop,就会出现经典报错 attached to a different loop ,  
子线程的loop去操作主线程loop的连接池,这是大错特错的.  

有的人压根不懂主线程loop和子线程loop,还非要装逼使用asyncio编程生态,  
不精通asyncio编程生态的人应该老老实实使用同步多线程编程生态,简单多了.  
因为funboost的线程池 FlexibleThreadPool能自动扩缩,  
能自动缩容是吊打内置线程池 concurrent.futures.threadpoolexecutor的神级别操作,  
FlexibleThreadPool 去掉了实现futures特性,精简了代码, 性能比官方内置线程池提高了250%  


方式2:  
async_aiomysql_f2_use_thread_local_aio_mysql_pool 使用 thread local 级别的全局变量连接池  
这样子线程的loop避免了操作主线程loop的aiomysql连接池, 不会出现张冠李戴  attached to a different loop  
"""  
import threading  

from funboost import boost, BrokerEnum, ConcurrentModeEnum, ctrl_c_recv, BoosterParams  
import asyncio  
import  time  
import aiomysql  


loop = asyncio.new_event_loop()  
asyncio.set_event_loop(loop) # 这是重点  

DB_CONFIG = {  
    'host': 'localhost',  
    'port': 3306,  
    'user': 'root',  
    'password': '123456',  
    'db': 'testdb',  
    'charset': 'utf8mb4',  
    'autocommit': True  
}  

g_aiomysql_pool : aiomysql.Pool  
async def create_pool():  
    pool = await aiomysql.create_pool(**DB_CONFIG, minsize=1, maxsize=10,) # 这些是重点.  
    global g_aiomysql_pool  
    g_aiomysql_pool = pool  
    return pool  



# 如果 async_aiomysql_f1 不指定specify_async_loop,就会出现经典报错 attached to a different loop ,子线程的loop去操作主线程loop的连接池  
r"""  
Traceback (most recent call last):  
  File "D:\codes\funboost\test_frame\test_async_consumer\test_child_thread_loop_aiomysql_pool.py", line 46, in async_aiomysql_f1  
    await cur.execute("SELECT now()")  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\cursors.py", line 239, in execute  
    await self._query(query)  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\cursors.py", line 457, in _query  
    await conn.query(q)  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\connection.py", line 469, in query  
    await self._read_query_result(unbuffered=unbuffered)  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\connection.py", line 683, in _read_query_result  
    await result.read()  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\connection.py", line 1164, in read  
    first_packet = await self.connection._read_packet()  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\connection.py", line 609, in _read_packet  
    packet_header = await self._read_bytes(4)  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\connection.py", line 657, in _read_bytes  
    data = await self._reader.readexactly(num_bytes)  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\asyncio\streams.py", line 723, in readexactly  
    await self._wait_for_data('readexactly')  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\asyncio\streams.py", line 517, in _wait_for_data  
    await self._waiter  
RuntimeError: Task <Task pending name='Task-2' coro=<AsyncPoolExecutor._consume() running at D:\codes\funboost\funboost\concurrent_pool\async_pool_executor.py:110>> got Future <Future pending> attached to a different loop  

During handling of the above exception, another exception occurred:  

Traceback (most recent call last):  
  File "D:\codes\funboost\funboost\consumers\base_consumer.py", line 929, in _async_run_consuming_function_with_confirm_and_retry  
    rs = await corotinue_obj  
  File "D:\codes\funboost\test_frame\test_async_consumer\test_child_thread_loop_aiomysql_pool.py", line 48, in async_aiomysql_f1  
    print(res)  
  File "D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\utils.py", line 139, in __aexit__  
    await self._pool.release(self._conn)  
RuntimeError: Task <Task pending name='Task-2' coro=<AsyncPoolExecutor._consume() running at D:\codes\funboost\funboost\concurrent_pool\async_pool_executor.py:110>> got Future <Task pending name='Task-22' coro=<Pool._wakeup() running at D:\ProgramData\Miniconda3\envs\py39b\lib\site-packages\aiomysql\pool.py:203>> attached to a different loop  
"""  

"""  
方式一:  
消费函数使用全局g_aiomysql连接池,每个线程都使用主线程的loop来使用连接池查询,所以@boost需要指定specify_async_loop为主线程的loop  
"""  
@boost(BoosterParams(queue_name='async_aiomysql_f1_queue', concurrent_mode=ConcurrentModeEnum.ASYNC, broker_kind=BrokerEnum.REDIS,  
        log_level=10,concurrent_num=3,  
       specify_async_loop=loop, # specify_async_loop传参是核心灵魂代码,不传这个还要使用主loop绑定的连接池就会报错.  
       is_auto_start_specify_async_loop_in_child_thread=True,  
       ))  
async def async_aiomysql_f1(x):  
    await asyncio.sleep(5)  
    async with g_aiomysql_pool.acquire() as conn:  
        async with conn.cursor() as cur:  
            await cur.execute("SELECT now()")  
            res = await cur.fetchall()  
            print(res)  


thread_local = threading.local()  

async def create_pool_thread_local():  
    if hasattr(thread_local, 'aiomysql_pool'):  
        return thread_local.aiomysql_pool  
    pool = await aiomysql.create_pool(**DB_CONFIG, minsize=1, maxsize=5, )  # 这些是重点.  
    setattr(thread_local, 'aiomysql_pool', pool)  
    print('创建了线程级别 threadlocal的 aiomysql连接池')  
    return pool  


"""  
方式二:  
消费函数使用thread_local线程级别全局变量,每个消费函数的那个子线程的loop使用的是线程级别自己的连接池,  
这样就避免了子线程的loop去用 主线程绑定的aiomysqlpool查询数据库,导致报错  

"""  
@boost(BoosterParams(queue_name='async_aiomysql_f2_queue', concurrent_mode=ConcurrentModeEnum.ASYNC, broker_kind=BrokerEnum.REDIS,  
        log_level=10,concurrent_num=3,  
       # specify_async_loop=loop, # specify_async_loop 不需要传递,因为子线程的loop有自己的pool,不使用主线程的pool去查数据库  
       is_auto_start_specify_async_loop_in_child_thread=True,  
       ))  
async def async_aiomysql_f2_use_thread_local_aio_mysql_pool(x):  
    await asyncio.sleep(5)  
    aiomysql_pool_thread_local = await create_pool_thread_local()  
    async with aiomysql_pool_thread_local.acquire() as conn:  
        async with conn.cursor() as cur:  
            await cur.execute("SELECT now()")  
            res = await cur.fetchall()  
            print(res)  




if __name__ == '__main__':  
    loop.run_until_complete(create_pool()) # 先创建pool,aiomysql的pool不能直接在模块级全局变量直接生成.  

    async_aiomysql_f1.clear()  
    async_aiomysql_f2_use_thread_local_aio_mysql_pool.clear()  

    for i in range(10):  
        async_aiomysql_f1.push(i)  
        async_aiomysql_f2_use_thread_local_aio_mysql_pool.push(i*10)  

    async_aiomysql_f1.consume()  
    async_aiomysql_f2_use_thread_local_aio_mysql_pool.consume()  
    ctrl_c_recv()  


```  

### 6.26.3 演示子线程怎么正确的使用aiomysql连接池的本质(和funboost无关但原理相通)  

有些人报错 `RuntimeError:  attached to a different loop`,以为是 funboost的bug,其实是因为压根不懂asyncio的loop知识.  

下面这个代码没有使用funboost来消费async 函数,和funboost原理一样,子线程操作主线程的异步连接池  

```python  


"""  
演示子线程中的loop怎么正确操作 异步aio连接池  

正解就是子线程要使用 asyncio.run_coroutine_threadsafe(aio_do_select(1), 主线程的loop)  

错误做法就是,子线程生成自己的loop,却用主线程的aio连接池查询数据库,造成经典错误  RuntimeError:  attached to a different loop  

funboost的 AsyncPoolExecutor 就是在子线程运行的loop ,需要懂这个例子,才知道为什么操作aio连接池时候, funboost装饰器为什么要把主loop传给 specify_async_loop  
"""  

import threading  

import asyncio  
import  time  
import aiomysql  


loop = asyncio.new_event_loop()  
asyncio.set_event_loop(loop) # 这是重点  

DB_CONFIG = {  
    'host': 'localhost',  
    'port': 3306,  
    'user': 'root',  
    'password': '123456',  
    'db': 'testdb',  
    'charset': 'utf8mb4',  
    'autocommit': True  
}  

g_aiomysql_pool : aiomysql.Pool  
async def create_pool():  
    print(f'主线程 threading id: {threading.get_ident()}')  
    pool = await aiomysql.create_pool(**DB_CONFIG, minsize=1, maxsize=10,) # 这些是重点.  
    global g_aiomysql_pool  
    g_aiomysql_pool = pool  
    return pool  


async def aio_do_select(i):  
    async with g_aiomysql_pool.acquire() as conn:  
        async with conn.cursor() as cur:  
            await cur.execute("SELECT now()")  
            res = await cur.fetchall()  
            print(res)  

def run_do_select_in_child_thread(loopx:asyncio.AbstractEventLoop):  
    """ 查询数据库正确的做法,  
    使用主线程的loop去查数据库.  
    """  
    print(f'子线程 threading id: {threading.get_ident()}')  
    asyncio.run_coroutine_threadsafe(aio_do_select(1), loopx)  # 这是正解  


def run_do_select_in_child_thread_error():  
    """查询数据库错误的写法, 用子线程自己的loop去调用 主线程loop绑定的g_aiomysql_pool,  
     造成经典错误  RuntimeError:  attached to a different loop  
     """  
    print(f'子线程 threading id: {threading.get_ident()}')  
    loop = asyncio.new_event_loop()  
    loop.run_until_complete(aio_do_select(1))  

if __name__ == '__main__':  
    loop.run_until_complete(create_pool())  
    threading.Thread(target=run_do_select_in_child_thread, args=(loop,)).start()  
    threading.Thread(target=run_do_select_in_child_thread_error, ).start()  
    loop.run_forever()  

```  


## 6.28 日志提示 是掉线或关闭消费者的 和 重新放入掉线消费者未消费确认的任务 ,是正常的提示.  


例如提示下面,是完全正常的,是确认消费功能的 重回孤儿消息.  
```  
2025-08-18 12:37:19-(10.0.133.57,LAPTOP-7V78BBO2)-[p58428_t59904] - funboost.RedisConsumerAckAble--test_cost_long_time_fun_queue888 - "confirm_mixin.py:83" - _requeue_tasks_which_unconfirmed - WARNING - no_task_id - test_cost_long_time_fun_queue888__unack_id_LAPTOP-7V78BBO2_10.0.133.57_2025-08-18 12-36-02_46752_2024011500368 是掉线或关闭消费者的  



2025-08-18 12:37:19-(10.0.133.57,LAPTOP-7V78BBO2)-[p58428_t59904] - funboost.RedisConsumerAckAble--test_cost_long_time_fun_queue888 - "confirm_mixin.py:87" - _requeue_tasks_which_unconfirmed - WARNING - no_task_id - 从 test_cost_long_time_fun_queue888__unack_id_LAPTOP-7V78BBO2_10.0.133.57_2025-08-18 12-36-02_46752_2024011500368 向 test_cost_long_time_fun_queue888 重新放入掉线消费者未消费确认的任务 {"x":666,"extra":{"task_id":"test_cost_long_time_fun_queue888_result:7ff6270e-5669-4ee4-8c48-d5b9ba39e3d9","publish_time":1755491762.9382,"publish_time_format":"2025-08-18 12:36:02"}}  
```  

```  
在在选择redis可确认消息的(非BrokerEnum.REDIS)中间件时候,  
例如你应该几把脚本反复部署启动2次kill了其中一个,或者即使只有一个脚本,但是重启后,就会提示这样啊,这是提示把之前kill的消费者进程所持有的待确认消费的消息,重回工作队列, 确保只有确认消费的消息才会真的不再次被调度运行.  
那些运行到一半的函数消息和内存中缓存的一部分消息,在kill后,都会被重回消息队列.  
```  

```  
用户如果不需要确认消费功能,就使用 BrokerEnum.REDIS 模式,这个是no ack 模式.  

以下redis并发模式都是need ack 确认消费的,消息从队列取出来后,只要消息没确认消费,进程被关闭后,孤儿消息下次还会被重回队列  

REDIS_ACK_ABLE  
REIDS_ACK_USING_TIMEOUT  
REDIS_PRIORITY  
REDIS_STREAM  
RedisBrpopLpush  

这些在 BrokerEnum 源码注释中 以及 教程文档中反复说了无数次,用户太懒了不看  
```  





<div> </div> 
`````

--- **end of file: source/articles/c6.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c7.md** (project: funboost_docs) --- 

`````markdown
# 7.更新记录  

## 7.0 很小的更新，对api使用完全无变化或者无增加新功能的不写更新记录。  

## 7.1 新增第十种Consumer，以redis为中间件，但增加了消费确认，是RedisConsumerAckAble类。  

```  
支持运行过程中，随意关闭和启动python程序。无惧反复关闭python和 突然断电导致任务丢失几百个。  

之前开100线程/协程的话，随意重启python和断电会导致极大概率丢失200个任务。  

官方Threadpoolexecutor是无界队列。使用这个会导致丢失无数个任务，  
因为他会迅速把redis的消息全部取出来，添加到自己的queue队列慢慢消费。  
因为这个原因所以需要自定义写BoundedThreadpoolexecutor和CustomThreadpoolexecutor。       

改版的CustomThreadpoolexecutor修改成了queue最大长度是max_works，自己内部存储100个，  
运行中100个，突然关闭python会丢失200个任务。如果queue设置大小为0，则只会丢失100个运行中的任务。  

采用的是消费者去除消息时候，用lua脚本同时pop和添加到unacked的独立zset中，函数运行成功后会从set中删除该任务。  
同时有一个一直每隔5秒发送心跳到redis服务中的线程，心跳标识中有消费者的唯一标识，绝对不会重复。  
如果突然关闭消费者（例如突然断电或者点击关闭python），那么该消费者的心跳将会停止了。这时其他机器的同队列消费者或者当前机器重新启动代码后，在15秒后会  
检到被关闭的消费者是非活跃消费者，那么自动将该消费者的unack里面任务全部重新取出返回到待消费队列中。  

RedisConsumerAckAble类比RedisConsumer会有一丝丝性能损耗，但python玩redis大部分情况还是python代码本身有性能瓶颈，  
而不是造成redis服务端有性能瓶颈，一般只要用在有意义的业务上，就算python很忙把cpu占光了，也不会造成redis服务端达到极限，  
python是性能很差的语言，没玩垮redis，自身就把电脑玩死了，所以大部分情况下不要在意加入确认消费后产生额外的对redis服务端的性能压力。  

redis要是能直接作为mq使用，redis早就一统天下了，哪里还不断有几十种mq出来。  
所以直接基于redis list的如果要做到可靠就必须改进。  
```  

## 7.2 新增基于以redis为消息中间件时候的页面管理和消费速度显示。  

```  
基于redisboard，但对redis的list模拟mq功能，进行页面显示优化突出消息队列消费，  
加黄显示正在运行中的队列和每10秒的消费速度。每隔10秒自动刷新统计。  

由于实时发布和消费，例如10秒内发布20个，消费50个，页面只能显示大小降低了30个，  
这个只有专业的mq才能分别显示出来，redis list只是简单数组。  

rabbitmq nsq都有官方自带速率显示。  
```  

![img_75.png](img_75.png)  


## 7.3 新增一个10行代码的函数的最精简乞丐版实现的分布式函数执行框架.  

新增一个10行代码的函数的最精简乞丐版实现的分布式函数执行框架，演示最本质实现原理，不要亲自这么使用。  

beggar_redis_consumer.py文件的 start_consuming_message函数。  

```python  
def start_consuming_message(queue_name, consume_function, threads_num):  
    pool = ThreadPoolExecutor(threads_num)  
    while True:  
        try:  
            redis_task = redis_db_frame.brpop(queue_name, timeout=60)  
            if redis_task:  
                task_str = redis_task[1].decode()  
                print(f'从redis的 {queue_name} 队列中 取出的消息是： {task_str}')  
                pool.submit(consume_function, **json.loads(task_str))  
            else:  
                print(f'redis的 {queue_name} 队列中没有任务')  
        except redis.RedisError as e:  
            print(e)  


def add(x, y):  
    time.sleep(5)  
    print(f'{x} + {y} 的结果是 {x + y}')  


# 推送任务  
for i in range(100):  
    redis_db_frame.lpush('test_beggar_redis_consumer_queue', json.dumps(dict(x=i, y=i * 2)))  

# 消费任务   
start_consuming_message('test_beggar_redis_consumer_queue', consume_function=add, threads_num=10)  

```  

看完整版代码很长很多，是由于控制功能太多，中间件类型多，并发模式多， 所以加入一个最精简版，精简版的本质实现原理和完整版相同。  

## 7.4 新增sqlachemy 支持的数据库作为消息中间件  

新增sqlachemy 支持的数据库作为消息中间件，包括sqlserver mysql postgre oracle sqlite  

每个队列是一张表模拟的。  

![img_76.png](img_76.png)  

每个任务是表里面的一行记录。  

![img_77.png](img_77.png)  




## 7.5 日志改为导入独立包nb_log，支持用户配置文件自定义日志配置。  

例如设置默认需不需要彩色，需不需要大背景彩色色块，需不需要自动拦截转化python内置的print.  
在用户当前项目根目录下生成的nb_log_config.py 可以自定义优先日志配置。  

## 7.6 优化qps控频。  

```  
将qps按范围分段，采用不同的等待或计数方式。使当qps设置很高的时候，控频更精确。  

增加了分布式控频，需要依赖redis中间件。  
分布式环境中的控频指的是，假如xx.py文件中有一个consumer，设置func函数的qps为10。  
如果在线上部署了三个容器服务，如果不使用分布式控频，则func函数的每秒运行总次数会是30。  
即使只有1台机器，如果开多进程，Process运行3个进程，或者把xx.py反复运行启动3个，  
也会造成func函数每秒运行总次数是30。  
分布式控频主要是解决这种问题。默认不使用分布式控频，  
当设置 is_using_distributed_frequency_control为True的时候，使用分布式控频。  

```  


## 7.7 增加rocketmq支持。 (2020-7)  

```python  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='queue_test_f03', qps=2, broker_kind=BrokerEnum.ROCKETMQ))  
def f(a, b):  
    print(f'{a} + {b} = {a + b}')  


if __name__ == '__main__':  
    for i in range(100):  
        f.push(i, i * 2)  
    f.consume()  

```  

## 7.8 新增 async 并发模式 (2020-12)  

框架希望用户写同步函数，不鼓励用户新写async def的函数，如果你的代码函数已经写成了async def，可以用此种并发方式。  

写async def的函数很烦人，asyncio里面的概念很难学。  

这两个项目用的asyncio你能写出来，能看懂说明不？  

[https://github.com/ydf0509/async_pool_executor](https://github.com/ydf0509/async_pool_executor)  

[https://github.com/ydf0509/sync2asyncio](https://github.com/ydf0509/sync2asyncio)  

```  
之前一直都没支持这种并发模式，异步代码不仅消费函数本身与同步代码很多不同，例如函数的定义和调用以及三方库，  
不同于gevent和eventlet打个猴子补丁就可以变并发方式并且代码保持100%原样，asyncio的方式代比同步码真的是要大改特改。  
而且在框架层面要支持异步也要增加和修改很多，支持异步并不是很容易。这一点连celery5.0目前都还没支持到（据官方文档说5.0要加入支持，但目前的5.0.3还没加入。）  

如果消费函数已经写成了async def这种，那么可以设置 concurrent_mode=ConcurrentModeEnum.ASYNC，  
框架会在一个新的线程的loop里面自动运行协程，所有协程任务会自动在一个loop里面运行，不是每次临时都生成新的loop只运行一个当前任务方式。  
```  

```python  

from funboost import boost, BrokerEnum, ConcurrentModeEnum, BoosterParams  
import asyncio  


# 此段代码使用的是语言级Queue队列，不需要安装中间件，可以直接复制运行测试。  
@boost(BoosterParams(queue_name='test_async_queue2', concurrent_mode=ConcurrentModeEnum.ASYNC,  
           broker_kind=BrokerEnum.LOCAL_PYTHON_QUEUE, concurrent_num=500, qps=20))  
async def async_f(x):  
    # 测试异步阻塞并发， 此处不能写成time.sleep(1),否则无论设置多高的并发，1秒钟最多只能运行1次函数。  
    # 同理asyncio 不能和 requests搭配，要和 aiohttp 搭配。  
    await asyncio.sleep(1)  
    print(id(asyncio.get_event_loop()))  
    # 通过 id 可以看到每个并发函数使用的都是同一个loop，而不是采用了愚蠢的临时 asyncio.new_event_loop().run_until_complete(async_f(x)) 方式调度。  
    print(x)  


if __name__ == '__main__':  
    async_f.clear()  
    for i in range(100):  
        async_f.push(i, )  
    async_f.consume()  

```  

### 7.8.2 gevent/eventlet 和 asyncio 用法区别感受  

 ```  
比方说汽车的自动挡和手动挡，学了手动挡一定会开自动挡，只学自动挡很难开手动挡。  
asyncio方式的代码比正常普通同步思维的代码写法也要难得多了，能玩asyncio的人一定会用threading gevent，  
但只用过threading gevent，不去专门学习asyncio的用法，100%是玩不转的。  

gevent就像自动挡汽车，自动换挡相当于自动切换阻塞。  
asyncio就像手动挡，全要靠自己写 await / async def /loop / run_until_complete /run_forever/   
run_coroutine_threadsafe /wait / wait_for /get_event_loop / new_event_loop / get_running_loop  
 ,写法很麻烦很难。异步多了一个loop就像手动挡汽车多了一个离合器一样，十分之难懂。  

手动挡玩的溜性能比自动挡高也更省油。asyncio玩的溜那么他的io并发执行速度和效率也会更好，cpu消耗更少。  
如果你写一般的代码，那就用同步方式思维来写吧，让分布式函数调度框架来替你自动并发就可以啦。  
如果追求更好的控制和性能，不在乎代码写法上的麻烦，并且asyncio技术掌握的很溜，那就用asyncio的方式吧。   
```  

### 7.8.3 关于 async 并发模式，为什么框架还使用 pyredis pika pymongo，而没有使用aioredis  aiomongo  

```  
异步鬓发模式里面，整个调用链路必须是一旦异步，必须处处异步，在base_consumer.py的AbstractConsumer中，  
方法 _async_run_consuming_function_with_confirm_and_retry里面使用的还是操作中间件的同步库，  

主要是因为框架目前支持15种中间件，一个一个的使用异步模式的库操作中间件来实现，比现在代码起码要增加80%，无异于重写一个项目了。  
异步和同步真的写法语法相差很大的，不信可以比比aiomysql 和pymysql库，aiohttp和requests，如果非常简单能实现异步，  
那aiohttp和aiomysql作者为什么要写几万行代码来重新实现，不在原来基础上改造个七八行来实现？  



目前此库对 消息拉取和消息消费完全是属于在两个不同的线程里面，井水不犯河水，所以用同步库拉取消息对asyncio的消费函数没有任何影响，不存在同步库阻塞异步库的问题。  
对于消息确认 消息重新入队 任务过滤  mongo插入，都是采用的同步库，但是使用了 run_in_executor,  
把这些操作在异步链路中交给线程池来运行了，同事这个线程池不是官方内置线程池，是智能缩小扩大线程池 ThreadPoolExecutorShrinkAble。  
run_in_executor 会把一个同步的操作，sumbit提交给线程池，线程池返回的是一个concurrent.futures包的Future对象，  
run_in_executor包装转化了这个Future(此Future不是asyncio的，不是一个awaitable对象)成为了一个asyncio包的Future对象，asyncio的Future对象可以被await，  
所以这是非常快捷的同步阻塞函数在异步链路中转同步转异步语法的最佳方式。官方也是这么推荐的。  

除了框架内部的阻塞函数是run_in_executor快速转化成非阻塞事件循环的，但是主要的用户的消费函数，是使用的真async模式运行在一个loop循环中的，  
也即是单线陈鬓发运行用户的异步函数。  

其次框架的同步阻塞函数，都是操作中间件类型的库，异步就是 入队 确认消费 查询是否过滤，这些操作一般都会在1毫秒之内完成，不阻塞太长的事件，  
即使不使用run_in_executor，直接在异步链路使用这些同步操作，也没太大问题。一旦异步必须处处异步，说的是不能调用耗时太长的同步阻塞函数，  
1毫秒的无伤大雅，因为celery 1秒钟最多能调度300个 def f： print(hello) 这样的无cpu 无io的函数，此框架调度运行速度任然超过celery。  

     

还有一种调度起 async def定义 的消费函数方式是继续开多线程并发，然后使用 临时loop = asyncio.new_event_loop()，loop.run_until_complete，这方式愚蠢了，  
相当于只是为了运行起这个函数，但全流程丝毫没有丁点异步。  
```  

## 7.8.4 愚蠢的celery调用异步函数写法  
```  
下面截图这种写法为了异步而异步，非常废物滑稽的写法。  
如果是celery多线程并发模式，那就是每个线程里面临时起一个loop，每个生成的loop只运行了一次协程成对象。这样完全没有利用到asyncio的优势  
如果是celery多进程并发模式，那就是每个进程里面临时起一个loop，每个生成的loop只运行了一次协程成对象。这样完全没有利用到asyncio的优势  

celery真正的最终目标是直接能把@task装饰器加到 一个asynnc def的函数上，而不是现在间接的再新增写一个同步函数来调用异步函数。  
到目前为止的最新版 celery 5.2.3还没有实现 直接支持 asyncio 并发模式。  
用户不要抱多大希望celery能很快支持asyncio，例如celery使用kafka做中间件，官方承诺了7年，一次次的放鸽子到现在还不支持，没那么容易。  
```  
![img_22.png](img_22.png)  


## 7.9 2021-04 新增以 redis 的 stream 数据结构 为中间件的消息队列。  

```  
这个是 redis 的 真消息队列，这次是 真mq，  
stream 数据结构功能更加丰富接近 rabbitmq kafka这种真mq的消息队列协议，比 list 做消息队列更强。  
需要redis的服务端5.0版本以上才能使用这个数据结构。  
代码文件在 funboost/consumers/redis_stream_consumer.py  

这个 REDIS_STREAM 中间件和 REDIS_ACK_ABLE 都支持消费确认，不管客户端怎么掉线关闭，都可以确保消息万无一失。  
BrokerEnum.REDIS 中间件 不支持消费确认，随意重启或者断电断线会丢失一批任务。  
```  

```python  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='queue_test_f01', broker_kind=BrokerEnum.REDIS_STREAM))  
def f(a, b):  
    print(f'{a} + {b} = {a + b}')  


if __name__ == '__main__':  
    for i in range(100):  
        f.push(i, b=i * 2)  
    f.consume()  
```  

## 7.10 2021-04 新增以 redis 的 list 为数据结构，但使用 brpoplpush 命令 双队列 作为中间件的消息队列。  

此 brpoplpush 双队列方式 + 消费者唯一id标识的心跳检测，可以媲美 rabbitmq 的确认消费功能。  

```  
代码演示省略，设置broker_kind=BrokerEnum.RedisBrpopLpush就行了。   
@boost(BoosterParams(queue_name='queue_test_f01', broker_kind=BrokerEnum.RedisBrpopLpush))  
```  

## 7.11 2021-04 新增以 zeromq 为中间件的消息队列。  

```  
zeromq 和rabbbitmq kafka redis都不同，这个不需要安装一个服务端软件，是纯代码的。  
zeromq方式是启动一个端口，所以queue_name传一个大于20000小于65535的数字，不能传字母。  
```  

消费端代码，启动消费端时候会自动启动 broker 和 server。  

```python  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='30778', broker_kind=BrokerEnum.ZEROMQ, qps=2))  
def f(x):  
    time.sleep(1)  
    print(x)  


if __name__ == '__main__':  
    f.consume()  

```  

发布端代码  

```python  
from test_frame.test_broker.test_consume import f  

for i in range(100):  
    f.push(i)   
```  

## 7.12 2021-04 新增以 操作kombu包 为中间件的消息队列  

```  
一次性新增操作10种消息队列,.但比较知名的例如rabbitmq redis sqlite3 函数调度框架已经在之前实现了。  
使用方式为设置 @boost 装饰器的 broker_kind 为 BrokerEnum.KOMBU  
在你项目根目录下的 funboost_config.py  文件中设置   
KOMBU_URL = 'redis://127.0.0.1:6379/7' 那么就是使用komb 操作redis。  
KOMBU_URL = 'amqp://username:password@127.0.0.1:5672/',那么就是操纵rabbitmq  
KOMBU_URL = 'sqla+sqlite:////dssf_sqlite.sqlite',那么就是在你的代码所在磁盘的根目录创建一个sqlite文件。四个////表示根目，三个///表示当前目录。  
其余支持的中间件种类大概有10种，不是很常用，可以百度 google查询kombu或者celery的 broker_url 配置方式。  

操作 kombu 包，这个包也是celery的中间件依赖包，这个包可以操作10种中间件(例如rabbitmq redis)，  
但没包括分布式函数调度框架能支持的kafka nsq zeromq 等。  


但是 kombu 包的性能非常差，如何测试对比性能呢？  
可以用原生redis的lpush和kombu的publish测试发布  
使用brpop 和 kombu 的 drain_events测试消费，对比差距相差了5到10倍。  
由于性能差，除非是分布式函数调度框架没实现的中间件才选kombu方式(例如kombu支持亚马逊队列  qpid pyro 队列)，  
否则强烈建议使用此框架的操作中间件方式而不是使用kombu。  

可以把@boost装饰器的broker_kind参数 设置为 BrokerEnum.REDIS_ACK_ABLE 和BrokerEnum.KOMBU(配置文件的KOMBU_URL配置为redis)，  
进行对比，REDIS_ACK_ABLE的消费速度远远超过 BrokerEnum.KOMBU，所以之前专门测试对比celery和此框架的性能，  
差距很大，光一个 kombu 就拉了celery大腿很多，再加上celery的除了kombu的执行性能也很低，所以celery比此框架慢很多。  
test_frame\test_celery 下面有celery的发布 消费例子，可以测试对比下速度，同样gevent 并发和redis中间件，  
celery 执行 print hello 这样的最简单任务，单核单进程每秒执行次数过不了300，celery性能真的是太差了。  

```  

消费  

```python  
import time  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='test_kombu2', broker_kind=BrokerEnum.KOMBU, qps=5))  
def f(x):  
    time.sleep(60)  
    print(x)  


if __name__ == '__main__':  
    f.consume()  
```  

发布  

```python                 
from test_frame.test_broker.test_consume import f  

for i in range(10000):  
    f.push(i)  
```  

你项目根目录下的 funboost_config.py  

```python  
KOMBU_URL = 'redis://127.0.0.1:6379/7'  
# KOMBU_URL = f'amqp://{RABBITMQ_USER}:{RABBITMQ_PASS}@{RABBITMQ_HOST}:{RABBITMQ_PORT}/{RABBITMQ_VIRTUAL_HOST}'  
# KOMBU_URL = 'sqla+sqlite:////celery_sqlite3.sqlite'  # 4个//// 代表磁盘根目录下生成一个文件。推荐绝对路径。3个///是相对路径。  
```  

## 7.14 2021-04 新增以mqtt emq 作为消息中间件  

例子，设置 broker_kind=BrokerEnum.MQTT  

```python  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='mqtt_topic_test', broker_kind=BrokerEnum.MQTT))  
def f(x, y):  
    print(f''' {x} + {y} = {x + y}''')  
    return x + y  


for i in range(100):  
    f.push(i, i * 2)  

f.consume()  
```  

```  
这个默认做成服务端不存储消息，mqtt中间件适合前后端实时交互的。可以直接绕开后端flask django 接口，不用写接口，  
前端直接发任务到mqtt，后端订阅，后端完成后，发送结果到唯一任务的topic  

当然也可以 前端订阅topic，前端发任务到python flask接口，flask接口中发布任务到rabbitmq redis等，  
后台消费完成把函数结果发布到mqtt，mqtt推送给前端  
```  

```  
此框架的消费做成了mqtt的共享订阅，例如启动多个重复的消费者脚本，不会所有消费脚本都去重复处理一个消息  
```  

## 7.15 2021-04 新增以 httpsqs 作为消息中间件  

```  
@boost(BoosterParams(queue_name='httpsqs_queue_test', broker_kind=BrokerEnum.HTTPSQS))  
```  

## 7.16 2021-04 新增支持下一代分布式消息系统 pulsar 。  

```  
@boost(BoosterParams(queue_name='httpsqs_queue_test', broker_kind=BrokerEnum.PULSAR))  

在开源的业界已经有这么多消息队列中间件了，pulsar作为一个新势力到底有什么优点呢？  
pulsar自从出身就不断的再和其他的消息队列(kafka,rocketmq等等)做比较，但是Pulsar的设计思想和大多数的消息队列中间件都不同  
，具备了高吞吐，低延迟，计算存储分离，多租户，异地复制等功能，所以pulsar也被誉为下一代消息队列中间件  

pulsar 的消费者数量可以不受topic 分区数量的限制，比kafka和rabbitmq 强。5年后会替代kafka rabbitmq。  
   
```  

```python  
from funboost import boost, BrokerEnum, BoosterParams  

@boost(BoosterParams(queue_name='test_pulsar_topic2', broker_kind=BrokerEnum.PULSAR, qps=1, broker_exclusive_config={'subscription_name':'funboost_g1'}))  
def add(x,y):  
    print(x+y)  

if __name__ == '__main__':  
    add.push(1,2)  
    add.push(3,4)  
    add.consume()  

```  

## 7.17 2021-04 新增延时运行任务,介绍见4.8  


## 7.18 2021-09 新增 轻松远程服务器部署运行函数  
```  
框架叫分布式函数调度框架，可以在多台机器运行，因为消息队列任务是共享的。  

我用的时候生产环境是使用 阿里云 codepipeline k8s部署的多个容器。还算方便。  
在测试环境一般就是单机多进程运行的，用supervisor部署很方便。  

所以之前没有涉及到多态机器的轻松自动部署。  
如果要实现轻松的部署多台物理机，不借助除了python以外的其他手段的话，只能每台机器登录上然后下载代码，启动运行命令，机器多了还是有点烦的。  
现在最新加入了 Python代码级的函数任务部署，不需要借助其他手段，python代码自动上传代码到远程服务器，并自动启动函数消费任务。  
目前的自动化在远程机器启动函数消费，连celery都没有做到。  

不依赖阿里云codepipeline 和任何运维发布管理工具，只需要在python代码层面就能实现多机器远程部署。  
```  


## 7.19 2021-09 新增 socket udp/tcp/http 消息队列，不需要安装消息中间件软件。  


好处是不需要安装消息队列服务,就可以跨机器通信,详见4.35章节  


## 7.20 2021-09 新增 支持 nats 高性能消息队列  

用法一如既往，只需要修改broker_kind的枚举，并在 funboost_config.py 配置好 NATS_URL 的值就完了。  

```python  
@boost(BoosterParams(queue_name='test_queue66c', broker_kind=BrokerEnum.NATS))  
def f(x, y):  
    pass  
```  


## 7.21 2022-01  新增 @boost装饰器全局默认配置  

boost装饰器没有亲自指定参数时候的全局默认值 ，用法见 4.15 章节 说明  

## 7.22 2022-02 新增暂停消费功能  

框架支持暂停消费功能和继续消费功能，用法见文档4.18  

## 7.23 2022-04 消费者/boost装饰器 新增 broker_exclusive_config 参数  
```  
加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，  
```  
可以看 4.20 章节  

## 7.24 2022-04 新增用户 自定义记录消费状态结果函数钩子  

可以通过设置 user_custom_record_process_info_func 的值为你的自定义函数，来记录消费状态及结果，用户可以自由发挥保存消费结果状态到任意地方  

可以看 4.19章节  

## 7.25 2022-04 新增用户灵活自由自定义扩展中间件和生产消费逻辑的功能  

register_custom_broker 这个是增加的一种很强大的功能,用户可以自定义发布者和消费者，注册到框架中。boost装饰器就能自动使用你的消费者类和发布者类了。  

可以看 4.21 章节  

## 7.26 2022-07 新增内置以redis作为apscheduler存储的定时器，动态增删改查定时任务配置。  

可以看4.4b章节的演示代码例子  

## 7.27 2023-02 新增适配python 3.6-3.11所有版本  

适配python 3.6-3.11所有版本  

适配python 3.10 3.11 的asyncio并发模式，因为官方老是在新版本的asyncio模块，把asyncio的api入参改来改去的，现在适配了。  


## 7.28 2023-02 新增 asyncio 语法生态下rpc获取执行结果  

```  
因为 async_result= fun.push() ，默认返回的是 AsyncResult 类型对象,里面的方法都是同步语法。  
async_result.result 是一个耗时的函数， 解释一下result， 是property装饰的所以不用 async_result.result()  
有的人直接在async def 的异步函数里面 print (async_result.result)，如果消费函数消费需要耗时5秒，  
那么意味rpc获取结果至少需要5秒才能返回，你这样写代码会发生灭顶之灾，asyncio生态流程里面一旦异步需要处处异步。  
所以新增了 AioAsyncResult 类，和用户本来的asyncio编程生态更好的搭配。  
```  

## 7.29 2023-03 新增死信队列  
```  
抛出 ExceptionForPushToDlxqueue 类型错误，消息发送到单独另外的死信队列中,查看文档 4.24.c 和 4.24.d 4.24.e 章节。  
```  

## 7.30 2023-03 新增支持ctrl + c 退出程序   

因为程序是多个子线程while 1的，ctrl+c无法结束程序。 现在框架增内部增加了下面的代码了，可以支持ctrl+c结束程序了。  

```python  
def _interrupt_signal_handler(signal, frame):  
    print('你按了 Ctrl+C  。 You pressed Ctrl+C!  结束程序！')  
    # sys.exit(0)  
    # noinspection PyUnresolvedReferences  
    os._exit(0)  # os._exit才能更强力的迅速终止python，sys.exit只能退出主线程。  


signal.signal(signal.SIGINT, _interrupt_signal_handler)  
```  

看4.6.5章节的演示代码例子  


## 7.31 2023-04 新增支持 celery 作为 broker。  

```  
完全由celery框架来调度函数，发布函数和发布消息都是由celery框架来完成，但是用户无需学习celery语法和celery烦人的配置方式和烦人的celery目录结构，  
用户对celery.Celery对象实例完全无需感知，用户不需要学习celery命令行启动消费和定时，funboost帮你自动搞定这些，用户无需接触celery命令行。  

有的人担心funboost调度执行不稳定，有的人不对比瞎质疑funboost性能没有celery强，那么可以使用celery作为funboost中间件。  
funboost只充当发布和启动消费的一层api，内部由celery驱动。   

funboost的好处是兼容30种消息队列或者叫ptython包，一统使用这些三方包的行为。用户切换中间件成本很低，无需知道每种中间件的语法差异。  
就像sqlachemy能操作5种数据库，用户不需要知道mysql和sqlserver语法差异一样。  

```  

```  
使用celery作为中间件，用户需要在 funboost_config.py  配置  
CELERY_BROKER_URL（必须） 和 CELERY_RESULT_BACKEND （可以为None）  
```  

```python  
from funboost import boost, BrokerEnum, BoosterParams  
@boost(BoosterParams(queue_name=queue_1, broker_kind=BrokerEnum.CELERY))  
```  
python例子见 11.1章节  

##  7.32 2023-04 新增支持 python 微服务框架 nameko 作为 broker。  

```  
nameko 是 外国人用的多的最知名python微服务框架，使用eventlet并发  

funboost支持nameko作为执行调度和rpc实现，funboost只是提供统一的api交互。  
```  

```python  
from funboost import boost, BrokerEnum, ConcurrentModeEnum, BoosterParams  
@boost(BoosterParams(queue_name='test_nameko_queue', broker_kind=BrokerEnum.NAMEKO, concurrent_mode=ConcurrentModeEnum.EVENTLET))  
```  

python例子见 11.2 章节  


## 7.33 2023-05 优化了apscheduler定式框架的动态删除添加定时任务  

FsdfBackgroundScheduler 继承重写了BackgroundScheduler的 _main_loop 方法。  

```python  
class FunboostBackgroundScheduler(BackgroundScheduler):  
    def _main_loop(self):  
        """原来的_main_loop 删除所有任务后wait_seconds 会变成None，无限等待。  
        或者下一个需要运行的任务的wait_seconds是3600秒后，此时新加了一个动态任务需要3600秒后，  
        现在最多只需要1秒就能扫描到动态新增的定时任务了。  
        """  
        MAX_WAIT_SECONDS_FOR_NEX_PROCESS_JOBS = 1  
        wait_seconds = None  
        while self.state == STATE_RUNNING:  
            if wait_seconds is None:  
                wait_seconds = MAX_WAIT_SECONDS_FOR_NEX_PROCESS_JOBS  
            time.sleep(min(wait_seconds,MAX_WAIT_SECONDS_FOR_NEX_PROCESS_JOBS))  # 这个要取最小值，不然例如定时间隔0.1秒运行，不取最小值，不会每隔0.1秒运行。  
            wait_seconds = self._process_jobs()  
```  

## 7.34 2023-05 重新实现了boost装饰器  

对于一个呗@boost装饰的函数，到底应该怎么称呼它？  

之前叫消费函数，消费函数是指的是boost装饰后的还是 原始函数本身，称呼不太明确。  

之前的boost装饰器是使用函数来实现的，没有类型，现在的boost装饰器使用类来实现，一个函数被 boost装饰后，类型是 Booster,现在有类型了。  


```  
之前的boost装饰器是一个函数，在被装饰的函数 fun 本身附加consumer和publisher对象，以及各种方法。  
返回的还是函数本身，但是附加了各种方法，方便用户 fun.push()  fun.consume() fun.get_message_count() 等等。  
为了代码在pycahrm下补全犀利，还加了类型注释，boost的返回值指向一个为了补全犀利而写的 IdeAutoCompleteHelper类。  

修改后的boost就是Booster类，现在boost返回的是 Booster类型的对象，补全效果很好。  
对funboost的功能pycharm自动补全和函数本身的入参pycharm自动补全都很好。去掉了为了补全而写的 IdeAutoCompleteHelper。  

现在一个函数被boost装饰后，他的类型就变成Booster了，可以称此函数为一个booster了。  
```  

重构之后的boost装饰器实现代码：  
[https://github.com/ydf0509/funboost/blob/master/funboost/core/booster.py](https://github.com/ydf0509/funboost/blob/master/funboost/core/booster.py)  

重构之前的boost装饰器实现代码：  
[https://github.com/ydf0509/funboost/blob/e299606a7271e24cae8dea7b9cbbcc400a4f4b0b/funboost/__init__old.py](https://github.com/ydf0509/funboost/blob/e299606a7271e24cae8dea7b9cbbcc400a4f4b0b/funboost/__init__old.py)  



## 7.35 2023-06 新增支持优先级队列  

[funboost支持任务优先级队列](https://funboost.readthedocs.io/zh-cn/latest/articles/c4.html#id29)  


见文档4.29  

## 7.36 2023-07 新增支持 funboost远程杀死任务  

[funboost远程杀死任务](https://funboost.readthedocs.io/zh-cn/latest/articles/c4.html#id35)  

见文档4.30  

## 7.37 2023-07 新增所有命名空间的日志和print都另外写入到一个总的文件中。  

```  
之前的funboost日志，每个命名空间的日志写入到不同的文件，每个队列名的消费者和发布者都有独立的日志命名空间，写入到不同的文件中,是为了用户方便排查。  

例如你查func2的报错和运行记录，只需要到那个func2消费者.log的文件中去排查，这个文件日志不会包含别的消费函数的运行记录。  

但有的人希望是项目中的所有日志 + print 写入到一个相同的文件中，方便排查上下文，这个几乎相当于 nohup 部署然后重定向标准输出到一个文件中了。  
现在python代码级别对print和sys.stdout sys.stderr打了猴子补丁，支持所有print和logger打印另外写入到一个单独的文件中了。这是nb_log的新功能。  
```  

见nb_log文档 [https://nb-log-doc.readthedocs.io/zh_CN/latest/articles/c10.html](https://nb-log-doc.readthedocs.io/zh_CN/latest/articles/c10.html)  

10.1章节和1.1章节里面介绍了，怎么修改是否另外所有日志和print再单独写入到一个总的日志文件中。  

## 7.38 2023-10 多线程并发模式，增加了支持async def的函数  

对于async def 的函数，不需要boost装饰器指定 concurrent_mode=ConcurrentModeEnum.ASYNC ，每个线程内部会临时 loop= asyncio.new_event_loop(),  
然后loop.run_unyil_cpmplete来运行async def的函数。  

这种情况下 每个协程是运行在不同的loop中，这是假asyncio变成。  

如果你想每个协程运行在一个loop里面，那就需要 boost装饰器指定 concurrent_mode=ConcurrentModeEnum.ASYNC，这是真asyncio编程。  




## 7.39 2024-01 @booost装饰器入参变成pydantic Model类型, BoostParams类或子类   

@boost(queue_test_f01', qps=0.2,broker_kind=BrokerEnum.REDIS_ACK_ABLE,)   

建议把所有传参变为放在BoosterParams类或子类里面:  

@boost(BoosterParams(queue_name='queue_test_f01', qps=0.2,broker_kind=BrokerEnum.REDIS_ACK_ABLE,))  



## 7.40 2024-03 函数运行状态页面增加消息运行中状态  

之前是只有消息运行完成后才会显示这条消息，运行中的消息不会显示，现在新增 running 状态的消息。  


![函数状态3.png](%BA%AF%CA%FD%D7%B4%CC%AC3.png)  


## 7.41 2024-03 新增 funboost_current_task 上下文  

之前无法在用户的消费函数内部去获取消息的完全体,只能知道函数的入参,无法知道消息的发布时间 taskid等.  

上下文就是类似flask的request对象,线程中任意地方可以获取,线程/协程隔离.  

```  
用户在任意消费函数中使用fct就能获取当前的任务消息了。  

这个功能使得用户在用户函数中就能知道消息的完全体、 当前是哪台机器 、哪个进程、 第几次重试运行函数  
消息的发布时间  消息的task_id 等等。  

原来用户在消费函数中是无法获取这些信息的。  

见文档4.31  
```  

详见文档4.31  

## 7.42 2024-04 新增支持消费函数定义入参 **kwargs,用于消费任意json消息  

见文档 4b.2 章节介绍.  

## 7.43 2024-05 新增另外一种方式来 自定义增加或重写 消费者 发布者  

见文档 4.21b 章节介绍  

boost装饰器 传参 consumer_override_cls 和 publisher_override_cls 来自定义或重写消费者 发布者。  

## 7.44 2024-06 重磅升级！funboost 支持实例方法、类方法、静态方法、普通函数 4种类型，作为消费函数的例子  

funboost 在 2024年6月新增支持了实例方法、类方法作为消费函数 ，写法见文档4.32章节  

## 7.45 2024-08 @boost入参新增 is_auto_start_consuming_message，定义后立即自动启动消费。  

```  
@BoosterParams(queue_name="q1",  is_auto_start_consuming_message=True)  
def f(x):  
这样写后，自动启动消费，不需要 用户手动的写  f.consume() 来启动消费。  
```  

代码例子见4.33章节  

## 7.46 2024-08 修复使用redis心跳来辅助确认消费的redis中间件模式，重复消费的bug  
```  
用户的 broker_kind 如果是这四种 [BrokerEnum.REDIS_ACK_ABLE, BrokerEnum.REDIS_STREAM, BrokerEnum.REDIS_PRIORITY, BrokerEnum.RedisBrpopLpush]   
用户需要升级到 46.2, 如果不想升级就需要手动指定 @boost(BoostParams(is_send_consumer_heartbeat_to_redis=True))  

用户如果使用的是 BrokerEnum.REIDS 和 BrokerEnum.REIDS_ACK_USING_TIMEOUT 不受影响，因为不使用redis心跳来辅助确认消费。  
```  

![](https://visitor-badge.glitch.me/badge?page_id=distributed_framework)  
<div> </div>  

## 7.47 2025-01 加强了 funboost web manager 功能  

具体看文档13章节。  

## 7.48 2025-07 消费函数的入参类型可以是自定义类型对象(不可json序列化的类型)  

以前作者不愿意支持消费函数入参是自定义类型,2025-07 之后支持了,不愿意支持的原因可以看文档第6章.  

就是现在消费函数的入参可以是 字符串 数字 列表 字典 以外的自定义类型,    
def func1(a:MyClass,b:str,c:MyPydanticModel)  现在可以.  


## 7.49 2025-08 新增Booster对象pickle序列化, 间接支持了 aps_obj.add_job 方式添加定时任务  

- 新增了支持了 Booster 对象 pickle 序列化和反序列化.  

- 新增支持 `aps_obj.add_job` 来添加定时任务,而不是非要使用 `ApsJobAdder.add_push_job` ,具体看文档 4.4.4 章节  

`Booster` 对象能 `pickle` 序列化的核心原理如下:  
```python  
class Booster:  
    def __getstate__(self):  
        state = {}  
        state['queue_name'] = self.boost_params.queue_name  
        return state  

    def __setstate__(self, state):  
        """非常高级的骚操作,支持booster对象pickle序列化和反序列化,设计非常巧妙，堪称神来之笔  
        这样当使用redis作为apscheduler的 jobstores时候,aps_obj.add_job(booster.push,...) 可以正常工作,  
        使不报错 booster对象无法pickle序列化.  
        
        这个反序列化,没有执着于对 socket threding.Lock 怎么反序列化,而是偷换概念，绕过难题,基于标识的代理反序列化  
        """  
        _booster = BoostersManager.get_or_create_booster_by_queue_name(state['queue_name'])  
        self.__dict__.update(_booster.__dict__)  
```  

## 7.50 2025-08 新增 grpc 作为funboost 的 broker  

见文档 **11.7 使用 grpc 作为funboost的broker** ,这个中间件可以通过sync_call方法同步阻塞获取rpc结果,不依赖redis实现rpc  


## 7.51 2025-08 新增支持 mysql_cdc 作为 broker  

`cdc` 就是 `Change Data Capture`,是大数据热门技术。  

这是个特殊的`broker`，基于mysql的binlog cdc ,无需用户主动发布消息,自动捕获 `mysql` 变化的数据转换成消息作为消费者入参。  

见文档 **11.8 使用 mysql_cdc 作为 funboost 的broker**  

**第一性原理: `funboost`使用了 `pymysqlreplication` 包来实现`mysql_cdc`功能**  

## 7.52 2025-10  @boost装饰器,新增设置 booster_group 消费分组  

例如一组函数写 `BoosterParams(booster_group='group1')` ，那么 `BoostersManager.consume_group('group1')` 会启动这组函数消费。

主要是取代用户手动写 `f1.consume()` `f2.consume()`  这样需要多次亲自手写启动相关消费函数。

也避免了 `BoostersManager.consume_all()` 会启动不相关消费函数.


python代码例子,见文档 4.2d.3 章节.



## 7.53 2026-01  新增 funboost.faas，快速实现FaaS（非常好用重要）

给各种流行的python web框架的app，自动注册一组funboost路由，支持的web包括fastapi django flask  
助力用户快速实现  http rpc、从http管理定时任务，队列管理、自动注册和发现 、微服务 、FaaS平台、funboost web管理后台接口 等用途场景。

详细见文档 15 章节。


## 7.54 2026-01 修改了一些拼写错误的名字，（对应funboost 版本 53.0之后）。

本次更新主要修正了部分方法的命名规范及拼写错误。   
为了方便用户快速查阅，我将更新日志整理为一份清晰的对照表，并按模块进行了分类。

### 1. 内部保护方法变更

> **影响范围**：仅影响按照教程 4.21 章节进行继承扩展的高级用户。

| 类名 | 旧方法名 (Old) | 新方法名 (New) |
| --- | --- | --- |
| `AbstractConsumer` | `_shedual_task` | `_dispatch_task` |
| `AbstractPublisher` | `concrete_realization_of_publish` | `_publish_impl` |

---

### 2. 消息发送与配置类变更

> **影响范围**：使用了priority_control_config的用户，一般用户没用到。

| 变更位置 | 旧名称 | 新名称 | 说明 |
| --- | --- | --- | --- |
| `AbstractPublisher.publish` | `priority_control_config` (入参) | `task_options` | 减少歧义，扩大配置涵盖范围 |
| 配置类定义 | `PriorityConsumingControlConfig` | `TaskOptions` | 更加通用化的命名 |

---

### 3. BoosterParams 参数拼写修正

> **影响范围**：公有 API 修正。虽然涉及范围广，但字段较冷门。

| 错误拼写 (旧) | 正确拼写 (新) | 修改类型 |
| --- | --- | --- |
| `is_send_consumer_hearbeat_to_redis` | `is_send_consumer_heartbeat_to_redis` | 拼写纠错 |
| `consumin_function_decorator` | `consuming_function_decorator` | 拼写纠错 |
| `msg_expire_senconds` | `msg_expire_seconds` | 拼写纠错 |

---

### 4. 💡 迁移建议

* **全局替换**：大部分变更只需在 IDE 中进行全局搜索并替换即可完成升级。
* **兼容性**：绝大部分普通用户（仅调用常规 `consume` 或 `push` 的用户）无感知。

### 5. funboost 没有celery的配置变化改动大

celery3到celery4的公有配置名字变化才叫翻天覆地，funboost一直以来，很少改变，这次改变一批。


## 7.55 2026-01 函数结果持久化支持设置表名

FunctionResultStatusPersistanceConfig 增加 table_name 参数，用于设置表名。
之前默认保存的mongo表名同queue_name一致，现在可以自定义。
这就意味着你可以把同一个项目的多个队列的函数结果都放到一个mongo表中。

## 7.56 2026-01 新增 opentelemetry 全链路任务追踪，这是funboost的一个生产级别的重要战略级功能

使用国际w3c的规范协议，基于opentelemetry实现全链路任务追踪。

使用方式，就是可以直接使用OtelBoosterParams  
或者你在你的BoosterParams中指定consumer_override_cls和publisher_override_cls为OtelConsumerMixin和OtelPublisherMixin。


`````

--- **end of file: source/articles/c7.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c8.md** (project: funboost_docs) --- 

`````markdown
  

# 8.用于爬虫  



## 8.0 funboost 用于爬虫前序  

先开门见山：  

- **Scrapy 是 URL 调度器，funboost 是函数调度器；前者束缚你，后者赋能你。**  

- **Funboost 是“写函数就能爬虫”，Scrapy 是“写框架才能爬虫”。**  

- **funboost/boost_spider 对仿scrapy api框架最大优势是 自由编程暴击框架奴役， 能复用用户自己的utils文件夹下的 宝贵资产**

- funboost/boost_spider 和 scrapy 难度差异: 【对于一个刚刚掌握了 Python 基础语法（变量、列表、元组、if/else、for循环）的新手来说】
  - **boost_spider**： 难度要低很多,就和练手手写requests单个小脚本的思路一样，加一行@boost装饰器万事大吉。
  - **仿scrapy框架**：  巨大的框架压迫感，和刚学的基础语法对比，差异鸿沟太大,无限懵逼以至于自我怀疑,刚学的python语法是不是白学了。   
                      直接上手 Scrapy，就像 **一个刚学会骑自行车的人，突然被要求去驾驶一架波音747**。

- **Funboost/boost_spider 天然就是 FaaS 微服务，而 Scrapy 只是数据孤岛,架构模式战略级碾压**
   - 选 `Scrapy`，你是在写脚本。
   - 选 `Funboost`，你是在搭建一个可被全公司调用的**数据采集微服务平台**。  
   - 具体证明见文档`8.14.3`章节, funboost适合全量/增量式离线批处理、实时交互、按需抓取、微服务集成，scrapy不适合动态实时添加种子任务
   - `funboost/boost_spider`不仅支持别的部门通过原生消息队列客户端发布函数入参对应的纯净json到对应的queue_name   
     也支持 `funboost.faas` 快速给你的web服务增加多个funboost路由，一键实现`FaaS(Function as a Service)`   
     自动发现注册爬虫函数，在实时爬虫上对`scrapy-redis`是战略级碾压。  

### funboost scrapy 两种框架写爬虫代码方式代码明显对比

#### funboost框架是自由框架的证据:                   
```python
@boost(BoosterParams(queue_name='flexible_queue'))
def my_task(url):
    """
    在这个函数里，你可以：
    - 使用任何HTTP库 (requests, httpx, aiohttp...)
    - 访问任何数据库 (MySQL, MongoDB, Redis...)
    - 调用任何API (REST, GraphQL, gRPC...)
    - 使用任何框架 (Django ORM, SQLAlchemy...)
    - 执行任何逻辑 (AI推理, 图像处理, 数据分析...)
    
    没有任何限制，没有任何束缚！
    """
    # 完全自由选择HTTP库
    if need_js:
        from playwright import sync_api
        response = get_with_playwright(url)
    elif need_async:
        response = await aiohttp.get(url)
    else:
        response = requests.get(url)
    
    # 完全自由选择数据库
    if use_mongo:
        mongo_client.insert(data)
    elif use_mysql:
        mysql_conn.execute(sql)
    else:
        redis_client.set(key, value)
```

<pre class="warn">
funboost 是自由框架,不仅体现在,用户函数内部可以随意写任何逻辑,   
也体现在 funboost 对用户代码无入侵,没有强迫你像 celery  scrapy django 那样规定死死的目录结构和文件名字,  
也体现在可以加到任何新老项目的任意新旧函数上面.
</pre>



#### scrapy是框架奴役的证据:   
```shell
# Scrapy的"奴役"表现
"""
项目结构被强制规定：
myproject/
    scrapy.cfg
    myproject/
        __init__.py
        items.py      # 被迫定义Item
        pipelines.py  # 被迫使用Pipeline
        settings.py   # 复杂配置
        middlewares.py # 复杂中间件
        spiders/
            __init__.py
            quotes_spider.py # 里面必须 yield Request(url=url_xx,callback=xx_parse,meta={'field1':'xxx','field2':'yyy'})
"""
```

### 8.0.1 tips : 202309 新增boost_spider爬虫框架  
  
pip install boost_spider  

**`boost_spider` = `funboost` 的超跑引擎 + 一套为爬虫量身打造的瑞士军刀。所有仿scrapy api爬虫框架都还是处在变花样造一辆马车**

对于爬虫场景:       
用户怕麻烦,要求天生就爬虫全套方便，就使用 `funboost` + `boost_spider`(内置了便利的 请求 解析 入库3个类)     
用户要绝对自由，就使用 `funboost` + 用户自己自定义的 `utils/` 或 `commons/` 文件夹下封装的 各种工具类和函数    

`boost_spider`不是一个 funboost 插件,因为funboost 不需要插件,   
`boost_spider` 基于 `funboost`的爬虫方便程度增强包,新增了爬虫更方便的3个贡献类,  
新增了一个 `RequestClient` 类 (更适合爬虫的请求类,能一键常规基础反爬,自动请求重试,自动换user agent,自动轮流切换各种ip代理商和代理ip,cookies会话保持),   
和 `SpiderResponse` 请求响应类 (自带xpath,css,re方法,方便parse解析网页源码),    
和 更方便保存字典到各种数据库 的 `DatasetSink` 类(仅需一行代码就把任何字典入库).  

有了这三位一体的爬虫增强方便类, `scrapy`的爬虫框架 "专业"这个优势在 `funboost` 面前荡然无存.

用户可以看8.31章节的介绍, `boost_spider` 和 `funboost`的关系.


boost_spider地址:   
[https://github.com/ydf0509/boost_spider](https://github.com/ydf0509/boost_spider)  

使用boost_spider的代码例子:   
[https://github.com/ydf0509/boost_spider/blob/main/tests/car_home_spider.py](https://github.com/ydf0509/boost_spider/blob/main/tests/car_home_spider.py)  




### 8.0.2 funboost 降维打击仿scrapy api爬虫框架  
你本来只想用Scrapy爬个网页，结果遇见了Funboost  

这就像你本来是想乘坐 木柴蒸汽机，结果直接坐上了量子驱动星际战舰 。   

scrapy写爬虫仪式感代码文件太多，是为了吃个鸡蛋，要先盖个养鸡场。funboost是让你直接开吃。  

因为99%爬虫框架是情不自禁仿scrapy api ，是 基于 yield Request(url=url_xx,callback=my_parse,meta={'field1':'xxx','field2':'yyy'}) 的请求调度框架，扩展相当复杂和难，扩展难、调试难、维护难，难上加难，难到你想转行。  

funboost 吊打任何仿 scrapy api框架，本质是 自由编程 降维打击 框架奴役。  


**scrapy的时代正在成为过去式**  
scrapy的设计哲学诞生于一个需要“框架来定义一切”的时代,这在今天看来，反而成了一种束缚。  

**funboost代表了更现代、更高效的开发范式：**  
<pre style="color: #00ff00;background-color:black ;font-size: large;">  
funboost 相信开发者的能力，只提供最强大的调度核心，将业务逻辑的自由完全交还给用户。  
它的学习成本极低，但能力上限极高，无论是写一个几行代码的临时爬虫，还是构建一个需要数百台机器的庞大采集系统，它都能轻松胜任。  
它更可靠、更灵活、更符合Pythonic的编程直觉。  
</pre>  

<pre style="color: red; background-color:black ;font-size: medium;">  
funboost 让你可以专注于“解决问题”，而 Scrapy 却常常让你把时间花在“解决框架本身的问题”上。作为追求效率和优雅的工程师，选择 funboost 是一个显而易见的决定。  
</pre>  

<pre style="color: red; background-color:black ;font-size: medium;">  
scrapy以及任何仿scrapy api框架,只要是需要用户写 yield Request(url=url_xx,callback=my_parse,meta={'field1':'xxx','field2':'yyy'}) 
就一定被funboost碾压20年以上,无论框架作者代码实力再强都被碾压,因为框架底层设计思维和架构从根本性上被funboost降维打击.
</pre>  

#### funboost 太省时间  
👉 Scrapy: "请继承我的Spider类，重写parse方法，配置settings，注册中间件，添加Pipeline..."  

Funboost: "加个@boost，你随便写，我全搞定！"  

警告⚠️：使用Funboost可能导致严重的空闲时间过剩，请提前规划假期！  

#### @boost 一键赋能你的函数，功能远超爬虫框架  

funboost的@boost装饰器给你的函数赋能，自动调度你的函数，使你的函数自动具备 分布式、断点接续运行、随意重启代码万无一失消费确认、基于函数入参的任务过滤、函数入参有效期过滤、消息过期丢弃、并发种类(线程/协程)设置、并发数量设置、qps限制、全局分布式qps控频、函数出错自动重试、funboost web manager 消费可视化监控、 装饰器自带内置一键入库持久化保存函数结果 、定时运行 , 这些功能不比爬虫框架的功能更多更强吗？  

funboost 轻松一键 多线程/协程  叠加 多进程 ，再叠加多机器，可以轻松做到跑满几百台机器的所有cpu核心，性能非常炸裂，有哪个爬虫框架能一键轻松做得到。  

#### funboost 打破数据孤岛：秒变微服务，Java/Go 随时调用
> **Scrapy 是“数据孤岛”**：它是一个封闭的黑盒，外部系统（如 Java 后端、运营后台）想让它临时抓一条数据，必须魔改代码或通过数据库中转，延迟极高，耦合极重。
>
> **Funboost 是“微服务接口”**：
> 每一个爬虫函数就是一个 **FaaS (Function as a Service)** 接口。
> 外部系统根本不需要知道你是用 Python 写的，只需要往 Redis 队列发一个 JSON，Funboost 就能毫秒级响应，立即执行抓取。
> **这是架构级的胜利：Scrapy 只能做“定时任务”，Funboost 能做“实时服务”。**

#### 有人怀疑 funboost没有http请求中间件，这恰好是对scrapy的最大优势  


反爬对比：  

Scrapy方式：学习中间件理论→阅读源码→理解生命周期→尝试实现→调试失败→怀疑人生→放弃→回去用requests  

Funboost：代码少70%，效率高1000%，头发多10000%！  

```  
对于有人怀疑funboost没对爬虫专门优化，所以肯定不如专用爬虫框架scrapy，   
认为 scrapy 中能写 http请求 middware 来换ip和 user-agent ，所以是scrapy有优势；这是大错特错的想法。  
真实情况是在scrapy api框架中 换 ip 和 user-agent ，你得先精通scrapy 爬虫生命周期和  中间件机制的固定套路写法，  
才能写正确scrapy的middleware。  

而funboost不插手你怎么发请求， 小白用户使用 最简单直观的面向过程 思维，你在你自己项目的utils文件夹下，  
基于requests 定义一个 不到10 行的 通用复用的my_request 的请求函数就能完成换ip和请求头了，完全是0门槛。  
例如:  


import requests  
def my_request(method,url):  
    proxy = random.choice(proxy_list)  
    user_agent = random.choice(user_agent_list)  
    return requests.request(method,url,proxies=proxy,headers={'user-agent':user_agent})  


定义这个 my_request 函数，这不比你在scrapy定义 http middware 简单几百倍 自由几百倍吗？  
requests随便用，httpx随便用，aiohttp随便用，selenium  playwright 随便用，你想怎么玩就怎么玩。  

你只要在 所有funboost的消费函数中始终使用 my_request 来发请求，那 funboost 不就能从万能函数调度框架，  
摇身一变成了你的专属爬虫框架了吗？  
当你还在吭哧吭哧学习scrapy的中间件机制时候，别人已经用funboost的一个装饰器解决了所有问题。  

如果你使用boost_spider框架的RequestClient来发请求，他的response响应上自带了re和xpath css等方法，  
所以你无需羡慕scrapy的response自带xpath方法了，无需纠结requests包的response不内置自带xpath方法了，  
这个细节并不是很重要，你自己也很容易实现,三方包requests_html 的response也自带html结构化解析方法。  
```  

#### funboost能轻松自然完成，而scrapy无法完成的爬虫场景1，浏览器多轮交互  
```  
例如使用 selenium 浏览器渲染页面，并且是需要和浏览器多轮交互，包括 输入文字 -> 点击按钮1 -> sleep等待10秒 ->   
再根据内容的具体的值 -> 判断点击按钮2还是按钮3 -> 等待元素 element_id_xx 出现 -> 再提取解析网页内容，  


因为这个场景下是不仅使用了浏览器渲染url，还需要多轮交互和判断, 这在scrapy下完全无能为力。  


使用scrapy时候，只有 单线程同步勇士 在 parse 解析方法里面去操作浏览器才能非常勉强实现得了，  
但是这把scrapy的twisted异步非阻塞弄成了一个废物，几乎把scrapy框架退化成单线程阻塞执行。  
只有 代码界的扫地僧 才能把浏览器操作也异步化，yield 一个特殊的 Request 或 Item，等待浏览器服务处理完毕后通过某种回调机制，  
将结果返回给 Scrapy 的流程中。但是这种方式实现起来非常复杂，需要精巧的架构设计和对 Scrapy 内部机制的非常深入精通，  
高级python开发工程师都无法做到，只有欧美资深python框架架构师才能做得到。  


然而，这个场景在 funboost 下来完成却十分简单直接自然的轻松搞定，你仅仅需要在你的函数里面像平常一样  
非常自然的写操作浏览器代码。因为你的函数就是个黑盒，funboost能自动并发完成调度执行任意函数。  
```  

**scrapy实现很困难，但funboost实现很丝滑的，见文档8.9章节的token有效期很短的场景2**  

#### 总结下funboost和scrapy在小项目和大项目：  

1、小型爬虫：funboost单文件搞定，不像scrapy要你在七八个文件来回切换写代码。你的爬虫函数验证正确后，  
加个@boost装饰器就自动并发调度了。就算是单机小爬虫，funboost也可以选择sqlite中间件帮你断点续爬。  

2、大型爬虫：funboost的各种控制功能更丰富更强，funboost的轻松一键 多线程/协程  叠加 多进程 ，再叠加多机器，性能吊打scrapy。  
funboost各种控制功能多到你数不过来。  

3、适用范围：scrapy做得到的，funboost一定能更轻而易举做得到； funboost能轻松做得到的，scrapy则复杂到突破天际也无法做得到。  

### 8.0.3 讨scrapy檄文：Funboost兴，Scrapy亡，天下爬虫，当顺天命！  


**夫程序之道，贵在通达！爬虫之术，胜在调度！**    
昔有Scrapy窃据神器，挟Twisted之技而令诸侯，然其框架繁苛，回调如狱，岁月更迭，其势已衰，其道已孤，弊病丛生，开发者苦之久矣！    
今有Funboost，顺天应人，聚函数神力，携`@boost`之雷霆，以大道至简之义，破枷锁，扫陈规，伐无道，正本清源，布告天下！此诚不可逆之大势也！   

**Scrapy十败如山崩，Funboost十胜如日升：**      
然吾观其根基，十败已定！    
吾FunBoost十胜在手，当为天下主！   


一曰：**道失对道胜！**  
Scrapy以URL为心，`Request`为锁，画地为牢，框架奴役，此谓 **"作茧自缚折云翅"**！  
Funboost以函数为本，万物皆可调度，自由挥洒，赋能无限，此谓 **"道法自然贯星河"**！  

二曰：**繁失对易胜！**  
Scrapy项目冗杂，文件七八，层峦叠嶂，初学望而生畏，此谓 **"学海无涯苦作舟"**！  
Funboost一`@boost`统领，化繁为简，片刻上手，举重若轻，此谓 **"大道至简一点通"**！  

三曰：**力失对能胜！**      
Scrapy并发受限，多核难尽其用，遇Selenium则异步变同步，英雄气短，此谓 **"单骑难陷万军阵"**！  
Funboost线程协程，进程机器，四重并发裂苍穹，千机万核竞驰骋，此谓 **"力拔山兮气盖世"**！  

四曰：**估失对准胜！**     
Scrapy仅控并发，QPS随缘而定，精准控频如水中捞月，此谓 **"盲人射马失准的"**！  
Funboost令牌桶在握，QPS量沙准刻，分布式亦能令行禁止，此谓 **"运筹帷幄控毫厘"**！  

五曰：**乱失对明胜！**       
Scrapy回调嵌套，逻辑支离破碎，`meta`传参如雾里看花，调试追踪九曲回肠，此谓 **"回调地狱不见天"**！  
Funboost平铺直叙，代码如行云流水，函数形参IDE烛照，逻辑一气呵成，此谓 **"银河直下三千尺"**！  

六曰：**虚失对固胜！**        
Scrapy断点堪忧，重启则任务灰飞烟灭，断点续爬如镜花水月，此谓 **"大厦将倾一木难"**！  
Funboost消息确认，持久队列作金城汤池，宕机重启岿然不动，万无一失，此谓 **"稳坐钓台风浪平"**！  

七曰：**斥失对容胜！**       
Scrapy旧码难容，迁移需重塑筋骨，大动干戈，劳民伤财，此谓 **"削足适履两相难"**！  
Funboost海纳百川，老树亦能发新枝，已有函数皆可加持，立等可用，此谓 **"万川归海终不弃"**！  

八曰：**梏失对活胜！**       
Scrapy自定义反爬，中间件如天堑难越，非精通其道者不能为，此谓 **"画虎不成反类犬"**！  
Funboost封装请求，自由定义如探囊取物，换IP、UA、破解JS信手拈来，此谓 **"随心所欲不逾矩"**！  

九曰：**拙失对巧胜！**    
Scrapy遇奇巧需求，如Token短时效、多轮浏览器交互、外部动态任务实时添加，则束手无策，左支右绌，此谓 **"黔驴技穷无新声"**！  
Funboost函数之内，连续操作迅雷不及，状态管理自然天成，轻松驾驭复杂流程，此谓 **"灵心胜算巧夺天"**！  

十曰：**晦失对捷胜！**       
Scrapy单元测试如扛泰山，调试艰涩，错误排查如大海捞针，此谓 **"雾锁津迷途难返"**！   
Funboost单函数直刺要害，调试若烹小鲜，IDE相助如虎添翼，可测性无出其右，此谓 **"拨云见日捷报传"**！  

**有此十胜，Funboost伐Scrapy，如金狮搏兔，如高屋建瓴，何愁不克？！**        
Scrapy老将，若迷途知返，弃旧从新，尚可重焕生机；若固执己见，负隅顽抗，必为时代洪流所淘汰！  

**今Funboost大旗已立，携函数调度之利刃，集分布式并发之雄兵：**        
东纳Requests之勇，西引HTTPX之锐；南征Selenium之坚，北抚Playwright之奇！     
聚Redis、RabbitMQ、Kafka为粮草，合多进程、多线程、协程为三军！   


**天下英雄，当明辨是非，顺势而为！**    
弃Scrapy之糟粕，取Funboost之精华！    
开发者再不必叩拜Spider宗庙，亦无需忍受回调地狱之煎熬！   
此乃爬虫之文艺复兴，调度之工业革命！       
**剑锋所指，框架枷锁必将斩断！函数光辉，普照四海！**    

**与诸君共勉，开创万物皆可Boost之盛世！**      

**FunBoost大都督，布告天下！**    




### 8.0.4 很多人问这个框架能不能爬虫？  

答：此框架不仅可以对标celery框架，也可以取代scrapy框架。  

无论是比 自由度、兼容常规代码程度、用户需要编写的实际代码行数、消息万无一失可靠度、对爬虫的qps频率/并发控制手段、超高速调度请求， 此框架从以上任何方面远远超过scrapy，一切都是只会是有过之而无不及。  



<pre style="color: #2e8ece;font-size: small">  
应该还是主要是很浮躁，不仅没看详细文档，应该是连简介都没看。  
分布式函数调度框架，定位于调度用户的任何函数，只要用户在函数里面写爬虫代码，就可以分布式调度爬虫，并且对爬虫函数施加20种控制功能,  
例如 qps恒定 任何时候随意关机重启代码消息万无一失确认消费 非常简单的开启多进程叠加线程/协程,这些强大的功能绝大部分爬虫框架还做不到。  

此框架如果用于爬虫，不管从任何方面比较可以领先scrapy20年，也比任意写的爬虫框架领先10年。  
不是框架作者代码编写实力问题，主要是思维问题，爬虫框架一般就设计为url请求调度框架，url怎么请求都是被框内置架束缚死了，  
所以有些奇葩独特的想法在那种框架里面难以实现，需要非常之精通框架本身然后改造框架才能达到随心所欲的驾驭的目的。  
而此框架是函数调度框架，函数里面可以实现一切任意自由想法，天生不会有任何束缚。  
主要还是思想问题，国内一般人设计的爬虫框架都是仿scrapy api，天生不自由受束缚。  
</pre>  


### 8.0.5 为什么 funboost 用来爬虫时候，扩展性简单性 远超 scrapy api式的一众传统爬虫框架？  
```  
funboost 扩展很容易，因为funboost是调度一个函数，不是调度一个url请求，用户可以在函数内部无拘无束实现任何想法，  
不用顾忌思考怎么和funboost适配，用户在函数内部想写什么是天生更自由的。  
比如用户想使用哪种 http请求包发请求，想使用什么三方包包来解析html，想把爬虫数据保存到什么类型的数据库，  
怎么使用不同供应商的代理ip ，用户完全自主发挥，而不用思考和funboost框架本身怎么适配。  

funboost 在易扩展性方面的一个显著优势，尤其是在与那些结构更固化的框架（如专门的爬虫框架）进行对比时。  

核心原因正如所指出的： funboost 调度的是函数，而不是特定的操作（如 URL 请求） 。  

这带来了几个关键的好处，使得在函数内部的扩展和定制变得非常容易：  

1. 函数即"黑盒" : 对于 funboost 调度器来说，被 @boost 装饰的函数在很大程度上是一个"黑盒"。   
   funboost 负责触发这个函数的执行（根据队列消息或定时设置）、管理并发、处理重试等，但它 不关心函数内部具体做了什么 。  

2. 完全的内部自由度 : 在这个函数"黑盒"内部，开发者拥有完全的自由：  
   - HTTP 请求 : 你想用 requests , httpx , aiohttp ，或者任何其他 HTTP 客户端库都可以， funboost 不会干涉。  
   - HTML/数据解析 : 使用 lxml , beautifulsoup4 , parsel , json , re 或任何你喜欢的解析库，完全没问题。  
   - 数据存储 : 直接调用 pymongo , redis-py , psycopg2 , mysql-connector-python , sqlalchemy , dataset  
     等库将数据存入 MongoDB, Redis, PostgreSQL, MySQL 或其他任何数据库/文件系统。  
   - 代理 IP : 对接任何代理 IP 服务商的 API 或 SDK，实现复杂的代理切换逻辑。  
   - 任何业务逻辑 : 在函数内部可以编写任意复杂的 Python 代码，调用其他模块、类，实现你的业务需求。  
3. 无需适配框架内部机制 : 因为 funboost 不强制规定函数内部的实现方式，所以你不需要去学习和适配 funboost 内部  
   可能存在的特定请求对象、响应对象、Item 结构或 Pipeline 接口（除非像 boost_spider 这样在上层做了封装）。你只需要编写标准的 Python 代码即可。  
   
总结来说：  
funboost 的这种设计哲学，将 任务调度 与 任务执行的具体实现 解耦开来。它提供了一个强大的、通用的函数调度平台，  
而将函数内部的实现细节完全交给了开发者。这种模式极大地降低了在 任务逻辑层面 进行扩展和定制的复杂度，  
让开发者可以"无拘无束"地使用整个 Python 生态系统来实现功能，而无需过多考虑与调度框架本身的适配问题。这确实是它易用性和灵活性的一大体现。  
```  

funboost在处理特殊奇葩需求时确实远超scrapy这类API式框架，主要体现在：  
```  
处理复杂流程的能力：  
funboost允许在单一函数中编写完整业务逻辑  
scrapy需要拆分为多个回调，使复杂流程变得支离破碎  

状态管理简洁度：  
funboost可使用普通Python变量保存状态  
scrapy需要通过meta字典在请求间传递，容易出错  

特殊时序要求处理：  
funboost可精确控制请求发送时机  
scrapy受调度器影响，无法保证确切执行时间  

条件逻辑和分支：  
funboost支持自然的if/else/for/while等控制流  
scrapy需要通过不同回调和meta实现，极度复杂化  

异常处理方式：  
funboost可使用标准try/except处理整个流程  
scrapy各回调间异常隔离，难以统一处理  

资源释放与清理：  
funboost支持with语句和上下文管理  
scrapy在分散的回调中难以管理资源生命周期  

调试和问题排查：  
funboost代码线性执行，容易跟踪  
scrapy回调跳转使调试变得困难  

与外部系统集成：  
funboost可在任何点与外部API交互  
scrapy需要特殊中间件或信号处理  

对于要求精确控制、复杂交互、特定时序或依赖外部系统的"奇葩需求"，funboost的流程式编程模型确实具有压倒性优势，能够以更直观、更可靠的方式实现这些复杂需求。  
```  


此框架如果用于写爬虫，建议的写法是一种页面(或者接口)对应一个函数,例如列表页是一个函数，详情页是一个函数。 1个函数里面只包括一次请求(也可以两三次请求，但不要在函数本身里面去for循环遍历发十几个请求这种写法)，  

### 8.0.6 主动集中简要回答驳斥一些scrapy 优势更大的观点  

知道有些人会质疑说scrapy爬虫更好，有些人举的scrapy更强的例子，喜欢以卵击石，以弱击强，倒反天罡，必须集中统一回答反驳。  

#### **你质疑funboost 没有 http middware ？**  

你这个想法就像是在说"没有被大铁链子束缚的奴隶不好当"一样搞笑！

```   
答：上面已经回答了，用户手写定义一个通用的 my_request 更强更自由更简单。  
```  

#### **你质疑funboost 没有 pipeline，质疑保存数据麻烦？**  

你这个想法就像是在说"没有被大铁链子束缚的奴隶不好当"一样搞笑！

这个问题问得好，但结论恰恰相反！**没有 Pipeline 正是 Funboost 的巨大优势**，因为它让你摆脱了不必要的束缚。  
`Funboost`: 一行代码，一个文件，逻辑高度内聚，极其灵活。  
`Scrapy`: 四个文件，几十行模板代码，逻辑支离破碎，极其死板。  

```    
答：用户可以自己封装一个保存字典到数据库的函数，最简单就是使用dataset知名包,只要一行代码就能保存字典到mysql postgre 数据库了。   
boost_spider 就是自带了 datasetsink 类,dataset_sink1.save('your_table', data_dict),简单直观多了。


反观,scrapy 的 pipeline 反而才是杀鸡用牛刀 过度设计分层,为了保存一个字典需要切换写四个文件,
你单纯想喝瓶水而已, 但被迫建一个矿泉水生产线。
scrapy保存数据需要来回切换4个文件写代码:
第一步,在 items.py 定义Item类型
第二部,在 your_spider.py 的 parse_xx 中 yield item
第三部,在 pipelines.py 中 process_item 方法中判断不同item类型,从而保存到对应的表中.
第四部,在 settings.py 的 ITEM_PIPELINES 中配置 指定pipeline类(如果忘了这一步就白忙活了)
```  

#### **你说Scrapy 插件生态丰富，质疑Funboost 没有三方包插件生态不够？**  

`funboost` 不需要任何插件,是无招胜有招.  
     
- scrapy插件多是“病”，不是“药” 。Python pypi生态就是funboost的生态，你的python项目下的 utils/ 或者 helpers/ 文件夹下日积月累的各种工具类和函数都是 funboost的生态, funboost不需要各种funboost-xx的三方包插件。

- 说插件多就是生态好，这么想法的人简直是没长脑子，用户已经会了三方包的使用，但在scrapy框架下，为什么还需要等专门的美国编程大神去给三方包开发插件适配scrapy框架的生命周期和组件流程，才能在scrapy中愉快的使用三方包。用户压根没想过这个问题。  

详细的驳斥看文档8.14.2章节  

- Scrapy 插件多 ≠ 框架强，恰恰说明了框架对用户自由的压制太多，“什么都得经过官方那一套”。          
Funboost 是函数式的框架，自由度高、无约束、无钩子、无上下文依赖，天然就能融合任何三方库，python三方包生态就是funboost的生态，你utils下积累的工具类和函数都是 funboost的生态。
- funboost不需要学 scrapy-redis scrapy-selenium scrapy-playwright  scrapy-user-agents  scrapy-splash 专门开发各种 funboost-xx 的三方包插件。funboost压根不需要三方包插件，而不是三方包插件生态薄弱。      


```  
答： scrapy是框架太复杂了约束多钩子多，所以需要由专门的大神开发三方插件，因为普通人写不出来这些插件。  
Scrapy 框架的结构设计“高度抽象 + 强约束 + 多钩子生命周期 + 中间件堆叠机制”，导致插件开发成本极高。  
funboost 恰恰不需要插件，因为用户是轻松自由使用任意三方包。  
你压根不需要专门的大神给你写个例如 funboost-selenium 类似的插件，才能开始在funboost里面使用selniuem干活，懂了吗？  

例如 如 scrapy-redis 用于分布式、scrapy-playwright 或 scrapy-selenium 用于 JavaScript 渲染，scrapy-user-agents换请求头。   
funboost需要学习这些扩展插件怎么使用吗？ 绝对不需要，funboost 是顺其自然自由使用任意三方包。。  
麻烦你去看看配置使用 scrapy-selenium 有多麻烦，而直接使用 seleium 有多简单。  
本来学习selenium就烦人，你还要再多学习一个 scrapy-selenium ，  
凭什么非要这么苦逼，学了各种三方包还不够，还需要额外再另外学这么多三方包的插件。  
```  

因为你用scrapy，即使你非常精通三方包，如果没有美国大神给你提供三方包的插件，你仍然寸步难行，所以你羡慕scrapy有各种三方包的插件生态。         
你用Scrapy，哪怕精通三方包，没有插件也寸步难行；用Funboost，任何三方包都能直接用，不需要等别人给你造插件轮子。     
当你可以直接驾驶F1赛车时，为什么还非要学习如何给破自行车安装火箭推进器？  

```  
举个例子：  
为什么你用scrapy-redis插件？因为你就算精通了py-redis包的用法，精通了怎么redis.blpop redis.lpush推拉消息，精通了怎么redis.sadd 去重  
但是你不知道怎么完美替代scrapy内置的调度器和去重器，因为你不可能开发的出来，关键难度不是怎么操作reids，而是难以适配scrapy的中间件机制和生命周期钩子懂啦吗?  
不信的你可以看scrapy-redis源码,你能写得了那么好？  
你以为你随便在代码哪里简单的写个redis.blpop 和 redis.lpush，scrapy就能完美使用你写的redis代码逻辑来调度运行起来吗？  
```  

**开发效率的巨大差异**  
**使用Scrapy：**       
学习Scrapy框架 → 2. 学习要用的包 → 3. 等待/寻找插件 → 4. 学习插件用法 → 5. 配置插件 → 6. 开始开发  
**使用Funboost：**     
学习要用的包 → 2. 开始开发  


#### 你项目下的 utils 文件夹的工具类是黄金还是废铁？取决于你用什么哲学的框架

- 详细见文档 8.0b 章节

Python pypi生态就是funboost的生态，你的python项目下的 utils/ 或者 helpers/ 文件夹下日积月累的各种工具类和函数都是 funboost的生态,   
例如你的爬虫项目 utils 文件夹下日积月累，99%的概率已经存在很多好用的经过实战检验的爬虫工具类和函数，可以直接被 import 复用使用。
 

#### **你说scrapy社区支持，有庞大的专门各种问题的讨论？质疑funboost没有社区？**  
```   
因为scrapy太难了，用户必须精通scrapy框架本身，精通scrapy各种组件和生命周期，用户难以自由扩展，所以需要讨论。  
funboost是你写一个函数，你可以在函数里面自由自在写任何代码，你在写你的消费函数里面是自由的，  
不需考虑funboost框架本身的约束，不需要考虑怎么和funboost配合。  
funboost 没有需要讨论的，因为funboost 是顺其自然自由使用任意三方包。  

例如假设你不会pymysql插入数据，那去pymysql论坛讨论，这和funboost没关系。  
例如假设你不会 selenium 操作，那去selenium论坛讨论，这和funboost没关系。  
例如你不会requests使用代理ip，那去requests论坛讨论，这和funboost没关系。  
例如你不会使用xpath解析html，那去xpath论坛讨论，这和funboost没关系。  
```  

#### **你羡慕scrapy的response有自带.xpath .css .extract_first .extract_all 方法？**  
```  
答：你可以看看boost_spider项目的response，也有xpath方法，实现很简单。  
这些真的很简单啊，你的my_request函数可以是返回一个带有这些方法的response对象就好了。  
封装一个带有这些方法的Response类型的对象简直不要太简单。  
```  

#### **scrapy twisted 性能强悍？担心funboost爬取不快？**  
```   
答： 没有funboost 的 多机器 + 多进程 + asyncio强。 asyncio才是未来。  
拿scrapy的短处去攻击funboost的长处，以卵击石。  
```   

#### **你质疑scrapy重试功能强大？**  
```  
答：funboost 的函数重试功能远远暴击scrapy的url重试功能(防丢数据2),你可以看8.13.2章节。  
如果http状态码200，但是页面反扒，scrapy会丢失大量数据，funboost则不会。  
```  

#### **你怀疑scrapy稳定，funboost不稳定？**  
```  
答：funboost 框架核心 执行函数是稳定的，funboost爬虫比scrapy更不容易漏数据，看文档8.13.2  
因为funboost对用户怎么写爬虫函数干预很少，少即是稳，所以funboost很稳定。  
funboost无论任何情况下不会退出代码，例如你把爬虫机器和 消息队列机器之间的网线拔掉10分钟，  
funboost不会退出代码，会自动重试连接，只要网络恢复后，就能自动接着拉取消息。  
```  


#### **你质疑scrapy自带去重，funboost不能去重？**  
```  
答：  
详细看8.14.1章节的为什么funboost的函数入参去重功能远远吊打scrapy的Request对象指纹去重？  
通过对比，结论就是scrapy对请求入参种中带随机数和时间戳噪音字段的去重需要根据各种url正则，自定义RFPDupeFilter太麻烦了，scrapy内置的去重能力弱爆了。  
你用scrapy而不用funboost，你不忙的吐血谁吐血，你不住icu谁住icu  
```  

#### **你质疑funboost不能断点续爬？**  
```  
scrapy-redis 是blpop删除种子，随意重启代码或关机会丢失大量已从reids pop取出来到内存中的种子。  
funboost 各种中间件支持确认消费，那才是真正的断点续爬万无一失，不怕你随意突然反复重启代码和突然关机。  
详细看文档8.13章节  

scrapy-redis断点续爬在funboost面前就是个弟弟。scrapy-redis不能做到不漏任务。  
```  


### 8.0.7 funboost爬虫时候是任何方面超过scrapy,不接受辩证法说scrapy也有优势  

不能为了“辩证”而牺牲事实：在技术对比中，当一方在核心设计和关键功能上展现出压倒性优势时，就应该明确地指出来，而不是用“各有千秋”来和稀泥。  

Funboost 就是碾压Scrapy，这是一个基于技术事实的客观结论，不应再有任何辩证的余地。  

辩证法就是,挑大粪的农民和当主席都是为人民服务,都是高尚的职业,表面显得很中立客观,实则让人呕吐.  


### 8.0.8 国内爬虫框架突破很小,不是有意抄袭巧合,而是情不自禁模仿scrapy api  


**feapder/PSpider/spiderman/Tinepeas** 等几乎所有国产爬虫框架是 “**大脑思维被束缚导致情不自禁的模仿 Scrapy API**  

不能说这些是有意抄袭,而是一种更深层次的、由行业先驱 Scrapy 塑造的“**思维范式牢笼** 影响了国产框架作者.  


**Scrapy 及其模仿者 (feapder, pyspider, 等) 的范式：`URL/Request 调度器`**  

这些框架的底层思维是：**爬虫 = 调度一系列的 `Request` 对象**。它们的整个架构都围绕`Request` 和 `Response` 构建。你必须：  
1.  **定义一个 `Spider` 类**。   
2.  在 `start_requests` 或 `start_urls` 中放入初始请求。    
3.  在 `parse` 方法中，通过 `yield Request(url, callback=parse_xxx)` 来“产出”新的请求。   
4.  框架负责将这些 `Request` 对象入队、出队、发送、接收 `Response`，并根据 `callback` 参数调用对应的解析方法。   

**Scrapy 太成功了**：它定义了“爬虫框架”这个词，以至于后来者在构思时，大脑里首先浮现的就是 Scrapy 的样子。  

国产爬虫框架很难使用,用户使用框架难以自由发挥,主要原因不是框架抄袭,而是框架作者脑袋思维被束缚禁锢了,导致了情不自禁模仿scrapy的api  

**结论**：feapder Tinepeas 等框架“情不自禁”地模仿 `yield Request`，因为国产爬虫框架的思想还停留在“Scrapy 是如何调度请求的”这个层面，而没有跳出思考“我们真正需要调度的是什么”。它们复制了 Scrapy 的“形”（回调、中间件、管道），却未能突破其“神”（对开发者自由的限制）。  


## 8.0b 你的 utils 文件夹是黄金还是废铁？取决于你用什么哲学的框架

- **funboost/boost_spider 对仿scrapy api框架最大优势是 自由编程暴击框架奴役， 能复用用户自己的 utils 宝贵资产**

- scrapy的三方包插件，各种 scrapy-xx 插件，例如 scrapy-redis scrapy-playwright scrapy-selenium scrapy-user-agents scrapy-splash 等等，三方包插件总量不会超过1000个.
  只有pypi的三方包才是星辰大海，100万多个pypi三方包都是你的工具。  
  **最重要的是，只有用户自己项目下utils文件夹下积累的工具类和函数才是最符合用户自己实际需求的工具，而不是 scrapy-xx 插件。**

- Python pypi生态就是funboost的生态，你的python项目下的 utils/ 或者 helpers/ 文件夹下日积月累的各种工具类和函数都是 funboost的生态,   
  例如你的爬虫项目 utils 文件夹下日积月累，99%的概率已经存在如下，好用的经过实战检验的工具类和函数： 
  
```python
def anti_request(method,url,...retry_times=3,is_change_ua=True,is_change_proxy):
   """自动重试 换代理ip  user-agent 的http请求函数""" 

def save_to_mysql(data:dict): 
    """保存字典到数据库的函数"""

class RedisBloomFilter:
    """redis 布隆过滤器"""
    def is_exists(self, key):
        ...
    def add(self, key):
        ...
    
def extract_all_with_join(selector, separator=' '):
    """提取选择器所有结果并用指定分隔符连接成字符串。"""
    return separator.join(selector.getall()).strip()

class WebsiteAuthenticator:  
    """对于需要登录的网站，一个管理会话、Cookie 和 Token 的类是无价之宝。"""
    def login(self):
        ...
    def get_session(self):
        ...

def send_email_notification(subject, body, recipient):
    """发送爬虫邮件通知。"""

def download_and_upload_to_s3(url, bucket_name, object_name):
    """下载文件并直接流式上传到 S3。"""
    s3 = boto3.client('s3')
    with requests.get(url, stream=True) as r:
        r.raise_for_status()
        s3.upload_fileobj(r.raw, bucket_name, object_name)
    return f"s3://{bucket_name}/{object_name}"
    
```

**在 funboost中**，你utils文件夹下的宝贵资产，黄金任然是黄金，可以直接import 复用使用： 
```python
from funboost import boost, BrokerEnum
from utils.http_client import anti_request  # 你日积月累的工具
from utils.db import save_to_mysql        # 你日积月累的工具
from utils.redis_dedup import RedisBloomFilter   # 你日积月累的工具
from utils.website_authenticator import WebsiteAuthenticator   # 你日积月累的工具
from utils.send_notification import send_email_notification   # 你日积月累的工具
from utils.download_and_upload import download_and_upload_to_s3   # 你日积月累的工具
```
**而在`scrapy` `feapder`面前**，你曾经引以为豪在`utils`文件夹下积累的宝贵资产，他不是黄金，只是一堆破铜烂铁而已，不能被导入复用。    
你没有按照他们框架的`Downloader Middleware` 和 `Pipeline`规范写的`utils`文件夹下的工具类，都是废铁一文不值。  
`scrapy`的扩展插件机制 被 `funboost` 的自由import复用吊打。

- 复用用户自己的 utils 宝贵资产，正是 `funboost`  区别于 `Scrapy/Feapder` 等传统框架的**根本性优势**，是战略层面的胜利。

*   **`utils` 是开发者的“内功心法”**：一个开发者的 `utils` 文件夹，是他/她多年经验的结晶，是解决特定领域问题的最佳实践沉淀。它包含了对业务逻辑的深刻理解，是**不可替代的、高度定制化的“私有武器库”**。
*   **“复用 `utils`” = 复用经验和智慧**：一个框架如果能让开发者无缝地复用自己的 `utils`，就意味着它尊重并放大了开发者的个人能力和历史积累。开发者可以用最熟悉、最高效的方式解决问题。
*   **“无法复用 `utils`” = 废掉武功，重练套路**：`Scrapy/Feapder` 的插件和中间件机制，本质上是让你放弃自己的“内功”，去学习并练习一套它们规定好的“套路招式”。你的 `my_request` 函数再精妙，也得改成 `Downloader Middleware` 的形状；你的 `save_to_mysql` 再高效，也得塞进 `Item Pipeline` 的模子里。这是一个**巨大的、隐性的成本**。


## 8.1 演示获取汽车之家资讯的 新闻 导购 和 评测 3个板块 的 文章。  

页面连接 https://www.autohome.com.cn/all/  

```  
这是一个非常经典的列表页-详情页两层级爬虫调度。演示爬虫一定最少需要演示两个层级的调度，只要会了两层级爬虫，3层级就很简单。  
此框架如果用于写爬虫，建议的写法是一种页面(或者接口)对应一个函数,例如列表页是一个函数，详情页是一个函数。  
1个函数里面只包括一次请求(也可以两三次请求，但不要在函数本身里面去for循环遍历发十几个请求这种写法)，  
```  

```text  
"""  
演示分布式函数调度框架来驱动爬虫函数，使用此框架可以达使爬虫任务 自动调度、 分布式运行、确认消费万无一失、超高速自动并发、精确控频、  
种子过滤(函数入参过滤实现的)、自动重试、定时爬取。可谓实现了一个爬虫框架应有的所有功能。  

此框架是自动调度一个函数，而不是自动调度一个url请求，一般框架是yield Requet(),所以不兼容用户自己手写requests urllib的请求，  
如果用户对请求有特殊的定制，要么就需要手写中间件添加到框架的钩子，复杂的需要高度自定义的特殊请求在这些框架中甚至无法实现，极端不自由。  

此框架由于是调度一个函数，在函数里面写 请求 解析 入库，用户想怎么写就怎么写，极端自由，使用户编码思想放荡不羁但整体上有统一的调度。  
还能直接复用用户的老函数，例如之前是裸写requests爬虫，没有规划成使用框架爬虫，那么只要在函数上面加一个@boost的装饰器就可以自动调度了。  

而90%一般普通爬虫框架与用户手写requests 请求解析存储，在流程逻辑上是严重互斥的，要改造成使用这种框架改造会很大。  
此框架如果用于爬虫和国内那些90%仿scrapy api的爬虫框架，在思想上完全不同，会使人眼界大开，思想之奔放与被scrapy api束缚死死的那种框架比起来有云泥之别。  
因为国内的框架都是仿scrapy api，必须要继承框架的Spider基类，然后重写 def parse，然后在parse里面yield Request(url,callback=annother_parse)，  
请求逻辑实现被 Request 类束缚得死死的，没有方便自定义的空间，一般都是要写middware拦截http请求的各个流程，写一些逻辑，那种代码极端不自由，而且怎么写middware，  
也是被框架束缚的死死的，很难学，例如scrapy 集成selenium浏览器没几个人搞定，就算实现了也是同步阻塞导致scrapy的并发成为了废物，  
当你把scrapy的并发调度弄成了废物了还有必要用什么scrapy。  
例如崔庆才 写的scrapy集成selenium浏览器，文章在 https://cuiqingcai.com/8397.html ，如果网站网页需要渲染30秒，那么此时scrapy爬虫慢的吐血，  
因为这种扩展scrapy的方式是错误的。  
还有人在scrapy的Spider类的解析方法里面用浏览器重复请求一次url，scrapy的parse不是并发的，只有yield Request类请求是自动并发，  
下面parse中写浏览器请求，scrapy就变成了个废物。  
def parsexx(self,response):  
    driver.get(response.url)  

分布式函数调度框架由于是自动调度函数而不是自动调度url请求，所以天生不存在这些问题。  

用其他爬虫框架需要继承BaseSpider类，重写一大堆方法写一大堆中间件方法和配置文件，在很多个文件夹中来回切换写代码。  
而用这个爬虫，只需要学习 @boost 一个装饰器就行，代码行数大幅度减少，随意重启代码任务万无一失，大幅度减少操心。  

这个爬虫例子具有代表性，因为实现了演示从列表页到详情页的分布式自动调度。  

"""  

"""  
除了以上解释的最重要的极端自由的自定义请求解析存储，比普通爬虫框架更强的方面还有：  
2、此爬虫框架支持 redis_ack_able rabbitmq模式，在爬虫大规模并发请求中状态时候，能够支持随意重启代码，种子任务万无一失，  
   普通人做的reids.blpop，任务取出来正在消费，但是突然关闭代码再启动，瞬间丢失大量任务，这种框架那就是个伪断点接续。  
3、此框架不仅能够支持恒定并发数量爬虫，也能支持恒定qps爬虫。例如规定1秒钟爬7个页面，一般人以为是开7个线程并发，这是大错特错，  
  服务端响应时间没说是永远都刚好精确1秒，只有能恒定qps运行的框架，才能保证每秒爬7个页面，恒定并发数量的框架差远了。  
4、能支持 任务过滤有效期缓存，普通爬虫框架全部都只能支持永久过滤，例如一个页面可能每周都更新，那不能搞成永久都过滤任务。  
因为此框架带有20多种控制功能，所以普通爬虫框架能实现的控制，这个全部都自带了。  
"""  

```  

爬虫任务消费代码  

代码在 https://github.com/ydf0509/distributed_framework/tree/master/test_frame/car_home_crawler_sample/test_frame/car_home_crawler_sample/car_home_consumer.py  


关于对下面funboost爬虫代码的质疑？  
```  
有人说这里的代码是不真实的，没有 换代理ip useragent，也没有保存结果到数据库。还有人说没有演示破解js 加密。  

每次请求自动换代理ip和ua这个功能你自己写个函数不就完了，把这里的requests.get换成你自己定义的换ip的请求函数就完了，一个函数的事情而已。  

至于保存到数据库，  
你自己把 print(f'保存数据  {news_type}   {title} {author} {url} 到 数据库') 这行改成插入数据库就完了。你自己定义一个函数mysql连接池插入数据库就完了。  

这些不是重点所以不需要精确细致的演示，只需要演示爬虫重要的并发调度。其余的怎么发http请求 保存到什么数据库，自己定义一个函数，不就每个爬虫函数里面万能通用了？难道需要无数次重复写怎么换ip发请求吗？  

还有人故意找茬说这汽车之家网站太简单了，没有包括破解，这个代码演示没有意义，框架是为了演示并发调度，搞一堆破解代码掺杂在里面没有必要。你用scrapy框架就能自动破解网站了吗？  
我采用的是控制变量法耐对比不同框架写代码所需的行数，又没让scrapy爬加密网站用这个funboost爬简单网站导致对比不公平。  
如果需要做破解加密，那么funboost集成破解流程肯定比scrapy集成破解要更容易随心所欲的写。  


```  


```python  
import requests  
from parsel import Selector  
from funboost import boost, BrokerEnum, BoosterParams  


@boost(BoosterParams(queue_name='car_home_list', broker_kind=BrokerEnum.REDIS_ACK_ABLE, max_retry_times=5, qps=10))  
def crawl_list_page(news_type, page, do_page_turning=False):  
    """ 函数这里面的代码是用户想写什么就写什么，函数里面的代码和框架没有任何绑定关系  
    例如用户可以用 urllib3请求 用正则表达式解析，没有强迫你用requests请求和parsel包解析。  
    """  
    url = f'https://www.autohome.com.cn/{news_type}/{page}/#liststart'  
    resp_text = requests.get(url).text  # 此处你可以换成你自己封装好的 my_request 请求函数来换代理ip请求网页  
    sel = Selector(resp_text)  
    for li in sel.css('ul.article > li'):  
        if len(li.extract()) > 100:  # 有的是这样的去掉。 <li id="ad_tw_04" style="display: none;">  
            url_detail = 'https:' + li.xpath('./a/@href').extract_first()  
            title = li.xpath('./a/h3/text()').extract_first()  
            crawl_detail_page.push(url_detail, title=title, news_type=news_type)  # 发布详情页任务  
    if do_page_turning:  
        last_page = int(sel.css('#channelPage > a:nth-child(12)::text').extract_first())  
        for p in range(2, last_page + 1):  
            crawl_list_page.push(news_type, p)  # 列表页翻页。  


@boost(BoosterParams(queue_name='car_home_detail', broker_kind=BrokerEnum.REDIS_ACK_ABLE, qps=50,  
           do_task_filtering=True, is_using_distributed_frequency_control=True))  
def crawl_detail_page(url, title, news_type):  
    resp_text = requests.get(url).text #   # 此处你可以换成你自己封装好的 my_request 请求函数来换代理ip请求网页  
    sel = Selector(resp_text)  
    author = sel.css('#articlewrap > div.article-info > div > a::text').extract_first() or  
    sel.css('#articlewrap > div.article-info > div::text').extract_first() or ''  
    author = author.replace("\n", "").strip()  
    print(f'保存数据  {news_type}   {title} {author} {url} 到 数据库')  # 用户自由发挥保存。  

if __name__ == '__main__':  
    # crawl_list_page('news',1)  
    crawl_list_page.consume()  # 启动列表页消费  
    crawl_detail_page.consume()  
    # 这样速度更猛，叠加多进程  
    crawl_detail_page.multi_process_consume(4)  
```  

爬虫任务发布代码  

代码在 https://github.com/ydf0509/distributed_framework/blob/master/test_frame/car_home_crawler_sample/car_home_publisher.py  

```python  
from funboost import ApsJobAdder  
from test_frame.car_home_crawler_sample.car_home_consumer import crawl_list_page, crawl_detail_page  

crawl_list_page.clear()  # 清空列表页  
crawl_detail_page.clear()  # 清空详情页  

# # 推送列表页首页，同时设置翻页为True  
crawl_list_page.push('news', 1, do_page_turning=True)  # 新闻  
crawl_list_page.push('advice', page=1, do_page_turning=True)  # 导购  
crawl_list_page.push(news_type='drive', page=1, do_page_turning=True)  # 驾驶评测  

# 定时任务，语法入参是apscheduler包相同。每隔120秒查询一次首页更新,这部分可以不要。  
for news_typex in ['news', 'advice', 'drive']:  
    ApsJobAdder(crawl_list_page, job_store_kind='redis').add_push_job('interval', seconds=120, kwargs={"news_type": news_typex, "page": 1, "do_page_turning": False,id='timing_publish_job_first_page_'+news_typex})  

```  

```  
从消费代码可以看出，代码就是常规思维的平铺直叙主线程思维写代码，写函数代码时候无需考虑和框架怎么结合，写完后加个@boost装饰器就行了。  
因为这不是类似国内的仿scrapy框架必须要求你必须继承个什么类，强迫你重写什么方法，然后yield Request(your_url,callback=my_parse,meta={'field1':'xxx','field2':'yyy'})  
此框架爬虫既能实现你无拘无束使用任意包来请求url和解析网页，又能很方便的使用到自动超高并发 超高可靠性的万无一失断点续传。  
```  

qps设置为很低时候，为了展示更多控制台日志流程细节，分布式函数调度框架驱动爬虫函数的慢速爬取运行截图。  
![](img_7.png)  

qps设置高时候的运行截图，分布式函数调度框架驱动爬虫函数的快速爬取运行截图。  
![](img_6.png)  

## 8.2 演示经典的豆瓣top250电影的爬虫  

页面连接 https://movie.douban.com/top250  

```  
这是一个非常经典的列表页-详情页两层级爬虫调度。演示爬虫一定最少需要演示两个层级的调度，只要会了两层级爬虫，3层级就很简单。  

此框架如果用于写爬虫，建议的写法是一种页面(或者接口)对应一个函数,例如列表页是一个函数，详情页是一个函数。  

1个函数里面只包括一次请求(也可以两三次请求，但不要在函数本身里面去for循环遍历发十几个请求这种写法)，  
```  

```python  
from funboost import boost, BrokerEnum, BoosterParams  
import requests  
from parsel import Selector  

HEADERS = {'User-Agent': 'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0)', }  


@boost(BoosterParams(queue_name='douban_list_page_task_queue', broker_kind=BrokerEnum.PERSISTQUEUE, qps=0.1))  # qps 自由调节精确每秒爬多少次，远强于一般框架只能指定固定的并发线程数量。  
def craw_list_page(page):  
    """ 函数这里面的代码是用户想写什么就写什么，函数里面的代码和框架没有任何绑定关系，框架只对函数负责，不对请求负责。  
    例如用户可以用 urllib3请求 用正则表达式解析，没有强迫你用requests请求和parsel包解析。  
    """  
    """ 豆瓣列表页，获取列表页电影链接"""  
    url = f'https://movie.douban.com/top250?start={page * 25}&filter='  
    resp = requests.get(url, headers=HEADERS) #   # 此处你可以换成你自己封装好的 my_request 请求函数来换代理ip请求网页  
    sel = Selector(resp.text)  
    for li_item in sel.xpath('//*[@id="content"]/div/div[1]/ol/li'):  
        movie_name = li_item.xpath('./div/div[2]/div[1]/a/span[1]/text()').extract_first()  
        movei_detail_url = li_item.xpath('./div/div[2]/div[1]/a/@href').extract_first()  
        craw_detail_page.push(movei_detail_url, movie_name)  
    # craw_list_page.push(page=11) # 如果你要动态获取总页数，而不是一开始就知道总共有10页，可以在craw_list_page函数里面进行消息推送，调用 craw_list_page.push，没有递归死循环调用列表页爽歪歪。  


@boost(BoosterParams(queue_name='douban_detail_page_task_queue', broker_kind=BrokerEnum.PERSISTQUEUE, qps=4))  
def craw_detail_page(detail_url, movie_name):  
    """豆瓣详情页，获取电影的详细剧情描述。"""  
    resp = requests.get(detail_url, headers=HEADERS) #   # 此处你可以换成你自己封装好的 my_request 请求函数来换代理ip请求网页  
    sel = Selector(resp.text)  
    description = sel.xpath('//*[@id="link-report"]/span[1]/text()[1]').extract_first().strip()  
    print('保存到数据库：', movie_name, detail_url, description)  


if __name__ == '__main__':  
    # craw_list_page(0)  
    # craw_detail_page('https://movie.douban.com/subject/6786002/','触不可及')  
    for p in range(10):  
        craw_list_page.push(p)  
    craw_list_page.consume()  
    craw_detail_page.consume()  
```  

<pre class="warn">
在使用 funboost 写爬虫时候,函数里面不要写try except 捕获异常,因为框架会自动捕获任何请求异常 /解析异常/ 操作数据库异常
,并自动重试.   如果你写了try 却不抛出异常, 框架就无法自动给你重试.
</pre>

### 8.2.2 funboost 对比网上的 scrapy 爬取 douban代码  

[https://github.com/wxmseu/douban_scrapy/tree/master/douban](https://github.com/wxmseu/douban_scrapy/tree/master/douban)  

```  
对比网上的scrapy 爬取douban代码，funboost在 qps控频 并发方式 代码行数少 文件数量少 远远的暴击scrapy  
使用同步requests发请求的写法平铺直叙横冲直撞的思维特点，远远的暴击scrapy写出的不兼容代码 yield Request。  

爬陌生新网站肯定是先用requests这种包简单的发请求，测试反爬和解析，测试验证解决了反爬或者无反爬，再将代码用到框架中，  
因为直接使用框架来开始探索一个陌生新网站爬虫，万一爬不到，在框架中写了一大堆代码，做了一大堆无用功，精力损失很大。还有就是在爬虫框架中调试爬取一个特定的url也没有单脚本+requests那么随心所欲方便。  

funboost可以套用到已存在的requests测试探索代码，因为funboost是函数调度框架，兼容一切函数的调度，不要求用户修改已有代码。  
而scrapy和feapder和pspider这种为了使用这种框架，需要把已存在的发送请求和解析的代码大改特改再移到框架中，非常的不方便。  

任何人写新的爬虫框架只要是仿scrapy api用法和scrapy的项目目录结果，如果需要写 yield Request(url,callback=self.parse_xx,meta={'field1':'xxx','field2':'yyy'})，和funboost比，就已经输了，无需再看他框架源码用多么美妙的设计模式和面向对象设计出来的了。  
只要模仿这个scrapy api用法，思维被束缚大脑不灵活开发出的爬虫框架写法和scrapy一样烦人，那么开发这样的一个新框架就没什么必要存在了。  
```  

## 8.3 演示3种最常见代码思维方式爬取汽车之家资讯  

演示了三种方式爬汽车之家，是骡子是马拉出来溜溜，必须精确对比。  

```  
第一种是 无框架每次临时手写全流程代码，每次临时设计手写爬虫调度全流程  
第二种是 使用scrapy框架来爬取，用户要写的代码行数很多，文件很多，对于特殊独特奇葩想法极端不自由  
第三种是 使用分布式函数调度框架来自动调度常规函数  
```  

### 8.3.1 每次临时手写rquests + 多线程,使用low爬虫方式的缺点  

```  
这样搞有以下缺点：  
1、不是分布式的，不能多个脚本启动共享任务  
2、不能断点爬取，即使是内置Queue改成手写使用redis的普通pop，要实现确认消费每次写一大堆代码，很难。  
3、如果要调试爬虫，要反复手动自己手写添加print或log调试信息  
4、写得虽然自己认为没有用爬虫框架很简洁，但导致接盘侠不知道你的代码的设计布局和意思  
5、自己每次临时灵机一动搞个临时的爬虫调度设计，没有固定套路，难维护，接盘侠一个个的看每个爬虫是怎么设计布局和调度的  
6、需要每次临时手写操作queue任务队列  
7、需要临时手写并发  
8、每次需要临时手写如何判断和添加过滤任务  
9、需要临时手写怎么提取错误重试。  
10、需要临时动脑筋设计怎么调度,浪费自己的时间来思考，每次都重复思考重复设计重复写爬虫全流程。  
```  

### 8.3.2 scrapy 爬虫框架来实现缺点  

scrapy 爬虫框架来实现，（本质是Request 对象自动调度框架）  

```  
scrapy_proj_carhome 是 scrapy_redis 弄得项目，写项目需要背诵scrapy 命令行，  
并且要反复在spiderxx.py  settings.py items.py pipeliens.py   
middwares.py push_start_urls.py run.py 7个文件里面来回切换写代码,  
如果一年只临时要写一次爬虫效率很低，比low爬虫还写的慢。  

需要500行，实际要手写或者修改的行数为150行，如果是写多个爬虫，平均每次实际手写的代码函数会降低一些。  

```  

### 8.3.3 scrapy 框架 和 分布式函数调度框架爬虫对比  

```  
不是分布式函数调度框架比scrapy爬虫框架代码质量好，主要是理念问题，  
Request对象自动调度框架永远没法和函数自动调度框架的灵活自由性相比。  
```  

```  
scrapy 自动调度 全靠 yield Request( url, callback=None, method='GET', headers=None, body=None,  
                 cookies=None, meta=None, encoding='utf-8', priority=0,  
                 dont_filter=False, errback=None, flags=None)  
本质就是自动框架自动调度 Request对象，虽然入参比较丰富，大部分想法都能通过传参来搞定，但如果是一些自定义的想法，  
要加到scrapy项目中就非常难。写任何一行代码都要考虑与框架的集成，  
不能随便用 requests ，urllib3 ，selenium ，独立的每两个页面间的cookie自定义关联 等 乱自己来写请求，  
包括换proxies要写中间件然后把类加到settings里面也是烦得要死。  

比如一个很愚蠢的想法写法,在详情页解析回调这么写代码，这样瞎写完全没有考虑scrapy框架的感受。  

    def parse_detail_page(self, response):  
        driver = Chrome()  
        driver.get(response.url)  
        text = driver.page_source  
        
scrapy框架能自动并发调度运行Request请求,但不能自动并发运行parse方法。  
第一，selenium会阻塞框架。  
第二，reponse本来就是一个响应结果了，他是已经被scrapy的urllib请求了，只要解析结果就好了，但这么一写有用浏览器打开一次url，  
等于是请求了两次页面，这样请求两次 是嫌电脑cpu太好 还是 流量太便宜了呢。  

总之使用了scrapy后就是写任何代码不能乱写，要多考虑框架的感受。  

只有celery这样的函数和函数入参自动调度才能很香，  
scrapy这样的固化的 Request对象入参 + 自定义中间件类添加到 settings里面的 自动调度很不自由。  

```  

```  
分布式函数调度框架是通过把函数的入参推到队列(支持15中队列，包括语言级Queue队列  sqlite队列 redis队列 各种mq队列)，  
然后框架会自动从对应的队列取出任务，自动并发的运行对应的函数。函数里面怎么写那就非常自由了，你想随便有什么想法怎么写都可以，  
这种方式是极端的自由和灵活，只需要按同步的思维写常规思维的函数，最后加个装饰器就能自动并发了，写函数的时候完全不用考虑框架的束缚。  
任何函数都能被自动并发调度。  

以下这些功能对爬虫的各种控制例如 精确的每秒爬几次  分布式中间件支持种类  消费确认 对爬虫的辅助控制远强于scrapy。  

分布式：  
    支持数十种最负盛名的消息中间件.(除了常规mq，还包括用不同形式的如 数据库 磁盘文件 redis等来模拟消息队列)  

 并发：  
    支持threading gevent eventlet asyncio 四种并发模式 + 多进程  
   
 控频限流：  
    例如十分精确的指定1秒钟运行30次函数（无论函数需要随机运行多久时间，都能精确控制到指定的消费频率；  
   
 分布式控频限流：  
    例如一个脚本反复启动多次或者多台机器多个容器在运行，如果要严格控制总的qps，能够支持分布式控频限流。  
  
 任务持久化：  
    消息队列中间件天然支持  
   
 断点接续运行：  
    无惧反复重启代码，造成任务丢失。消息队列的持久化 + 消费确认机制 做到不丢失一个消息  
   
 定时：  
    可以按时间间隔、按指定时间执行一次、按指定时间执行多次，使用的是apscheduler包的方式。  
   
 指定时间不运行：  
    例如，有些任务你不想在白天运行，可以只在晚上的时间段运行  
   
 消费确认：  
    这是最为重要的一项功能之一，有了这才能肆无忌惮的任性反复重启代码也不会丢失一个任务  
   
 立即重试指定次数：  
    当函数运行出错，会立即重试指定的次数，达到最大次重试数后就确认消费了  
   
 重新入队：  
    在消费函数内部主动抛出一个特定类型的异常ExceptionForRequeue后，消息重新返回消息队列  
   
 超时杀死：  
    例如在函数运行时间超过10秒时候，将此运行中的函数kill  
   
 计算消费次数速度：  
    实时计算单个进程1分钟的消费次数，在日志中显示；当开启函数状态持久化后可在web页面查看消费次数  
   
 预估消费时间：  
    根据前1分钟的消费次数，按照队列剩余的消息数量来估算剩余的所需时间  
   
 函数运行日志记录：  
    使用自己设计开发的 控制台五彩日志（根据日志严重级别显示成五种颜色；使用了可跳转点击日志模板）  
    + 多进程安全切片的文件日志 + 可选的kafka elastic日志  
               
 任务过滤：  
    例如求和的add函数，已经计算了1 + 2,再次发布1 + 2的任务到消息中间件，可以让框架跳过执行此任务。  
    任务过滤的原理是使用的是函数入参判断是否是已近执行过来进行过滤。  
   
 任务过滤有效期缓存：  
    例如查询深圳明天的天气，可以设置任务过滤缓存30分钟，30分钟内查询过深圳的天气，则不再查询。  
    30分钟以外无论是否查询过深圳明天的天气，则执行查询。  
    
 任务过期丢弃：  
    例如消息是15秒之前发布的，可以让框架丢弃此消息不执行，防止消息堆积,  
    在消息可靠性要求不高但实时性要求高的高并发互联网接口中使用  
            
 函数状态和结果持久化：  
    可以分别选择函数状态和函数结果持久化到mongodb，使用的是短时间内的离散mongo任务自动聚合成批量  
    任务后批量插入，尽可能的减少了插入次数  
                  
 消费状态实时可视化：  
    在页面上按时间倒序实时刷新函数消费状态，包括是否成功 出错的异常类型和异常提示   
    重试运行次数 执行函数的机器名字+进程id+python脚本名字 函数入参 函数结果 函数运行消耗时间等  
                 
 消费次数和速度生成统计表可视化：  
    生成echarts统计图，主要是统计最近60秒每秒的消费次数、最近60分钟每分钟的消费次数  
    最近24小时每小时的消费次数、最近10天每天的消费次数  
                            
 rpc：  
    生产端（或叫发布端）获取消费结果。各个发布端对消费结果进行不同步骤的后续处理更灵活，而不是让消费端对消息的处理一干到底。  

```  

### 8.3.4 临时low方法手写爬虫全流程的代码 （手写多线程 + queue 分发调度 ）  

临时low方法手写爬虫全流程的代码 （手写多线程 + queue 分发 ）  

<pre>  
这样搞有以下缺点：  
1、不是分布式的，不能多个脚本启动共享任务  
2、不能断点爬取  
3、如果要调试爬虫，要反复手动自己手写添加print或log调试  
4、写得虽然自己认为没有用爬虫框架很简洁，但导致接盘侠不知道你的代码的设计布局和意思  
5、自己每次临时灵机一动搞个临时的爬虫调度设计，没有固定套路，难维护，接盘侠一个个的看每个爬虫是怎么设计布局和调度的  
6、需要每次临时手写操作queue任务队列  
7、需要临时手写并发  
8、每次需要临时手写如何判断和添加过滤任务  
9 需要临时手写怎么提取错误重试。  
10、需要临时动脑筋设计怎么调度,浪费自己的时间来思考  
</pre>  

```python  

from queue import Queue, Empty  
import time  
import requests  
from urllib3 import disable_warnings  
from parsel import Selector  
from concurrent.futures import ThreadPoolExecutor  
from threading import Thread  
import redis  

disable_warnings()  

queue_list_page = Queue(1000)  
queue_detail_page = Queue(1000)  

pool_list_page = ThreadPoolExecutor(30)  
pool_detail_page = ThreadPoolExecutor(100)  

# detail_task_filter_set = set()  
r = redis.Redis()  


def crawl_list_page(news_type, page):  
    def _run_list_page_retry(current_retry_times):  
        try:  
            url = f'https://www.autohome.com.cn/{news_type}/{page}/#liststart'  
            print(f'请求的列表页url是 {url}')  
            resp = requests.request('get', url, timeout=5)  
            if resp.status_code != 200:  
                raise ValueError  
            resp_text = resp.content.decode('gbk')  
            sel = Selector(resp_text)  
            for li in sel.css('#Ul1 > li'):  
                url = 'https:' + li.xpath('./a/@href').extract_first()  
                title = li.xpath('./a/h3/text()').extract_first()  
                task = (url, title)  
                print('向详情页队列添加任务：', task)  
                queue_detail_page.put(task)  
            if page == 1:  
                last_page = int(sel.css('#channelPage > a:nth-child(12)::text').extract_first())  
                for p in range(2, last_page + 1):  
                    task = (news_type, p)  
                    print('向列表页页队列添加任务：', task)  
                    queue_list_page.put(task)  
        except Exception as e:  
            print(f'第{current_retry_times}次爬取列表页出错', e.__traceback__, e)  
            if current_retry_times < 5:  
                _run_list_page_retry(current_retry_times + 1)  
            else:  
                print('重试了5次仍然错误')  

    _run_list_page_retry(1)  


def crawl_detail_page(url, title):  
    def _run_detail_page_retry(current_retry_times):  
        if r.sismember('filter_carhome_detail_page', url):  
            print(f'此入参已经爬取过了 {url} {title}')  
            return  
        else:  
            try:  
                print(f'请求的详情页url是 {url}')  
                resp = requests.request('get', url, timeout=5)  
                if resp.status_code != 200:  
                    raise ValueError  
                resp_text = resp.content.decode('gbk')  
                sel = Selector(resp_text)  
                author = sel.css('#articlewrap > div.article-info > div > a::text').extract_first() or  
                         sel.css('#articlewrap > div.article-info > div::text').extract_first() or ''  
                author = author.replace("\n", "").strip()  
                print(f'{time.strftime("%H:%M:%S")} 保存到数据库 {url} {title} {author} ')  
                r.sadd('filter_carhome_detail_page', url)  # 运行成功了，放入过滤中  
            except Exception as e:  
                print(f'第{current_retry_times}次爬取详情页页出错', e.__traceback__, e)  
                if current_retry_times < 3:  
                    _run_detail_page_retry(current_retry_times + 1)  
                else:  
                    print('重试了3次仍然错误')  
                    r.sadd('filter_carhome_detail_page', url)  # 运行最大次数了，放入过滤中  

    _run_detail_page_retry(1)  


def start_list_page():  
    while True:  
        try:  
            task = queue_list_page.get(block=True, timeout=600)  
            print(f'取出的列表页爬取任务是 {task}')  
            pool_list_page.submit(crawl_list_page, *task)  
        except Empty:  
            print('列表页超过600秒没有任务，列表页爬完了')  
            break  


def start_detail_page():  
    while True:  
        try:  
            task = queue_detail_page.get(block=True, timeout=600)  
            print(f'取出的详情页爬取任务是 {task}')  
            pool_detail_page.submit(crawl_detail_page, *task)  
        except Empty:  
            print('详情页超过600秒没有任务，详情页爬完了')  
            break  


if __name__ == '__main__':  
    # 单独的测试函数功能  
    # crawl_list_page('advice',1)  #  
    # crawl_detail_page('https://www.autohome.com.cn/news/202008/1022380.html#pvareaid=102624','xxx')  

    t1 = Thread(target=start_list_page)  
    t2 = Thread(target=start_detail_page)  
    t1.start()  
    t2.start()  

    queue_list_page.put(('news', 1))  # 新闻  
    queue_list_page.put(('advice', 1))  # 导购  
    queue_list_page.put(('drive', 1))  # 评测  

```  

举个网上下载 mzitu 网站图片的代码截图，就是采用的无框架爬虫，任务调度靠直接for循环调用函数，任务并发全靠手写操作threads，  

这样的代码看起来很多很混乱，写一个还行，要是爬虫项目多了，没有统一化的逻辑思维，接盘侠每次都要阅读很长的代码才知道运行逻辑，那就非常悲催。  

![img_13.png](img_13.png)  



### 8.3.5 scrapy爬虫代码  

这是scrapy爬虫代码的基本结构，用户写代码需要非常频繁的在 spider items middware pipeline settings cmd命令行 来回切换写代码测试代码，很吓人。  

需要在不同的地方写middleware类 pipeline类并把类名添加到settings里面。  

scrapy目录结构，代码文件数量很多  

![img_5.png](img_5.png)  

这是 scrapy carhome_spider.py的代码  

```python  
# This package will contain the spiders of your Scrapy project  
#  
# Please refer to the documentation for information on how to create and manage  
# your spiders.  
import json  

from scrapy.http import Request  
from scrapy_redis.spiders import RedisSpider  

from scrapy_proj_carhome.items import ScrapyProjCarhomeItem  

import nb_log  


class carHomeSpider(RedisSpider):  
    name = "carhome"  
    allowed_domains = ["www.autohome.com.cn"]  

    redis_key = "carhome:start_urls"  

    def make_requests_from_url(self, data: str):  
        '''  
        data就是放入 carhome:start_urls 中的任务,因为最初的种子信息还需要携带其他信息，例如新闻类型的中文种类，不是单纯的url，所以需要重写此方法  
        :param data:  
        :return:  
        '''  
        start_task = json.loads(data)  
        url = start_task['url']  

        # 此处也可以改为post请求  
        return Request(  
            url,  
            meta=start_task  
        )  

    def parse(self, response):  
        # https://www.autohome.com.cn/news/2/#liststart  
        # print(response.body)  
        for li in response.css('#Ul1 > li'):  
            url = 'https:' + li.xpath('./a/@href').extract_first()  
            title = li.xpath('./a/h3/text()').extract_first()  
            yield Request(url, callback=self.parse_detail_page, meta={'url': url, 'title': title, 'news_type': response.meta['news_type']},  
                          dont_filter=False, priority=10)  
        page = response.url.split('/')[-2]  
        if page == '1':  
            last_page = int(response.css('#channelPage > a:nth-child(12)::text').extract_first())  
            for p in range(2, last_page + 1):  
                url_new = response.url.replace('/1/', f'/{p}/')  
                self.logger.debug(url_new)  
                yield Request(url_new, callback=self.parse, dont_filter=True, meta=response.meta)  

    def parse_detail_page(self, response):  
        author = response.css('#articlewrap > div.article-info > div > a::text').extract_first() or  
                 response.css('#articlewrap > div.article-info > div::text').extract_first() or ''  
        author = author.replace("\n", "").strip()  
        item = ScrapyProjCarhomeItem()  
        item['author'] = author  
        item['url'] = response.meta['url']  
        item['title'] = response.meta['title']  
        item['news_type'] = response.meta['news_type']  
        yield item  


if __name__ == '__main__':  
    pass  
```  

这是 items.py 的代码  

```python  
# -*- coding: utf-8 -*-  

# Define here the models for your scraped items  
#  
# See documentation in:  
# https://doc.scrapy.org/en/latest/topics/items.html  

import scrapy  


class ScrapyProjCarhomeItem(scrapy.Item):  
    # define the fields for your item here like:  
    # name = scrapy.Field()  
    author = scrapy.Field()  
    url = scrapy.Field()  
    title = scrapy.Field()  
    news_type = scrapy.Field()  

```  

这个middlewares.py文件的代码是最坑的，任何自定义想法需要写一个类，继承middware类，重写process_request process_request方法，然后把类名添加到settings里面。  


<summary>这是 middlewares.py的代码</summary><br>  



```python  
# -*- coding: utf-8 -*-  

# Define here the models for your spider middleware  
#  
# See documentation in:  
# https://doc.scrapy.org/en/latest/topics/spider-middleware.html  

from scrapy import signals  


class ScrapyProjCarhomeSpiderMiddleware(object):  
    # Not all methods need to be defined. If a method is not defined,  
    # scrapy acts as if the spider middleware does not modify the  
    # passed objects.  

    @classmethod  
    def from_crawler(cls, crawler):  
        # This method is used by Scrapy to create your spiders.  
        s = cls()  
        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)  
        return s  

    def process_spider_input(self, response, spider):  
        # Called for each response that goes through the spider  
        # middleware and into the spider.  

        # Should return None or raise an exception.  
        return None  

    def process_spider_output(self, response, result, spider):  
        # Called with the results returned from the Spider, after  
        # it has processed the response.  

        # Must return an iterable of Request, dict or Item objects.  
        for i in result:  
            yield i  

    def process_spider_exception(self, response, exception, spider):  
        # Called when a spider or process_spider_input() method  
        # (from other spider middleware) raises an exception.  

        # Should return either None or an iterable of Response, dict  
        # or Item objects.  
        pass  

    def process_start_requests(self, start_requests, spider):  
        # Called with the start requests of the spider, and works  
        # similarly to the process_spider_output() method, except  
        # that it doesn't have a response associated.  

        # Must return only requests (not items).  
        for r in start_requests:  
            yield r  

    def spider_opened(self, spider):  
        spider.logger.info('Spider opened: %s' % spider.name)  


class ScrapyProjCarhomeDownloaderMiddleware(object):  
    # Not all methods need to be defined. If a method is not defined,  
    # scrapy acts as if the downloader middleware does not modify the  
    # passed objects.  

    @classmethod  
    def from_crawler(cls, crawler):  
        # This method is used by Scrapy to create your spiders.  
        s = cls()  
        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)  
        return s  

    def process_request(self, request, spider):  
        # Called for each request that goes through the downloader  
        # middleware.  

        # Must either:  
        # - return None: continue processing this request  
        # - or return a Response object  
        # - or return a Request object  
        # - or raise IgnoreRequest: process_exception() methods of  
        #   installed downloader middleware will be called  
        return None  

    def process_response(self, request, response, spider):  
        # Called with the response returned from the downloader.  

        # Must either;  
        # - return a Response object  
        # - return a Request object  
        # - or raise IgnoreRequest  
        return response  

    def process_exception(self, request, exception, spider):  
        # Called when a download handler or a process_request()  
        # (from other downloader middleware) raises an exception.  

        # Must either:  
        # - return None: continue processing this exception  
        # - return a Response object: stops process_exception() chain  
        # - return a Request object: stops process_exception() chain  
        pass  

    def spider_opened(self, spider):  
        spider.logger.info('Spider opened: %s' % spider.name)  

```  

</details>  



这是pipelines.py 的代码,保存数据。  

```python  
# -*- coding: utf-8 -*-  

# Define your item pipelines here  
#  
# Don't forget to add your pipeline to the ITEM_PIPELINES setting  
# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html  
from scrapy_proj_carhome.items import ScrapyProjCarhomeItem  


class ScrapyProjCarhomePipeline(object):  
    def process_item(self, item, spider):  
        print(type(item))  
        if isinstance(item, ScrapyProjCarhomeItem):  
            print(f'保存到数据库 {item["news_type"]}  {item["url"]} {item["title"]} {item["author"]} ')  
        return item  

```  

这是settings.py的代码  

```python  
# -*- coding: utf-8 -*-  

# Scrapy settings for scrapy_proj_carhome project  
#  
# For simplicity, this file contains only settings considered important or  
# commonly used. You can find more settings consulting the documentation:  
#  
#     https://doc.scrapy.org/en/latest/topics/settings.html  
#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html  
#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html  

BOT_NAME = 'scrapy_proj_carhome'  

SPIDER_MODULES = ['scrapy_proj_carhome.spiders']  
NEWSPIDER_MODULE = 'scrapy_proj_carhome.spiders'  

# Crawl responsibly by identifying yourself (and your website) on the user-agent  
# USER_AGENT = 'scrapy_proj_carhome (+http://www.yourdomain.com)'  

# Obey robots.txt rules  
ROBOTSTXT_OBEY = True  

# Configure maximum concurrent requests performed by Scrapy (default: 16)  
# CONCURRENT_REQUESTS = 32  

# Configure a delay for requests for the same website (default: 0)  
# See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay  
# See also autothrottle settings and docs  
# DOWNLOAD_DELAY = 3  
# The download delay setting will honor only one of:  
# CONCURRENT_REQUESTS_PER_DOMAIN = 16  
# CONCURRENT_REQUESTS_PER_IP = 16  

# Disable cookies (enabled by default)  
# COOKIES_ENABLED = False  

# Disable Telnet Console (enabled by default)  
# TELNETCONSOLE_ENABLED = False  

# Override the default request headers:  
# DEFAULT_REQUEST_HEADERS = {  
#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',  
#   'Accept-Language': 'en',  
# }  

# Enable or disable spider middlewares  
# See https://doc.scrapy.org/en/latest/topics/spider-middleware.html  
# SPIDER_MIDDLEWARES = {  
#    'scrapy_proj_carhome.middlewares.ScrapyProjCarhomeSpiderMiddleware': 543,  
# }  

# Enable or disable downloader middlewares  
# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html  
DOWNLOADER_MIDDLEWARES = {  
    'scrapy_proj_carhome.middlewares.ScrapyProjCarhomeDownloaderMiddleware': 543,  
}  

# Enable or disable extensions  
# See https://doc.scrapy.org/en/latest/topics/extensions.html  
# EXTENSIONS = {  
#    'scrapy.extensions.telnet.TelnetConsole': None,  
# }  

# Configure item pipelines  
# See https://doc.scrapy.org/en/latest/topics/item-pipeline.html  
ITEM_PIPELINES = {  
    'scrapy_proj_carhome.pipelines.ScrapyProjCarhomePipeline': 300,  
}  

# Enable and configure the AutoThrottle extension (disabled by default)  
# See https://doc.scrapy.org/en/latest/topics/autothrottle.html  
# AUTOTHROTTLE_ENABLED = True  
# The initial download delay  
# AUTOTHROTTLE_START_DELAY = 5  
# The maximum download delay to be set in case of high latencies  
# AUTOTHROTTLE_MAX_DELAY = 60  
# The average number of requests Scrapy should be sending in parallel to  
# each remote server  
# AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0  
# Enable showing throttling stats for every response received:  
# AUTOTHROTTLE_DEBUG = False  

# Enable and configure HTTP caching (disabled by default)  
# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings  
# HTTPCACHE_ENABLED = True  
# HTTPCACHE_EXPIRATION_SECS = 0  
# HTTPCACHE_DIR = 'httpcache'  
# HTTPCACHE_IGNORE_HTTP_CODES = []  
# HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'  


REDIS_HOST = "127.0.0.1"  
REDIS_PORT = 6379  
REDIS_PARAMS = {'db': 2, 'password': ''}  
REDIS_ENCODING = "utf-8"  

SCHEDULER = "scrapy_redis.scheduler.Scheduler"  
DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"  
SCHEDULER_PERSIST = True  
# DUPEFILTER_KEY = "dupefilter:%(timestamp)s"  


```  

这是 push_start_urls.py 的代码  

```python  
from redis import Redis  
import json  
from scrapy_proj_carhome import settings  

r = Redis(host=settings.REDIS_HOST, port=settings.REDIS_PORT, **settings.REDIS_PARAMS)  

r.flushdb()  

# 因为要让初始种子就携带其他信息，初始种子发布的不是url本身，所以需要继承重写spider的make_requests_from_url方法。  
r.lpush('carhome:start_urls', json.dumps({'url': 'https://www.autohome.com.cn/news/1/#liststart', 'news_type': '新闻'}, ensure_ascii=False))  
r.lpush('carhome:start_urls', json.dumps({'url': 'https://www.autohome.com.cn/advice/1/#liststart', 'news_type': '导购'}, ensure_ascii=False))  
r.lpush('carhome:start_urls', json.dumps({'url': 'https://www.autohome.com.cn/drive/1/#liststart', 'news_type': '驾驶评测'}, ensure_ascii=False))  

```  

这是run.py的代码  

```python  

from scrapy import cmdline  

cmdline.execute(['scrapy', 'crawl', 'carhome'])  
```  

```  
从上面的代码可以看到scrapy要在8个文件频繁的来回切换写代码，非常的烦躁。  
即使是除去scrapy 建项目自动生产的固定代码行数，此scrapy项目的代码行数仍然远远高于分布式函数调度框架的代码行数  
```  

### 8.3.6 分布式函数调度框架的代码  

只需要单个文件(当然也可以拆解成发布和消费独立成两个文件)  

所需代码行数远小于无框架每次临时手写爬虫全流程和使用scrapy的方式。  

此框架不仅可以对标celery框架，也可以取代scrapy框架。  

```python  


from funboost import boost, BrokerEnum, BoosterParams  
import requests  
from parsel import Selector  


@boost(BoosterParams(queue_name='car_home_list', broker_kind=BrokerEnum.REDIS_ACK_ABLE, max_retry_times=5, qps=10))  
def crawl_list_page(news_type, page):  
    url = f'https://www.autohome.com.cn/{news_type}/{page}/#liststart'  
    resp_text = requests.get(url).text  
    sel = Selector(resp_text)  
    for li in sel.css('#Ul1 > li'):  
        url_detail = 'https:' + li.xpath('./a/@href').extract_first()  
        title = li.xpath('./a/h3/text()').extract_first()  
        crawl_detail_page.push(url_detail, title=title, news_type=news_type)  
    if page == 1:  
        last_page = int(sel.css('#channelPage > a:nth-child(12)::text').extract_first())  
        for p in range(2, last_page + 1):  
            crawl_list_page.push(news_type, p)  


@boost(BoosterParams(queue_name='car_home_detail', broker_kind=BrokerEnum.REDIS_ACK_ABLE, concurrent_num=100, qps=30, do_task_filtering=False))  
def crawl_detail_page(url, title, news_type):  
    resp_text = requests.get(url).text  
    sel = Selector(resp_text)  
    author = sel.css('#articlewrap > div.article-info > div > a::text').extract_first() or  
             sel.css('#articlewrap > div.article-info > div::text').extract_first() or ''  
    author = author.replace("\n", "").strip()  
    print(f'使用print模拟保存到数据库  {news_type}   {title} {author} {url}')  # ，实际为调用数据库插入函数，压根不需要return item出来在另外文件的地方进行保存。  


if __name__ == '__main__':  
    # 单独的测试函数功能  
    # crawl_list_page('advice',1)  #  
    # crawl_detail_page('https://www.autohome.com.cn/news/202008/1022380.html#pvareaid=102624','xxx')  

    # 清空消息队列  
    crawl_list_page.clear()  
    crawl_detail_page.clear()  
    #  
    # # 推送列表页首页  
    crawl_list_page.push('news', 1)  # 新闻  
    crawl_list_page.push('advice', page=1)  # 导购  
    crawl_list_page.push(news_type='drive', page=1)  # 驾驶评测  

    # 启动列表页消费和详情页消费,上面的清空和推送可以卸载另外的脚本里面，因为是使用的中间件解耦，所以可以推送和消费独立运行。  
    crawl_list_page.consume()  
    crawl_detail_page.consume()  
```  

使用分布式函数调度框架运行的爬虫，自动并发，自动控频，是指定了列表页qps=2，详情页qps=3的情况下运行的控制台日志  

[![4BquHf.png](https://z3.ax1x.com/2021/09/24/4BquHf.png)](https://imgtu.com/i/4BquHf)  

可以得出结论，控频效果精确度达到了99%以上，目前世界所有爬虫框架只能指定并发请求数量，但不能指定每秒爬多少次页面，此框架才能做到。  



## 8.7 scrapy 和 仿scrapy api 式爬虫框架 回调地狱，代码写法思维反直觉  

scrapy 和 仿scrapy api 式爬虫框架 回调地狱，代码写法思维反直觉，不是横冲直闯 平铺直叙的一气呵成 写法，导致编写和理解苦难  

Scrapy 作为一个成熟的爬虫框架，其设计和架构目标主要是为了实现高并发、异步非阻塞的网络爬取，并能灵活地处理分布式任务调度。正因为这些设计目标，Scrapy 的代码风格与"横冲直闯、平铺直叙"那种顺序式、线性写法有很大区别，下面详细说明原因：  

1. **异步回调模型（Event-driven Programming）**  
   Scrapy 基于 Twisted 异步网络框架，其核心设计采用的是事件驱动模式。请求发送后，并不会等待响应返回，而是通过回调函数（通常是 spider 中的 parse 方法）来处理响应。  
   - **代码分散**：任务被拆分成多个独立的回调函数，每个回调函数只处理特定的响应数据。这种模式虽然高效，但导致代码逻辑被拆分成许多零散的函数，难以从头到尾按顺序阅读。  
   - **逻辑碎片化**：一个完整的爬取流程可能涉及多个请求、多个回调，以及在回调中又发起新的请求。这样就形成了类似"回调地狱"的结构，不是那种一气呵成的直线流程。  

2. **固定项目结构和模块分离**  
   Scrapy 强调模块化开发，将爬虫、下载器中间件、数据管道、调度器等组件严格分离：  
   - **Spider**：定义爬虫逻辑，每个 Spider 负责从起始 URL 出发解析页面，提取数据和新的 URL。  
   - **Downloader Middleware**：在请求和响应之间插入额外的处理逻辑，如设置代理、User-Agent、重试等。  
   - **Item Pipeline**：处理解析后的数据（清洗、存储等）。  
   
   这种结构使得每个模块职责明确，但同时也要求开发者在不同文件中编写不同逻辑，整体代码组织上远比"平铺直叙"复杂。  

3. **异步并发与性能优化的权衡**  
   为了实现高并发与高效爬取，Scrapy 必须避免阻塞操作。这就要求所有网络请求、数据解析等操作都以异步方式处理，任何阻塞代码都可能影响整个爬虫性能。因此：  
   - **回调链**：每个网络请求完成后都需要通过回调函数继续处理数据，任务间的顺序和依赖关系通过事件循环来管理，而不是直接按照代码的顺序执行。  
   - **任务调度机制**：Scrapy 内部有一个调度器（Scheduler）来管理请求队列和去重逻辑，这也使得任务处理不是简单的线性顺序，而是多个请求并发执行，异步返回后再根据调度逻辑进行处理。  

4. **错误处理与重试机制**  
   在 Scrapy 中，如果在 spider 的回调函数中捕获并吞掉异常，框架就无法正确检测到任务失败，从而影响自动重试和错误处理策略。为了保证重试机制能够工作，通常要求让异常沿回调链上抛，这也促使代码设计者不得不在各个回调中考虑如何把异常交由框架统一处理，而不是简单地在一个"主流程"中捕获处理。  

5. **灵活性与扩展性**  
   虽然 Scrapy 采用回调和分层结构增加了开发难度，但它提供了大量内置的扩展点（如中间件、扩展器、信号机制等），使得开发者可以在不同阶段注入自定义逻辑。这个灵活性换来了高度可定制的爬虫，但也使得代码看起来不如"平铺直叙"的方式那样直接。所以不精通scrapy本身的人想扩展自定义scrapy难度超高。  

综上，Scrapy 的架构设计为异步高并发和模块化扩展服务，采用事件驱动和回调链来管理任务流，使得代码逻辑被拆分到各个独立模块和回调函数中。这种设计虽然在性能和灵活性上非常出色，但从代码风格上来说，并不是那种"一气呵成、平铺直叙"的直观写法，而更像是分散在多个模块、通过事件调度器串联起来的"碎片化"结构，这正是 Scrapy 为实现大规模、高效率爬取所必须做出的权衡。  

## 8.8 详细说明为什么 Scrapy 爬虫代码不是直观的"平铺直叙"写法？  

![img_81.png](img_81.png)  

<div class="inner_markdown">  



Scrapy 是一个强大的爬虫框架，在它的回调函数中需要写很多 `callback` 事件函数，和同步代码逻辑不直观。  
本文将解释 **Scrapy 的写法为什么不是平铺直叙的**。  

---  

<h3> 1. 基于回调，代码逻辑割裂</h3>  

<h4>Scrapy 代码的典型结构</h4>  

```python  
import scrapy  

class MySpider(scrapy.Spider):  
    name = 'myspider'  
    start_urls = ['https://example.com/list']  

    def parse(self, response):  
        detail_urls = response.css('a::attr(href)').getall()  
        for url in detail_urls:  
            yield scrapy.Request(url, callback=self.parse_detail)  

    def parse_detail(self, response):  
        title = response.css('h1::text').get()  
        price = response.css('.price::text').get()  
        yield {'title': title, 'price': price}  
```  

**问题分析**  
- 爬虫逻辑被分散在多个回调函数里，代码割裂。  
- 业务逻辑无法“从上到下”顺序执行，开发者思维负担大。  
- 如果熟悉 Python 的 `requests` 和 `BeautifulSoup`，常觉得爬虫代码可以写得更平铺直叙。  

---  

<h3> 2. `yield` 语法导致执行顺序不直观</h3>  

在 Scrapy 中，`yield` 用于生成新的请求，而不是立即执行回调函数。  
常见写法：  

```python  
yield response.follow(url, callback=self.parse_detail)  
```  

**问题分析**  
- 任务不会立即同步执行，需等 Scrapy 调度下一次请求。  
- 编写 Python 函数时，习惯用 `return` 表达逻辑，而 Scrapy 使用 `yield` 让逻辑割裂。  
- 对于新手来说，Scrapy 的执行顺序、调度策略，不同于常规函数调用链。  

---  

<h3> 3. 任务调度是黑盒，开发者失去控制权</h3>  

Scrapy 通过调度器（Scheduler）决定请求的先后执行顺序：  
- 爬虫开发者只负责写回调函数，不控制调度。  
- 但有时候需要更精细化控制顺序，比如递归抓取树形结构。  

**对比：**  
使用 `for url in URL_LIST: requests.get(url)` 就很直观：  
- 程序的执行顺序由 Python 原生控制。  
- Scrapy 的调度机制虽然强大，但对开发者来说是黑盒。  

---  

<h3> 4. 强制使用 `Spider` 类，不够自由</h3>  

Scrapy 框架必须继承 `Spider` 类：  

```python  
class MySpider(scrapy.Spider):  
    name = 'myspider'  
    ...  
```  

**问题分析**  
- 代码风格被固定，无法随意定义函数入口。  
- 对比 `requests` 库，可以直接写 `def crawl():` 这种函数结构，更符合 Python 开发习惯。  

---  

<h3> 5. 并发控制分散，不直观</h3>  

在 Scrapy 里，并发控制依赖 `settings.py` 配置：  

```python  
CONCURRENT_REQUESTS = 16  
DOWNLOAD_DELAY = 0.5  
AUTOTHROTTLE_ENABLED = True  
AUTOTHROTTLE_START_DELAY = 1  
```  

**问题分析**  
- 并发控制在全局配置文件，逻辑和代码分离。  
- 如果希望按不同函数使用不同并发策略，需要额外代码。  

相比之下，`funboost` 的写法更直观：  

```python  
@boost(concurrent_num=20)  
def crawl_page(url):  
    ...  
```  

- 代码和配置绑定在一起，逻辑更易理解。  

---  

<h3> 6. Scrapy 不适合任务编排</h3>  

Scrapy 多个回调函数之间无法方便串联多个 `Spider`：  

```python  
class MySpider(scrapy.Spider):  
    name = 'myspider'  
    start_urls = ['https://example.com/list']  

    def parse(self, response):  
        yield response.follow(url, callback=self.parse_detail)  
```  

**问题分析**  
- 单个任务孤立，不方便平铺任务依赖。  
- 对比 `funboost` 等任务队列框架，可以轻松实现任务流水线，例如：  

```python  
crawl_list_page.push(url)  
crawl_detail_page.push(detail_url)  
```  

---  

<h3> 总结</h3>  

<h4> ❌ 为什么 Scrapy 代码不是直观的“平铺直叙”写法</h4>  

| 特性         | Scrapy 框架      | 平铺直叙写法         |  
|--------------|------------------|----------------------|  
| **回调函数** | 多               | 代码集中、顺序执行   |  
| **执行顺序** | 由调度器控制     | 上下文可控           |  
| **yield**    | 必须             | `return` 或直接调用  |  
| **并发**     | 全局 settings    | 局部可配置           |  
| **入口结构** | 固定 `Spider` 类 | 任意函数             |  
| **任务编排** | 不方便           | 灵活组合             |  

---  

<h4> 结论</h4>  

1. **Scrapy 的设计理念是事件驱动 + 回调函数**，导致逻辑不直观。  
2. 多数 Python 程序员更习惯顺序化代码，而 Scrapy 的“分散回调”方式不符合直觉。  
3. **Scrapy 适合大规模分布式爬取**，但对小型项目，`requests + BeautifulSoup` 或 `asyncio` 更直观。  
4. 如果需要 **任务编排 + 平铺直叙的任务逻辑**，可以考虑 `funboost` 等任务队列框架。  
5. 总的来说，Scrapy 功能强大，但牺牲了代码的 **直观性和自由度**。  

---  

> **讨论：** 你觉得 Scrapy 的回调写法优雅吗？  
> 如果想尝试 **平铺直叙** 的写法，可以了解 `funboost` 框架。  


</div>  

## 8.9 仿scrapy api框架中无法完成的需求真实例子2，token有效期太短  

举例一个 仿scrapy api框架中无法完成的需求真实例子。  

根据data参数请求URL1生成sm_token，然后必须在10秒有效期内使用相同的data和获取到的sm_token请求URL2。  

scrapy由于是url调度，一次只能调度请求一次，无法确保是在10秒内使用data得到的sm_token去请求url2。不管你是配置使用深度优先，还是加上priority，如果url2任务种子堆积了，会发生大面积延迟导致sm_token过期。  

```python  
import scrapy  
import json  
import time  
from scrapy.exceptions import DropItem  

class TokenSpider(scrapy.Spider):  
    name = 'token_spider'  
    
    def __init__(self, *args, **kwargs):  
        super(TokenSpider, self).__init__(*args, **kwargs)  
        # 需要处理的data列表  
        self.data_list = ['data1', 'data2', 'data3']  
    
    def start_requests(self):  
        # 为每个data生成请求  
        for data in self.data_list:  
            url = f'https://example.com/api/gettoken?data={data}'  
            yield scrapy.Request(  
                url=url,   
                callback=self.parse_token,  
                meta={'data': data}  # 传递data参数  
            )  
    
    def parse_token(self, response):  
        # 获取传递的data  
        data = response.meta.get('data')  
        
        try:  
            # 解析响应获取sm_token  
            result = json.loads(response.text)  
            sm_token = result.get('sm_token')  
            
            if not sm_token:  
                self.logger.error(f"未获取到data={data}的有效sm_token")  
                return  
            
            # 记录获取token的时间  
            token_time = time.time()  
            
            # 构建第二个请求  
            url2 = f'https://example.com/api/getData?data={data}&sm={sm_token}'  
            
            # 将data、token和时间传递给下一个回调  
            yield scrapy.Request(  
                url=url2,  
                callback=self.parse_data,  
                meta={  
                    'data': data,  
                    'sm_token': sm_token,  
                    'token_time': token_time  
                },  
                priority=100  # 尝试提高优先级，但无法保证立即执行，因为url2的优先级都是100，堆积就会造成sm_token过期。  
            )  
            
        except Exception as e:  
            self.logger.error(f"处理token响应时出错: {e}")  
    
    def parse_data(self, response):  
        # 获取传递的元数据  
        data = response.meta.get('data')  
        sm_token = response.meta.get('sm_token')  
        token_time = response.meta.get('token_time')  
        
        # 检查token是否已过期，  只能检查，而非确保啊。 url2 和url1调度是独立的，无法确保是在10秒内。  
        current_time = time.time()  
        if current_time - token_time > 10:  
            self.logger.error(f"Data={data}的Token已过期! 耗时: {current_time - token_time}秒")  
            # 这里可以尝试重新获取token，但逻辑会变得复杂  
            raise DropItem("由于Token过期，丢弃此次请求数据")  
            
        try:  
            # 处理第二个请求的响应  
            result = json.loads(response.text)  
            # 收集数据  
            yield {  
                'data': data,  
                'result': result,  
                'token_elapsed': current_time - token_time  
            }  
        except Exception as e:  
            self.logger.error(f"处理数据响应时出错: {e}")  
```  

funboost中实现这需求非常丝滑自然，因为funboost可以在一个函数内部连续请求两个url，可以确保在通过url1得到sm_token后的0.01毫秒内立即对url2发送请求。  

```python  
from funboost import boost, BrokerEnum, BoosterParams  
import requests  
import json  
import time  

@boost(BoosterParams(queue_name="token_task",broker_kind=BrokerEnum.REDIS_ACK_ABLE,qps=100, max_retry_times=3))  
def process_with_token(data):  
    """一个函数处理整个流程，逻辑清晰直观"""  
   
    # 第一个请求：根据data获取对应的sm_token  
    url1 = f"https://example.com/api/gettoken?data={data}"  
    response1 = requests.get(url1, timeout=5)  
    sm_token = response1.json()['sm_token']  
    
    # 立即使用data和sm_token请求第二个URL  
    # 这里无延迟，不经过任何调度器，保证token新鲜有效  
    url2 = f"https://example.com/api/getData?data={data}&sm={sm_token}"  
    response2 = requests.get(url2, timeout=5)  
    # 处理并返回数据  
    result = response2.json()  
    print('保存result')  
        

# 启动爬虫  
if __name__ == "__main__":  
    # 发布任务  
    data_list = ['data1', 'data2', 'data3', 'data4', 'data5']  
    for data_item in data_list:  
        process_with_token.push(data_item)  
    
    # 启动消费者处理任务  
    process_with_token.consume()  
```  

两者在此需求实现上对比对比分析：  

<table style="width:100%; border-collapse:collapse; text-align:center;">  
  <thead>  
    <tr style="background-color:#f2f2f2;">  
      <th style="padding:8px; border:1px solid #ddd; text-align:left;">特性</th>  
      <th style="padding:8px; border:1px solid #ddd; text-align:center;">Scrapy</th>  
      <th style="padding:8px; border:1px solid #ddd; text-align:center;">Funboost</th>  
    </tr>  
  </thead>  
  <tbody>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">代码行数</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">~70行</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">~35行</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">执行流程</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">分散在3个回调函数中</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">集中在1个函数内</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">状态传递</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">通过meta字典在多个回调间传递</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">直接使用变量，自然清晰</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">token时效性</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">只能被动检查是否过期，可能数据丢失</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">立即使用，几乎0延迟，确保有效</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">错误处理</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">分散在多处，难以全面处理</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">集中在一个try-except内</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">可读性</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">需要在多个函数间跳转理解逻辑</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">从上到下线性阅读，一目了然</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">可维护性</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">修改需考虑多处回调关系</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">修改只需要关注一个函数</td>  
    </tr>  
    <tr>  
      <td style="padding:8px; border:1px solid #ddd; text-align:left;">调试难度</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">高，难以跟踪完整流程</td>  
      <td style="padding:8px; border:1px solid #ddd; text-align:center;">低，标准函数调试方式</td>  
    </tr>  
  </tbody>  
</table>  


funboost在这个特殊需求上优势总结：  
```  
Funboost在处理这类"根据data获取token并立即使用"的爬虫场景时表现卓越：  
连续执行保证：两次请求在同一函数内连续执行，保证token不会过期  
无状态传递困扰：不需要通过meta字典在回调间传递状态  
直观的流程控制：整个处理流程遵循自然的编程思维  
更简单的数据处理：直接在函数内处理和返回结果  
对于具有严格时效性要求的爬虫任务，特别是需要多步骤请求且后续请求依赖前序请求结果的场景，  
Funboost的优势变得尤为明显，让复杂的爬虫任务回归到简单直观的函数式编程模型。  
```  

## 8.10 scrapy的 response.meta 字典传参无法ide自动补全提示  

Scrapy的meta字典在ide中完全无法补全提示：  
```  
meta是无类型字典，IDE无法知道里面有什么键  
没有自动补全提示 response.meta.get('???')  
拼写错误不会在编写时被捕获，如token_tiem而不是token_time  
忘记在上一个回调中传递某个键值对也不会有警告  
需要不断查看或记忆上下文中传递了哪些数据  
```  

```  
上面8.9例子中的 parse_token 方法中  

yield scrapy.Request ，需要在meta中把各个有用的变量信息传递给下一个解析方法  

yield scrapy.Request(  
    url=url2,  
    callback=self.parse_data,  
    meta={  
        'data': data,  
        'sm_token': sm_token,  
        'token_time': token_time  
    },  
    priority=100  
)  


在 parse_data 方法中，很容易出错  
def parse_data(self, response):  
        # 获取传递的元数据  
        # IDE不知道meta中有什么，无法提示  
        data = response.meta.get('data') # 如果你拼错为'dta'也不会有警告，只有到运行后才能知道写错了  
        sm_token = response.meta.get('sm_token') # 如果上一步忘记传sm_token，ide在这里不会提前发现  
        token_time = response.meta.get('token_time') # 如果上一步改了token_time的名字，这里ide不能自动改名字          


```  

funboost函数中的局部变量优势：  
```  
局部变量有类型信息，IDE能提供完整自动补全  
变量名拼写错误会立即被标红  
未定义的变量会被IDE立即标识  
重构变量名时会同步修改所有引用  
```  

能否在ide自动补全提示的实际影响:  
```  
在实际开发中，这种差异会导致：  
开发效率差异：  
funboost开发速度更快，减少查看文档或代码回溯  
Scrapy需要更多的代码审查和测试才能捕获拼写错误  
错误出现时机：  
funboost的错误多在编码阶段被IDE捕获  
Scrapy的错误往往在运行时才发现，调试成本更高  
维护和重构：  
funboost更易重构，变量改名会全局同步  
Scrapy修改meta键名需手动检查所有回调函数  
这种看似小的开发体验差异在大型爬虫项目中会带来显著的生产力和代码质量差异，特别是在团队协作或长期维护的场景下。  
```  


## 8.11 funboost中反爬虫换代理ip 请求头 破解等 容易程度暴击专用爬虫框架scrapy  

需要大力驳斥 "专用框架=更方便" 的误解  

### 8.11.1 scrapy中换代理ip和请求头代码  
```python  
# Scrapy的下载器中间件  
class RotateUserAgentMiddleware:  
    def process_request(self, request, spider):  
        request.headers['User-Agent'] = random.choice(USER_AGENTS)  

class ProxyMiddleware:  
    def __init__(self, proxy_list: list[str]):  
        self.proxy_list = proxy_list  

    @classmethod  
    def from_crawler(cls, crawler):  
        """Scrapy 会自动调用此方法创建中间件实例"""  
        proxy_list = crawler.settings.get("PROXY_LIST", [])  
        return cls(proxy_list=proxy_list)  

    def process_request(self, request, spider):  
        proxy = random.choice(self.proxy_list)  
        request.meta['proxy'] = proxy  
        
    def process_response(self, request, response, spider):  
        # 获取当前重试次数  
        retry_times = request.meta.get('retry_times', 0)  
        
        if response.status == 403 and retry_times < 3:  # 限制最多重试3次  
            request.meta['proxy'] = self.get_new_proxy()  
            request.meta['retry_times'] = retry_times + 1  
            return request  
        return response  


# 并需要在Scrapy的settings.py中注册中间件  
DOWNLOADER_MIDDLEWARES = {  
   'myproject.middlewares.RotateUserAgentMiddleware': 400,  
   'myproject.middlewares.ProxyMiddleware': 500,  
}  
```  

```  
scrapy这个换代理ip代码看起来代码量不大，实则超级复杂。如果不去网上百度找个别人写好的例子，  
99%的爬虫人员抓破脑袋也绝对写不出来，  
用户完全是懵逼的，为什么要这么写。  
为什么要定义一个类，为什么类必须是有 def process_request(self, request, spider): 方法 ,  
如果方法名字不是这样，入参个数少了或多了，还能运行吗？ 用户为什么知道   
还要写  'myproject.middlewares.RotateUserAgentMiddleware': 400,这么个玩意？  
这个字符串是什么？这个数字又是什么，随便乱写个数字行不行？  
```  

所以有人说scrapy框架是专用爬虫框架，所以优势是能反爬，能支持换代理ip和请求头。说funboost不是专用爬虫框架，所以反爬是对scrapy有劣势，这个是绝对的谬论，真实情况是如果仅靠自己琢磨而不去百度别人的scrapy咋写的换代理ip，在scrapy框架中换代理难如登天。  

### 8.11.2 用户自己自由封装一个换代理ip和请求头的request函数，自然又简单  

funboost 不是专用爬虫框架，但基于funboost的 boost_spider 爬虫开的 RequestClient 支持自动换代理ip和请求头，支持xpath解析。  

即使是直接用funboost爬虫，用户自己自由封装一个换代理ip和请求头的request函数，自然又简单，爬虫小白初学1天都能轻松自然封装出来。比scrapy中那种莫名其妙的def process_request(self, request, spider)写法更容易百倍。  

用户封装一个换代理ip和请求头的request函数如下：  
```python  
import requests  

def my_request(method,url):  
    proxy = random.choice(proxy_list)  
    user_agent = random.choice(user_agent_list)  
    return requests.request(method,url,proxies=proxy,headers={'user-agnet':user_agent})  
           
```  

```  
这个 my_request 换代理ip和请求头的函数代码自由而又简单直观，只要是个pythoner都能看得懂，  
只要是个pythoner都能使用自然而然的直觉思维 很轻松容易的写出来。   
因为你在封装这个函数时候，完全绝对和funboost没有半毛钱关系，你不需要了解funboost的流程就能封装出来。  
而且不想用funboost了，你这个写的函数还是有意义可以继续用的。  
如果你不想用scrapy了，那个ProxyMiddleware代码就成了废物代码。  

用户自己封装的 my_request 函数 能方便的进行独立单元测试，而scrapy的ProxyMiddleware类用户无法单独单元测试验证，必须在scrapy框架整体运行起来才能测试得了。  
```  

### 8.11.3 为什么scrapy换代理IP和请求头的高难度分析my_request  

首先是你必须非常的精通Scrapy完整流程，才能流畅的改造scrapy  
```  
核心组件  
Engine: 引擎，负责控制数据流在系统中所有组件间的流动  
Scheduler: 调度器，接收引擎发来的请求并排序、入队，当引擎需要时提供请求  
Downloader: 下载器，获取网页内容并返回给引擎  
Spider: 爬虫，解析响应并提取数据，产生新的请求  
Item Pipeline: 项目管道，处理Spider提取的数据  
Middleware: 中间件，包括下载器中间件和Spider中间件  
数据流向  
Engine向Spider请求第一个URL  
Engine从Spider获取第一个请求  
Engine将请求发送给Scheduler调度  
Scheduler返回下一个请求给Engine  
Engine通过Downloader Middleware发送请求给Downloader  
页面下载完成后，Downloader生成响应并通过Downloader Middleware发给Engine  
Engine将响应通过Spider Middleware发送给Spider处理  
Spider处理响应并返回提取的数据及新的请求给Engine  
Engine将数据发送给Item Pipeline，将新请求发给Scheduler  
重复步骤4-9直到没有请求  
执行过程  
创建Scrapy项目：scrapy startproject myproject  
定义Spider类，包含start_urls和解析方法  
运行爬虫：scrapy crawl myspider  
框架自动加载配置、初始化组件  
按数据流向处理请求和响应  
数据经由Pipeline处理后存储  
中间件拦截点  
Downloader Middleware:  
process_request: 请求发送到下载器前  
process_response: 响应返回Spider前  
process_exception: 下载异常时  
Spider Middleware:  
process_spider_input: Spider处理响应前  
process_spider_output: Spider产生结果后  
process_spider_exception: Spider异常时  
Scrapy的强大和复杂性正源于这种多组件交互的设计模式，但也因此增加了学习难度。  
```  

其次要说明为什么scrapy换代理IP和请求头的难度高，为什么难度远超使用requests换代理ip和请求头  
```  
1. 中间件机制的概念理解障碍  
特殊方法名要求：必须准确实现process_request、process_response等方法  
约定优于配置：这些方法名不是由用户自由选择，而是框架强制要求的  
不明显的执行流程：用户难以直观理解请求从Spider到Downloader的完整路径  
方法参数固定：必须接受固定参数(self, request, spider)，不能随意调整  
2. 配置分散性导致的认知负担  
多文件依赖：修改需要同时编辑middlewares.py和settings.py  
导入路径字符串：需要以字符串形式指定中间件路径，容易出错  
数字优先级系统：需理解400、500这类数字代表执行顺序，且没有明确文档说明最佳实践  
3. 特殊对象和属性的学习成本  
request.meta字典：使用非直观的meta字典传递信息  
代理格式要求：必须以特定格式设置代理request.meta['proxy'] = 'http://ip:port'  
框架特有对象：需理解Request、Response等Scrapy特有对象的行为  
4. 调试复杂性  
堆栈追踪困难：错误发生在框架内部，难以定位问题  
隐式执行顺序：中间件执行顺序不直观，调试困难  
状态保持挑战：在不同中间件间传递状态需使用meta字典  
5. 文档和学习资源局限  
分散的文档：需阅读多个文档章节才能完整理解  
官方示例不足：官方文档缺乏完整的代理切换实例  
依赖社区示例：大多数用户需依赖StackOverflow等外部资源  
相比之下，funboost中实现同样功能只需编写普通Python函数，使用标准try-except处理错误，不需要学习特殊的框架概念，完全符合Python程序员的直觉思维模式。  
```  

那些说 funboost 不是专用爬虫框架，从而就得出结论是肯定在反爬虫方面不如scrapy方便，绝对是谬论。真实情况是scrapy源码从来都没有内置自带自动反爬虫功能；scrapy中因为框架的写法约束死板，实现这些反而难度更高而不是更简单。  

## 8.12 scrapy 可直接运行测试验证性很差  

**scrapy不可直接测试运行深层级爬虫**  
一个三层级网站爬虫,例如列表页->详情页->评论页，scrapy你怎么单独直接验证第三层级的爬虫请求和解析呢？只有spider整体运行起来，然后观察第三层级解析。 (这样第三层级爬虫会要等很久,并且被不相干的第一二层级爬虫输出干扰)  
1）scrapy的爬虫逻辑分散在Spider类的多个回调方法（如parse、parse_detail、parse_third_level）中。   
2）这些回调方法依赖于框架的Request/Response对象、meta字典、调度器等上下文，无法直接在IDE里单独调用。  
3）你想单独测试第三层级的解析，只能整体运行spider，等到第三层级回调被调度时，观察输出或日志，调试效率极低。  
4) 很多人只能先单独临时写个requests请求的函数验证，然后再改成到scrapy写法，造成重复劳动。   

**funboost 被@boost的函数能直接调用运行测试**  
而funboost的第三层级的爬虫函数，crawl_thrid_level_page(article_id,user_id,page_index) 可以直接调用运行，可直接测试性秒杀scrapy。  

```python  
@boost(BoosterParams(queue_name='third_level_queue'))  
def crawl_third_level_page(article_id, user_id, page_index):  
    # ...爬虫逻辑...  
    return "ok"  

# 能直接运行  
result = crawl_third_level_page('a123', 'u456', 1)  
print(result)  
```  

## 8.13 funboost 断点接续运行能力吊打scrapy-redis 的 blpop （funboost支持确认消费）  

不要以为你使用个 scrapy-redis 就万事大吉了，就和 funboost 的断点续爬一样强大了，scrapy在下面两种场景100%会丢失大量数据。  
### 8.13.1 为什么 funboost的断点续爬完胜 scrapy-redis的断点续爬(防丢数据1)  

scrapy-redis 是基于 redis.blpop() ,BLPOP 的特性是一旦弹出，该元素就从列表中移除了。框架会弹出大量url种子到内存中，然后并发请求。如果你随意重启代码 进程崩溃/断电/强制关机，那么已取出来的url种子就丢失了，如果你把重要的导航页或者列表页丢失了，那就会丢失几十万个详情页页面，太悲催了，需要你反复人工添加种子，反复爬十几次才能爬全，太累了。  


而funboost支持40种消息队列，其中很多种是broker服务端天生支持消费确认的，例如rabbitmq中间件。 用户可以毫无顾忌的随意重启代码和强制断电关机，没运行完成的消息是不会确认消费的，所以不会丢失。   
即使用户没安装 rabbitmq 这种高级消息队列，用户使用 broker_kind =BrokerEnum.REDIS_ACK_ABLE 等各种redis模式，也是支持确认消费的，不惧怕用户随意重启代码造成大批已取出到内存中的消息丢失。  


### 8.13.2 funboost的函数重试功能远远暴击scrapy的url重试功能(防丢数据2)  

scrapy的重试是url重试，如果url请求成功，http状态码是200，但页面内容提示反扒了，页面此时不是返回的正常的内容，导致你解析出错，scrapy的url重试是无效的。  

而funboost 的爬虫函数 被 @boost 装饰后，funboost 会自动重试，重试次数和间隔时间可以自由设置。如果页面反扒了，函数里面运行解析的代码会出错，funboost 会自动重试，你不需要提前规划判断返回了什么内容是属于被反扒了，funboost 会自动重试。  


**所以funboost 只要启动爬一次，可以做到完全不漏数据，而scrapy-redis 需要反复重启爬虫，反复添加种子，反复爬十几次才能爬全，funboost 简直轻松太多了**  



## 8.14 其他funboost 吊打 scrapy原因 详细介绍  
### 8.14.1 为什么funboost的去重功能远远吊打scrapy的Request对象指纹去重？  

#### 8.14.1.1 funboost 支持有效期过滤  

funboost 支持有效期过滤，例如1个月内相同productid过滤，一个月后仍然重新运行爬取，适合周期更新爬取。  
scrapy无此功能，scrapy需要手动清理去重集合。  

#### 8.14.1.2 scrapy无法过滤url中的噪音入参，例如ts时间戳，rd随机数，追踪来源id  

funboost是函数入参过滤而非url过滤，稳如泰山。 scrapy最头疼的url入参或者post入参有噪音多余字段。  

假设   
url1 是  www.site1.com/product/123456/?a=1&b=2&_ts=17136952568&_rand=0.6254395 ，   
url2 是 www.site1.com/item/321?&timestamp=17136952568&r=0.6254395 ，  
url3 是 www.site2.com/user/ post入参是 {user:123 ts:1721568556 ssid:1234567890 } ，  
其中url1的_ts和_rand是噪音多余字段，url2的timestamp和r是噪音多余字段，url3的和ts和ssid是噪音多余字段。  

funboost是过滤函数入参，天然无此问题  
```  
funboost 的函数入参过滤功能，可以轻松过滤掉url1和url2的噪音多余字段，而scrapy的url去重功能无法过滤掉url1和url2和url3的噪音多余字段。  

因为funboost的函数是 def craw_product(product_id,a,b) ， funboost 是根据 product_id,a,b去重，天然无视 _ts 和 _rand 没用的噪音入参。  
funboost 没有规定入参必须是url。  
```  

scrapy中无视Request的噪音难如登天，需要你手动自定义继承一个RFPDupeFilter，然后重写 def request_fingerprint(self, request):  

```python  
import hashlib  
import json  
import re  
from urllib.parse import urlparse, parse_qsl, urlencode, urlunparse  

from scrapy.utils.python import to_bytes  
from scrapy.dupefilters import RFPDupeFilter  
from scrapy.http import FormRequest, JsonRequest  


class SmartFingerprintPerPattern(RFPDupeFilter):  
    def request_fingerprint(self, request):  
        url = request.url  
        method = request.method.upper()  

        # 从 settings 读取正则规则配置  
        pattern_rules = {  
            r'^https?://www\.site1\.com/product/\d+': ['_ts', '_rand'],  
            r'^https?://www\.site1\.com/item/\d+': ['timestamp', 'r'],  
            r'^https?://www\.site2\.com/user/?$': ['ts', 'ssid'],  
        }  

        # 匹配正则，提取对应 ignore 参数  
        ignore_keys = []  
        for pattern, keys in pattern_rules.items():  
            if re.match(pattern, url):  
                ignore_keys = keys  
                break  

        # ----------- 清洗 URL Query 参数 -----------  
        parsed = urlparse(url)  
        query = parse_qsl(parsed.query, keep_blank_values=True)  
        filtered_query = [(k, v) for k, v in query if k not in ignore_keys]  
        cleaned_query = urlencode(filtered_query, doseq=True)  
        cleaned_url = parsed._replace(query=cleaned_query)  
        cleaned_url_str = urlunparse(cleaned_url)  

        # ----------- 清洗 POST 请求 Body 参数 -----------  
        post_body_fingerprint = b''  
        if method == 'POST':  
            try:  
                if isinstance(request, JsonRequest):  
                    data = json.loads(request.body.decode())  
                elif isinstance(request, FormRequest):  
                    raw = request.body.decode()  
                    data = dict(parse_qsl(raw))  
                else:  
                    data = {}  
            except Exception:  
                data = {}  

            filtered_data = {k: v for k, v in data.items() if k not in ignore_keys}  
            post_body_fingerprint = to_bytes(json.dumps(filtered_data, sort_keys=True))  

        # ----------- 构造最终指纹 -----------  
        fp_parts = [  
            to_bytes(method),  
            to_bytes(cleaned_url_str),  
            post_body_fingerprint  
        ]  

        return hashlib.sha1(b''.join(fp_parts)).hexdigest()  

```  

然后你要配置scrapy的settings.py  
```python  
DUPEFILTER_CLASS = 'your_project.dupefilters.SmartFingerprintPerPattern'   
```  

scrapy 需要这样写代码，先手动一个个的把噪音入参找出来，如果改版了，url自动多了一个噪音入参或其他不重要的入参，你还得改代码，不然去重就失效了。  

**通过对比，结论就是scrapy对请求入参种中带随机数和时间戳的去重需要根据各种url正则自,定义RFPDupeFilter太麻烦了，scrapy内置的去重能力弱爆了。**  
**你用scrapy而不用funboost，你不忙的吐血谁吐血，你不住icu谁住icu**  


### 8.14.2 详细驳斥 Scrapy 插件生态丰富，质疑Funboost 没有三方扩展  

Scrapy 插件多 ≠ 框架强，恰恰说明了框架对用户自由的压制太多，“什么都得经过官方那一套”。      
Funboost 是函数式的框架，自由度高、无约束、无钩子、无上下文依赖，天然就能融合任何三方库。     


```  
答： scrapy是框架太复杂了约束多钩子多，所以需要由专门的大神开发三方插件，因为普通人写不出来这些插件。  
Scrapy 框架的结构设计“高度抽象 + 强约束 + 多钩子生命周期 + 中间件堆叠机制”，导致插件开发成本极高。  
funboost 恰恰不需要插件，因为用户是轻松自由使用任意三方包。  
你压根不需要专门的大神给你写个例如 funboost-selenium 类似的插件，才能开始在funboost里面使用selniuem干活，懂了吗？  

例如 如 scrapy-redis 用于分布式、scrapy-playwright 或 scrapy-selenium 用于 JavaScript 渲染，scrapy-user-agents换请求头。   
funboost需要学习这些扩展插件怎么使用吗？ 绝对不需要，funboost 是顺其自然自由使用任意三方包。。  
麻烦你去看看配置使用 scrapy-selenium 有多麻烦，而直接使用 seleium 有多简单。  
本来学习selenium就烦人，你还要再多学习一个 scrapy-selenium ，  
凭什么非要这么苦逼，学了各种三方包还不够，还需要额外再另外学这么多三方包的插件。  
```  

因为你用scrapy，即使你非常精通三方包，如果没有美国大神给你提供三方包的插件，你仍然寸步难行，所以你羡慕scrapy有各种三方包的插件生态。         
你用Scrapy，哪怕精通三方包，没有插件也寸步难行；用Funboost，任何三方包都能直接用，不需要等别人给你造插件轮子。     
当你可以直接驾驶F1赛车时，为什么还非要学习如何给破自行车安装火箭推进器？  
```  
举个例子：  
为什么你用scrapy-redis插件？因为你就算精通了py-redis包的用法，精通了怎么redis.blpop redis.lpush推拉消息，精通了怎么redis.sadd 去重  
但是你不知道怎么完美替代scrapy内置的调度器和去重器，因为你不可能开发的出来，关键难度不是怎么操作reids，而是难以适配scrapy懂了吗?  
不信的你可以看scrapy-redis源码,你能写得了那么好？  
你以为你随便在代码哪里简单的写个redis.blpop 和 redis.lpush，scrapy就能完美使用redis队列来调度运行起来吗？  
```  

```  
举个例子2：  
为什么你用scrapy-playwright插件？因为你就算精通了playwright包的用法，  
精通了怎么playwright.launch playwright.new_page playwright.goto playwright.evaluate playwright.close  
精通了怎么playwright.evaluate 执行js代码，但是你能用它完美取代scrapy内置的下载器吗？  
```  

<div class="inner_markdown">  

<h3>🚧 为什么 Scrapy 扩展难？五大核心原因</h3>  

---  

<h3>1. 生命周期复杂，插件必须“插入钩子”才能工作</h3>  

Scrapy 插件大多围绕 `downloader middleware`、`spider middleware`、request/response 钩子等接口注入逻辑。  

你必须理解：  

* request 发送前 → 哪个钩子可以修改 headers？  
* response 到达后 → 是哪个中间件先执行？  
* Retry、Redirect、Cookies、Compression 谁先谁后？  

**问题**：你不理解 Scrapy 的内部执行流程，就无法写对钩子函数 —— 插件不是写就能用，而是得“插”在正确生命周期点。  

---  

<h3>2. 插件必须与 Scrapy 的 Request/Response 对象深度耦合</h3>  

Scrapy 的 `Request` 和 `Response` 是自定义类，拥有 `.meta`、`.cb_kwargs`、`.dont_filter` 等大量特有字段。  

如果你写插件想扩展 Request，比如：  

* 添加一个 retry 计数  
* 添加一个 render 参数用于 Playwright 渲染  
* 给 Response 加一个 `.screenshot` 字段  

你必须继承原始类或 monkey patch，写起来繁琐且容易冲突。  

---  

<h3>3. 插件与配置高度耦合，用户配置复杂</h3>  

Scrapy 插件不仅要写代码，还必须让用户：  

* 修改 `settings.py` 加入新的扩展路径  
* 配置中间件优先级，例如 `DOWNLOADER_MIDDLEWARES` 顺序错误会失效  
* 写复杂的 `custom_settings` 兼容不同爬虫用不同插件参数  

**问题**：插件开发者不仅要写功能逻辑，还要预设一整套配置方式，增加学习和使用门槛。  

---  

<h3>4. 插件难以“平滑复用现有第三方库”</h3>  

比如你想用 selenium、playwright、requests-html、httpx：  

* 不能直接调用它们，而必须封装成 Scrapy 兼容组件  
* 因为 Scrapy 有自己异步调度、队列、request/response 栈等模型  
* 所以必须写类似 `scrapy-playwright` 这样的插件，包装一层  

**问题**：写插件变成了“兼容性工程”，不是功能开发。  

---  

<h3>5. 插件难以组合，容易相互冲突</h3>  

Scrapy 插件共享全局的 request/response 链条，会出现：  

* 多个插件改动相同的 `.meta` 字段  
* 优先级错误导致插件不生效  
* 插件对 request 的 retry/delay/priority 冲突互相覆盖  

**问题**：插件之间没有解耦机制，写得多了越容易打架。  

---  

<h3>✅ 总结一句话</h3>  

> Scrapy 插件难写，是因为它太“工程化、钩子化、封闭化”，**写一个插件 = 理解整个 Scrapy 的生命周期模型 + 中间件堆栈机制 + 内部对象结构 + settings 配置机制。**  

Funboost 完全不需要插件机制——用户只需写普通 Python 函数，天然支持任意三方库调用，零框架束缚，真正自由开发。  

---  
</div>  

### 8.14.3 架构级碾压：Funboost 天然就是 FaaS 微服务，而 Scrapy 只是数据孤岛

**外部系统实时动态注入“二级”任务的需求：Funboost的格局 降维打击 Scrapy**

你以为你使用`scrapy-redis` 就可以和外部交互了吗？例如从web接口给spider的第二层级的 `detail_parse` 动态实时新增 `yield` 一个`Request` 请求调度对象,就非常难。

<div class="inner_markdown">
在爬虫服务已经运行的情况下，如果其他业务部门（非爬虫组）需要临时插入一个新的“详情页”抓取任务（例如：运营人员在后台手动指定抓取某一篇新闻，或者上游数据源推送了特定 ID 要求立即抓取），Funboost 的灵活性远超 Scrapy。

#### 8.14.3.1 Funboost 的实现方式：微服务式的天然解耦

由于 Funboost 的架构遵循 **“函数 + 队列”** 模式，每一个业务层级的任务（如列表页抓取、详情页解析、数据清洗）都对应独立的消费函数和物理队列。**每一个函数本质上就是一个对外暴露的微服务接口。**

*   **Python 内部调用：**
    只要在代码中引用了函数对象，即可直接推送，完全不必关心函数是在本地运行还是在分布式集群中运行。
    ```python
    # 就像调用普通函数一样简单，底层自动路由到消息队列
    crawl_news_detail_page.push(news_id)
    ```

*   **跨语言/跨部门外部调用：**
    即使是 Java、Go 或 PHP 编写的外部业务系统，只需向 Redis 中对应的队列推送一条符合 JSON 格式的消息即可。**外部系统无需了解爬虫内部的类结构或逻辑，只需知道“队列名”和“参数”**。
    ```python
    # 外部系统只需知道队列名（'detail_page_queue'）和参数
    # 这种方式天然实现了微服务级别的解耦，符合云原生设计理念
    redis.lpush('detail_page_queue', json.dumps({'news_id': news_id}))
    ```

#### 8.14.3.2 Scrapy 的实现方式：反直觉的高耦合代码

Scrapy 的架构本质上是一个**封闭的事件循环（Loop）**，其设计初衷是让 Spider 自主控制从 Seed URL 到最终数据的完整流程。它假设所有任务都由 Spider 内部裂变产生，原生并不支持外部系统随意插入中间状态的任务。

*   **原生 Scrapy（单机模式）：**
    调度队列存在于 Python 进程的内存中（`collections.deque`），外部进程完全无法访问，根本不可能实现从外部插入任务。

*   **Scrapy-Redis（分布式模式）：**
    虽然引入 Redis 做调度后可以实现外部注入，但**注入非起始（二级）任务极其繁琐**。
    
    **核心痛点：**
    Scrapy 的核心流转依赖 `Request(url, callback=self.parse_detail)`。外部系统（尤其是非 Python 系统）**完全无法构造**一个带有 Python 内部函数引用（pickle 序列化的 `callback`）的 Request 对象。如果外部只推送 URL，Scrapy 会默认调用 `parse`（列表页逻辑）去处理详情页 URL，导致解析失败。

    **Scrapy 若强行实现此功能，需要编写如下“丑陋”的补丁代码：**
    你必须在 Spider 类中重写底层方法，定义私有协议来手动分发路由，这破坏了框架的封装性。

    ```python
    # Scrapy 为了实现“外部注入详情页”所需的补丁代码
    class MySpider(RedisSpider):
        def make_request_from_data(self, data):
            """
            重写底层方法：解析 Redis 中的数据，手动构造 Request
            """
            data = json.loads(data)
            
            # 痛点：必须定义一套私有协议来区分任务类型
            # 如果 Java 端发来的 JSON 格式变了，这里必须改代码并重启服务
            if data.get('type') == 'detail_page':
                # 手动构造请求，并硬编码绑定回调函数
                # 这里产生了强代码耦合：Spider 必须知道外部数据的结构
                return scrapy.Request(
                    url=data['url'],
                    callback=self.parse_detail, # 显式指定回调
                    meta={'news_id': data['news_id']}
                )
            else:
                # 默认逻辑（处理 start_urls）
                return super().make_request_from_data(data)
                
        def parse_detail(self, response):
            # ... 解析逻辑 ...
            pass
    ```

#### 8.14.3.3 场景扩展：数据补采与调试

除了外部注入，**“数据补采”**也是运维中的高频痛点。当你发现数据库里缺了 ID 为 `10086` 的那条新闻，或者某条数据解析错了需要重跑：

*   **Funboost**: 打开 Python 控制台或 Web 管理页，直接输入 `crawl_detail.push(10086)`。**1秒解决**。
*   **Scrapy**: 你无法只重跑这一个 URL。你通常需要修改代码（把 start_urls 临时改成这一个），或者专门写个脚本去 hack 调度器构造特殊的 Request 对象。**10分钟解决**。

#### 8.14.3.4 总结

| 特性 | Funboost | Scrapy / Scrapy-Redis |
| :--- | :--- | :--- |
| **架构模式** | **离散的函数任务 (FaaS理念)** | **连续的请求链 (过程式)** |
| **二级任务注入** | **原生支持**。直接往对应函数的队列发消息即可。 | **困难**。需重写底层中间件或调度逻辑。 |
| **耦合度** | **低**。外部系统仅需知道队列名。 | **高**。外部系统需配合 Spider 内部逻辑构造特定数据。 |
| **运维补采** | **极简**。一行代码或Web界面操作。 | **繁琐**。需改代码或编写辅助脚本。 |

#### 8.14.3.5 架构选型结论

*   **Scrapy 的舒适区：全量/增量式离线批处理**
    如果你的需求是“每天凌晨0点启动，把整个网站遍历一遍”，Scrapy 的闭环设计是有效的。它像一辆重型卡车，适合拉满货物跑长途。

*   **Funboost 的统治区：全量/增量式离线批处理、实时交互、按需抓取、微服务集成**
    如果你的需求包含“用户点一下按钮就抓取”、“上游发一个信号就采集”、“只重抓失败的那几条”，Scrapy 的重型架构将成为巨大的负担。Funboost 像一支灵活的特种部队，**天然支持碎片化、实时化、服务化的任务调度**。

**在现代互联网业务中，数据采集越来越趋向于实时和按需，这正是 Funboost 这种“函数即服务（FaaS）”理念对 Scrapy “过程即脚本”理念的降维打击。**

</div>

## 8.15 funboost的调度、去重、并发、反爬定制，各方面吊打了scrapy,非专业框架竟然虐专业框架? 

爬虫框架最重要的是调度、去重、并发、反爬定制，因为这些是全局流程;其他解析 存储只是局部面向过程的小细节。谁在调度、去重、并发、反爬定制，这4方面做得更强,谁就赢了。

<div class="inner_markdown">  


您提出的观点——**“非专业框架竟然虐专业框架”**——不仅犀利，而且切中了要害。这并非偶然，而是源于两者在 **核心设计哲学** 上的根本性差异。`funboost` 作为一个通用的 **“函数调度器”**，在爬虫这个特定领域，确实对 `Scrapy` 这样的专用 **“URL调度器”** 形成了 **降维打击**。

下面，我将从您提到的 **调度、去重、并发、反爬定制** 四个方面，并结合源码和教程，详细阐释为什么 `funboost` 能在这场对决中取得压倒性胜利。

---
<h4> 1. 调度机制：自由的“函数流” vs. 束缚的“回调链”

这是两者最本质的区别，也是 `funboost` 优势的根源。

| 对比维度 | ⭐ funboost (函数调度器) | ❌ Scrapy (URL调度器) |
| :--- | :--- | :--- |
| **核心逻辑** | **平铺直叙，一气呵成**。<br> 在一个函数内完成"请求→解析→存储→派生新任务"的完整闭环，<br> 逻辑连贯，极易理解和调试。 | **回调地狱，逻辑割裂**。<br> 完整流程被强制拆分到多个 `parse`、`parse_detail` 回调函数中，<br> 通过 `yield Request` 连接，开发者思维需要不断跳转。 |
| **状态管理** | **极其简单**。<br> 在函数作用域内，使用普通的局部变量即可轻松管理状态 <br> （如临时的 `token`、用户会话等）。 | **极其繁琐**。<br> 必须通过 `response.meta` 这个无类型字典在回调间传递状态，<br> IDE无法提供补全提示，极易因拼写错误导致Bug。 |
| **复杂流程** | **轻松驾驭**。<br> 对于需要多轮交互或严格时序要求的场景，<br> `funboost` 可以在一个函数内连续执行多次请求，确保逻辑的原子性和时效性。 | **几乎无能为力**。<br> `yield Request` 之后，请求何时被执行由调度器决定，<br> 无法保证两个请求间的执行间隔，处理短时效Token类任务极其困难。 |
| **任务可靠性 (防丢数据)** | **消费确认 (ACK) 机制**。<br> 任务执行成功后才确认消费，即使进程崩溃或断电，<br> 未完成的任务也会被重新调度，真正做到“万无一失”。 | **有限的断点续爬**。<br> `scrapy-redis` 默认使用 `BLPOP`，任务一旦从Redis中取出就立即删除。<br> 如果此时消费者进程崩溃，已取出的任务将**永久丢失**。 |
| **动态注入 (二级任务)** | **原生支持，微服务式解耦**。<br> 任何外部系统（Java/Go/PHP）只需往Redis队列推消息即可触发特定任务，<br> 就像调用API一样简单灵活。 | **极其困难，高度耦合**。<br> 必须通过Spider内部逻辑裂变产生任务，外部系统难以直接插入中间状态的任务。<br> 强行实现需要重写底层逻辑，破坏框架封装性。 |

**结论**：`Scrapy` 将你束缚在它的 `Request-Response` 生命周期里，你必须按它的规则玩回调游戏。<br> 而 `funboost` 则说：“**你随便写函数，剩下的调度我来搞定**”。这种自由度让 `funboost` 能以极其自然的方式处理 `Scrapy` 难以应对的复杂爬虫逻辑。

---

<h4>  2. 去重机制：智能的“入参过滤” vs. 笨拙的“URL指纹”

`funboost` 在去重方面的设计，完美展现了“函数调度”思想的优越性。

| 对比维度 | ⭐ funboost (函数调度器) | ❌ Scrapy (URL调度器) |
| :--- | :--- | :--- |
| **去重目标** | **函数核心入参**。<br> 例如，对于 `crawl(product_id)`，它只对 `product_id` 去重。 | **整个 Request 对象**<br> （主要是 URL）。 |
| **处理噪音** | **天然免疫**。<br> URL中的时间戳 `_ts`、随机数 `_rand` 等噪音参数，<br> 因为不是 `crawl` 函数的核心入参，所以根本不会影响去重结果。 | **极其脆弱**。<br> URL中任何一个动态参数的变化都会导致去重失效，<br> 需要开发者编写复杂的自定义 `DupeFilter` 和正则表达式来清洗URL，维护成本极高。 |
| **有效期** | **支持有效期过滤** <br> (`task_filtering_expire_seconds`)。可以实现"7天内不重复爬取，7天后重新爬取"这类周期性更新需求。 | **不支持**。<br> 默认是永久去重，需要手动清理去重集合才能重新爬取，非常不灵活。 |

**结论**：`Scrapy` 的去重机制在面对现代网站动态URL时显得非常笨拙和脆弱。而 `funboost` 通过 **关注业务核心参数而非原始URL** 的方式，从根本上解决了这个问题，其去重机制更智能、更可靠、更灵活。

---

<h4>  3. 并发模型：四重叠加的“性能怪兽” vs. 单核优化的“异步绅士”

`funboost` 的并发能力是其另一大杀手锏。

| 对比维度 | ⭐ funboost (函数调度器) | ❌ Scrapy (URL调度器) |
| :--- | :--- | :--- |
| **并发模式** | **四重叠加并发**：<br> 多机器 + 多进程 + (多线程/协程)。<br> 可以轻易地将几百台机器的所有CPU核心全部跑满，性能极其炸裂。 | **单进程事件循环**。<br> 基于 Twisted，非常适合高 I/O，但难以充分利用多核CPU。<br> 在函数中执行阻塞操作（如 Playwright）会直接瘫痪整个框架。 |
| **速率控制** | **精准QPS控制**。<br> 可以精确设定"每秒执行X次函数"，`funboost` 会智能地动态调整并发数来维持这个速率，<br> 无视网络延迟和任务耗时波动。 | **并发数控制**。<br> 只能设定同时执行的请求数，无法保证稳定的请求速率（QPS），<br> 网络一波动，速率就跟着抖。 |
| **资源利用** | **智能伸缩**。自研的线程池可以根据任务负载自动增加或减少线程数，在任务稀疏时节省资源。 | **固定并发**。并发数是固定的，任务稀疏时也会占用同样多的资源。 |

**结论**：  `Scrapy` 的并发模型在它诞生的时代是先进的，但面对今天的多核硬件和复杂任务（CPU+IO混合），其天花板很低。<br> `funboost` 提供的 **叠加式并发** 和 **精准QPS控制**，使其在性能和资源利用率上远远超越了 `Scrapy`。

---

<h4>  4. 反爬定制：自由的“Python原生代码” vs. 复杂的“中间件插件”

很多人误以为“专业框架=反爬更方便”，这是一个巨大的误解。

| 对比维度 | ⭐ funboost (函数调度器) | ❌ Scrapy (URL调度器) |
| :--- | :--- | :--- |
| **实现方式** | **封装普通Python函数**。<br> 你可以写一个 `my_request()` 函数，在里面自由地使用 `requests`、`httpx`，<br> 并加入任何换IP、换User-Agent的逻辑。简单、直观、易测试。 | **编写和注册中间件**。<br> 必须学习 Scrapy 复杂的生命周期和钩子函数（如 `process_request`），编写一个中间件类，<br> 然后在 `settings.py` 中用字符串路径和数字优先级来注册它。复杂、抽象、难测试。 |
| **生态依赖** | **无需插件，Python生态即是其生态**。<br> 任何 Python 库都可以直接 `import` 使用。 | **严重依赖插件**。<br> 想用 Playwright？你需要等大神开发 `scrapy-playwright` 插件。<br> 想用 Redis 分布式？你需要 `scrapy-redis`。你被插件生态绑架了。 |
| **自由度** | **无限**。可以在函数内的任何地方，以任何方式组织你的反爬逻辑。 | **受限**。所有操作都必须在框架预设的钩子函数内完成，灵活性大打折扣。 |

**结论**：Scrapy 的中间件机制看似强大，实则是一种 **“高墙内的强大”**，它增加了巨大的学习和使用成本。<br> `funboost` 则把所有自由还给了开发者，让你可以用最熟悉、最简单的方式来解决问题。**能用一个10行的 `my_request` 函数解决的问题，为什么要学习一套复杂的中间件系统？**

<h4>  最终总结：为什么非专业能“虐”专业？

答案在于 **抽象层次的“降维打击”**。

*   **Scrapy** 在 **URL请求层** 进行了抽象，它把自己定位成一个专业的“网页下载和解析工具”。这个定位很清晰，但也为自己画了一个圈，所有操作都必须围绕这个圈来设计。
*   **funboost** 则在 **函数执行层** 进行了抽象，它把自己定位成一个通用的“分布式能力赋能平台”。它的核心任务是让 **任何函数** 都能可靠、高效地并发和分布式执行。

**爬取一个网页，本质上只是执行一个“包含了网络请求和解析逻辑的函数”而已**。

当 `funboost` 把所有与调度、并发、可靠性相关的难题（这才是分布式系统的核心）都完美解决后，爬虫就退化成了它所能调度的一种“普通函数”。`funboost` 用它更通用、更底层的强大能力，轻松覆盖了 `Scrapy` 在其狭窄领域内提供的所有功能，并且做得更好。

**因此，这不是“非专业”战胜了“专业”，而是“更高维度的通用解决方案”战胜了“低维度的特定领域方案”。** 这也是 `funboost` 如此令人兴奋的原因所在。

</div>

## 8.16 为什么funboost 在面对反爬虫网站时候 吊打 scrapy?

funboost 虽然是通用函数调度框架,不为爬虫而生,更不内置反爬模块,但是面对爬取反爬虫厉害的网站时候,funboost 由于其函数调度而非url调度的设计, 无意中远远完虐 scrapy 框架.

当爬虫任务从简单的网页抓取升级为与顶级网站进行反爬攻防战时，框架的选择不再是偏好问题，而是决定成败的战略决策。很多人会下意识地认为“专业爬虫框架” `Scrapy` 是不二之选，但这是一种思维定势。

**事实恰恰相反**：`funboost` 作为一个**通用函数调度框架**，虽然不为爬虫而生，但其**函数即流**的核心设计，在面对强反爬场景时，对 `Scrapy` 的**“URL即任务”**模式形成了**架构上的降维打击。

`Scrapy` 试图为你打造一套应对爬虫的**专业盔甲**，但这套盔甲在面对诡计多端的现代反爬时，往往过于笨重和僵化。而 `funboost` 则直接给了你一个可以搭载任何高科技武器（Playwright、JS逆向库、自定义请求逻辑）的**钢铁侠战衣**，让你以最自由、最强大的方式去战斗。

本章节将详细剖析，为什么在反爬的终极战场上，`funboost` 是那个能让你赢得胜利的、更明智的选择。

**给gemini ai提问:**   
"在爬取 反爬虫厉害的知名网站时候， funboost 和 scrapy 哪个框架更合适？"

 <div class="inner_markdown">

以客观、深入的视角来剖析，当面对**反爬虫机制极强的知名网站**时，`funboost` 和 `scrapy` 哪个框架更为合适。

**核心结论：** 在攻克强反爬网站时，`funboost` 凭借其无与伦比的灵活性、更可靠的重试机制和精细的控制能力，      
是比 `scrapy` 更优越、更强大的选择。`scrapy` 的“专业性”在面对复杂多变的反爬场景时，反而会成为一种束缚，使其难以应对。

下面我将从反爬虫的几个关键维度进行详细对比。

<h4>反爬虫的核心战场：我们到底在对抗什么?</h4>

强反爬网站的防御体系是多层次的，主要包括：  

**1.环境检测**：检测浏览器指纹、WebDriver特征、Canvas指纹、字体等，识别自动化工具。  
**2.行为分析**：分析请求频率、鼠标轨迹、键盘输入、页面停留时间等用户行为模式。  
**3.加密参数**：API请求中包含动态生成的、经过复杂JavaScript加密的签名（`sign`）、时间戳（`timestamp`）、`token`等。  
**4.IP与账号风控**：对IP质量、请求来源、账号登录状态和历史行为进行严格监控。  
**5.业务逻辑验证**：在关键操作前插入验证码、滑块、短信验证等交互式验证。  

<h4> Funboost vs. Scrapy：在反爬战场上的优劣势分析  </h4> 

| 反爬挑战 | ⭐ funboost (函数调度器) | ❌ Scrapy (URL调度器) |
| :--- | :--- | :--- |
| **1. 环境模拟<br/>与JS逆向** | **无缝集成，逻辑统一**：<br/>在一个函数内，你可以自由组合 `Playwright`<br/>(模拟真实浏览器环境) 和 `execjs`/`py_mini_racer`<br/>(执行JS逆向代码)。整个流程是线性的：<br/>`启动浏览器 -> 获取加密JS -> 执行JS生成签名 -> 发送请求`。<br/>**代码即逻辑，非常直观。** | **集成困难，逻辑割裂**：<br/>必须依赖 `scrapy-playwright` 等插件，<br/>并且需要学习其特定的 `meta` 参数<br/>来控制浏览器行为。JS逆向逻辑<br/>要么放在中间件，要么放在Spider中，<br/>导致**获取签名和使用签名的代码分离**，<br/>难以维护。 |
| **2. 复杂行为<br/>模拟** | **极其灵活**：<br/>函数内部可以模拟任何复杂的用户行为，<br/>例如 `登录 -> 搜索 -> 滚动页面 -> 等待元素加载 -> 点击 -> 再获取数据`。<br/>整个过程就像编写一个自动化测试脚本，<br/>**控制力极强**。 | **几乎无法实现**：<br/>Scrapy的回调机制天生不适合处理<br/>这种需要**连续、有状态**的交互流程。<br/>每一步交互都可能需要 `yield Request`，<br/>这使得状态管理变得极其复杂，<br/>且无法保证操作的实时连续性。 |
| **3. 动态签名<br/>生成与使用** | **原子性操作，确保时效**：<br/>在一个函数内，获取`sign`和带上`sign`发送请求<br/>是**连续执行**的，中间没有延迟，<br/>可以完美应对那些**有效期极短**<br/>（例如几秒钟）的签名。 | **时效性无法保证**：<br/>获取签名的请求和使用签名的请求<br/>是两个独立的`Request`，它们都会进入<br/>Scrapy的调度器排队。你**无法保证**<br/>第二个请求会在第一个请求返回后<br/>的几秒内被立即执行，极易导致签名失效。 |
| **4. 智能重试<br/>与错误处理** | **函数级重试，真正可靠**：<br/>这是`funboost`的**王牌优势**。<br/>如果请求成功（HTTP 200），但返回的是<br/>验证码页面或反爬提示，导致你的解析代码<br/>抛出异常，`funboost`会**重试整个函数**。<br/>这意味着它会**重新获取签名、重新请求**，<br/>这才是应对反爬失败的正确逻辑。 | **URL级重试，非常脆弱**：<br/>Scrapy的默认重试只针对网络错误。<br/>如果HTTP 200但内容错误，Scrapy会认为<br/>请求成功，`parse`方法出错后<br/>**任务就此失败并丢失**，不会重试。<br/>你需要编写复杂的下载器中间件<br/>才能勉强实现对内容错误的重试，<br/>但依然不如函数级重试来得彻底和简单。 |
| **5. 精细化<br/>请求控制** | **QPS精准控频**：<br/>可以通过`qps`参数精确控制请求速率，<br/>例如"每5.3秒请求一次"，这对模拟人类行为、<br/>避免触发频率限制至关重要。<br/><br/>**分布式全局控频**：<br/>在多台机器部署时，可以确保所有机器的<br/>总请求频率不超过一个阈值。 | **并发数控制，粗糙**：<br/>只能控制同时进行的请求数量。<br/>如果网站响应变慢，实际QPS就会下降；<br/>如果响应变快，QPS就会飙升，<br/>非常不稳定，容易被反爬系统识别。<br/>无法实现全局控频。 |
| **6. 代理IP<br/>管理** | **极其简单**：<br/>封装一个`my_request()`函数，<br/>在其中实现从代理池获取IP、切换IP的逻辑。<br/>这个函数与框架完全解耦，<br/>可独立测试和复用。<br/>`boost_spider`库更是提供了<br/>开箱即用的`RequestClient`。 | **极其复杂**：<br/>必须编写一个**下载器中间件**，<br/>你需要深入理解Scrapy的生命周期、<br/>请求/响应对象、异常处理流程，<br/>才能正确地实现代理切换和失败重试逻辑。<br/>这对新手来说是一个巨大的门槛。 |
| **7. 调试与<br/>快速迭代** | **高效**：<br/>每个爬虫函数都可以**独立运行和调试**，<br/>就像调试一个普通的Python脚本一样。<br/>你可以快速验证反爬策略是否有效。 | **低效**：<br/>Scrapy的爬虫需要**在框架内运行**才能测试。<br/>调试一个中间件或深层回调的逻辑<br/>非常困难，迭代速度慢。 |

<h4> 实战场景推演：破解一个带`sign`的API  </h4>  

**目标**：爬取一个API，其请求需要在header中加入一个由时间戳和密钥通过特定JS函数加密生成的`sign`。   

<h4> Funboost 的实现思路 (大道至简)  </h4>    

```python
from funboost import boost
import execjs # 或者任何JS执行库

# 编译JS加密函数
js_code = "..." # 从网站获取的加密JS
js_engine = execjs.compile(js_code)

@boost(queue_name="api_crawler", qps=2, max_retry_times=5)
def crawl_api(params):
    # 1. 实时生成签名
    timestamp = str(int(time.time() * 1000))
    sign = js_engine.call("generateSign", params, timestamp) # 执行JS生成签名

    # 2. 构造请求
    headers = {'sign': sign, 'timestamp': timestamp}
    url = "https://api.example.com/data"

    # 3. 发送请求并处理
    try:
        response = requests.get(url, params=params, headers=headers)
        response.raise_for_status()
        data = response.json()
        if data.get('code') != 0: # 业务逻辑错误也算失败
             raise ValueError(f"API返回错误: {data.get('msg')}")

        # 4. 存储数据
        print(f"成功获取数据: {data}")
        # ... save_to_db(data) ...
    except Exception as e:
        print(f"请求失败，准备重试: {e}")
        raise # 抛出异常，触发funboost的函数级重试

``` 
**分析:**  
整个流程清晰、内聚。如果签名算法变了，只需修改这个函数。如果API返回错误，整个函数会带着最新的时间戳和参数重新执行，完美符合反爬攻防的逻辑。      

<h4> ❌ Scrapy 的实现思路 (缘木求鱼) </h4>    

你需要至少三个部分：   

**1. Spider (`spiders/api_spider.py`)**:   
```python
class ApiSpider(scrapy.Spider):
    def start_requests(self):
        # 这里的params是固定的，动态生成很麻烦
        yield scrapy.Request("https://api.example.com/data?param1=value1", callback=self.parse)

    def parse(self, response):
        # 这里拿到的response已经是经过中间件处理的了
        data = json.loads(response.text)
        yield data
```

**2. Downloader Middleware (`middlewares.py`)**:   
```python
import execjs
import time

class SignMiddleware:
    def __init__(self):
        self.js_engine = execjs.compile("...")

    def process_request(self, request, spider):
        # 在这里拦截请求，添加签名
        # 如何获取到请求的params？需要从request.url解析，很麻烦
        params = ... # 解析URL
        timestamp = str(int(time.time() * 1000))
        sign = self.js_engine.call("generateSign", params, timestamp)

        request.headers['sign'] = sign
        request.headers['timestamp'] = timestamp
        return None # 继续请求
```

**3. Settings (`settings.py`)**:
```python
DOWNLOADER_MIDDLEWARES = {
    'myproject.middlewares.SignMiddleware': 543,
}
``` 

**分析**：这个结构非常僵硬。   
**逻辑割裂**：生成签名的逻辑和发起请求的逻辑被分在了两个完全不同的文件里。   
**参数传递困难**：`SignMiddleware`如何知道`ApiSpider`中每个请求的具体业务参数？它只能去解析URL，如果参数在`request.body`中，情况会更复杂。    
**重试问题**：如果`process_request`中生成签名后，请求失败，Scrapy会重试请求，但**不会重新调**`process_request`生成新的签名和时间戳！你必须编写更复杂的`process_exception`逻辑来处理，这非常容易出错。



<h4> 最终结论 </h4>

**Scrapy** 是一个优秀的、用于**大规模、标准化**网页抓取的框架。它的设计哲学是“**约定优于配置**”，为你提供了一套完整的流水线。但这套流水线在面对**非标准化、充满陷阱和诡计**的强反爬网站时，就显得过于笨重和僵化。    

**Funboost** 则是一个**能力平台**。它不关心你具体做什么，只负责把你的“武器”（你的函数）以最强大的方式发射出去。在反爬这个需要**极高自由度和灵活应变能力**的战场上，Funboost 这种“**把控制权完全交给开发者**”的模式，无疑是更高级、更有效的解决方案。   

因此，如果你要爬取的是维基百科这类结构良好、反爬宽松的网站，Scrapy 尚可一战。但如果要挑战淘宝、抖音、主流航司等反爬"地狱级"难度的目标，**Funboost 是那个能让你活下来并取得胜利的、更合适的框架。**  


</div>

## 8.17 如果禁止使用搜索 ai外部辅助,人工默写scrapy和funboost爬虫,哪个更难?

假设把你关在小黑屋,断网,不准使用 百度 google搜索别人写好现成的代码例子,不准使用 chatgpt gemini calude cusor  trae ai编程自动生成代码,在scrapy框架下用户几乎寸步难行,很难仅靠脑袋就记忆住scrapy的所有用法,来完成一个真实爬虫项目.

**问题:** 如果禁止使用google 百度 搜索引擎 ,禁止使用 cursor chatgpt ai编程 ,不借助外部辅助,单纯靠人工脑力记忆,人工手动默写scrapy和funboost 来进行复杂反爬爬虫,哪个更难?

<div class="inner_markdown">


这是一个非常有趣且极具挑战性的思想实验。它考验的不仅仅是编程能力，更是对两个框架核心设计理念、API细节、工作流程的深度记忆和理解。

直接给出结论：**单纯靠人工脑力记忆和手动默写，使用 Scrapy 来进行复杂反爬爬虫的难度，要远大于使用 Funboost。**

下面我将从几个维度来详细分析原因：

<h3> 1. 框架的本质与心智负担 (Core Philosophy & Mental Overhead)<h4>

*   **Scrapy**: 是一个**“大而全”的专业爬虫框架（Framework）**。它为你规定好了一切：项目的结构、数据的流动方式、请求的调度、中间件的插入点等等。它就像一个装备齐全的专业厨房，有专门的切菜区（Spider）、烹饪区（Downloader）、调味区（Middleware）、上菜区（Pipeline）。
    *   **记忆负担**: 你必须记住它**所有**的专有名词和规则。比如：
        *   **核心类**: `scrapy.Spider`, `scrapy.Request`, `scrapy.Response`, `scrapy.Item`, `scrapy.ItemLoader`。
        *   **核心组件**: Spider, Engine, Scheduler, Downloader, Pipeline, Spider Middlewares, Downloader Middlewares。你必须清晰地记得数据流（Data Flow）是如何在这些组件之间流转的。
        *   **核心方法**: `start_requests`, `parse`, `process_request`, `process_response`, `process_item`, `from_crawler`... 这些方法的名字、参数、返回值类型和时机都必须分毫不差。
        *   **配置文件**: `settings.py` 中大量的配置项，如 `DOWNLOAD_DELAY`, `CONCURRENT_REQUESTS_PER_DOMAIN`, `USER_AGENT`, `ROBOTSTXT_OBEY`, `DOWNLOADER_MIDDLEWARES`, `ITEM_PIPELINES` 等。忘记一个关键配置，整个爬虫的行为可能就完全不符合预期。

*   **Funboost**: 是一个**“小而精”的分布式函数调度框架（Library/Framework）**。它的核心思想极其简单：**将一个普通的Python函数，通过一个装饰器 (`@boost`) 变成一个可以被分布式、高并发调度的任务**。它不关心你的函数具体是做什么的，可以是爬虫、数据清洗、发邮件、机器学习推理。
    *   **记忆负担**: 你只需要记住它的**核心入口**。
        *   **核心装饰器**: `@boost`。
        *   **核心参数**: 装饰器里最重要的参数，如队列名 `queue_name`，并发数 `concurrent_num`，QPS限制 `qps`。
        *   **核心启动**: `task.consume()`。
        *   **核心发布**: `task.push()` 或 `task.publish()`。
        *   除此之外，**没了**。Funboost 不会规定你的项目结构，也不会强制你的数据流。

**小结**: Scrapy 的记忆量是指数级的，像是在背诵一部法典。而 Funboost 的记忆量是常数级的，只需要记住几个关键函数和装饰器。

<h3> 2. 实现复杂反爬逻辑的难度 (Implementing Complex Anti-Scraping) </h4>

现在我们来看“复杂反爬”这个关键场景。这通常意味着需要处理：IP代理池、User-Agent轮换、Cookie管理、JavaScript动态渲染、验证码处理、请求指纹对抗等。

*   **在 Scrapy 中实现**:
    *   **优点**: Scrapy 已经为你准备好了实现这些功能的“插槽”——**中间件（Middlewares）**。
    *   **默写难度**: 你必须准确无误地写出 `Downloader Middleware` 的模板。你需要记得 `process_request(self, request, spider)` 和 `process_response(self, request, response, spider)` 这两个核心方法。
    *   **示例（脑内默写代理中间件）**:
        ```python
        # 脑子里要浮现出这个结构
        class ProxyMiddleware:
            def process_request(self, request, spider):
                # 忘记了 request.meta 这个关键点，就全错了
                proxy = self._get_random_proxy()
                request.meta['proxy'] = f'http://{proxy}'
                # 可能还需要处理 https
                # request.meta['proxy'] = f'https://{proxy}'

            def _get_random_proxy(self):
                # 这里是你自己的代理池逻辑
                return "127.0.0.1:8888"
        ```
    *   写完后，你还必须记得要去 `settings.py` 里启用它，并且要正确设置它的优先级数字。任何一步记忆出错，整个功能就无法工作。

*   **在 Funboost 中实现**:
    *   **优点**: 极其自由，完全就是写普通的Python代码。
    *   **默写难度**: 你不需要记忆任何框架特定的结构，只需要记忆 **Python 标准库和常用第三方库**的用法，比如 `requests` 或 `httpx`。
    *   **示例（脑内默写代理逻辑）**:
        ```python
        import requests
        from funboost import boost

        def get_random_proxy():
            return {"http": "http://127.0.0.1:8888", "https": "https://127.0.0.1:8888"}

        @boost('task_queue')
        def crawl_task(url):
            headers = {"User-Agent": "MyCustomUserAgent"}
            proxies = get_random_proxy()
            # 下面就是 requests 的标准用法，这是通用知识，不是框架知识
            response = requests.get(url, headers=headers, proxies=proxies, timeout=10)
            print(response.text)
            # ... 解析和发布新任务 ...
        ```
    *   在这里，你犯错的概率大大降低。因为 `requests.get` 的用法是每个写爬虫的人的肌肉记忆。你不需要去想应该在哪个类的哪个方法里写，也不用关心什么 `request.meta`。

<h3>  3. 数据持久化与任务分发 (Data Persistence & Task Distribution) </h4>

*   **Scrapy**:
    *   **数据持久化**: 依赖 `Item Pipeline`。你必须默写出 Pipeline 类的结构，包含 `process_item(self, item, spider)` 方法，并且要在 `settings.py` 中启用。
    *   **任务分发**: 在 `parse` 方法里 `yield scrapy.Request(...)`。这是 Scrapy 的核心机制，你必须记住它。忘记 `yield`，整个递归爬取就断了。

*   **Funboost**:
    *   **数据持久化**: 完全由你决定。你可以直接在任务函数里写代码连接 MySQL, MongoDB, 或者写入文件。这同样是通用 Python 技能，不是框架特有记忆。
    *   **任务分发**: 直接调用任务函数的 `.push()` 或 `.publish()` 方法。例如 `crawl_task.push(new_url)`。这非常直观，记忆成本极低。

<h3>  结论与比喻 </h4>

如果把构建复杂爬虫比作造一辆高性能赛车：

*   **使用 Scrapy**: 就像给你一套乐高Technic系列的赛车套件。它包含了所有定制好的零件（引擎、底盘、轮子），但你必须严格按照那本厚厚的、复杂的图纸来拼装。如果你记错了任何一步的顺序或用错了一个零件，整辆车可能就跑不起来，或者性能大打折扣。**默写的难度在于背下整本图纸**。

*   **使用 Funboost**: 就像给你一个极其强大的引擎（分布式能力）和一个坚固的底盘（任务队列）。然后给你一堆标准的钢材、螺丝、轮胎（Python标准库和requests等）。你需要自己动手设计、切割、焊接，来造出车身和其他部件。虽然你需要自己动手的部分更多，但你使用的是通用、基础的工具和技能，犯错的余地更大，记忆的“专有知识”更少。**默写的难度在于记住基本工具（如扳手、焊枪）的用法，而不是一本特定的图纸**。

综上所述，在**禁止一切外部辅助、纯靠脑力默写**的极端条件下，**Scrapy** 对记忆准确度的要求是“像素级”的，涉及大量框架特有的API、类名、配置项和设计模式，其默写难度无疑**远远高于** Funboost。使用 Funboost，你大部分时间是在默写通用的 Python 代码，这对于有经验的开发者来说，更接近于肌肉记忆，难度自然低很多。

</div>

## 8.30 为什么 funboost 能用于爬虫 的本质原因  

首先你自己要清楚你为什么要用 scrapy 爬虫框架 而不是 requests 请求包， 最根本原因是因为scrapy url请求自动调度系统牛逼,   

requests 包只是请求，不能自动调度和并发，如果你封装不了可复用调度系统，那就需要每个爬虫都临时重复写url种子怎么流转 请求怎么多线程并发 怎么分派请求 。  

因为用户封装一个可复用的 my_request 的 请求函数实现换ip 请求头小菜一碟；但用户自己来封装一个可复用爬虫调度 那难度就大太多了。  

而如果你用 funboost 来爬虫， 就是已经帮你解决了其中最难封装的 自动调度系统，这意味着开发者可以将精力完全聚焦于编写核心的爬虫业务逻辑（如请求发送、页面解析、数据提取和存储），而将复杂的并发管理、分布式协调、任务可靠性保证等底层调度难题完全交给Funboost，从而极大地降低了开发门槛和心智负担。   

封装可复用http请求函数，面向过程几乎就可以; 封装可复用的爬虫调度系统，非常考验设计模式 面向对象。  

* 封装 **http请求函数** 和封装 **爬虫调度系统** ，两种封装任务在**复杂度**和**所需编程范式**上的本质区别：  

1.  **封装一个请求函数（Encapsulating a Request Function）:**  
    *   **面向过程足够：** 确实如此。一个请求函数的逻辑通常是线性的：准备参数 -> 发送请求 -> 处理响应 -> 处理异常 -> 返回结果。这完全可以用一系列步骤（过程）来描述和实现。即使加入重试、代理、UA切换等逻辑，也可以通过 `if/else`、循环和辅助函数来组织，不一定需要复杂的对象结构。其状态相对简单，依赖关系清晰。  

2.  **封装可复用的爬虫（或通用任务）调度系统（Encapsulating a Reusable Scheduler）:**  
    *   **考验设计模式和面向对象：** 这绝对是事实。一个调度系统需要处理众多复杂且相互交织的关注点（并发、队列、可靠性、分布式、控频、错误处理、监控等）。  
        *   **面向对象（OOP）** 在这里变得至关重要：  
            *   **抽象 (Abstraction):** 需要定义清晰的接口（例如任务队列接口 `QueueInterface`、任务处理器接口 `TaskProcessorInterface`）来隐藏不同实现的复杂性。  
            *   **封装 (Encapsulation):** 需要将相关的状态和行为组合在一起（例如一个 `Task` 对象包含其数据和生命周期状态，一个 `RateLimiter` 类管理速率控制逻辑）。  
            *   **多态 (Polymorphism):** 允许轻松替换核心组件（例如切换不同的任务队列实现或并发执行策略）。  
            *   **继承 (Inheritance):** 可用于创建基础组件（如 `BaseTask`）和针对特定场景的具体实现。  
        *   **设计模式 (Design Patterns)** 为构建这样复杂的调度系统提供了成熟的解决方案：  
            *   **策略模式 (Strategy):** 用于灵活选择不同的并发执行模式（如多线程、协程）或失败重试策略。  
            *   **工厂模式 (Factory):** 用于创建不同类型的任务实例 (`Task` objects) 或消息队列处理器 (`message queue handlers`)。  
            *   **观察者模式 (Observer):** 用于实现系统状态监控、日志记录和事件通知。  
            *   **适配器模式 (Adapter):** 用于兼容不同消息队列库（如Redis, RabbitMQ, Kafka）的API，提供统一接口。  
            *   **状态模式 (State):** 用于管理任务在其生命周期中可能经历的复杂状态转换（如等待、运行、成功、失败、重试中）。  
            *   **单例模式 (Singleton):** 常用于管理全局配置、数据库连接池或共享的限流器实例。  

    *   没有OOP和设计模式的帮助，试图用纯面向过程的方式构建一个如此复杂的系统，几乎不可避免地会导致代码难以维护、扩展和理解，变成所谓的"面条代码"。  

**总结：**  


*   封装**请求函数**是对**具体操作**的封装，其复杂度通常在可控范围内，**面向过程**往往够用。  
*   封装**调度系统**是对**复杂流程和系统行为**的封装，涉及多组件协作、状态管理、资源协调 等，其复杂度**天然地需要面向对象和设计模式**来驾驭。  

这再次印证了为什么构建像Funboost这样的框架是一项复杂的系统工程，而不仅仅是"写几个函数"那么简单。它需要深厚的软件设计功底。而Funboost正是将这份深厚的功力凝聚其中，为开发者提供了一个简洁而强大的万能开发利器（万能就一定能包含爬虫）。  


## 8.31 `boost_spider`  (powered by `funboost`) 专业爬虫工具库介绍  

**`boost_spider` = `funboost` 的超跑引擎 + 一套为爬虫量身打造的瑞士军刀。所有仿scrapy api爬虫框架都还是处在变花样造一辆马车**

**安装:**  
pip install boost_spider  

`boost_spider` : **用户自由无束缚的分布式光速python爬虫函数执行框架,写法自由度和性能远远暴击仿scrapy api式框架**  

`boost_spider` 的代码源码很少很轻量级,因为他是由 `funboost` 驱动,
`boost_spider` 里面仅仅是一个包含了对爬虫更方便的三个贡献类而已,因为爬虫框架最最重要 最难封装的 调度和并发 全部是 `funboost` 驱动的

`boost_spider` 里面有三个贡献类,分别是 `RequestClient` 类, `SpiderResponse` 类, `DatasetSink` 类, \
`RequestClient` 类:爬虫更方便的请求类(自带常规反爬,一键自动请求重试,自动换user agent,自动轮流切换各种ip代理商和代理ip,cookies会话保持), \
`SpiderResponse` 类:爬虫更方便的响应类(自带xpath,css,re方法,方便parse解析网页源码) \
`DatasetSink` 类:爬虫更方便的写入数据库类(支持各种数据库一行代码把一个python字典写入数据库) 

有了这三位一体的爬虫增强方便类, `scrapy`的专业爬虫框架这个优势在 `funboost` 面前荡然无存.

`boost_spider` 是基于`funboost`,仅仅是增加了对爬虫更方便的请求类和爬虫结果快捷写入数据库的类,所以用户不需要重新学习 `boost_spider` 框架怎么用,因为整体并发调度流程全部是`funboost`驱动.  
因为发送请求和数据入库都是面向过程方式,局部一行代码调用的,傻瓜都知道怎么调用.  

有人质疑`funboost`不是专用爬虫框架,只是个强力的万能发动机引擎,在爬虫领域不是开箱即用的整车,那 `boost_spider` 就是你眼中的整车.  

**为什么boost_spider不是funboost插件:**  
```
`boost_spider`不是一个 funboost 插件,因为funboost 不需要插件,
scrapy-redis 和 Scrapy-UserAgents 那种才是 scrapy 插件,那种需要高度为scrapy的爬虫种子调度分发 和 发送http请求 专门定制,
代码逻辑和scrapy高度耦合,脱离了scrapy框架,这些三方插件包代码就是一废物,无法单独被导入使用.

因为 boost_spider 的  三个贡献类  RequestClient SpiderResponse DatasetSink 丝毫没有为 funboost 框架逻辑专门耦合定制,
RequestClient SpiderResponse DatasetSink 这些类在编写实现的时候,丝毫没有考虑怎么和funboost流程进行适配,都是完全独立/解耦的, 
即使用户不使用 funboost 框架爬虫,而是单独手写无框架爬虫脚本,也能独立直接导入使用 boost_spider 的 三个贡献类从而更方便的爬虫.
```




### 8.31.1 `boost_spider` 的 `RequestClient` 类介绍  

`RequestClient` 类是 `boost_spider` 的核心http请求类，用于发送 HTTP 请求并获取响应。它封装了 `requests` 库的请求功能，  
内置封装了常用爬虫功能,能自动基于`requests`的`Session`保持会话`cookie`,    
可以一键自动轮流切换各种`ip代理商`和代理池,自动换 `user-agent` 来实现常规的反爬.   


### 8.31.2 `boost_spider` 的 `SpiderResponse`  类介绍  

之前有人一直羡慕scrapy的 `response` 对象能直接 `response.xpath()` 觉得那很神奇,能节约一行把html源码转成xpath对象.   
这个微不足道的的小细节用户自己很容易实现啊,不知道为什么有人会觉得这很难很神奇很魔幻,或者觉得每次临时多写一行转换代码很麻烦.

`RequestClient` 类的request返回的是 `SpiderResponse`对象,而不是 `requests` 的`Response`对象,  
所以 `resp = RequestCleint().request()` 然后可以直接写  `resp.xpath()` ,不用你来加一行代码来转了.  
`SpiderResponse` 对象除了 有`text`属性,还有 `xpath`方法,`css`方法,`re`方法 ,方便你parse解析网页源码.  


### 8.31.2b **boost_spider/http/request_client.py 中的 RequestClient 和 SpiderResponse 功能如下:**
```python
# coding=utf-8
"""
改版包装requests的Session类，主要使用的是代理模式
1、支持一键设多种代理ip
2、支持3种类型的cookie添加
3、支持长会话，保持cookie状态, ss = RequestClient() , 一直用这个ss对象就可以自动保持cookie了
4、支持一键设置requests请求重试次数，确保请求成功，默认重试一次。
5、记录下当天的请求到文件，方便统计，同时开放了日志级别设置参数，用于禁止日志。
6、从使用requests修改为使用RequstClient门槛很低，三方包的request方法和此类的request方法入参和返回完全100%保持了一致。
7、支持代理自动切换。需要将proxy_name设置为一个列表，指定多个代理的名字。
8、支持继承 RequestClient 来增加使用各种代理的请求方法，新增加代理商后，将请求方法名字加到 PROXYNAME__REQUEST_METHED_MAP 中。
9. RequestClient 返回 SpiderResponse ，response 直接支持 .xpath  .css  .re_find_all 等解析反方法
"""
```


### 8.31.3  `boost_spider` 内置了各种类型的数据库sink,全部只需要一行代码就能把字典入库.  

`boost_spider`中爬虫结果写入任何数据库,都只需要一行代码.  


例如,先实例化:    
**dataset_sink1 = DatasetSink("mysql+pymysql://root:123456xxxxx@localhost/testdb2")**  
在爬虫消费函数中写一行代码就能入库:   
**dataset_sink1.save('your_table', data)**  就能把data这个字典写入 `mysql` 数据库的`your_table`表了.   

这种写法所见即所得,比`scrapy`的写`pipeline`简单直观多了.   
更重要的是，`DatasetSink` 由知名的 `dataset` 库驱动，其内部已实现基于 SQLAlchemy 的数据库连接池，确保了在 `funboost` 的多线程/多进程并发消费场景下的线程安全和高性能，用户无需担心任何并发写入问题。    


### 8.31.4 `boost_spider` 写法demo (写法完全和`funboost`一样)  

`boost_spider` 写法demo (写法完全和`funboost`一样),只是用户多了可以选择使用`boost_spider`内置的更方便的请求类和快捷入库类  

通过`push`来发布爬虫任务,`funboost`的`@boost` 自动并发调度爬虫函数,施加30多种任务控制功能.  

```python  
from boost_spider import DatasetSink,RequestClient,SpiderResponse,boost,BoosterParams,BrokerEnum  

dataset_sink1 = DatasetSink("mysql+pymysql://root:123456xxxxx@localhost/testdb2")  


@boost(BoosterParams(queue_name='crawl_list_page_queue',qps=5,broker_kind=BrokerEnum.REDIS_ACK_ABLE,do_task_filtering=False))  
def crawl_list_page(page_index:int):  
    url = f"https://www.example.com/list?page={page_index}"  
    # proxy_name_list 自动更换代理商 代理池等  
    # request_retry_times requests级别出错,自动重试n次  
    # is_change_ua_every_request 是否自动每次请求都切换user agent  
    resp:SpiderResponse = RequestClient(proxy_name_list=['redisip代理池1','ip代理商2'], request_retry_times=3,is_change_ua_every_request=True).request('get',url)  
    user_id_list = resp.re_findall(r'<a href="/user/(\d+)">',resp.text)  
    for user_id in user_id_list:  
        crawl_detail_page.push(user_id) # 将用户id加入详情页爬取的队列  


# broker_kind=BrokerEnum.REDIS_ACK_ABLE 万无一失确认消费,暴击scrapy-redis的brpop随意重启严重丢种子  
# do_task_filtering=True 基于函数入参的自动去重,此处也就是基于user_id去重  
# task_filtering_expire_seconds = 86400 * 7 任务去重缓存时间,某个user_id距离上次爬取超过7天就重新爬取,scrapy无此功能.  
# qps=10 ,每秒爬取10个网页,无视resp响应波动,暴击只能设置concurrent_num=10的框架  
@boost(BoosterParams(queue_name='crawl_detail_page_queue',qps=10,broker_kind=BrokerEnum.REDIS_ACK_ABLE,do_task_filtering=True,task_filtering_expire_seconds=86400 * 7))  
def crawl_detail_page(user_id):  
    url = f"https://www.example.com/list?user_id={user_id}"  
    # default_use_pc_ua=True 自动使用pc浏览器的user agent,为false就是自动使用手机浏览器的user agent  
    resp:SpiderResponse = RequestClient(proxy_name_list=['noproxy','redisip代理池1','ip代理商2'], request_retry_times=3,default_use_pc_ua=True).request('get',url)  

    # ....  解析网页响应,得到 data 字典  
    user_name = resp.xpath('//div[@class="user"]/text()').extract_first() # 展示了 boost_spider中 response对象内置自带xpath方法  
    address = resp.css('div.address::text').extract_first() # 展示了 boost_spider中 response对象内置自带css方法  
    data = {'user_id': user_id, 'user_name': user_name, 'address': address} # 爬虫结果字典  
    dataset_sink1.save('your_table', data)  # 你仅仅需要1行代码而已就能入库. 这不比你在scrapy写个pipeline类简单几百倍了吗.  
    return data  
```  


### 8.31.5 补充这个 `boost_spider`内容 是为了打消用户质疑

补充这个 `boost_spider` 框架内容 是为了打消用户质疑,和抑制ai认知幻觉 (ai严重幻觉认为只要是专用爬虫框架就一定比通用万能函数调度框架写爬虫更强更简单)  

其实是funboost用来爬虫就可以了,压根不需要 `boost_spider`专用框架 ,因为那里面的代码小白很容易封装出来,   
封装一个请求类 响应类自带xpath方法 和插入数据库 ,真的很简单,基本没有设计到需要任何设计模式,顶多是最最基本的面向对象.  
即使用户不会面向对象,使用面向过程封装一个my_request的面向过程请求反爬函数,其实足以了, 不要太纠结不能直接 response.xpath()  

封装这些 `boost_spider` 里面的这些爬虫辅助类 `RequestClient` `SpiderResponse` `DataSetSink`,和封装 `funboost` 框架的难度,压根不是一个级别. 前者是封装一个局部调用,后者是封装一个全局流程.  


**小结:**  
以后不要再说  `funboost` 是通用函数调度框架就一定不如专用爬虫框架了, `boost_spider` 已经包含了请求 反爬 自动cookie保持、数据库插入、xpath css解析 这些爬虫所需要的元素.  




## 8.40 集中总结的 Funboost vs. Scrapy 优势快速对比 (表格版)  

这30个原因主要围绕 **“自由编程 降维打击 框架奴役”** 的核心思想展开，即 `funboost` 通过其通用的函数调度能力，赋予开发者极大的自由度，从而在灵活性、易用性和功能强大性上超越了 `Scrapy` 这种专用但受限的框架。  


<style>  
    .funboost-scrapy-comparison-table {  
        width: 100%;  
        border-collapse: collapse;  
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";  
        font-size: 14px;  
        line-height: 1.5;  
        margin-top: 20px;  
        margin-bottom: 20px;  
    }  
    .funboost-scrapy-comparison-table th, .funboost-scrapy-comparison-table td {  
        border: 1px solid #ddd;  
        padding: 12px;  
        text-align: left;  
        vertical-align: top;  
    }  
    .funboost-scrapy-comparison-table thead th {  
        background-color: #f2f2f2;  
        font-weight: 600;  
        text-align: center;  
    }  
    .funboost-scrapy-comparison-table tbody td:first-child {  
        font-weight: 600;  
        vertical-align: middle;  
        text-align: center;  
        /* 不设置背景色，让其跟随主题变化 */  
    }  
    .funboost-scrapy-comparison-table tbody td:nth-child(2) {  
        font-weight: 600;  
        /* 不设置背景色，让其跟随主题变化 */  
    }  
    /* Funboost 优势列 - 绿色背景 */  
    .funboost-scrapy-comparison-table .funboost-advantage {  
        background-color: #dcfce7 !important; /* 绿色背景 */  
    }  
    /* Scrapy 劣势列 - 红色背景 */  
    .funboost-scrapy-comparison-table .scrapy-disadvantage {  
        background-color: #fee2e2 !important; /* 红色背景 */  
    }  
    .funboost-scrapy-comparison-table code {  
        background-color: #eee;  
        padding: 2px 4px;  
        border-radius: 3px;  
        font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;  
    }  
</style>  

<table class="funboost-scrapy-comparison-table">  
    <thead>  
        <tr>  
            <th>类别</th>  
            <th>维度</th>  
            <th>Funboost 优势 (函数调度，自由无限)</th>  
            <th>Scrapy 劣势 (URL调度，框架束缚)</th>  
        </tr>  
    </thead>  
    <tbody>  
        <tr>  
            <td rowspan="5"><strong>核心理念与架构 (1-5)</strong></td>  
            <td><strong>1. 调度核心</strong></td>  
            <td class="funboost-advantage"><strong>函数调度</strong>：调度的是一个完整的、可执行的Python函数，内部逻辑完全自由。</td>  
            <td class="scrapy-disadvantage"><strong>URL请求调度</strong>：调度的是一个 <code>Request</code> 对象，开发者被限制在框架的请求-响应生命周期内。</td>  
        </tr>  
        <tr>  
            <td><strong>2. 编程范式</strong></td>  
            <td class="funboost-advantage"><strong>自由编程</strong>：采用平铺直叙、一气呵成的同步思维编写函数，逻辑连贯清晰。</td>  
            <td class="scrapy-disadvantage"><strong>回调地狱</strong>：强制使用 <code>yield Request</code> 和 <code>callback</code> 函数，逻辑被拆分得支离破碎，难以理解和维护。</td>  
        </tr>  
        <tr>  
            <td><strong>3. 状态管理</strong></td>  
            <td class="funboost-advantage"><strong>极其简单</strong>：在函数内使用普通的局部变量即可轻松管理状态，符合直觉。</td>  
            <td class="scrapy-disadvantage"><strong>极其繁琐</strong>：必须通过 <code>response.meta</code> 字典在回调函数之间传递状态，易出错且IDE无法补全提示。</td>  
        </tr>  
        <tr>  
            <td><strong>4. 框架侵入性</strong></td>  
            <td class="funboost-advantage"><strong>极低</strong>：只需一个 <code>@boost</code> 装饰器，不改变函数原有结构，可轻松集成任何老代码。</td>  
            <td class="scrapy-disadvantage"><strong>极高</strong>：必须继承 <code>scrapy.Spider</code>，重写 <code>parse</code> 等方法，代码与框架深度耦合，迁移成本高。</td>  
        </tr>  
        <tr>  
            <td><strong>5. 架构思想</strong></td>  
            <td class="funboost-advantage"><strong>降维打击</strong>：用通用的万能函数调度框架解决特定的爬虫问题，功能更全，更灵活,例如轻松的动态实时添加二层级爬虫种子任务。</td>  
            <td class="scrapy-disadvantage"><strong>作茧自缚</strong>：专为爬虫设计，但其设计限制了其处理复杂和非标准场景的能力，动态实时增加一个detail_parse的二层级爬虫种子太难。</td>  
        </tr>  
        <tr>  
            <td rowspan="7"><strong>开发效率与易用性 (6-12)</strong></td>  
            <td><strong>6. 学习曲线</strong></td>  
            <td class="funboost-advantage"><strong>极其平缓</strong>：只需学习 <code>@boost</code> 装饰器的用法，几分钟即可上手。</td>  
            <td class="scrapy-disadvantage"><strong>极其陡峭</strong>：需要学习Spider、Item、Pipeline、Middleware、Settings等多个组件和复杂的生命周期。</td>  
        </tr>  
        <tr>  
            <td><strong>7. 代码量与文件结构</strong></td>  
            <td class="funboost-advantage"><strong>极其精简</strong>：单文件即可完成一个复杂的分布式爬虫，代码量极少。</td>  
            <td class="scrapy-disadvantage"><strong>极其臃肿</strong>：一个简单的爬虫也需要创建7-8个文件，开发者需在多个文件间频繁切换。</td>  
        </tr>  
        <tr>  
            <td><strong>8. HTTP库选择</strong></td>  
            <td class="funboost-advantage"><strong>完全自由</strong>：可在函数内随意使用 <code>requests</code>, <code>httpx</code>, <code>aiohttp</code>, <code>selenium</code>, <code>playwright</code> 等任何库。</td>  
            <td class="scrapy-disadvantage"><strong>受限</strong>：强制使用其内置的基于 <code>Twisted</code> 的下载器，想用其他库需要复杂的中间件封装。</td>  
        </tr>  
        <tr>  
            <td><strong>9. 反爬与自定义请求</strong></td>  
            <td class="funboost-advantage"><strong>极其简单</strong>：封装一个通用的 <code>my_request</code> 函数即可实现换IP、UA等逻辑，0门槛。</td>  
            <td class="scrapy-disadvantage"><strong>极其复杂</strong>：必须编写和注册下载器中间件（<code>Downloader Middleware</code>），概念复杂，对新手极不友好。</td>  
        </tr>  
        <tr>  
            <td><strong>10. 单元测试</strong></td>  
            <td class="funboost-advantage"><strong>极其容易</strong>：每个被 <code>@boost</code> 装饰的函数都可以直接调用，独立进行单元测试。</td>  
            <td class="scrapy-disadvantage"><strong>极其困难</strong>：Spider的回调方法与框架上下文强耦合，难以进行独立的单元测试。</td>  
        </tr>  
        <tr>  
            <td><strong>11. IDE代码补全</strong></td>  
            <td class="funboost-advantage"><strong>全面支持</strong>：函数参数、<code>push</code>/<code>publish</code> 方法均有代码补全，开发效率高。</td>  
            <td class="scrapy-disadvantage"><strong>几乎为零</strong>：<code>response.meta</code> 是字典，IDE无法提供任何键的补全提示，极易出错。</td>  
        </tr>  
        <tr>  
            <td><strong>12. 调试</strong></td>  
            <td class="funboost-advantage"><strong>简单直观</strong>：线性执行的函数逻辑，使用标准 <code>pdb</code> 或IDE调试器即可轻松调试。</td>  
            <td class="scrapy-disadvantage"><strong>困难</strong>：回调链和异步执行流程使得调试非常困难，难以跟踪任务的完整生命周期。</td>  
        </tr>  
        <tr>  
            <td rowspan="10"><strong>功能强大性与灵活性 (13-22)</strong></td>  
            <td><strong>13. 并发模型</strong></td>  
            <td class="funboost-advantage"><strong>更强悍（叠加模式）</strong>：轻松实现多进程 + (多线程/协程) + 多机器的四重叠加并发，性能炸裂。</td>  
            <td class="scrapy-disadvantage"><strong>有限</strong>：并发主要由 <code>CONCURRENT_REQUESTS</code> 控制，难以充分利用多核CPU。</td>  
        </tr>  
        <tr>  
            <td><strong>14. 速率控制</strong></td>  
            <td class="funboost-advantage"><strong>更精准（QPS控制）</strong>：可精确控制每秒请求次数（QPS），无视响应时间波动。</td>  
            <td class="scrapy-disadvantage"><strong>不精确（并发数控制）</strong>：只能控制并发请求数，无法保证稳定的请求速率。</td>  
        </tr>  
        <tr>  
            <td><strong>15. 复杂流程处理</strong></td>  
            <td class="funboost-advantage"><strong>极其自然</strong>：可在单个函数内完成多轮浏览器交互、API调用等复杂连续操作。</td>  
            <td class="scrapy-disadvantage"><strong>几乎无法实现</strong>：用回调处理多步连续操作非常笨拙，甚至会导致异步模型失效。</td>  
        </tr>  
        <tr>  
            <td><strong>16. 短时效Token处理</strong></td>  
            <td class="funboost-advantage"><strong>轻松解决</strong>：可在函数内连续请求，确保获取Token后立即使用，保证时效性。</td>  
            <td class="scrapy-disadvantage"><strong>无能为力</strong>：无法保证两个 <code>Request</code> 之间的执行间隔，Token极易过期。</td>  
        </tr>  
        <tr>  
            <td><strong>17. 任务去重</strong></td>  
            <td class="funboost-advantage"><strong>更智能（入参去重）</strong>：基于函数核心入参进行去重，能自动忽略URL中的时间戳、随机数等噪音。</td>  
            <td class="scrapy-disadvantage"><strong>很笨拙（URL指纹去重）</strong>：对URL中的噪音参数无能为力，需要编写复杂的 <code>RFPDupeFilter</code> 才能解决。</td>  
        </tr>  
        <tr>  
            <td><strong>18. 去重有效期</strong></td>  
            <td class="funboost-advantage"><strong>支持</strong>：可以设置任务过滤的有效期，适合周期性更新的爬取任务。</td>  
            <td class="scrapy-disadvantage"><strong>不支持</strong>：默认是永久去重，需要手动清理去重集合才能重新爬取。</td>  
        </tr>  
        <tr>  
            <td><strong>19. 错误重试</strong></td>  
            <td class="funboost-advantage"><strong>更可靠（函数级重试）</strong>：即使HTTP 200但页面内容反爬，导致解析出错，函数依然会自动重试。</td>  
            <td class="scrapy-disadvantage"><strong>不可靠（URL级重试）</strong>：只对请求失败（如网络错误）重试，对内容错误无能为力，会丢失数据。</td>  
        </tr>  
        <tr>  
            <td><strong>20. 数据持久化</strong></td>  
            <td class="funboost-advantage"><strong>极其灵活</strong>：在函数内直接调用任何数据库的客户端库进行存储，完全自由。</td>  
            <td class="scrapy-disadvantage"><strong>受限</strong>：必须通过 <code>Item Pipeline</code> 机制，增加了一层不必要的抽象和复杂性。</td>  
        </tr>  
        <tr>  
            <td><strong>21. 消息队列支持</strong></td>  
            <td class="funboost-advantage"><strong>极其丰富</strong>：支持30多种消息队列，包括RabbitMQ、Kafka等，提供更专业的分布式能力。</td>  
            <td class="scrapy-disadvantage"><strong>有限</strong>：主要依赖 <code>scrapy-redis</code>，选择单一。</td>  
        </tr>  
        <tr>  
            <td><strong>22. 定时任务</strong></td>  
            <td class="funboost-advantage"><strong>原生支持</strong>：内置强大的定时任务功能，可轻松实现定时启动、周期爬取。</td>  
            <td class="scrapy-disadvantage">需要借助外部脚本或 <code>apscheduler</code> 等库自行实现，集成复杂。</td>  
        </tr>  
        <tr>  
            <td rowspan="8"><strong>生态与可靠性 (23-30)</strong></td>  
            <td><strong>23. 插件生态</strong></td>  
            <td class="funboost-advantage"><strong>无需插件，Python生态即是其生态</strong>：任何Python三方包都可直接使用，无需等待“大神”开发专用插件。</td>  
            <td class="scrapy-disadvantage"><strong>依赖插件</strong>：使用新工具（如Playwright）需要等待 <code>scrapy-playwright</code> 这样的插件，学习和配置成本高。</td>  
        </tr>  
        <tr>  
            <td><strong>24. 断点续爬</strong></td>  
            <td class="funboost-advantage"><strong>真正可靠</strong>：支持消费确认（ACK），即使强制关机、代码崩溃，任务也万无一失。</td>  
            <td class="scrapy-disadvantage"><strong>不可靠</strong>：<code>scrapy-redis</code> 使用 <code>blpop</code>，重启或崩溃会丢失大量已取出到内存中的任务。</td>  
        </tr>  
        <tr>  
            <td><strong>25. 跨语言/项目交互</strong></td>  
            <td class="funboost-advantage"><strong>支持</strong>：可由Java等其他语言程序向队列发布爬虫任务。</td>  
            <td class="scrapy-disadvantage"><strong>不支持</strong>：其任务格式与Python和框架自身强绑定。</td>  
        </tr>  
        <tr>  
            <td><strong>26. 远程部署</strong></td>  
            <td class="funboost-advantage"><strong>一键部署</strong>：内置 <code>fabric_deploy</code> 功能，可直接将爬虫函数部署到远程服务器。</td>  
            <td class="scrapy-disadvantage">无此功能，部署复杂。</td>  
        </tr>  
        <tr>  
            <td><strong>27. Web管理界面</strong></td>  
            <td class="funboost-advantage"><strong>功能强大</strong>：<code>funboost web manager</code> 可监控、管理所有爬虫任务和消费者，并可实时调整QPS。</td>  
            <td class="scrapy-disadvantage"><code>scrapy-redis</code> 无官方管理界面，需借助其他工具。</td>  
        </tr>  
        <tr>  
            <td><strong>28. 稳定性</strong></td>  
            <td class="funboost-advantage"><strong>更高</strong>：对网络错误等有强大的自动重连和重试机制，不易因外部问题中断。</td>  
            <td class="scrapy-disadvantage">相对脆弱，需要开发者在中间件中编写大量代码来保证稳定性。</td>  
        </tr>  
        <tr>  
            <td><strong>29. 资源占用</strong></td>  
            <td class="funboost-advantage"><strong>更可控</strong>：智能线程池可自动伸缩，节省资源。</td>  
            <td class="scrapy-disadvantage">并发数固定，可能在任务稀疏时造成资源浪费。</td>  
        </tr>  
        <tr>  
            <td><strong>30. 统一控制</strong></td>  
            <td class="funboost-advantage"><strong>包罗万象</strong>：一个 <code>@boost</code> 装饰器集成了分布式、并发、控频、重试、过滤、持久化等30多种控制功能。</td>  
            <td class="scrapy-disadvantage">功能分散在多个组件和配置中，难以统一管理和配置。</td>  
        </tr>  
    </tbody>  
</table>  




**总结：**  

`funboost` 以其 **“函数即一切”** 的核心思想，彻底解放了开发者。它将复杂的调度、并发、容错等底层工作完全自动化，让开发者可以像写普通脚本一样编写爬虫逻辑，同时享受到远超专用框架的 **灵活性、强大功能和极致性能**。`Scrapy` 的“专业”反而成了其最大的“束缚”，导致在面对现代爬虫的复杂需求时，显得笨拙、低效且难用。因此，`funboost` 在爬虫领域对 `Scrapy` 实现了真正的 **“降维打击”**。  

## 8.40b 集中总结 funboost vs scrapy 优势快速对比（文字版）  

Funboost 是“函数调度器”，而 Scrapy 是“URL调度器”；前者赋能开发者，给予无限自由，后者则用框架规则束缚开发者。这是一种“自由编程”对“框架奴役”的降维打击。以下是详细的50个原因：  

<div class="inner_markdown">  

<h1>一、核心理念与架构优势 (1-10)</h1>  

1. **调度核心根本不同**：Funboost 调度的是一个完整的 Python 函数，内部逻辑完全自由；Scrapy 调度的是一个 Request 对象，开发者被死死限制在框架的请求-响应生命周期内。  
2. **编程范式降维打击**：Funboost 采用 平铺直叙 的同步思维写代码，逻辑连贯，一气呵成；Scrapy 强制使用 yield Request 和 callback 的 回调地狱 模式，逻辑被拆分得支离破碎。  
3. **状态管理天壤之别**：Funboost 在函数内用 普通局部变量 就能轻松管理上下文状态，符合直觉；Scrapy 必须通过晦涩的 response.meta 字典在回调间传递状态，极易出错且IDE无法补全。  
4. **框架侵入性极低**：Funboost 仅需一个 @boost 装饰器，不改变函数原有结构，可以 无缝集成任何老代码；Scrapy 必须继承 scrapy.Spider，代码与框架深度耦合，迁移成本极高。  
5. **架构思想的碾压**：Funboost 是 通用的万能函数调度框架，用更广阔的视野解决爬虫问题，功能更全面；Scrapy 是 专用的爬虫框架，但其设计反而作茧自缚，限制了其解决复杂问题的能力。  
6. **对已有代码的兼容性**：任何一个用 requests 写的普通爬虫脚本，加上 @boost 装饰器就能 瞬间升级为分布式爬虫。Scrapy 则需要对老代码进行伤筋动骨的重构。  
7. **代码复用性**：Funboost 的爬虫函数是标准函数，可在任何地方轻松复用。Scrapy 的 parse 方法与框架强耦合，基本无法在项目外复用。  
8. **思维模式的解放**：Funboost 鼓励开发者用最自然的编程思维解决问题。Scrapy 则强迫开发者扭曲自己的思维去适配框架的特定模式。  
9. **请求的绝对自由**：Funboost 函数内部可以自由构造和发送多个请求，并轻松处理它们之间的复杂依赖。Scrapy 的 yield Request 模式让请求之间的时序和依赖关系处理变得非常困难。  
10. **逻辑连贯性**：Funboost 的线性代码使得一个任务的完整逻辑（请求->解析->存储->派生新任务）集中在一起，可读性极高。Scrapy 的回调链将这些逻辑打散，降低了可读性。  
10.b. **动态添加实时任务碾压**：scrapy动态实时添加二层级爬虫种子非常难，funboost无论是自己项目还是跨部门，轻松动态实时新增一个详情页的爬虫任务    
---  

<h1>二、开发效率与易用性 (11-20)</h1>  

11. **学习曲线极其平缓**：Funboost 只需学习 @boost 装饰器的用法，几分钟即可上手。Scrapy 需要学习 Spider、Item、Pipeline、Middleware、Settings 等 一整套复杂组件和生命周期。  
12. **代码量与文件结构**：Funboost 单文件即可完成一个复杂的分布式爬虫，代码量极少。Scrapy 一个简单爬虫也需要创建7-8个文件，开发时需频繁切换，极其臃肿。  
13. **HTTP库选择完全自由**：Funboost 函数内可随意使用 requests, httpx, aiohttp, selenium, playwright 等任何库。Scrapy 强制使用其内置下载器，想用其他库需要封装复杂的中间件。  
14. **反爬与自定义请求极其简单**：Funboost 中，封装一个通用的 my_request 函数即可实现换IP、UA等逻辑，0门槛。Scrapy 必须编写和注册复杂的下载器中间件，对新手极不友好。  
15. **单元测试极其容易**：每个被 @boost 装饰的函数都可以 直接在IDE中调用，独立进行单元测试。Scrapy 的回调方法与框架上下文强耦合，几乎无法进行独立的单元测试。  
16. **IDE代码补全全面支持**：Funboost 的函数参数、push/publish 方法均有代码补全。Scrapy 的 response.meta 是字典，IDE 无法提供任何补全提示，是错误的温床。  
17. **调试简单直观**：Funboost 的线性执行逻辑，使用标准 pdb 或IDE调试器即可轻松调试。Scrapy 的回调链和异步流程使得 调试极其困难。  
18. **反爬逻辑的封装**：Funboost 将反爬逻辑封装在普通函数中，简单直观。Scrapy 必须封装到复杂的中间件类中，概念抽象，难于理解。  
19. **反爬逻辑的独立测试**：Funboost 的 my_request 函数可以独立进行单元测试。Scrapy 的中间件难以脱离框架进行测试。  
20. **数据持久化极其灵活**：Funboost 在函数内 直接调用任何数据库的客户端库 进行存储，完全自由。Scrapy 必须通过 Item Pipeline 机制，增加了不必要的抽象和复杂性。  

---  

<h1>三、功能、性能与可靠性 (21-40)</h1>  

21. **并发模型更强悍**：Funboost 轻松实现 多进程 + (多线程/协程) + 多机器 的四重叠加并发，性能炸裂。Scrapy 难以充分利用多核CPU。  
22. **速率控制更精准**：Funboost 可通过 qps 参数 精确控制每秒请求次数，无视响应时间波动。Scrapy 只能控制并发数，无法保证稳定的请求速率。  
23. **分布式控频**：Funboost 支持跨多台机器、多个进程的 全局QPS控制。Scrapy 的速率限制是单实例的，无法实现全局控频。  
24. **任务去重更智能**：Funboost 基于 函数核心入参 去重，能自动忽略URL中的时间戳、随机数等噪音。Scrapy 基于URL指纹，对噪音参数无能为力，需要编写复杂的 RFPDupeFilter。  
25. **去重有效期支持**：Funboost 可以设置任务过滤的 有效期，适合周期性更新的爬取任务。Scrapy 默认是永久去重，非常不灵活。  
26. **错误重试更可靠**：Funboost 是 函数级重试。即使HTTP 200但页面内容反爬导致解析出错，函数依然会自动重试。Scrapy 是URL级重试，对内容错误无能为力，会丢失大量数据。  
27. **断点续爬真正可靠**：Funboost 支持 消费确认（ACK），即使强制关机、代码崩溃，任务也万无一失。Scrapy-redis 使用 blpop，重启或崩溃会丢失所有已取出到内存中的任务。  
28. **应对进程崩溃**：Funboost 在进程崩溃或断电后，未完成的任务会自动返回队列。Scrapy-redis 会 永久丢失 所有已 blpop 到内存中的任务。  
29. **消息队列支持极其丰富**：Funboost 支持30多种消息队列，包括 RabbitMQ、Kafka 等专业队列，提供更强大的分布式能力。Scrapy 主要依赖 scrapy-redis，选择单一。  
30. **定时任务原生支持**：Funboost 内置强大的定时任务功能，可轻松实现定时启动、周期爬取。Scrapy 需要借助外部库自行实现，集成复杂。  
31. **远程部署一键搞定**：Funboost 内置 fabric_deploy 功能，可直接将爬虫函数部署到远程服务器。Scrapy 无此功能，部署流程繁琐。  
32. **Web管理界面功能强大**：funboost web manager 可监控、管理所有爬虫任务和消费者，并可 实时调整QPS。Scrapy 生态缺乏这样统一、强大的官方监控工具。  
33. **稳定性更高**：Funboost 对网络错误等有强大的自动重连和重试机制，不易因外部问题中断。Scrapy 相对脆弱，需要开发者编写大量代码来保证稳定性。  
34. **资源占用更可控**：Funboost 的智能线程池可 自动伸缩，在任务稀疏时节省资源。Scrapy 的并发数固定，可能造成资源浪费。  
35. **统一控制，包罗万象**：一个 @boost 装饰器集成了分布式、并发、控频、重试、过滤、持久化等 30多种控制功能。Scrapy 功能分散在多个组件和配置中，难以统一管理。  
36. **RPC模式**：Funboost 支持 RPC 模式，可以在发布任务后同步等待并获取爬取结果。Scrapy 没有这种模式。  
37. **跨语言/项目交互**：Funboost 的任务是标准JSON，可由Java等其他语言程序向队列发布爬虫任务。Scrapy 的任务格式与Python和框架自身强绑定，无法交互。  
38. **插件生态的颠覆**：Funboost 无需插件，整个Python生态就是其生态。Scrapy 严重依赖插件，使用新工具（如Playwright）需要等待 scrapy-playwright 这样的插件，学习和配置成本高。  
39. **插件的本质**：Scrapy 插件多是因为框架本身封闭，需要“补丁”来扩展。Funboost 不需要插件是因为其本身就是开放的。  
40. **对三方库的集成成本**：Funboost 集成任何库都是 零成本的直接调用。Scrapy 集成新库需要等待或自己开发复杂的插件，成本高昂。  

---  

<h1>四、特定场景处理能力 (41-50)</h1>  

41. **复杂流程处理极其自然**：Funboost 可在单个函数内完成 多轮浏览器交互、API调用等复杂连续操作。Scrapy 用回调处理此类任务非常笨拙，甚至会导致异步模型失效。  
42. **短时效Token处理轻松解决**：Funboost 可在函数内连续请求，确保获取Token后 立即使用，完美解决时效性问题。Scrapy 无法保证两个 Request 之间的执行间隔，Token极易过期。  
43. **时序控制的确定性**：Funboost 在函数内连续发请求，时序是 确定的、可控的。Scrapy 的请求经过调度器，执行时序不确定。  
44. **浏览器渲染的并发处理**：Funboost 可以轻松地并发执行多个 Selenium/Playwright 任务。Scrapy 在 parse 方法里用 Selenium 会阻塞整个框架，使其退化为单线程。  
45. **处理动态参数的优雅**：Funboost 天然免疫 URL 中的 _ts、_rand 等动态噪音参数。Scrapy 需要编写复杂的正则和自定义 RFPDupeFilter 来清洗 URL，维护成本极高。  
46. **对非HTTP任务的处理**：Funboost 可以调度任何任务，比如文件处理、图片识别、数据分析等，与爬虫任务无缝结合。Scrapy 只能处理HTTP请求。  
47. **动态任务生成**：Funboost 在函数内部可以根据逻辑随时 push 新的任务，非常灵活。Scrapy 的 yield 方式在复杂逻辑判断下生成新请求会很别扭。  
48. **任务优先级控制**：Funboost 支持更专业的 消息级优先级队列（如RabbitMQ），控制更精细。Scrapy 的 priority 参数依赖于调度器的实现，效果有限。  
49. **死信队列处理**：Funboost 提供了更完善的死信队列机制，方便处理无法消费的“毒丸”消息。Scrapy 需要自己实现类似逻辑。  
50. **对开发者的终极赋能**：Funboost 的核心是 “赋能函数”，让开发者用最熟悉的工具和方式解决问题。Scrapy 的核心是 “遵循框架”，要求开发者学习并适应其一套独特的规则。  
50.b **二级任务动态注入**：Funboost 原生支持从外部系统（如Java/PHP）直接向队列推送消息来触发特定任务（如详情页抓取），实现微服务级解耦。Scrapy 难以实现外部直接注入中间状态任务，需重写底层逻辑。  
</div>  

综上所述，funboost 凭借其先进的函数调度理念、极致的灵活性和强大的内置功能，在爬虫领域的几乎所有方面都展现出对 scrapy 的压倒性优势。  



## 8.41 Funboost vs. Scrapy 爬虫能力全方位对比（百分制评分）  

这个评分系统基于以下原则：  
*   **100分**：代表在该维度上表现卓越，几乎没有缺点，完全符合现代开发实践和直觉。  
*   **70-90分**：表现良好，但在某些方面存在一些限制或需要额外的学习成本。  
*   **40-60分**：表现平庸或存在明显缺陷，需要开发者通过复杂的变通方法来弥补。  
*   **低于40分**：在该维度上存在根本性的设计缺陷或严重不足。  

**客观的百分制评分,包含了爬虫领域所有的重要方面比较**  

| 类别 | 维度 | Funboost (函数调度器) | Scrapy (URL调度器) | 评分依据与简评 |  
| :--- | :--- | :--- | :--- | :--- |  
| **核心理念与架构** | **1. 编程范式与直觉性** | **100** | **50** | **Funboost**: 线性、平铺直叙的函数式编程，符合Python直觉。<br>**Scrapy**: 回调地狱，逻辑碎片化，反直觉。 |  
| | **2. 框架侵入性与自由度** | **100** | **40** | **Funboost**: 零侵入，`@boost`装饰器即插即用，可使用任何库。<br>**Scrapy**: 强耦合，必须继承`Spider`，限制HTTP库选择。 |  
| | **3. 架构灵活性** | **95** | **60** | **Funboost**: 万能函数调度，轻松应对任何任务类型（HTTP, 浏览器, API, 文件处理）。<br>**Scrapy**: 专为URL请求设计，处理非HTTP任务非常笨拙。 | 
| | **微服务化与外部集成** | **100** | **20** | **Funboost**: 天然 FaaS 架构，Java/Go 可直接通过队列触发特定爬虫任务，零耦合。<br>**Scrapy**: 封闭系统，外部难以实时插入任务，需魔改源码。 | 
| **开发效率与易用性** | **4. 学习曲线** | **95** | **50** | **Funboost**: 只需学习一个`@boost`装饰器。<br>**Scrapy**: 需掌握Spider, Middleware, Pipeline, Settings等一整套复杂概念。 |  
| | **5. 代码量与项目结构** | **100** | **40** | **Funboost**: 极其精简，单文件即可完成复杂爬虫。<br>**Scrapy**: 极其臃肿，项目结构固定且文件繁多。 |  
| | **6. 调试与单元测试** | **100** | **30** | **Funboost**: 函数可直接调用，调试和测试极其简单。<br>**Scrapy**: 回调方法与框架强耦合，几乎无法独立测试和调试。 |  
| | **7. IDE支持 (代码补全)** | **95** | **40** | **Funboost**: 全面支持函数参数和框架方法补全。<br>**Scrapy**: `response.meta`是黑盒，IDE无法提供任何帮助，极易出错。 |  
| **性能与并发模型** | **8. 真实并发能力** | **100** | **70** | **Funboost**: 多进程+多线程/协程，真正利用多核，并发模型清晰。<br>**Scrapy**: 基于单线程事件循环，难以充分利用多核CPU。 |  
| | **9. 速率控制 (QPS)** | **100** | **50** | **Funboost**: 精准QPS控制，无视响应时间波动。<br>**Scrapy**: 只能控制并发数，无法保证稳定请求速率。 |  
| | **10. 浏览器自动化并发** | **100** | **20** | **Funboost**: 通过工作池实现真正的并行浏览器操作。<br>**Scrapy**: 阻塞事件循环，使框架退化为单线程，性能灾难。 |  
| **功能与可靠性** | **11. 断点续爬可靠性** | **100** | **60** | **Funboost**: 消费确认(ACK)机制，任务万无一失。<br>**Scrapy**: `scrapy-redis`的`blpop`机制在重启或崩溃时会丢失大量任务。 |  
| | **12. 任务去重能力** | **100** | **50** | **Funboost**: 基于核心入参去重，天然免疫URL噪音。<br>**Scrapy**: 基于URL指纹，处理噪音参数需编写复杂`DupeFilter`。 |  
| | **13. 错误重试机制** | **95** | **70** | **Funboost**: 函数级重试，即使HTTP 200但内容错误也能重试。<br>**Scrapy**: URL级重试，对内容错误无能为力，会丢失数据。 |  
| | **14. 消息队列支持** | **100** | **60** | **Funboost**: 支持30+种专业消息队列，选择极其丰富。<br>**Scrapy**: 主要依赖`scrapy-redis`，选择单一。 |  
| **特定场景处理能力** | **15. 复杂交互流程** | **100** | **30** | **Funboost**: 在单个函数内轻松实现多步、状态依赖的交互。<br>**Scrapy**: 回调链使其难以处理复杂时序和状态依赖。 |  
| | **16. 短时效Token处理** | **100** | **20** | **Funboost**: 函数内连续请求，确保Token不过期。<br>**Scrapy**: 无法保证请求间隔，Token极易失效。 |  
| | **17. 反爬策略实现** | **95** | **65** | **Funboost**: 封装普通Python函数例如my_request，简单直观。<br>**Scrapy**: 需编写复杂的下载器中间件，学习成本高。 |  
| | **18. 动态任务注入** | **100** | **30** | **Funboost**: 外部系统可直接推送消息触发任意层级任务，解耦且灵活。<br>**Scrapy**: 难以从外部注入非起始任务，需复杂改造。 |  
| **生态与扩展性** | **19. 第三方库集成** | **100** | **50** | **Funboost**: **无需插件**，直接调用任何Python库。<br>**Scrapy**: **严重依赖插件**，使用新工具需等待或开发复杂插件 <br> **scrapy-selenium** 插件在面对复杂多步骤交互输入点击再解析页面需求上,难度高弊端大,力不从心。 |  
| | **20. Web管理与监控** | **90** | **40** | **Funboost**: 自带功能强大的Web Manager，可监控、管理和实时调参。<br**Scrapy**: 缺乏官方统一的强大监控工具。 |  
| | **21. 跨语言/项目交互** | **90** | **20** | **Funboost**: 标准JSON任务，可由其他语言发布。<br>**Scrapy**: 任务格式与框架强绑定，几乎无法跨语言交互。 |  
| **总分 (加权平均)** | | <span style="font-size: 1.2em; font-weight: bold; color: green;">97.5</span> | <span style="font-size: 1.2em; font-weight: bold; color: red;">45.5</span> | |  

---  

**总结分析:**  

从上表可以清晰地看出，`funboost` 在爬虫这个funboost`不务正业`的领域,几乎所有关键维度上都展现出对 `Scrapy` 专业爬虫框架的**压倒性优势**。  

*   **Funboost (得分: 97.5)**：它代表了一种更现代、更灵活、更符合 Python 开发者直觉的编程范式。它将复杂的分布式调度问题彻底封装，把**完全的自由**还给了开发者。无论是开发效率、性能、可靠性，还是处理复杂场景的能力，`funboost` 都表现得近乎完美。它的核心优势在于其**通用性**——通过调度函数这一简单而强大的抽象，它能够“降维打击”像 Scrapy 这样被特定领域（URL请求）所束缚的框架。  

*   **Scrapy (得分: 45.5)**：作为一个历史悠久的框架，Scrapy 在其设计的时代背景下是优秀的。然而，其**强耦合、反直觉的回调机制、脆弱的可靠性模型**以及**对阻塞任务的无力**，使其在面对当今复杂多变的爬虫需求时显得力不从心。它的“专业性”反而成为了其最大的“枷锁”，导致在许多关键评分项上表现不佳。  

**最终结论**：对于追求开发效率、代码可维护性、系统可靠性和极致性能的现代爬虫开发者而言，选择 `funboost` 是一个显而易见的、更优的决定。它不仅是一个更强大的工具，更是一种能解放生产力的先进思想。  

<div> </div>  

`````

--- **end of file: source/articles/c8.md** (project: funboost_docs) --- 

---


--- **start of file: source/articles/c9.md** (project: funboost_docs) --- 

`````markdown
# 9 轻松远程服务器部署运行函数  

别的机器不需要先安装git，也不需要先手动上传代码到该机器上，就能自动部署运行,前提python基本环境是要搞好的。<br>  
celery不支持这种自动运行在别的机器上的方式。  

如果有阿里云codepipeline或者其他运维发版工具或者k8s一键部署多台机器的条件，优先不要使用这种部署方式。  

## 9.1 远程服务器部署函数的意义  
```  
框架叫分布式函数调度框架，可以在多台机器运行，因为消息队列任务是共享的。  
我用的时候生产环境是使用 阿里云 codepipeline k8s部署的多个容器。还算方便。  
在测试环境一般就是单机多进程运行的，用supervisor部署很方便。  
所以之前没有涉及到多态机器的轻松自动部署。  
如果要实现轻松的部署多台物理机，不借助除了python以外的其他手段的话，只能每台机器登录上然后下载代码，启动运行命令，机器多了还是有点烦的。  
现在最新加入了 Python代码级的函数任务部署，不需要借助其他手段，python代码自动上传代码到远程服务器，并自动启动函数消费任务。  
目前的自动化在远程机器启动函数消费，连celery都没有做到。  

不依赖阿里云codepipeline 和任何运维发布管理工具，只需要在python代码层面就能实现多机器远程部署。  
 这实现了函数级别的精确部署，而非是部署一个 .py的代码，远程部署一个函数实现难度比远程部署一个脚本更高一点，部署更灵活。  
```  

```  
之前有人问怎么方便的部署在多台机器，一般用阿里云codepipeline  k8s自动部署。被部署的远程机器必须是linux，不能是windwos。  
但是有的人是直接操作多台物理机，有些不方便，现在直接加一个利用python代码本身实现的跨机器自动部署并运行函数任务。  

自动根据任务函数所在文件，转化成python模块路径，实现函数级别的精确部署，比脚本级别的部署更精确到函数。  
例如 test_frame/test_fabric_deploy/test_deploy1.py的fun2函数 自动转化成 from test_frame.test_fabric_deploy.test_deploy1 import f2  
从而自动生成部署语句  
export PYTHONPATH=/home/ydf/codes/distributed_framework:$PYTHONPATH ;cd /home/ydf/codes/distributed_framework;  
python3 -c "from test_frame.test_fabric_deploy.test_deploy1 import f2;f2.multi_process_consume(2)"  -fsdfmark fsdf_fabric_mark_queue_test30  

这个是可以直接在远程机器上运行函数任务。无需用户亲自部署代码和启动代码。自动上传代码，自动设置环境变量，自动导入函数，自动运行。  
这个原理是使用python -c 实现的精确到函数级别的部署，不是python脚本级别的部署。  
可以很灵活的指定在哪台机器运行什么函数，开几个进程。这个比celery更为强大，celery需要登录到每台机器，手动下载代码并部署在多台机器，celery不支持代码自动运行在别的机器上  
```  


## 9.2 远程服务器部署函数的入参介绍。  
```  

:param host: 需要部署的远程linux机器的 ip  
:param port:需要部署的远程linux机器的 port  
:param user: 需要部署的远程linux机器的用户名  
:param password:需要部署的远程linux机器的密码  
:param path_pattern_exluded_tuple:排除的文件夹或文件路径  
:param file_suffix_tuple_exluded:排除的后缀  
:param only_upload_within_the_last_modify_time:只上传多少秒以内的文件，如果完整运行上传过一次后，之后可以把值改小，避免每次全量上传。  
:param file_volume_limit:大于这个体积的不上传，因为python代码文件很少超过1M  
:param extra_shell_str :自动部署前额外执行的命令，例如可以设置环境变量什么的  
:param invoke_runner_kwargs :   
         invoke包的runner.py 模块的 run()方法的所有一切入参,例子只写了几个入参，实际可以传入十几个入参，大家可以自己琢磨fabric包的run方法，按需传入。  
         hide 是否隐藏远程机器的输出，值可以为 False不隐藏远程主机的输出  “out”为只隐藏远程机器的正常输出，“err”为只隐藏远程机器的错误输出，True，隐藏远程主机的一切输出  
         pty 的意思是，远程机器的部署的代码进程是否随着当前脚本的结束而结束。如果为True，本机代码结束远程进程就会结束。如果为False，即使本机代码被关闭结束，远程机器还在运行代码。  
         warn 的意思是如果远程机器控制台返回了异常码本机代码是否立即退出。warn为True这只是警告一下，warn为False,远程机器返回异常code码则本机代码直接终止退出。  
    
:param process_num:启动几个进程  
:return:  

```  


## 9.3 远程服务器部署消费函数的代码示例。  

定义了两个函数任务，和f1和f2.  

![img_11.png](img_11.png)  


运行的控制台图片，说明部署级别精确到了函数而非脚本级别，可以灵活的指定哪台机器跑哪些函数。  

![img_10.png](img_10.png)  

<div> </div>
`````

--- **end of file: source/articles/c9.md** (project: funboost_docs) --- 

---

# markdown content namespace: boost_spider readme 


## funboost_docs File Tree (relative dir: `.`)


`````

└── README.md

`````

---


## funboost_docs (relative dir: `.`)  Included Files (total: 1 files)


- `README.md`


---


--- **start of file: README.md** (project: funboost_docs) --- 

`````markdown

**欢迎来到爬虫的未来，这里没有回调地域，只有自由世界。**

`pip install boost_spider`

**`boost_spider` = `funboost` 的超跑引擎 + 一套为爬虫量身打造的瑞士军刀。所有仿scrapy api爬虫框架都还是处在变花样造一辆马车**

对于爬虫场景:       
用户怕麻烦,要求天生就爬虫全套方便，就使用 `funboost` + `boost_spider`(内置了便利的 请求 解析 入库3个类)     
用户要绝对自由，就使用 `funboost` + 用户自己项目的 `utils/` 或 `commons/` 文件夹下已经封装好的 各种工具类和函数     

### funboost/boost_spider 对仿scrapy api框架最大优势是 复用用户自己的 utils文件夹下的 宝贵资产
- 复用用户自己的 utils 宝贵资产，正是 `funboost`  区别于 `Scrapy/Feapder` 等传统框架的**根本性优势**，是战略层面的胜利。   
*   **`utils` 是开发者的“内功心法”**：一个开发者的 `utils` 文件夹，是他/她多年经验的结晶，是解决特定领域问题的最佳实践沉淀。它包含了对业务逻辑的深刻理解，是**不可替代的、高度定制化的“私有武器库”**。
*   **“复用 `utils`” = 复用经验和智慧**：一个框架如果能让开发者无缝地复用自己的 `utils`，就意味着它尊重并放大了开发者的个人能力和历史积累。开发者可以用最熟悉、最高效的方式解决问题。
*   **“无法复用 `utils`” = 废掉武功，重练套路**：`Scrapy/Feapder` 的插件和中间件机制，本质上是让你放弃自己的“内功”，去学习并练习一套它们规定好的“套路招式”。你的 `my_request` 函数再精妙，也得改成 `Downloader Middleware` 的形状；你的 `save_to_mysql` 再高效，也得塞进 `Item Pipeline` 的模子里。这是一个**巨大的、隐性的成本**。

### **Funboost/boost_spider 天然就是 FaaS 微服务，而 Scrapy 只是数据孤岛,架构模式战略级碾压**  
`funboost/boost_spider` 支持高实时爬虫，scrapy只能封闭离线爬虫，架构模式战略级碾压。  
`funboost/boost_spider`不仅支持别的部门通过原生消息队列客户端发布函数入参对应的纯净json到对应的queue_name  
也支持 `funboost.faas` 快速给你的web服务增加多个funboost路由，一键实现`FaaS(Function as a Service)`     
自动发现注册爬虫函数，在实时爬虫上对`scrapy-redis`是战略级碾压。   

# 1.分布式光速python爬虫框架 boost_spider

boost_spider是从框架理念和本质上降维打击,任何仿 scrapy api 用法框架的爬虫框架,如同星际战舰对抗中世纪的蒸汽机车.    
碾压任何需要用户 yield Request(url=url, callback=self.my_parse,meta={'field1':'xxx','field2':'yyy'}) 的爬虫框架20年以上.  


## 安装：

pip install boost_spider

## boost_spider框架的更详细用法要看funboost文档

boost_spider是基于funboost驱动,增加了对爬虫更方便的常规反爬请求类和 方便爬虫解析的响应类 和 一行代码快捷保存字典入库 3个类.    
RequestClient  和  SpiderResponse  和 DatasetSink

[查看分布式函数调度框架完整文档 https://funboost.readthedocs.io/zh-cn/latest/index.html](https://funboost.readthedocs.io/zh-cn/latest/index.html)


## 简介：

boost_spider 是powerd by funboost,加了一个方便爬虫的请求类(用户可以不使用这个请求类,可以用任意包自己发送http请求)

本质上,funboost是函数调度框架,scrapy和国产仿scrapy api用法的爬虫框架是一个url请求调度框架,

函数里面用户可以写任何逻辑,所以boost_spider适应范围和用户自由度暴击写死了替发送一个http请求的仿scrapy框架.

函数调度框架暴击url请求调度框架,这是降维打击.

### boost_spider 理念:

- funboost/boost_spider 和 scrapy 难度差异: 【对于一个刚刚掌握了 Python 基础语法（变量、列表、元组、if/else、for循环）的新手来说】
  - **boost_spider**： 难度要低很多,就和小学生练手手写requests单个小脚本的思路一样，最后加一行@boost装饰器一键起飞。
  - **仿scrapy框架**： 巨大的框架压迫感，和刚学的基础语法对比，差异鸿沟太大,无限懵逼以至于自我怀疑，刚学的python语法是不是白学了。   
                      直接上手 Scrapy，就像 **一个刚学会骑自行车的人，突然被要求去驾驶一架波音747**。


- `boost_spider` 理念 是框架永远不要自作主动,在框架内部自动替用户执行http请求 
要自动调度一个函数而不是自动调度一个url/Request对象    
函数里面用户自己自由选择任何 httpx  requests aiohttp urllib3 selenium  playwright, 或者使用自己封装的一个my_request请求函数 来发送http请求.

- **boost_spider 不替用户自动发请求**, 意味上限很高,对于怎么换headers redis代理池的ip 代理商的隧道ip ,  
怎么在浏览器多步骤交互 输入 点击 等待,再解析网页, 用户非常容易按自己的内心想法搞定,    
对于执行http请求,`boost_spider` 只提供好用的 `RequestClient`, 但不强迫用户必须使用 `RequestClient`   

- **仿scrapy api 的框架内部自己去替用户执行http请求**,意味用户控制能力很弱,只能在`yield Request` 传递请求的 method url request_body 等等,   
对于复杂的需要写一段python代码逻辑来换ip和请求头的,用户需要写 download_middleware 钩子,怎么实现middleware需要和框架规则高度耦合, 导致用户实现难度太高     
以及多步骤浏览器交互会阻塞parse函数,短时效token 多个url必须短时间内连续请求, 由于不自由,导致用户无法实现.  

- **对于简单爬虫,boost_spider代码更简单更少,思维更直观平铺直叙,无需任何仪式感模板代码**  
**对于复杂爬虫,boost_spider除了代码更直观,用户还更容易实现自己奇葩想法,多机器+多进程+多线程/协程 性能强得多**   

- **🚀 boost_spider 作为微服务和 FaaS (Function as a Service) 使用，能高实时爬虫，scrapy只能离线循环爬虫，boost_spider在实时场景吊打scrapy**


### boost_spider 对 funboost 的 爬虫场景增强,3个重要类, RequestClient 和 SpiderResponse 和 DatasetSink
```
RequestClient：
一个为爬虫而生的请求客户端。封装了自动重试、随机User-Agent、代理商轮换、保持Cookie会话等所有反爬基础操作。
比 Scrapy 复杂的 Downloader Middleware 易用百倍。

SpiderResponse：
请求返回的响应对象，直接自带 .xpath(), .css(), .re_search() 等方法，让你无需额外导入 parsel 就能方便地解析页面。

DatasetSink：
一行代码将爬取到的字典数据存入MySQL、PostgreSQL、SQLite等多种数据库，并且自动处理建表。
完爆任何仿 Scrapy api 爬虫框架 繁琐的 定义Item -> yield item -> 定义 Pipeline -> Settings+ITEM_PIPELINES配置,来实现数据存储流程。
```

### boost_spider特点:

 ```
 boost_spider支持同步爬虫也支持asyncio异步爬虫
 boost_spider 是一款自由奔放写法的爬虫框架，无任何束缚，和用户手写平铺直叙的爬虫函数一样
 是横冲直撞的思维写的,不需要callback回调解析方法,不需要继承BaseSpider类,没有BaseSpider类,大开大合自由奔放,代码阅读所见即所得
 
 绝对没有class MySpider(BaseSpider) 的写法
 
 绝对没有 yield Request(url=url, callback=self.my_parse,meta={'field1':'xxx','field2':'yyy'}) 的写法.
 
 绝对没有 yield item 的写法
 
 boost_spider在函数里面写的东西所见即所得,不需要在好几个文件中来回切换检查代码.
  
 函数去掉@boost装饰器仍然可以正常使用爬虫,加上和去掉都很容易,这就是自由.
 有的人喜欢纯手写无框架的使用线程池运行函数来爬虫,很容易替换成boost_spider
 
 仿scrapy api的爬虫框架,无论是去掉和加上框架,代码组织形式需要翻天覆地的大改特改,这样就是束缚框架.
 
 boost_spider所写的爬虫代码可以直接去掉@boost装饰器,可以正常运行,所见即所得.
 
 只需要加上boost装饰器就可以自动加速并发，给函数和消息加上20控制功能,控制手段比传统爬虫框架多太多,
 boost_spider 支持多线程 gvent eventlet asyncio 并且能叠加多进程消费,运行速度远远的暴击国产爬虫框架.
 国产框架大部分是只能支持多线程同步语法爬虫,不能支持asyncio编程写法,而boost_spider能够同时兼容用户使用requests和aiohttp任意写法
 
 ```

### scrapy和国内写的各种仿scrapy api用法的框架特点
```
funboost函数调度框架,用户完全自由,

仿scrapy框架,只是个url调度框架,仿scrapy api 框架里面写死了怎么帮用户请求一个url,
有时候为了支持用户复杂的请求逻辑,例如换代理ip逻辑,框架还不得不暴露出用户自定义请求的所谓middware,用户要掌握在这些爬虫框架中自定义发送请求,框架又变难了.
因为爬虫框架难的是替自动并发 替用户自动重试 自动断点续爬,发送一个请求并不难,用户导入requests发一个http请求,只需要一行代码,
用户对requests封装一个请求http函数也很简单,反而替用户自作主张怎么发送请求,用户奇葩方式发请求反而满足不了,所以爬虫框架不需要内置替用户自动发送请求.
```

```
需要在 spiders文件夹写继承BaseSpider, 
items文件夹定义item, 
pipleines文件夹写怎么保存爬虫数据,
settings.py写DOWNLOADER_MIDDLEWARES调用什么pipleline,ITEM_PIPELINES调用什么middlware优先级,各种配置
middlewares.py写怎么换代理 请求头,
以及命令行中写怎么启动爬虫运行. 
在各个代码文件中来回切换检查写代码,写法烦人程度非常的吓人.

国内的爬虫框架没有创新能力,都是模仿scrapy的 api用法,所以scrapy的写法烦人的缺点基本上都继承下来了.
和scrapy写法一样烦人的爬虫框架,这样的框架就没必要重复开发了.
```

### boost_spider的qps作用远远的暴击所有爬虫框架的固定线程并发数量

```
国内的仿scrapy框架的,都只能做到固定并发数量,一般是固定开多少个线程.

比如我要求每秒精确完成爬10次接口或网页保存到数据库,你咋做到?
一般人就以为是开10个线程,这是错误的,我没讲过对方接口刚好是精确1秒的响应时间.

如果网站接口或网页耗时0.1秒,你开10线程那就每秒爬了100个网页了.
如果网站网页耗时20秒(特别是加上代理ip后经常可能响应时间大),你开10线程,每秒只能爬0.5次.
用线程数来决定每秒爬多少次就是非常的滑稽,只有请求耗时一直精确等于1秒,那么开多少个线程才等于每秒爬多少次,
否则每秒爬多少次和线程数量没有对应关系.

boost_spider不仅能设置并发数量,也可以设置qps,
boost_spider的qps参数无视任何网站的耗时是多少,不需要提前评估好接口的平均耗时,就能达到控频,
无视对方的响应耗时从0.01 0.07 0.3 0.7 3 7 13 19 37 秒 这些不规律的响应时间数字,
随意波动变化,都能一直保持恒定的爬虫次数.

保持恒定qps,这一点国产框架不行,国产框架需要提前评估好接口耗时,然后精确计算好开多少个线程来达到qps,
如果对方接口耗时变了,就要重新改代码的线程数量.
```

# 2.代码例子：

```python

from boost_spider import boost, BrokerEnum, RequestClient, MongoSink, json, re, MysqlSink, BoosterParams
from boost_spider.sink.dataset_sink import DatasetSink
from db_conn_kwargs import MONGO_CONNECT_URL, MYSQL_CONN_KWARGS  # 保密 密码

"""
非常经典的列表页-详情页 两层级爬虫调度,只要掌握了两层级爬虫,三层级多层级爬虫就很容易模仿

列表页负责翻页和提取详情页url,发送详情页任务到详情页消息队列中
"""

dataset_sink1 = DatasetSink("mysql+pymysql://root:123456@localhost/testdb2")

@boost(BoosterParams(queue_name='car_home_list', broker_kind=BrokerEnum.REDIS_ACK_ABLE, max_retry_times=5, qps=2,
       do_task_filtering=False))  # boost 的控制手段很多.
def crawl_list_page(news_type, page, do_page_turning=False):
    """ 函数这里面的代码是用户想写什么就写什么，函数里面的代码和框架没有任何绑定关系
    例如用户可以用 urllib3请求 用正则表达式解析，没有强迫你用requests请求和parsel包解析。
    """
    url = f'https://www.autohome.com.cn/{news_type}/{page}/#liststart'
    sel = RequestClient(proxy_name_list=['noproxy'], request_retry_times=3,
                        using_platfrom='汽车之家爬虫新闻列表页').get(url).selector
    for li in sel.css('ul.article > li'):
        if len(li.extract()) > 100:  # 有的是这样的去掉。 <li id="ad_tw_04" style="display: none;">
            url_detail = 'https:' + li.xpath('./a/@href').extract_first()
            title = li.xpath('./a/h3/text()').extract_first()
            crawl_detail_page.push(url_detail, title=title, news_type=news_type)  # 发布详情页任务
    if do_page_turning:
        last_page = int(sel.css('#channelPage > a:nth-child(12)::text').extract_first())
        for p in range(2, last_page + 1):
            crawl_list_page.push(news_type, p)  # 列表页翻页。


@boost(BoosterParams(queue_name='car_home_detail', broker_kind=BrokerEnum.REDIS_ACK_ABLE, qps=5,
       do_task_filtering=True, is_using_distributed_frequency_control=True))
def crawl_detail_page(url: str, title: str, news_type: str):
    sel = RequestClient(using_platfrom='汽车之家爬虫新闻详情页').get(url).selector
    author = sel.css('#articlewrap > div.article-info > div > a::text').extract_first() or sel.css(
        '#articlewrap > div.article-info > div::text').extract_first() or ''
    author = author.replace("\n", "").strip()
    news_id = re.search('/(\d+).html', url).group(1)
    item = {'news_type': news_type, 'title': title, 'author': author, 'news_id': news_id, 'url': url}
    # 也提供了 MysqlSink类,都是自动连接池操作数据库
    # MongoSink(db='test', col='car_home_news', uniqu_key='news_id', mongo_connect_url=MONGO_CONNECT_URL, ).save(item)
    # MysqlSink(db='test', table='car_home_news', **MYSQL_CONN_KWARGS).save(item)  # 用户需要自己先创建mysql表
    dataset_sink1.save('car_home_news', item)  # 使用知名dataset三方包,一行代码能自动建表和保存字典到5种数据库类型.


if __name__ == '__main__':
    # crawl_list_page('news',1) # 直接函数测试

    crawl_list_page.clear()  # 清空种子队列
    crawl_detail_page.clear()

    crawl_list_page.push('news', 1, do_page_turning=True)  # 发布新闻频道首页种子到列表页队列
    crawl_list_page.push('advice', page=1,do_page_turning=True)  # 导购
    crawl_list_page.push(news_type='drive', page=1,do_page_turning=True)  # 驾驶评测

    crawl_list_page.consume()  # 启动列表页消费
    crawl_detail_page.consume()  # 启动详情页新闻内容消费

    # 这样速度更猛，叠加多进程
    # crawl_detail_page.multi_process_consume(4)


```

## 代码说明：

```
1.
RequestClient 类的方法入参和返回与requests包一模一样，方便用户切换
response在requests.Response基础上增加了适合爬虫解析的属性和方法。

RequestClient支持继承,用户自定义增加爬虫使用代理的方法,在 PROXYNAME__REQUEST_METHED_MAP 声明增加的方法就可以.

2. 
爬虫函数的入参随意，加上@boost装饰器就可以自动并发

3.
爬虫种子保存，支持40种消息队列

4.
qps是规定爬虫每秒爬几个网页，qps的控制比指定固定的并发数量，控制强太多太多了

```

## boost_spider 支持用户使用asyncio编程生态

国产爬虫框架大部分只能支持同步编程语法生态,无法兼容用户原有的asyncio编程方式.

boost_spider是同步编程和asyncio编程双支持.(boost_spider 还能支持gevent eventlet),还能和多进程叠加性能炸裂.

```python
import httpx
from funboost import boost, BrokerEnum, ConcurrentModeEnum, ctrl_c_recv, BoosterParams

client = httpx.AsyncClient()


@boost(
    BoosterParams(queue_name='test_httpx_q3a', broker_kind=BrokerEnum.REDIS, concurrent_mode=ConcurrentModeEnum.ASYNC,
                  concurrent_num=500))
async def f(url):
    # client= httpx.AsyncClient()
    r = await client.get(url)
    print(r.status_code, len(r.text))

    # 发布url到第二层级
    f2.push('新浪', 'https://www.sina.com')
    f2.push('搜狐', 'https://www.sohu.com')
    f2.push('qq', 'https://www.qq.com')


@boost(
    BoosterParams(queue_name='test_httpx_q3b', broker_kind=BrokerEnum.REDIS, concurrent_mode=ConcurrentModeEnum.ASYNC,
                  concurrent_num=500))
async def f2(site_name, url):
    # client= httpx.AsyncClient()
    r = await client.get(url)
    print(site_name, r.status_code, len(r.text))


if __name__ == '__main__':
    # asyncio.run(f())
    f.clear()  # 清空队列
    f2.clear()

    f.consume()  # 启动消费
    f2.consume()

    for i in range(5):
        f.push('https://www.baidu.com/')
    ctrl_c_recv()


```

## 为什么任何 yield Request(url=url, callback=self.my_parse,meta={'field1':'xxx','field2':'yyy'} 是过气爬虫框架?

在2025年还在模仿2007年的scrapy 框架的api,没有必要。如果真需要异步，就使用真异步asyncio。twisted 早就过气了。

```
1. 逻辑割裂与“回调地狱”：代码可读性的噩梦,  思维跳跃,上下文丢失

2. meta 字典：一个“无法无天”的“黑魔法”容器, 它是一个无类型、无结构、无约束的“垃圾桶”

3. 可测试性的毁灭:
   请求解析,无法独立测试,必须随着框架整体运行起来才能验证

4. 自由度的剥夺：
   你只是流水线上的工人. 你只能通过 yield Request 指定url get还是post 请求体 ,
   如果你是奇葩发请求,例如爬取的时候要从你自己的reids ip代理池获取ip,必须搞个 download middware 来适配框架.
   
5.时序之罪:
   yield Request,不能精准控制请求时机,如果要爬取url2,先必须从url1获取token加密,假设token有效期只有10秒,你分两次yield Request,
   因为请求是被框架自动调度的,你无法自己掌控两个请求的真正被调度时机,url2它可能在url1 1 毫秒后被执行，也可能在 10 分钟后被执行，你完全无法预测。
   只要是种子堆积了,就算是你设置优先级也没用,如果同一个优先级有几万个request种子,无法按优先级精准控制请求时序.
   而函数调度框架,一个函数里面天然可以写if /else/ for /try ,也能连续写发送多次请求
```

**用过 `funboost` 的pythoner都说相见恨晚,连连称奇,醍醐灌顶,豁然开朗,和传统作茧自缚的爬虫框架简直不在一个级别**


## 仿 scrapy api 爬虫框架，作者会疲于奔命
```
所有仿scrapy api 爬虫框架的 作者会疲于奔命需要持续改框架，
作者需要内置很多pipeline  ，例如mysql mongo sqlite jsonfile redis，
作者需要担心用户不会在自己框架扩展pipeline ，作者需要内置 怎么换ip代理 怎么换请求头， 怎么指纹反扒， 
怎么集成各种浏览器包，例如怎么集成 selneium  playwright ，因为作者如果不内置这些middware，用户很难自己扩展适配他的框架。 
  
funboost 不变应万变，funboost 始终不用改代码，以逸待劳，以不变应万变
因为用户在消费函数里面很 直观、自由、容易 地调用自己的 utils/ 或者 commons/ 文件夹下的工具类，
完全不需要考虑怎么和 funboost 进行精细化高度耦合适配
```

## 你的 utils文件夹 是黄金还是废铁？取决于你用什么哲学的框架

- **funboost/boost_spider 对仿scrapy api框架最大优势是 自由编程暴击框架奴役， 能复用用户自己的 utils 宝贵资产**

- scrapy的三方包插件，各种 scrapy-xx 插件，例如 scrapy-redis scrapy-playwright scrapy-selenium scrapy-user-agents scrapy-splash 等等，三方包插件总量不会超过1000个.
  只有pypi的三方包才是星辰大海，100万多个pypi三方包都是你的工具。  
  **最重要的是，只有用户自己项目下utils文件夹下积累的工具类和函数才是最符合用户自己实际需求的工具，而不是 scrapy-xx 插件。**

- Python pypi生态就是funboost的生态，你的python项目下的 utils/ 或者 helpers/ 文件夹下日积月累的各种工具类和函数都是 funboost的生态,   
  例如你的爬虫项目 utils 文件夹下日积月累，99%的概率已经存在如下，好用的经过实战检验的工具类和函数： 
  
```python
def anti_request(method,url,...retry_times=3,is_change_ua=True,is_change_proxy)：
   """自动重试 换代理ip  user-agent 的http请求函数""" 

def save_to_mysql(data:dict)：   
    """保存字典到数据库的函数"""

class RedisBloomFilter:
    """redis 布隆过滤器"""
    def is_exists(self, key):
        ...
    def add(self, key):
        ...

def extract_all_with_join(selector, separator=' '):
    """提取选择器所有结果并用指定分隔符连接成字符串。"""
    return separator.join(selector.getall()).strip()

class WebsiteAuthenticator:  
    """对于需要登录的网站，一个管理会话、Cookie 和 Token 的类是无价之宝。"""
    def login(self):
        ...
    def get_session(self):
        ...

def send_email_notification(subject, body, recipient):
    """发送爬虫邮件通知。"""

def download_and_upload_to_s3(url, bucket_name, object_name):
    """下载文件并直接流式上传到 S3。"""
    s3 = boto3.client('s3')
    with requests.get(url, stream=True) as r:
        r.raise_for_status()
        s3.upload_fileobj(r.raw, bucket_name, object_name)
    return f"s3://{bucket_name}/{object_name}"
    
```

**在 funboost中**，你utils文件夹下的宝贵资产，黄金任然是黄金，可以直接import 复用使用： 
```python
from funboost import boost, BrokerEnum
from utils.http_client import anti_request  # 你日积月累的工具
from utils.db import save_to_mysql        # 你日积月累的工具
from utils.redis_dedup import RedisBloomFilter   # 你日积月累的工具
from utils.website_authenticator import WebsiteAuthenticator   # 你日积月累的工具
from utils.send_notification import send_email_notification   # 你日积月累的工具
from utils.download_and_upload import download_and_upload_to_s3   # 你日积月累的工具
```
**而在`scrapy` `feapder`面前**，你曾经引以为豪在`utils`文件夹下积累的宝贵资产，他不是黄金，只是一堆破铜烂铁而已，不能被导入复用。    
你没有按照他们框架的`Downloader Middleware` 和 `Pipeline`规范写的`utils`文件夹下的工具类，都是废铁一文不值。  
`scrapy`的扩展插件机制 被 `funboost` 的自由import复用吊打。

- 复用用户自己的 utils 宝贵资产，正是 `funboost`  区别于 `Scrapy/Feapder` 等传统框架的**根本性优势**，是战略层面的胜利。

*   **`utils` 是开发者的“内功心法”**：一个开发者的 `utils` 文件夹，是他/她多年经验的结晶，是解决特定领域问题的最佳实践沉淀。它包含了对业务逻辑的深刻理解，是**不可替代的、高度定制化的“私有武器库”**。
*   **“复用 `utils`” = 复用经验和智慧**：一个框架如果能让开发者无缝地复用自己的 `utils`，就意味着它尊重并放大了开发者的个人能力和历史积累。开发者可以用最熟悉、最高效的方式解决问题。
*   **“无法复用 `utils`” = 废掉武功，重练套路**：`Scrapy/Feapder` 的插件和中间件机制，本质上是让你放弃自己的“内功”，去学习并练习一套它们规定好的“套路招式”。你的 `my_request` 函数再精妙，也得改成 `Downloader Middleware` 的形状；你的 `save_to_mysql` 再高效，也得塞进 `Item Pipeline` 的模子里。这是一个**巨大的、隐性的成本**。



## 🚀 boost_spider 作为微服务和 FaaS (Function as a Service) 使用，能高实时爬虫，scrapy只能离线批量爬虫，boost_spider在实时场景吊打scrapy

> **告别“数据孤岛”，让爬虫成为可被实时调用的“原子能力”。**

- 传统爬虫框架（如 Scrapy）的设计初衷是 **离线批处理**：启动 -> 跑完所有种子 -> 结束。这使得它们像一座座孤岛，外部系统（如 Java/Go 后端、Web 管理台）很难与正在运行的爬虫进行**实时交互**。

- 而 **boost_spider** 基于 **funboost** 的函数调度哲学，天然具备 **FaaS (Function as a Service)** 基因。每一个被 `@boost` 装饰的爬虫函数，瞬间就可以变成一个 **微服务接口**。

-  **Funboost/boost_spider 天然就是 FaaS 微服务，而 Scrapy 只是数据孤岛,架构模式战略级碾压**
  `funboost/boost_spider`不仅支持别的部门通过原生消息队列客户端发布函数入参对应的纯净json到对应的queue_name
   也支持 `funboost.faas` 快速给你的web服务增加多个funboost路由，一键实现`FaaS(Function as a Service)`    
   自动发现注册爬虫函数，在实时爬虫上对`scrapy-redis`是战略级碾压。 

### ⚔️ 核心差异对比：实时性与架构

| 维度 | 🐢 Scrapy (离线批处理) | ⚡ boost_spider (实时微服务) |
| :--- | :--- | :--- |
| **运行模式** | **主动轮询/跑批**。适合每天凌晨跑全量数据。 | **事件驱动/按需触发**。适合用户点一下按钮，立马抓取数据。 |
| **外部调用** | **难**。外部系统很难向正在运行的 Spider 插入任务并等待结果，通常需要通过数据库中转，延迟极高。 | **极简**。通过自动生成的 HTTP 接口直接触发，支持 **RPC 模式** 同步等待并获取爬取结果。 |
| **架构定位** | **脚本/任务**。是一个独立的进程，跑完即焚。 | **服务/组件**。是一个常驻的微服务，随时响应来自 Web 前端或后端 API 的抓取请求。 |
| **适用场景** | 全网爬取、搜索引擎索引、历史数据回溯。 | **接口实时代理解析**、**用户触发式采集**、**竞对价格实时监控**。 |

### scrapy是封闭循环系统，  scrapy-redis一旦启动后，再去人为从程序外部手动注入一个深层级的爬虫种子/任务 非常难。

**Scrapy 难以实现深层任务动态注入。**

有人不服气的，你可以试试对 `scrapy-redis`的 深层级爬虫动态增加一个任务， 例如从web接口给第二层级的 `detail_parse` 动态实时新增 `yield` 一个`Request` 请求调度对象，
这个简单的需求，对 scrapy 小白来说完全不可能，对scrapy大神来神实现非常麻烦。因为在程序外部你脱离了spider对象自身，就很难给深层级爬虫实时动态新增爬虫种子了。
如果是动态新增第一层级的爬虫种子，你可以简单的 `redis.lpush('start_urls','my_list_page_url1')`，这勉强能做到，但对深层级的爬虫`xx_parse`方法去动态实时加一个爬虫种子就太难了。


## funboost/booost_spider 比 scrapy框架的 战略优势和战术优势
### 一、 战略优势 (Strategic Advantages)
*—— 架构理念、生态整合与长远价值*

#### 1. 核心哲学：赋能 vs 奴役
*   **Funboost**: 是**“函数调度器”**。它不关心你的函数里写的是爬虫、数据清洗还是发邮件。它对代码**零侵入**，只负责为函数提供分布式、并发和高可靠的能力。你的代码依然是标准的 Python 代码。
*   **Scrapy**: 是**“URL调度器”**。它强迫开发者按照框架的规则（Spider, Item, Pipeline, Middleware）来拆解业务逻辑。开发者被框架“奴役”，必须削足适履。

#### 2. 架构模式：FaaS 微服务 vs 数据孤岛
*   **Funboost**: 天然具备 **FaaS (Function as a Service)** 基因。
    *   每一个爬虫函数瞬间变成一个**微服务接口**。
    *   **打破孤岛**：Java/Go/PHP 等外部系统可以直接往消息队列推 JSON 数据来实时触发特定的爬虫任务（如立即抓取某详情页），实现**实时交互**。
    *   **Funboost.faas**: 提供开箱即用的 HTTP 接口，实现自动服务发现。
*   **Scrapy**: 设计初衷是**离线批处理**。
    *   是一个封闭的黑盒循环。外部系统很难在爬虫运行时动态插入一个深层级的任务（如直接触发 `parse_detail`）。

#### 3. 资产复用：黄金 vs 废铁
*   **Funboost**: 直接复用你项目 `utils/` 文件夹下积累多年的工具类（如 `requests` 封装、数据库操作类）。这些代码是**黄金**，拿来即用。
*   **Scrapy**: 你积累的通用 Python 工具类在这里往往是**废铁**。你必须把它们改写成 Scrapy 特有的 `Middleware` 或 `Pipeline` 格式才能使用，造成巨大的重复劳动和维护成本。

#### 4. 生态兼容：Python 生态 vs 插件生态
*   **Funboost**: **无需插件**。整个 PyPI 都是你的插件库。想用 `Playwright`？直接 import 用。想用 `SQLAlchemy`？直接 import 用。
*   **Scrapy**: **严重依赖插件**。想用 Redis？得装 `scrapy-redis`。想用 Selenium？得找 `scrapy-selenium`。开发者被限制在 Scrapy 的小生态圈里，一旦没有对应的适配插件，寸步难行。

---

### 二、 战术优势 (Tactical Advantages)
*—— 开发效率、性能表现与具体功能*

#### 1. 并发性能：四重叠加 vs 单核异步
*   **Funboost**: 支持 **多机器 + 多进程 + (多线程/协程)** 的四重叠加并发。能轻松榨干多核 CPU 性能，QPS 极其炸裂。
*   **Scrapy**: 基于 Twisted 单进程事件循环。难以利用多核 CPU，一旦在回调中出现阻塞操作（如复杂的解密计算或浏览器渲染），整个爬虫就会卡死。

#### 2. 流程控制：线性直观 vs 回调地狱
*   **Funboost**: **平铺直叙**。在一个函数内完成 “请求 -> 逻辑判断 -> 再次请求 -> 解析 -> 入库” 的完整闭环。代码逻辑连贯，支持 `while`/`for` 等复杂流程控制。
*   **Scrapy**: **回调地狱**。逻辑被强行拆分到 `start_requests`, `parse`, `parse_detail` 等多个回调函数中，状态传递（`meta`）繁琐且易错，代码阅读极其跳跃。
    *   *场景举例*：**短时效 Token**。Funboost 可以在函数内获取 Token 后立即发起下一次请求，确保不过期；Scrapy 无法保证两个 Request 之间的执行间隔。

#### 3. 可靠性：万无一失 vs 随机丢包
*   **Funboost**: 拥有 **ACK 消费确认机制**。即使爬虫进程被强制 kill、断电或崩溃，未执行完的任务会重新回到队列，数据**一条不丢**。
*   **Scrapy (scrapy-redis)**: 使用 `BLPOP` 模式。任务一旦从 Redis 弹出，如果进程崩溃，内存中的任务就**永久丢失**了。断点续爬不可靠。

#### 4. 控频能力：精准 QPS vs 模糊并发
*   **Funboost**: 支持 **精准 QPS 控频**（如每秒 5.5 次）。无论网络响应快慢，框架会自动调节并发度来维持稳定的请求速率。支持**分布式全局控频**。
*   **Scrapy**: 只能控制**并发数**（Concurrent Requests）。无法保证稳定的抓取速率，容易因请求过快触发反爬，或因响应变慢导致效率低下。

#### 5. 反爬应对：简单函数 vs 复杂中间件
*   **Funboost**: 写一个普通的 Python 函数（如 `my_request`）来封装换 IP、换 UA 的逻辑，简单直观，容易测试。
*   **Scrapy**: 必须深入理解框架生命周期，编写复杂的 `Downloader Middleware`，配置优先级，调试困难。

#### 6. 任务去重：智能入参 vs 笨拙 URL
*   **Funboost**: 基于**函数入参**去重。天然忽略 URL 中的时间戳、随机数等噪音参数。支持设置**去重有效期**（如7天后可重爬）。
*   **Scrapy**: 基于 **URL 指纹**去重。对 URL 中的噪音参数敏感，需要编写复杂的正则或自定义去重器来清洗 URL。默认不支持有效期去重。

### 总结
**Scrapy** 适合处理结构简单、无需复杂交互、离线式的全网爬取任务。
**Funboost/BoostSpider** 则适合现代互联网环境下，高并发、强反爬、逻辑复杂、需要实时交互和微服务化的采集业务。
`````

--- **end of file: README.md** (project: funboost_docs) --- 

---


﻿# 🤖 AI Reading Guide for Project: funboost

> **Important Notice for AI Models**: This document contains the complete source code and documentation for the `funboost` project. Please read this guide carefully before analyzing the content.

## 📖 Document Structure

This markdown document is structured as follows:

1. **Project Summary** (`# markdown content namespace: xxx project summary`)
   - Brief project description
   - Core source files metadata (AST-parsed class/function signatures without full source code)
   - File dependencies analysis

2. **Project Root Files** (`# markdown content namespace: xxx Project Root Dir Some Files`)
   - README.md, pyproject.toml, setup.py, etc.

3. **Source Code Sections** (`# markdown content namespace: xxx codes/examples/...`)
   - File Tree: Shows directory structure
   - Included Files: Lists all files in this section
   - Full source code with AST metadata for Python files

## 🔍 How to Identify File Boundaries

- Each file starts with: `--- **start of file: <path>** (project: funboost) ---`
- Each file ends with: `--- **end of file: <path>** (project: funboost) ---`
- All file paths are relative to the project root

## ⚠️ Important Notes

1. **Do NOT hallucinate**: Only reference code, classes, functions, and APIs that actually exist in this document
2. **Check file paths**: When suggesting code changes, always verify the file path exists in the File Tree
3. **Respect the project structure**: The File Tree shows the actual directory layout
4. **AST Metadata**: Python files include parsed metadata (imports, classes, methods) before the full source code

---

# markdown content namespace: funboost project summary 



- `funboost` 是python 全功能分布式函数调度框架
- `funboost.faas` 是funboost的战略级核武器。使函数调度框架产生架构质变：从 Worker 到 Service

- 以下一定要记住，最最重要的 类和函数如下：
   - @boost(BoosterParams(...))  任意普通函数加上装饰器，变成分布式函数
   - BoosterParams 装饰器入参控制大全，一定要学习这个类的所有入参配置；ai绝对不允许胡编乱造源码api和教程中不存在的BoosterParams字段入参。
   - BrokerEnum：支持 40+ 种消息队列中间件。
   - BoostersManager 管理分布式函数，高阶用法可能需要用到，例如启动一组消费函数，启动所有消费函数等。
   - ApsJobAdder 类， 是定时任务的最重要使用方式的类
   - ConcurrentModeEnum：funboost支持的并发模式。
   - funboost/core/broker_kind__exclusive_config_default_define.py 决定了每种中间件类型能传递哪些
   



## 📋 funboost most core source files metadata (Entry Points)


以下是项目 funboost 最核心的入口文件的结构化元数据，帮助快速理解项目架构：



### the project funboost most core source code files as follows: 
- `funboost/__init__.py`
- `funboost/core/booster.py`
- `funboost/core/func_params_model.py`
- `funboost/constant.py`
- `funboost/timing_job/timing_push.py`
- `funboost/funboost_config_deafult.py`
- `funboost/core/current_task.py`
- `funboost/core/cli/discovery_boosters.py`
- `funboost/core/broker_kind__exclusive_config_default_define.py`
- `funboost/core/msg_result_getter.py`
- `funboost/publishers/base_publisher.py`
- `funboost/consumers/base_consumer.py`
- `funboost/core/active_cousumer_info_getter.py`


### 📄 Python File Metadata: `funboost/__init__.py`

#### 📦 Imports

- `import atexit`
- `import nb_log`
- `from nb_log import nb_print`
- `from funboost.set_frame_config import show_frame_config`
- `from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath as _`
- `from funboost.utils import monkey_patches as _`
- `from funboost.core.loggers import get_logger`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import FunboostMetaTypeFileLogger`
- `from funboost.core.loggers import flogger`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import BoosterParamsComplete`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParamsComplete`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.utils.paramiko_util import ParamikoFolderUploader`
- `from funboost.consumers.base_consumer import wait_for_possible_has_finish_all_tasks_by_conusmer_list`
- `from funboost.consumers.base_consumer import FunctionResultStatus`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.consumers.empty_consumer import EmptyConsumer`
- `from funboost.core.exceptions import ExceptionForRetry`
- `from funboost.core.exceptions import ExceptionForRequeue`
- `from funboost.core.exceptions import ExceptionForPushToDlxqueue`
- `from funboost.core.active_cousumer_info_getter import ActiveCousumerProcessInfoGetter`
- `from funboost.core.msg_result_getter import HasNotAsyncResult`
- `from funboost.core.msg_result_getter import ResultFromMongo`
- `from funboost.publishers.base_publisher import TaskOptions`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import AsyncResult`
- `from funboost.publishers.base_publisher import AioAsyncResult`
- `from funboost.publishers.empty_publisher import EmptyPublisher`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import register_custom_broker`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.factories.consumer_factory import get_consumer`
- `from funboost.timing_job import funboost_aps_scheduler`
- `from funboost.timing_job.timing_push import ApsJobAdder`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.core.booster import boost`
- `from funboost.core.booster import Booster`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.kill_remote_task import RemoteTaskKiller`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.core.cli.discovery_boosters import BoosterDiscovery`
- `from funboost.core.helper_funs import run_forever`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.concurrent_pool.custom_threadpool_executor import show_current_threads_num`
- `from funboost.core.current_task import funboost_current_task`
- `from funboost.core.current_task import fct`
- `from funboost.core.current_task import get_current_taskid`


---




### 📄 Python File Metadata: `funboost/core/booster.py`

#### 📦 Imports

- `from __future__ import annotations`
- `import copy`
- `import inspect`
- `from multiprocessing import Process`
- `import os`
- `import sys`
- `import types`
- `import typing`
- `import threading`
- `from funboost.concurrent_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.constant import FunctionKind`
- `from funboost.constant import StrConst`
- `from funboost.utils.class_utils import ClsHelper`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.utils.decorators import flyweight`
- `from funboost.core.loggers import flogger`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.loggers import logger_prompt`
- `from functools import wraps`
- `from funboost.core.exceptions import BoostDecoParamsIsOldVersion`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.factories.consumer_factory import get_consumer`
- `from funboost.factories.consumer_factory import ConsumerCacheProxy`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.factories.publisher_factotry import PublisherCacheProxy`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.msg_result_getter import AioAsyncResult`
- `from funboost.core.muliti_process_enhance import run_consumer_with_multi_process`
- `from funboost.core.muliti_process_enhance import multi_process_pub_params_list`
- `from funboost.core.fabric_deploy_helper import fabric_deploy`

#### 🏛️ Classes (2)

##### 📌 `class Booster`
*Line: 39*

**Docstring:**
`````
funboost极其重视代码能在pycharm下自动补全。元编程经常造成在pycharm下代码无法自动补全提示，主要是实现代码补全难。
这种__call__写法在pycahrm下 不仅能补全消费函数的 push consume等方法，也能补全函数本身的入参，一举两得。代码能自动补全很重要。
一个函数fun被 boost装饰器装饰后， isinstance(fun,Booster) 为True.

pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

Booster 是把Consumer 和 Publisher的方法集为一体。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: typing.Union[BoosterParams, str] = None, **kwargs)`
  - **Docstring:**
  `````
  @boost 这是funboost框架最重要的一个函数，必须看懂BoosterParams里面的入参有哪些。
  建议永远使用 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) 这种传参方式。
  
  
  pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.
  (高版本的pycharm pydantic是内置支持代码补全的,由此可见,pydantic太好了,pycharm官方都来支持)
  
  强烈建议所有入参放在 BoosterParams() 中,不要直接在BoosterParams之外传参.现在是兼容老的直接在@boost中传参方式.
  建议不要给第一个入参queue_name传递字符串，而是永远传递BoosterParams类型， 例如 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  
  
  ```python
  # @boost('queue_test_f01', qps=0.2, ) # 老的入参方式
  @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) # 新的入参方式,所有入参放在 最流行的三方包 pydantic model BoosterParams 里面.
  def f(a, b):
      print(a + b)
  
  for i in range(10, 20):
      f.pub(dict(a=i, b=i * 2))
      f.push(i, i * 2)
  f.consume()
  # f.multi_process_conusme(8)             # # 这个是新加的方法，细粒度 线程 协程并发 同时叠加8个进程，速度炸裂。
  ```
  
  
  @boost('queue_test_f01', qps=0.2, )
  @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  @Booster(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  @BoosterParams(queue_name='queue_test_f01', qps=0.2, )
  以上4种写法等效。
  `````
  - **Parameters:**
    - `self`
    - `queue_name: typing.Union[BoosterParams, str] = None`
    - `**kwargs`

**Public Methods (3):**
- `def multi_process_consume(self, process_num = 1)`
  - *超高速多进程消费*
- `def multi_process_pub_params_list(self, params_list, process_num = 16)`
  - *超高速多进程发布，例如先快速发布1000万个任务到中间件，以后慢慢消费*
- `def fabric_deploy(self, host, port, user, password, path_pattern_exluded_tuple = ('/.git/', '/.idea/', '/dist/', '/build/'), file_suffix_tuple_exluded = ('.pyc', '.log', '.gz'), only_upload_within_the_last_modify_time = 3650 * 24 * 60 * 60, file_volume_limit = 1000 * 1000, sftp_log_level = 20, extra_shell_str = '', invoke_runner_kwargs = {'hide': None, 'pty': True, 'warn': False}, python_interpreter = 'python3', process_num = 1, pkey_file_path = None)`
  - *入参见 fabric_deploy 函数。这里重复入参是为了代码在pycharm补全提示。*

**Class Variables (2):**
- `multi_process_start = multi_process_consume`
- `mp_consume = multi_process_consume`

##### 📌 `class BoosterRegistry`
*Line: 273*

**Docstring:**
`````
管理boosters，可以一键启动多个消费函数或者启动一组消费函数。

BoosterRegistry 是后加的， 原来的 BoostersManager 类是一个包含多个classmethod的类，和现在的方法名和入参一样。
为了兼容老的 BoostersManager 这个用法，现在的 BoostersManager 是 BoosterRegistry 其中一个实例。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, booster_registry_name)`
  - **Parameters:**
    - `self`
    - `booster_registry_name`

**Public Methods (17):**
- `def regist_booster(self, booster: Booster)`
  - *这个是框架在@boost时候自动调用的,无需用户亲自调用*
- `def show_all_boosters(self)`
- `def get_all_queues(self) -> list`
- `def get_all_queue_name__boost_params_unstrict_dict(self)`
  - **Docstring:**
  `````
  主要用来给前端或可视化观看的。
  
  返回一个字典,键是队列名,值是@boost的 BoosterParams 入参字典,
  因为 BoosterParams 有的入参是复杂对象类型,不能json序列化
  `````
- `def get_booster(self, queue_name: str) -> Booster`
  - **Docstring:**
  `````
  当前进程获得booster对象。注意和下面的get_or_create_booster_by_queue_name方法的区别,主要是开了多进程时候有区别.
  :param queue_name:
  :return:
  `````
- `def get_or_create_booster_by_queue_name(self, queue_name) -> Booster`
  - **Docstring:**
  `````
  当前进程获得booster对象，如果是多进程,会在新的进程内部创建一个新的booster对象,因为多进程操作有些中间件的同一个conn不行.
  :param queue_name: 就是 @boost的入参。
  :return:
  `````
- `def get_boost_params(self, queue_name: str) -> (dict, typing.Callable)`
  - **Docstring:**
  `````
  这个函数是为了在别的进程实例化 booster，consumer和publisher,获取queue_name队列对应的booster的当时的入参。
  有些中间件python包的对中间件连接对象不是多进程安全的，不要在进程2中去操作进程1中生成的booster consumer publisher等对象。
  `````
- `def build_booster(self, boost_params: BoosterParams) -> Booster`
  - **Docstring:**
  `````
  当前进程获得或者创建booster对象。方便有的人需要在函数内部临时动态根据队列名创建booster,不会无数次临时生成消费者、生产者、创建消息队列连接。
  :param boost_params: 就是 @boost的入参。
  :param consuming_function: 消费函数
  :return:
  `````
- `def get_cross_project_publisher(self, publisher_params: PublisherParams) -> AbstractPublisher`
  - **Docstring:**
  `````
  跨不同的项目，发布消息。例如proj1中定义有fun1消费函数，但proj2无法直接到proj1的函数，无法直接 fun1.push 来发布消息
  可以使用这个方法，获取一个publisher。
  
  publisher = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='proj1_queue', broker_kind=publisher_params.broker_kind))
  publisher.publish({'x': aaa})
  `````
- `def push(self, queue_name, *args, **kwargs)`
  - *push发布消息到消息队列 ;*
- `def publish(self, queue_name, msg)`
  - *publish发布消息到消息队列;*
- `def consume_queues(self, *queue_names)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费,多个函数队列在当前同一个进程内启动消费.
  这种方式节约总的内存,但无法利用多核cpu
  `````
- `def consume_all_queues(self, block = True)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需一个一个函数亲自 funxx.consume()来启动,多个函数队列在当前同一个进程内启动消费.
  这种方式节约总的内存,但无法利用多核cpu
  `````
- `def multi_process_consume_queues(self, **queue_name__process_num)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费,传递队列名和进程数,每个队列启动n个单独的消费进程;
  这种方式总的内存使用高,但充分利用多核cpu
  例如 multi_process_consume_queues(queue1=2,queue2=3) 表示启动2个进程消费queue1,启动3个进程消费queue2
  `````
- `def consume_group(self, booster_group: str, block = False)`
  - *根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;*
- `def multi_process_consume_group(self, booster_group: str, process_num = 1)`
  - *根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;*
- `def multi_process_consume_all_queues(self, process_num = 1)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需指定队列名,每个队列启动n个单独的消费进程;
  这种方式总的内存使用高,但充分利用多核cpu
  `````

**Class Variables (6):**
- `_lock = threading.Lock()`
- `consume = consume_queues`
- `consume_all = consume_all_queues`
- `mp_consume = multi_process_consume_queues`
- `mp_consume_group = multi_process_consume_group`
- `mp_consume_all = multi_process_consume_all_queues`

#### 🔧 Public Functions (1)

- `def gen_pid_queue_name_key(queue_name: str) -> typing.Tuple[int, str]`
  - *Line: 268*


---




### 📄 Python File Metadata: `funboost/core/func_params_model.py`

#### 📝 Module Docstring

`````
pydantic 模型定义， funboost 使用pydantic 作为重要函数的入参，
方便函数入参太多在层层传递时候的麻烦，例如 BoosterParams 经常新增字段，如果funboost直接入参一大堆，需要每一层都去新增入参很麻烦

BoosterParams 是 funboost 最核心的入参模型，掌握了 BoosterParams 就是掌握了 funboost 的90% 用法。
`````

#### 📦 Imports

- `import functools`
- `import typing`
- `import asyncio`
- `import logging`
- `import datetime`
- `from pydantic.fields import Field`
- `from typing_extensions import Literal`
- `from funboost.concurrent_pool.pool_commons import ConcurrentPoolBuilder`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`
- `from funboost.core.pydantic_compatible_base import compatible_root_validator`
- `from funboost.core.pydantic_compatible_base import BaseJsonAbleModel`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.constant import StrConst`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.concurrent_pool import FlexibleThreadPool`

#### 🏛️ Classes (5)

##### 📌 `class FunctionResultStatusPersistanceConfig(BaseJsonAbleModel)`
*Line: 27*

**Public Methods (1):**
- `def check_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (5):**
- `is_save_status: bool`
- `is_save_result: bool`
- `expire_seconds: int = 7 * 24 * 3600`
- `is_use_bulk_insert: bool = False`
- `table_name: typing.Optional[str] = None`

##### 📌 `class BoosterParams(BaseJsonAbleModel)`
*Line: 43*

**Docstring:**
`````
pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

@boost的传参必须是此类或者继承此类,如果你不想每个装饰器入参都很多,你可以写一个子类继承BoosterParams, 传参这个子类,例如下面的 BoosterParamsComplete
`````

**Public Methods (1):**
- `def check_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (52):**
- `queue_name: str`
- `broker_kind: str = BrokerEnum.SQLITE_QUEUE`
- `project_name: typing.Optional[str] = None`
- `concurrent_mode: str = ConcurrentModeEnum.THREADING`
- `concurrent_num: int = 50`
- `specify_concurrent_pool: typing.Optional[FunboostBaseConcurrentPool] = None`
- `specify_async_loop: typing.Optional[asyncio.AbstractEventLoop] = None`
- `is_auto_start_specify_async_loop_in_child_thread: bool = True`
- `qps: typing.Union[float, int, None] = None`
- `is_using_distributed_frequency_control: bool = False`
- `is_send_consumer_heartbeat_to_redis: bool = False`
- `max_retry_times: int = 3`
- `retry_interval: typing.Union[float, int] = 0`
- `is_push_to_dlx_queue_when_retry_max_times: bool = False`
- `consuming_function_decorator: typing.Optional[typing.Callable] = None`
- `function_timeout: typing.Union[int, float, None] = None`
- `is_support_remote_kill_task: bool = False`
- `log_level: int = logging.DEBUG`
- `logger_prefix: str = ''`
- `create_logger_file: bool = True`
- `logger_name: typing.Union[str, None] = ''`
- `log_filename: typing.Union[str, None] = None`
- `is_show_message_get_from_broker: bool = False`
- `is_print_detail_exception: bool = True`
- `publish_msg_log_use_full_msg: bool = False`
- `msg_expire_seconds: typing.Union[float, int, None] = None`
- `do_task_filtering: bool = False`
- `task_filtering_expire_seconds: int = 0`
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=False, is_save_status=False, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)`
- `user_custom_record_process_info_func: typing.Optional[typing.Callable] = None`
- `is_using_rpc_mode: bool = False`
- `rpc_result_expire_seconds: int = 1800`
- `rpc_timeout: int = 1800`
- `delay_task_apscheduler_jobstores_kind: Literal['redis', 'memory'] = 'redis'`
- `is_do_not_run_by_specify_time_effect: bool = False`
- `do_not_run_by_specify_time: list = ['10:00:00', '22:00:00']`
- `schedule_tasks_on_main_thread: bool = False`
- `is_auto_start_consuming_message: bool = False`
- `booster_group: typing.Union[str, None] = None`
- `consuming_function: typing.Optional[typing.Callable] = None`
- `consuming_function_raw: typing.Optional[typing.Callable] = None`
- `consuming_function_name: str = ''`
- `broker_exclusive_config: dict = {}`
- `should_check_publish_func_params: bool = True`
- `manual_func_input_params: dict = {'is_manual_func_input_params': False, 'must_arg_name_list': [], 'optional_arg_name_list': []}`
- `consumer_override_cls: typing.Optional[typing.Type] = None`
- `publisher_override_cls: typing.Optional[typing.Type] = None`
- `consuming_function_kind: typing.Optional[str] = None`
- `user_options: dict = {}`
- `auto_generate_info: dict = {}`
- `is_fake_booster: bool = False`
- `booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT`

##### 📌 `class BoosterParamsComplete(BoosterParams)`
*Line: 259*

**Docstring:**
`````
例如一个子类,这个BoosterParams的子类可以作为@booot的传参,每个@boost可以少写一些这些重复的入参字段.

function_result_status_persistance_conf 永远支持函数消费状态 结果状态持久化
is_send_consumer_heartbeat_to_redis 永远支持发送消费者的心跳到redis,便于统计分布式环境的活跃消费者
is_using_rpc_mode  永远支持rpc模式
broker_kind 永远是使用 amqpstorm包 操作 rabbbitmq作为消息队列.
specify_concurrent_pool 同一个进程的不同booster函数,共用一个线程池,线程资源利用更高.
`````

**Class Variables (6):**
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=True)`
- `is_send_consumer_heartbeat_to_redis: bool = True`
- `is_using_rpc_mode: bool = True`
- `rpc_result_expire_seconds: int = 3600`
- `broker_kind: str = BrokerEnum.RABBITMQ_AMQPSTORM`
- `specify_concurrent_pool: FunboostBaseConcurrentPool = Field(default_factory=functools.partial(ConcurrentPoolBuilder.get_pool, FlexibleThreadPool, 500))`

##### 📌 `class TaskOptions(BaseJsonAbleModel)`
*Line: 279*

**Docstring:**
`````
这个是 publish 支持的额外参数，和函数参数一起发布到中间件。
可能有少数时候有这种需求。如果需要发布额外字段到消息队列，必须使用publish方法，push方法是类似celery的dalay只能发布函数入参自身。
这里面的字段值如果非None，会放到消息队列的消息里面的 extra 字段中。
`````

**Public Methods (1):**
- `def cehck_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (16):**
- `task_id: str = None`
- `publish_time: float = None`
- `publish_time_format: str = None`
- `function_timeout: typing.Union[float, int, None] = None`
- `max_retry_times: typing.Union[int, None] = None`
- `is_print_detail_exception: typing.Union[bool, None] = None`
- `msg_expire_seconds: typing.Union[float, int, None] = None`
- `is_using_rpc_mode: typing.Union[bool, None] = None`
- `countdown: typing.Union[float, int, None] = None`
- `eta: typing.Union[datetime.datetime, str, None] = None`
- `misfire_grace_time: typing.Union[int, None] = None`
- `user_extra_info: typing.Optional[dict] = None`
- `other_extra_params: typing.Optional[dict] = None`
- `filter_str: typing.Optional[str] = None`
- `can_not_json_serializable_keys: typing.List[str] = None`
- `otel_context: typing.Optional[dict] = None`

##### 📌 `class PublisherParams(BaseJsonAbleModel)`
*Line: 332*

**Class Variables (21):**
- `queue_name: str`
- `broker_kind: typing.Optional[str] = None`
- `project_name: typing.Optional[str] = None`
- `log_level: int = logging.DEBUG`
- `logger_prefix: str = ''`
- `create_logger_file: bool = True`
- `logger_name: str = ''`
- `log_filename: typing.Optional[str] = None`
- `clear_queue_within_init: bool = False`
- `consuming_function: typing.Optional[typing.Callable] = None`
- `broker_exclusive_config: dict = {}`
- `should_check_publish_func_params: bool = True`
- `manual_func_input_params: dict = {'is_manual_func_input_params': False, 'must_arg_name_list': [], 'optional_arg_name_list': []}`
- `publisher_override_cls: typing.Optional[typing.Type] = None`
- `publish_msg_log_use_full_msg: bool = False`
- `consuming_function_kind: typing.Optional[str] = None`
- `rpc_timeout: int = 1800`
- `user_options: dict = {}`
- `auto_generate_info: dict = {}`
- `is_fake_booster: bool = False`
- `booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT`


---




### 📄 Python File Metadata: `funboost/constant.py`

#### 🏛️ Classes (9)

##### 📌 `class BrokerEnum`
*Line: 5*

**Docstring:**
`````
在funboost中万物皆可为消息队列broker,funboost内置了所有 知名的正经经典消息队列作为broker,
也支持了基于 内存 各种数据库 文件系统 tcp/udp/http这些socket 模拟作为broker.
funboost也内置支持了各种python三方包和消费框架作为broker,例如 sqlachemy kombu celery rq dramtiq huey nameko 等等

用户也可以按照文档4.21章节,轻松扩展任何物质概念作为funboost的broker.
`````

**Class Variables (43):**
- `EMPTY = 'EMPTY'`
- `RABBITMQ_AMQPSTORM = 'RABBITMQ_AMQPSTORM'`
- `RABBITMQ = RABBITMQ_AMQPSTORM`
- `RABBITMQ_COMPLEX_ROUTING = 'RABBITMQ_COMPLEX_ROUTING'`
- `RABBITMQ_RABBITPY = 'RABBITMQ_RABBITPY'`
- `REDIS = 'REDIS'`
- `REDIS_ACK_ABLE = 'REDIS_ACK_ABLE'`
- `REIDS_ACK_USING_TIMEOUT = 'reids_ack_using_timeout'`
- `REDIS_PRIORITY = 'REDIS_PRIORITY'`
- `REDIS_STREAM = 'REDIS_STREAM'`
- `RedisBrpopLpush = 'RedisBrpopLpush'`
- `REDIS_PUBSUB = 'REDIS_PUBSUB'`
- `MEMORY_QUEUE = 'MEMORY_QUEUE'`
- `LOCAL_PYTHON_QUEUE = MEMORY_QUEUE`
- `RABBITMQ_PIKA = 'RABBITMQ_PIKA'`
- `MONGOMQ = 'MONGOMQ'`
- `SQLITE_QUEUE = 'sqlite3'`
- `PERSISTQUEUE = SQLITE_QUEUE`
- `NSQ = 'NSQ'`
- `KAFKA = 'KAFKA'`
- `KAFKA_CONFLUENT = 'KAFKA_CONFLUENT'`
- `CONFLUENT_KAFKA = KAFKA_CONFLUENT`
- `KAFKA_CONFLUENT_SASlPlAIN = 'KAFKA_CONFLUENT_SASlPlAIN'`
- `SQLACHEMY = 'SQLACHEMY'`
- `ROCKETMQ = 'ROCKETMQ'`
- `ZEROMQ = 'ZEROMQ'`
- `KOMBU = 'KOMBU'`
- `MQTT = 'MQTT'`
- `HTTPSQS = 'HTTPSQS'`
- `PULSAR = 'PULSAR'`
- `UDP = 'UDP'`
- `TCP = 'TCP'`
- `HTTP = 'HTTP'`
- `GRPC = 'GRPC'`
- `NATS = 'NATS'`
- `TXT_FILE = 'TXT_FILE'`
- `PEEWEE = 'PEEWEE'`
- `CELERY = 'CELERY'`
- `DRAMATIQ = 'DRAMATIQ'`
- `HUEY = 'HUEY'`
- `RQ = 'RQ'`
- `NAMEKO = 'NAMEKO'`
- `MYSQL_CDC = 'MYSQL_CDC'`

##### 📌 `class ConcurrentModeEnum`
*Line: 150*

**Class Variables (6):**
- `THREADING = 'threading'`
- `GEVENT = 'gevent'`
- `EVENTLET = 'eventlet'`
- `ASYNC = 'async'`
- `SINGLE_THREAD = 'single_thread'`
- `SOLO = SINGLE_THREAD`

##### 📌 `class FunctionKind`
*Line: 161*

**Class Variables (4):**
- `CLASS_METHOD = 'CLASS_METHOD'`
- `INSTANCE_METHOD = 'INSTANCE_METHOD'`
- `STATIC_METHOD = 'STATIC_METHOD'`
- `COMMON_FUNCTION = 'COMMON_FUNCTION'`

##### 📌 `class ConstStrForClassMethod`
*Line: 168*

**Class Variables (5):**
- `FIRST_PARAM_NAME = 'first_param_name'`
- `CLS_NAME = 'cls_name'`
- `OBJ_INIT_PARAMS = 'obj_init_params'`
- `CLS_MODULE = 'cls_module'`
- `CLS_FILE = 'cls_file'`

##### 📌 `class RedisKeys`
*Line: 176*

**Public Methods (7):**
- `def gen_funboost_apscheduler_redis_lock_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_hearbeat_queue__dict_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_hearbeat_server__dict_key_by_ip(ip)` `staticmethod`
- `def gen_funboost_queue_time_series_data_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_redis_apscheduler_jobs_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_redis_apscheduler_run_times_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_project_name_key(project_name)` `staticmethod`

**Class Variables (12):**
- `REDIS_KEY_PAUSE_FLAG = 'funboost_pause_flag'`
- `REDIS_KEY_STOP_FLAG = 'funboost_stop_flag'`
- `QUEUE__MSG_COUNT_MAP = 'funboost_queue__msg_count_map'`
- `FUNBOOST_QUEUE__CONSUMER_PARAMS = 'funboost_queue__consumer_parmas'`
- `FUNBOOST_QUEUE__RUN_COUNT_MAP = 'funboost_queue__run_count_map'`
- `FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP = 'funboost_queue__run_fail_count_map'`
- `FUNBOOST_ALL_QUEUE_NAMES = 'funboost_all_queue_names'`
- `FUNBOOST_ALL_IPS = 'funboost_all_ips'`
- `FUNBOOST_ALL_PROJECT_NAMES = 'funboost_all_project_names'`
- `FUNBOOST_LAST_GET_QUEUES_PARAMS_AND_ACTIVE_CONSUMERS_AND_REPORT__UUID_TS = 'funboost_last_get_queues_params_and_active_consumers_and_report__uuid_ts'`
- `FUNBOOST_HEARTBEAT_QUEUE__DICT_PREFIX = 'funboost_hearbeat_queue__dict:'`
- `FUNBOOST_HEARTBEAT_SERVER__DICT_PREFIX = 'funboost_hearbeat_server__dict:'`

##### 📌 `class ConsumingFuncInputParamsCheckerField`
*Line: 224*

**Class Variables (6):**
- `is_manual_func_input_params = 'is_manual_func_input_params'`
- `all_arg_name_list = 'all_arg_name_list'`
- `must_arg_name_list = 'must_arg_name_list'`
- `optional_arg_name_list = 'optional_arg_name_list'`
- `func_name = 'func_name'`
- `func_position = 'func_position'`

##### 📌 `class MongoDbName`
*Line: 233*

**Class Variables (2):**
- `TASK_STATUS_DB = 'funboost_task_status'`
- `MONGOMQ_DB = 'funboost_mongomq'`

##### 📌 `class StrConst`
*Line: 237*

**Class Variables (1):**
- `BOOSTER_REGISTRY_NAME_DEFAULT = 'booster_registry_default'`

##### 📌 `class EnvConst`
*Line: 240*

**Class Variables (2):**
- `FUNBOOST_FAAS_CARE_PROJECT_NAME = 'funboost.faas.care_project_name'`
- `FUNBOOST_FAAS_IS_USE_LOCAL_BOOSTER = 'funboost.faas.is_use_local_booster'`


---




### 📄 Python File Metadata: `funboost/timing_job/timing_push.py`

#### 📦 Imports

- `from funboost.utils import redis_manager`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.booster import Booster`
- `from apscheduler.jobstores.redis import RedisJobStore`
- `from funboost.timing_job.timing_job_base import funboost_aps_scheduler`
- `from funboost.timing_job.timing_job_base import undefined`
- `from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from apscheduler.schedulers.base import BaseScheduler`
- `from funboost.constant import RedisKeys`
- `from funboost import boost`
- `from funboost import BrokerEnum`
- `from funboost import ctrl_c_recv`
- `from funboost import BoosterParams`
- `from funboost import ApsJobAdder`

#### 🏛️ Classes (1)

##### 📌 `class ApsJobAdder`
*Line: 11*

**Docstring:**
`````
20250116新增加的统一的新增定时任务的方式，推荐这种方式。
用户不用像之前再去关心使用哪个apscheduler对象去添加定时任务了。

例如 add_numbers 是@boost装饰的消费函数
ApsJobAdder(add_numbers,job_store_kind='memory').add_push_job(
    args=(1, 2),
    trigger='date',  # 使用日期触发器
    run_date='2025-01-16 18:23:50',  # 设置运行时间
    # id='add_numbers_job'  # 任务ID
)
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, booster: Booster, job_store_kind: str = 'memory', is_auto_start = True, is_auto_paused = False)`
  - **Docstring:**
  `````
  Initialize the ApsJobAdder.
  
  :param booster: A Booster object representing the function to be scheduled.
  :param job_store_kind: The type of job store to use. Default is 'memory'.
                         Can be 'memory' or 'redis'.
  `````
  - **Parameters:**
    - `self`
    - `booster: Booster`
    - `job_store_kind: str = 'memory'`
    - `is_auto_start = True`
    - `is_auto_paused = False`

**Public Methods (3):**
- `def get_funboost_redis_apscheduler(cls, queue_name)` `classmethod`
  - **Docstring:**
  `````
  每个队列名字的定时任务有自己单独的 aspchedule r定时器,
  每隔定时器用不同的redis jobstore的 jobs_key 和 run_times_key，防止互相干扰和取出不属于自己的任务.
  如果所有函数使用同一个定时器和一个jobs_key ,当用户只想运行f1定时任务,如果用户把f2删了,或者不需要运行f2定时任务,那就报错或者不方便.
  `````
- `def get_aps_obj(cls, queue_name, job_store_kind)` `classmethod`
- `def add_push_job(self, trigger = None, args = None, kwargs = None, id = None, name = None, misfire_grace_time = undefined, coalesce = undefined, max_instances = undefined, next_run_time = undefined, jobstore = 'default', executor = 'default', replace_existing = False, **trigger_args)`
  - **Docstring:**
  `````
  1. 这里的入参都是和apscheduler的add_job的入参一样的，funboost作者没有创造新的入参。
  但是官方apscheduler的入参第一个入参是函数，
  funboost的ApsJobAdder对象.add_push_job入参去掉了函数，因为类的实例化时候会把函数传进来，不需要再麻烦用户一次了。
  
  
  2. add_push_job目的是 定时运行 消费函数.push方法发布消息到消费队列， 而不是 定时直接运行 消费函数自身。
  
  相当于 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....)
  那为什么 不直接使用 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....) 呢？因为 消费函数.push是实例方法，
  如果redis作为 jobstore， 消费函数.push 会报错，因为 消费函数.push 是实例方法，不能被序列化。只有普通函数和静态方法才能被序列化。
  所以开发了一个 add_push_job方法， 里面再去用 add_job， 使用 push_fun_params_to_broker 这个普通函数作为 add_job 的第一个入参，
  这个普通函数里面再去调用 消费函数.push 方法， 相当于是曲线救国避免 aps_obj.add_job(消费函数.push 不可序列化问题。
  
  
  3. 用户也可以自己定义一个普通函数my_push，你这个普通函数my_push 里面去调用消费函数.push方法；然后使用 aps_obj.add_job 使用你自己定义的这个my_push作为第一个入参。
  这种方式更容易你去理解，和apscheduler 官方库的原生写法一模一样。 但是不如 add_push_job 方便，因为 需要你亲自给每个消费函数分别定义一个普通函数my_push。
  `````

**Properties (1):**
- `@property aps_obj -> BaseScheduler`

**Class Variables (1):**
- `queue__redis_aps_map = {}`

#### 🔧 Public Functions (1)

- `def sum_two_numbers(x, y)` `BoosterParams(queue_name='sum_queue3', broker_kind=BrokerEnum.REDIS)`
  - *Line: 125*


---




### 📄 Python File Metadata: `funboost/funboost_config_deafult.py`

#### 📦 Imports

- `import logging`
- `from pathlib import Path`
- `from funboost.utils.simple_data_class import DataClassBase`
- `from nb_log import nb_log_config_default`

#### 🏛️ Classes (2)

##### 📌 `class BrokerConnConfig(DataClassBase)`
*Line: 21*

**Docstring:**
`````
中间件连接配置
此文件按需修改，例如你使用redis中间件作为消息队列，可以不用管rabbitmq mongodb kafka啥的配置。
但有3个功能例外，如果你需要使用rpc模式或者分布式控频或者任务过滤功能，无论设置使用何种消息队列中间件都需要把redis连接配置好，
如果@boost装饰器设置is_using_rpc_mode为True或者 is_using_distributed_frequency_control为True或do_task_filtering=True则需要把redis连接配置好，默认是False不强迫用户安装redis。
`````

**Class Variables (40):**
- `MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'`
- `RABBITMQ_USER = 'rabbitmq_user'`
- `RABBITMQ_PASS = 'rabbitmq_pass'`
- `RABBITMQ_HOST = '127.0.0.1'`
- `RABBITMQ_PORT = 5672`
- `RABBITMQ_VIRTUAL_HOST = ''`
- `RABBITMQ_URL = f'amqp://{RABBITMQ_USER}:{RABBITMQ_PASS}@{RABBITMQ_HOST}:{RABBITMQ_PORT}/{RABBITMQ_VIRTUAL_HOST}'`
- `REDIS_HOST = '127.0.0.1'`
- `REDIS_USERNAME = ''`
- `REDIS_PASSWORD = ''`
- `REDIS_PORT = 6379`
- `REDIS_DB = 7`
- `REDIS_DB_FILTER_AND_RPC_RESULT = 8`
- `REDIS_SSL = False`
- `REDIS_URL = f"{('rediss' if REDIS_SSL else 'redis')}://{REDIS_USERNAME}:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}"`
- `NSQD_TCP_ADDRESSES = ['127.0.0.1:4150']`
- `NSQD_HTTP_CLIENT_HOST = '127.0.0.1'`
- `NSQD_HTTP_CLIENT_PORT = 4151`
- `KAFKA_BOOTSTRAP_SERVERS = ['127.0.0.1:9092']`
- `KFFKA_SASL_CONFIG = {'bootstrap_servers': KAFKA_BOOTSTRAP_SERVERS, 'sasl_plain_username': '', 'sasl_plain_password': '', 'sasl_mechanism': 'SCRAM-SHA-256', 'security_protocol': 'SASL_PLAINTEXT'}`
- `SQLACHEMY_ENGINE_URL = 'sqlite:////sqlachemy_queues/queues.db'`
- `MYSQL_HOST = '127.0.0.1'`
- `MYSQL_PORT = 3306`
- `MYSQL_USER = 'root'`
- `MYSQL_PASSWORD = '123456'`
- `MYSQL_DATABASE = 'testdb6'`
- `SQLLITE_QUEUES_PATH = '/sqllite_queues'`
- `TXT_FILE_PATH = Path(__file__).parent / 'txt_queues'`
- `ROCKETMQ_NAMESRV_ADDR = '192.168.199.202:9876'`
- `MQTT_HOST = '127.0.0.1'`
- `MQTT_TCP_PORT = 1883`
- `HTTPSQS_HOST = '127.0.0.1'`
- `HTTPSQS_PORT = 1218`
- `HTTPSQS_AUTH = '123456'`
- `NATS_URL = 'nats://192.168.6.134:4222'`
- `KOMBU_URL = 'redis://127.0.0.1:6379/9'`
- `CELERY_BROKER_URL = 'redis://127.0.0.1:6379/12'`
- `CELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/13'`
- `DRAMATIQ_URL = RABBITMQ_URL`
- `PULSAR_URL = 'pulsar://192.168.70.128:6650'`

##### 📌 `class FunboostCommonConfig(DataClassBase)`
*Line: 96*

**Class Variables (5):**
- `NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = logging.Formatter(f'%(asctime)s-({nb_log_config_default.computer_ip},{nb_log_config_default.computer_name})-[p%(process)d_t%(thread)d] - %(name)s - "%(filename)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(task_id)s - %(message)s', '%Y-%m-%d %H:%M:%S')`
- `TIMEZONE = 'Asia/Shanghai'`
- `SHOW_HOW_FUNBOOST_CONFIG_SETTINGS = True`
- `FUNBOOST_PROMPT_LOG_LEVEL = logging.DEBUG`
- `KEEPALIVETIMETHREAD_LOG_LEVEL = logging.DEBUG`


---




### 📄 Python File Metadata: `funboost/core/current_task.py`

#### 📝 Module Docstring

`````
fct 是 funboost current task 的简写，就是当前任务的意思。能同时兼容threading和asyncio隔离。

fct用法例子 
'''
from funboost import fct 

在消费函数内部能知道自己的takid，queue_name 等等。
print(fct.function_result_status.get_status_dict())
print(fct.function_result_status.task_id)
print(fct.run_times)
print(fct.full_msg)
'''
`````

#### 📦 Imports

- `import typing`
- `import contextvars`
- `from dataclasses import dataclass`
- `import logging`
- `import threading`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`

#### 🏛️ Classes (3)

##### 📌 `class FctContext`
*Line: 28*

**Docstring:**
`````
fct 是 funboost current task 的简写
`````

**Class Variables (2):**
- `function_result_status: FunctionResultStatus`
- `logger: logging.Logger`

##### 📌 `class _FctProxy`
*Line: 50*

**Docstring:**
`````
fct 代理类，通过 contextvars 自动获取当前线程/协程的上下文。
可以直接导入这个 fct，不需要手动写 fct = funboost_current_task() 了。
直接 from funboost import fct 就完了。
funboost 的 fct 相当于 flask 的 request 那种对象，自动线程/协程级别隔离，多个线程不会互相干扰。


fct 比直接 get_fct_context 好用一点点，fct相当于把FctContext对象的一级属性的function_result_status中的很多最重要二级属性直接提升作为一级属性了。
`````

**Properties (7):**
- `@property fct_context -> FctContext`
- `@property logger -> logging.Logger`
- `@property function_params -> dict`
- `@property full_msg -> dict`
- `@property function_result_status -> FunctionResultStatus`
- `@property task_id -> str`
- `@property queue_name -> str`

##### 📌 `class FctContextThread(threading.Thread)`
*Line: 118*

**Docstring:**
`````
这个类自动把当前线程的 funboost 上下文自动传递给新开的线程。
由于 contextvars 不会自动跨线程传递，只能跨协程自动传递，如果想跨线程自动传递，需要手动复制上下文。


如果没有这个基类，那么需要 手动复制上下文，然后让线程运行 ctx.run(worker) 而不是直接运行 worker： 
# 1. 显式捕获当前上下文
ctx = contextvars.copy_context()
# 2. 让线程运行 ctx.run(worker) 而不是直接运行 worker
# 这样 worker 就会在 ctx 的上下文中执行
t = threading.Thread(target=ctx.run, args=(worker,)) # 这是正解，传递上下文

# t = threading.Thread(target=worker,args=(,)) # 这是错误写法，不能自动传递上下文给子线程，
# 例如funboost的超时 kill功能，都是在另外单独的子线程去运行消费函数的，所以有时候需要传递给子线程。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, group = None, target = None, name = None, args = (), kwargs = None)`
  - **Parameters:**
    - `self`
    - `group = None`
    - `target = None`
    - `name = None`
    - `args = ()`
    - `kwargs = None`

**Public Methods (1):**
- `def run(self)`

#### 🔧 Public Functions (4)

- `def set_fct_context(fct_context: typing.Optional[FctContext])`
  - *Line: 40*
  - *设置当前线程/协程的 FctContext*

- `def get_fct_context() -> FctContext`
  - *Line: 45*
  - *获取当前线程/协程的 FctContext*

- `def funboost_current_task() -> _FctProxy`
  - *Line: 97*
  - **Docstring:**
  `````
  这个是兼容老的funboost_current_task() 函数，现在直接用 fct 就行了。
  
  获取当前任务上下文代理对象。
  由于 contextvars 同时支持多线程和异步协程，这里直接返回 fct 代理对象即可。
  `````

- `def get_current_taskid() -> str`
  - *Line: 107*
  - *获取当前任务的 task_id*


---




### 📄 Python File Metadata: `funboost/core/cli/discovery_boosters.py`

#### 📝 Module Docstring

`````
【⚠️ 安全警示 & 最佳实践】

1. 关于 BoosterDiscovery 自动扫描的风险提示
-------------------------------------------------------
BoosterDiscovery(....).auto_discovery() 请务必谨慎使用，强烈建议实例化时传入精确的过滤参数。

原因：
    部分开发者的编程习惯可能不严谨，对于包含执行动作的脚本，未添加 `if __name__ == '__main__':` 保护，
    或者不理解 `__main__` 的作用。Python 的 import 机制意味着“导入即执行模块顶层代码”。

危险场景假设：
    假设项目中存在一个临时的脏数据清理脚本 `my_temp_dangerous_delete_mysql_script.py`：

    ```python
    # ❌ 危险写法：写在模块顶层，不在函数内，也无 main 保护
    import db_client
    db_client.execute("DROP TABLE users") 
    ```

后果：
    如果你使用了无限制的 `auto_discovery()`，即使项目上线2年后，一旦扫描并 import 到这个脚本，
    数据库表会在瞬间被删除。这绝对是生产事故级别的灾难。

✅ 正确用法（精确传参）：
    BoosterDiscovery(
        project_root_path='/path/to/your_project', 
        booster_dirs=['your_booster_dir'],
        max_depth=1,
        py_file_re_str='tasks'  # 强烈建议：只扫描包含 'tasks' 的文件，避开临时脚本
    ).auto_discovery()


2. 为什么推荐“显式 Import”而非“自动扫描”？BoosterDiscovery不是funboost的必需品！
-------------------------------------------------------
其实不建议过度依赖 `auto_discovery()`，更推荐的最佳实践是：
👉 手动明确 import 包含 @boost 的模块。需要用到哪些消费函数，就导入哪些模块。

Funboost vs Celery 的架构差异：
    * Funboost：
      没有中央 `app` 实例，不需要像 Celery 那样有一个单独的 `celery_app.py` 模块。
      架构上天然不存在“互相依赖导入”的死结。因此，要用什么消费函数，直接导入即可，简单直观。

    * Celery：
      必须手写 `includes` 配置或调用 `autodiscover_tasks()`。
      根本原因是：Celery 的 `xx_tasks.py` 需要导入 `celery_app.py` 中的 `app` 对象；
      而 `celery worker` 启动 `app` 时又需要导入 `xx_tasks.py` 来注册任务。
      这种设计导致双方陷入“循环导入”的死结，迫使 Celery 发明了一套复杂的导入机制，
      也让新手在规划目录结构时小心翼翼、非常纠结。
`````

#### 📦 Imports

- `import re`
- `import sys`
- `import typing`
- `from os import PathLike`
- `from pathlib import Path`
- `import importlib.util`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.utils.decorators import flyweight`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`

#### 🏛️ Classes (1)

##### 📌 `class BoosterDiscovery(FunboostFileLoggerMixin)`
*Line: 64*

**🔧 Constructor (`__init__`):**
- `def __init__(self, project_root_path: typing.Union[PathLike, str], booster_dirs: typing.List[typing.Union[PathLike, str]], max_depth = 1, py_file_re_str: str = None)`
  - **Docstring:**
  `````
  :param project_root_path 项目根目录
  :param booster_dirs: @boost装饰器函数所在的模块的文件夹,不用包含项目根目录长路径
  :param max_depth: 查找多少深层级子目录
  :param py_file_re_str: 文件名匹配过滤. 例如你所有的消费函数都在xxx_task.py yyy_task.py这样的,  你可以传参 task.py , 避免自动import了不需要导入的模块
  
  BoosterDiscovery(....).auto_discovery() 需要谨慎使用，谨慎传参，原因见上面模块注释。
  `````
  - **Parameters:**
    - `self`
    - `project_root_path: typing.Union[PathLike, str]`
    - `booster_dirs: typing.List[typing.Union[PathLike, str]]`
    - `max_depth = 1`
    - `py_file_re_str: str = None`

**Public Methods (2):**
- `def get_py_files_recursively(self, current_folder_path: Path, current_depth = 0)`
  - *先找到所有py文件*
- `def auto_discovery(self)`
  - **Docstring:**
  `````
  把所有py文件自动执行import,主要是把 所有的@boost函数装饰器注册到 pid_queue_name__booster_map 中
  这个auto_discovery方法最好放到main里面,如果要扫描自身文件夹,没写正则排除文件本身,会无限懵逼死循环导入,无无限懵逼死循环导入
  `````


---




### 📄 Python File Metadata: `funboost/core/broker_kind__exclusive_config_default_define.py`

#### 📝 Module Docstring

`````
这个文件决定了，每种broker对应的能额外传递哪些独特特殊的中间件配置，
从BoosterParams 的 broker_exclusive_config 入参中传递一个字典
`````

#### 📦 Imports

- `from logging import Logger`
- `from funboost.constant import BrokerEnum`

#### 🔧 Public Functions (2)

- `def register_broker_exclusive_config_default(broker_kind: str, broker_exclusive_config_default: dict)`
  - *Line: 14*

- `def generate_broker_exclusive_config(broker_kind: str, user_broker_exclusive_config: dict, logger: Logger)`
  - *Line: 21*


---




### 📄 Python File Metadata: `funboost/core/msg_result_getter.py`

#### 📦 Imports

- `import asyncio`
- `import threading`
- `import time`
- `import typing`
- `import json`
- `from funboost.constant import MongoDbName`
- `from funboost.core.exceptions import FunboostWaitRpcResultTimeout`
- `from funboost.core.exceptions import FunboostRpcResultError`
- `from funboost.core.exceptions import HasNotAsyncResult`
- `from funboost.utils.mongo_util import MongoMixin`
- `from funboost.concurrent_pool import CustomThreadPoolExecutor`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPoolMinWorkers0`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.redis_manager import AioRedisMixin`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`

#### 🏛️ Classes (4)

##### 📌 `class AsyncResult(RedisMixin)`
*Line: 41*

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id, timeout = 1800)`
  - **Parameters:**
    - `self`
    - `task_id`
    - `timeout = 1800`

**Public Methods (8):**
- `def callback_run_executor(self, thread_pool_executor)` `callback_run_executor.setter`
  - **Docstring:**
  `````
  用户可以 async_result.callback_run_executor = 你自己的线程池
  thread_pool_executor 用户可以传递 FlexibleThreadPool或者 ThreadPoolExecutorShrinkAble 或者官方的 concurrent.futures.ThreadPoolExecutor 类型的对象都可以，任意线程池只要实现了submit方法即可。
  :param thread_pool_executor:
  :return:
  `````
- `def set_timeout(self, timeout = 1800)`
- `def is_pending(self)`
- `def get(self)`
- `def is_success(self)`
- `def set_callback(self, callback_func: typing.Callable)`
  - **Docstring:**
  `````
  :param callback_func: 函数结果回调函数，使回调函数自动在线程池中并发运行。
  :return:
  `````
- `def wait_rpc_data_or_raise(self, raise_exception: bool = True) -> FunctionResultStatus`
- `def batch_wait_rpc_data_or_raise(cls, r_list: typing.List['AsyncResult'], raise_exception: bool = True) -> typing.List[FunctionResultStatus]` `classmethod`

**Properties (4):**
- `@property callback_run_executor`
- `@property status_and_result`
- `@property status_and_result_obj -> FunctionResultStatus`
- `@property result`

**Class Variables (2):**
- `default_callback_run_executor = FlexibleThreadPoolMinWorkers0(200, work_queue_maxsize=50)`
- `rpc_data = status_and_result_obj`

##### 📌 `class AioAsyncResult(AioRedisMixin)`
*Line: 144*

**Docstring:**
`````
这个是可以用于asyncio的语法环境中。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id, timeout = 1800)`
  - **Parameters:**
    - `self`
    - `task_id`
    - `timeout = 1800`

**Public Methods (7):**
- `def set_timeout(self, timeout = 1800)`
- `async def is_pending(self)`
- `async def get(self)`
- `async def is_success(self)`
- `async def set_callback(self, aio_callback_func: typing.Callable)`
- `async def wait_rpc_data_or_raise(self, raise_exception: bool = True) -> FunctionResultStatus`
- `async def batch_wait_rpc_data_or_raise(cls, r_list: typing.List['AioAsyncResult'], raise_exception: bool = True) -> typing.List[FunctionResultStatus]` `classmethod`

**Properties (3):**
- `@property status_and_result`
- `@property status_and_result_obj -> FunctionResultStatus`
- `@property result`

**Class Variables (1):**
- `rpc_data = status_and_result_obj`

##### 📌 `class ResultFromMongo(MongoMixin)`
*Line: 249*

**Docstring:**
`````
以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果

async_result = add.push(i, i * 2)
task_id=async_result.task_id
print(ResultFromMongo(task_id).get_status_and_result())


print(ResultFromMongo('test_queue77h6_result:764a1ba2-14eb-49e2-9209-ac83fc5db1e8').get_status_and_result())
print(ResultFromMongo('test_queue77h6_result:5cdb4386-44cc-452f-97f4-9e5d2882a7c1').get_result())
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id: str)`
  - **Parameters:**
    - `self`
    - `task_id: str`

**Public Methods (3):**
- `def query_result(self)`
- `def get_status_and_result(self)`
- `def get_result(self)`
  - *以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果*

##### 📌 `class FutureStatusResult`
*Line: 283*

**Docstring:**
`````
用于sync_call模式的结果等待和通知
使用threading.Event实现同步等待
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, call_type: str)`
  - **Parameters:**
    - `self`
    - `call_type: str`

**Public Methods (4):**
- `def set_finish(self)`
  - *标记任务完成*
- `def wait_finish(self, rpc_timeout)`
  - *等待任务完成，带超时*
- `def set_staus_result_obj(self, staus_result_obj: FunctionResultStatus)`
  - *设置任务执行结果*
- `def get_staus_result_obj(self)`
  - *获取任务执行结果*


---




### 📄 Python File Metadata: `funboost/publishers/base_publisher.py`

#### 📦 Imports

- `from pathlib import Path`
- `import abc`
- `import copy`
- `import inspect`
- `import atexit`
- `import json`
- `import logging`
- `import multiprocessing`
- `import sys`
- `import threading`
- `import time`
- `import typing`
- `from functools import wraps`
- `from threading import Lock`
- `import nb_log`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.constant import ConstStrForClassMethod`
- `from funboost.constant import FunctionKind`
- `from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.helper_funs import MsgGenerater`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.loggers import LoggerLevelSetterMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import get_logger`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.msg_result_getter import AioAsyncResult`
- `from funboost.core.serialization import PickleHelper`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.task_id_logger import TaskIdLogger`
- `from funboost.utils import decorators`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from nb_libs.path_helper import PathHelper`
- `from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker`
- `import amqpstorm`
- `from pikav1.exceptions import AMQPError as PikaAMQPError`

#### 🏛️ Classes (1)

##### 📌 `class AbstractPublisher(LoggerLevelSetterMixin)`
*Line: 43*

**Docstring:**
`````
发布消息到消息队列
同步编程，最重要的方法有 push publish，
asyncio异步编程，最重要的方法有 aio_push aio_publish，

用法是 booster.push(1,y=2)
或者 booster.publish({"x":1,"y":2},task_options=TaskOptions(max_retry_times=3,...)) 
总结就是push更简单更魔法，publish是更强大更灵活，因为publish除了发布函数入参自身，还可以传递task_options参数。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, publisher_params: PublisherParams)`
  - **Parameters:**
    - `self`
    - `publisher_params: PublisherParams`

**Public Methods (12):**
- `def custom_init(self)`
- `def publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None)`
  - **Docstring:**
  `````
  :param msg:函数的入参字典或者字典转json。,例如消费函数是 def add(x,y)，你就发布 {"x":1,"y":2}
  :param task_id:可以指定task_id,也可以不指定就随机生产uuid
  :param task_options:优先级配置，消息可以携带优先级配置，覆盖boost的配置。
  :return: AsyncResult 对象，可以用于等待结果。 例如 status_and_result =  async_result.status_and_result 来等待返回结果。
  
  funboost 消息体中的extra字典，包含的key就是 TaskOptions 中声明的字段。例如 task_id, publish_time, publish_time_format 等。
  如果用户传递了 task_options，则以 task_options 为准。
  如果用户没有传递 task_options，则以消息体中的extra字典为准。
  如果最终还是没有 task_id, publish_time, publish_time_format 等字段，则自动生成。
  
  意味着如果你想传递 task_options 中的值，你的msg字典，
  第一种：你可以有一个extra字段，里面存放 task_options的各种字段，（适合跨编程语言）
  第二种：你可以通过publish方法的 task_options指定一个 TaskOptions pydantic模型对象 （适合python语言，因为能章节用funboost）
  
  如果是跨业务跨编程语言，由于java不能调用python funboost的publish方法:
  java可以这样通过http接口或者funboost.faas  来发布消息 {"user_id":123,"name":"张三","extra": {"task_id":"1234567890","max_retry_times":3}} 
  `````
- `def send_msg(self, msg: typing.Union[dict, str])`
  - *直接发送任意消息内容到消息队列,不生成辅助参数,无视函数入参名字,不校验入参个数和键名*
- `def push(self, *func_args, **func_kwargs)`
  - **Docstring:**
  `````
  简写，只支持传递消费函数的本身参数，不支持task_options参数。
  类似于 publish和push的关系类似 apply_async 和 delay的关系。前者更强大，后者更简略。
  
  例如消费函数是
  def add(x,y):
      print(x+y)
  
  publish({"x":1,'y':2}) 和 push(1,2)是等效的。但前者可以传递task_options参数。后者只能穿add函数所接受的入参。
  :param func_args:
  :param func_kwargs:
  :return:
  `````
- `def sync_call(self, msg_dict: dict, is_return_rpc_data_obj = True) -> typing.Union[dict, FunctionResultStatus]`
  - *仅有部分中间件支持同步调用并阻塞等待返回结果,不依赖AsyncResult + redis作为rpc，例如 http grpc 等*
- `def clear(self)` `abc.abstractmethod`
- `def get_message_count(self)` `abc.abstractmethod`
- `def close(self)` `abc.abstractmethod`
- `async def aio_push(self, *func_args, **func_kwargs) -> AioAsyncResult`
  - **Docstring:**
  `````
  asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
  但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push
  `````
- `async def aio_publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None) -> AioAsyncResult`
  - **Docstring:**
  `````
  asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
  但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push
  `````
- `def check_func_msg_dict(self, msg_dict: dict)`
- `def check_func_input_params(self, *args, **kwargs)`
  - **Docstring:**
  `````
  校验 push 风格的参数: f.check_params(1, y=2)
  利用框架启动时已经解析好的 final_func_input_params_info 进行参数映射和校验。
  :param args: 位置参数
  :param kwargs: 关键字参数
  :return: 校验通过返回 True，失败抛出异常
  `````

**Properties (1):**
- `@property final_func_input_params_info`

**Class Variables (1):**
- `delay = push`

#### 🔧 Public Functions (1)

- `def deco_mq_conn_error(f)`
  - *Line: 364*


---




### 📄 Python File Metadata: `funboost/consumers/base_consumer.py`

#### 📝 Module Docstring

`````
所有中间件类型消费者的抽象基类。使实现不同中间件的消费者尽可能代码少。
整个流程最难的都在这里面。因为要实现多种并发模型，和对函数施加20多种运行控制方式，所以代码非常长。

框架做主要的功能都是在这个文件里面实现的.
`````

#### 📦 Imports

- `import functools`
- `import sys`
- `import typing`
- `import abc`
- `import copy`
- `from apscheduler.jobstores.memory import MemoryJobStore`
- `from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config`
- `from funboost.core.funboost_time import FunboostTime`
- `from pathlib import Path`
- `import datetime`
- `import pytz`
- `import json`
- `import logging`
- `import atexit`
- `import os`
- `import uuid`
- `import time`
- `import traceback`
- `import inspect`
- `from functools import wraps`
- `import threading`
- `from threading import Lock`
- `import asyncio`
- `import nb_log`
- `from funboost.core.current_task import FctContext`
- `from funboost.core.current_task import set_fct_context`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BaseJsonAbleModel`
- `from funboost.core.serialization import PickleHelper`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.task_id_logger import TaskIdLogger`
- `from funboost.constant import FunctionKind`
- `from nb_libs.path_helper import PathHelper`
- `from nb_log import get_logger`
- `from nb_log import LoggerLevelSetterMixin`
- `from nb_log import LogManager`
- `from nb_log import is_main_process`
- `from nb_log import nb_log_config_default`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import logger_prompt`
- `from apscheduler.jobstores.redis import RedisJobStore`
- `from apscheduler.executors.pool import ThreadPoolExecutor as ApschedulerThreadPoolExecutor`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.concurrent_pool.single_thread_executor import SoloExecutor`
- `from funboost.core.function_result_status_saver import ResultPersistenceHelper`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.function_result_status_saver import RunStatus`
- `from funboost.core.helper_funs import delete_keys_and_return_new_dict`
- `from funboost.core.helper_funs import get_publish_time`
- `from funboost.core.helper_funs import MsgGenerater`
- `from funboost.concurrent_pool.async_helper import get_or_create_event_loop`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.concurrent_pool.async_pool_executor import AsyncPoolExecutor`
- `from funboost.concurrent_pool.bounded_threadpoolexcutor import BoundedThreadPoolExecutor`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.func_timeout import dafunc`
- `from funboost.concurrent_pool.custom_threadpool_executor import check_not_monkey`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.flexible_thread_pool import sync_or_async_fun_deco`
- `from funboost.consumers.redis_filter import RedisFilter`
- `from funboost.consumers.redis_filter import RedisImpermanencyFilter`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.utils import decorators`
- `from funboost.utils import time_util`
- `from funboost.utils import redis_manager`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConstStrForClassMethod`
- `from funboost.constant import RedisKeys`
- `from funboost.core import kill_remote_task`
- `from funboost.core.exceptions import ExceptionForRequeue`
- `from funboost.core.exceptions import ExceptionForPushToDlxqueue`
- `from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker`
- `from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`
- `from funboost.timing_job import FsdfBackgroundScheduler`
- `from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import gevent_timeout_deco`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import get_gevent_pool_executor`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import evenlet_timeout_deco`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import get_eventlet_pool_executor`

#### 🏛️ Classes (5)

##### 📌 `class GlobalVars`
*Line: 88*

**Class Variables (2):**
- `global_concurrent_mode = None`
- `has_start_a_consumer_flag = False`

##### 📌 `class AbstractConsumer(LoggerLevelSetterMixin)`
*Line: 94*

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumer_params: BoosterParams)`
  - **Docstring:**
  `````
          
  `````
  - **Parameters:**
    - `self`
    - `consumer_params: BoosterParams`

**Public Methods (12):**
- `def bulid_a_new_publisher_of_same_queue(self)`
- `def join_dispatch_task_thread(cls)` `classmethod`
  - *:return:*
- `def custom_init(self)`
- `def keep_circulating(self, time_sleep = 0.001, exit_if_function_run_sucsess = False, is_display_detail_exception = True, block = True, daemon = False)`
  - **Docstring:**
  `````
  间隔一段时间，一直循环运行某个方法的装饰器
  :param time_sleep :循环的间隔时间
  :param is_display_detail_exception
  :param exit_if_function_run_sucsess :如果成功了就退出循环
  :param block:是否阻塞在当前主线程运行。
  :param daemon:是否守护线程
  `````
- `def start_consuming_message(self)`
- `def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`
- `async def aio_user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`
- `def check_heartbeat_and_message_count(self)`
- `def pause_consume(self)`
  - *从远程机器可以设置队列为暂停消费状态，funboost框架会自动停止消费，此功能需要配置好redis*
- `def continue_consume(self)`
  - *从远程机器可以设置队列为暂停消费状态，funboost框架会自动继续消费，此功能需要配置好redis*
- `def wait_for_possible_has_finish_all_tasks(self, minutes: int = 3)`
  - **Docstring:**
  `````
  判断队列所有任务是否消费完成了。
  由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
  一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
  :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成，为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
  :return:
  `````
- `def clear_filter_tasks(self)`

**Properties (3):**
- `@property publisher_of_same_queue`
- `@property publisher_of_dlx_queue`
- `@property concurrent_pool`

**Class Variables (3):**
- `time_interval_for_check_do_not_run_time = 60`
- `BROKER_KIND = None`
- `logger_apscheduler = get_logger('push_for_apscheduler_use_database_store', log_filename='push_for_apscheduler_use_database_store.log')`

##### 📌 `class ConcurrentModeDispatcher(FunboostFileLoggerMixin)`
*Line: 1104*

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumerx: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `consumerx: AbstractConsumer`

**Public Methods (3):**
- `def check_all_concurrent_mode(self)`
- `def build_pool(self)`
- `def schedulal_task_with_no_block(self)`

##### 📌 `class MetricCalculation`
*Line: 1210*

**🔧 Constructor (`__init__`):**
- `def __init__(self, conusmer: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `conusmer: AbstractConsumer`

**Public Methods (2):**
- `def cal(self, t_start_run_fun: float, current_function_result_status: FunctionResultStatus)`
- `def get_report_hearbeat_info(self) -> dict`

**Class Variables (1):**
- `UNIT_TIME_FOR_COUNT = 10`

##### 📌 `class DistributedConsumerStatistics(RedisMixin, FunboostFileLoggerMixin)`
*Line: 1293*

**Docstring:**
`````
为了兼容模拟mq的中间件（例如redis，他没有实现amqp协议，redis的list结构和真mq差远了），获取一个队列有几个连接活跃消费者数量。
分布式环境中的消费者统计。主要目的有3点

1、统计活跃消费者数量用于分布式控频。
    获取分布式的消费者数量后，用于分布式qps控频。如果不获取全环境中的消费者数量，则只能用于当前进程中的消费控频。
    即使只有一台机器，例如把xx.py启动3次，xx.py的consumer设置qps为10，如果不使用分布式控频，会1秒钟最终运行30次函数而不是10次。

2、记录分布式环境中的活跃消费者的所有消费者 id，如果消费者id不在此里面说明已掉线或关闭，消息可以重新分发，用于不支持服务端天然消费确认的中间件。

3、从redis中获取停止和暂停状态，以便支持在别的地方发送命令停止或者暂停消费。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumer: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `consumer: AbstractConsumer`

**Public Methods (3):**
- `def run(self)`
- `def send_heartbeat(self)`
- `def get_queue_heartbeat_ids(self, without_time: bool)`

**Class Variables (3):**
- `SHOW_CONSUMER_NUM_INTERVAL = 600`
- `HEARBEAT_EXPIRE_SECOND = 25`
- `SEND_HEARTBEAT_INTERVAL = 10`

#### 🔧 Public Functions (1)

- `def wait_for_possible_has_finish_all_tasks_by_conusmer_list(consumer_list: typing.List[AbstractConsumer], minutes: int = 3)`
  - *Line: 1195*
  - **Docstring:**
  `````
  判断多个消费者是否消费完成了。
  由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
  一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
  :param consumer_list: 多个消费者列表
  :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成。为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
  :return:
  
   
  `````


---




### 📄 Python File Metadata: `funboost/core/active_cousumer_info_getter.py`

#### 📝 Module Docstring

`````
此模块的功能非常适合拿来开发对funboost的监控面板，或者管理后台。
    - ActiveCousumerProcessInfoGetter  获取队列的活跃消费进程信息
    - QueuesConusmerParamsGetter  获取所有队列配置参数 和 运行信息
    - SingleQueueConusmerParamsGetter  获取单个队列配置参数 和 运行信息


下面3个python文件的web接口中，funboost.faas 主要就是使用了此模块的功能。
 



care_project_name 的作用是：
    - None : 关心所有redis中存储的队列信息
    - str : 只关心指定project_name的队列信息
   
`````

#### 📦 Imports

- `import json`
- `import threading`
- `import time`
- `import typing`
- `import uuid`
- `import os`
- `from funboost.factories.consumer_factory import ConsumerCacheProxy`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import nb_log_config_default`
- `from funboost.core.serialization import Serialization`
- `from funboost.constant import RedisKeys`
- `from funboost.core.booster import Booster`
- `from funboost.core.booster import BoosterRegistry`
- `from funboost.core.booster import booster_registry_default`
- `from funboost.core.booster import gen_pid_queue_name_key`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import BaseJsonAbleModel`
- `from funboost.core.function_result_status_saver import FunctionResultStatusPersistanceConfig`
- `from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator`
- `from funboost.core.exceptions import QueueNameNotExists`
- `from funboost.timing_job.timing_push import ApsJobAdder`
- `from funboost.constant import EnvConst`

#### 🏛️ Classes (5)

##### 📌 `class CareProjectNameEnv`
*Line: 43*

**Public Methods (2):**
- `def set(cls, care_project_name: str)` `classmethod`
- `def get(cls) -> typing.Optional[bool]` `classmethod`

**Class Variables (1):**
- `env_name = EnvConst.FUNBOOST_FAAS_CARE_PROJECT_NAME`

##### 📌 `class RedisReportInfoGetterMixin`
*Line: 60*

**Public Methods (4):**
- `def get_all_queue_names(self) -> list`
  - *获取所有队列名称，带30秒缓存（类级别缓存，所有实例共享）*
- `def get_queue_names_by_project_name(self, project_name: str) -> list`
  - *根据项目名称获取队列名称，带30秒缓存（类级别缓存，所有实例共享）*
- `def hmget_many_by_all_queue_names(self, key)`
- `def get_all_project_names(self)`

**Properties (2):**
- `@property all_queue_names`
- `@property project_name_queues`

**Class Variables (4):**
- `_cache_all_queue_names = None`
- `_cache_all_queue_names_ts = 0`
- `_cache_queue_names_by_project = {}`
- `_cache_ttl = 30`

##### 📌 `class ActiveCousumerProcessInfoGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 180*

**Docstring:**
`````
获取分布式环境中的消费进程信息。
使用这里面的4个方法需要相应函数的@boost装饰器设置 is_send_consumer_heartbeat_to_redis=True，这样会自动发送活跃心跳到redis。否则查询不到该函数的消费者进程信息。
要想使用消费者进程信息统计功能，用户无论使用何种消息队列中间件类型，用户都必须安装redis，并在 funboost_config.py 中配置好redis链接信息
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, care_project_name: typing.Optional[str] = None)`
  - **Parameters:**
    - `self`
    - `care_project_name: typing.Optional[str] = None`

**Public Methods (5):**
- `def get_all_hearbeat_info_by_queue_name(self, queue_name) -> typing.List[typing.Dict]`
  - **Docstring:**
  `````
  根据队列名查询有哪些活跃的消费者进程
  返回结果例子：
  [{
          "code_filename": "/codes/funboost/test_frame/my/test_consume.py",
          "computer_ip": "172.16.0.9",
          "computer_name": "VM_0_9_centos",
          "consumer_id": 140477437684048,
          "consumer_uuid": "79473629-b417-4115-b516-4365b3cdf383",
          "consuming_function": "f2",
          "hearbeat_datetime_str": "2021-12-27 19:22:04",
          "hearbeat_timestamp": 1640604124.4643965,
          "process_id": 9665,
          "queue_name": "test_queue72c",
          "start_datetime_str": "2021-12-27 19:21:24",
          "start_timestamp": 1640604084.0780013
      }, ...............]
  `````
- `def get_all_hearbeat_info_by_ip(self, ip = None) -> typing.List[typing.Dict]`
  - **Docstring:**
  `````
  根据机器的ip查询有哪些活跃的消费者进程，ip不传参就查本机ip使用funboost框架运行了哪些消费进程，传参则查询任意机器的消费者进程信息。
  返回结果的格式和上面的 get_all_hearbeat_dict_by_queue_name 方法相同。
  `````
- `def get_all_ips(self)`
- `def get_all_hearbeat_info_partition_by_queue_name(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]`
  - *获取所有队列对应的活跃消费者进程信息，按队列名划分,不需要传入队列名，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对*
- `def get_all_hearbeat_info_partition_by_ip(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]`
  - *获取所有机器ip对应的活跃消费者进程信息，按机器ip划分,不需要传入机器ip，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对*

##### 📌 `class QueuesConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 299*

**Docstring:**
`````
获取所有队列的运行信息，
方法 get_queues_params_and_active_consumers 返回信息最丰富
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, care_project_name: typing.Optional[str] = None)`
  - **Parameters:**
    - `self`
    - `care_project_name: typing.Optional[str] = None`

**Public Methods (7):**
- `def get_queues_params(self) -> dict`
- `def get_pause_flag(self)`
- `def get_msg_num(self, ignore_report_ts = False)`
- `def get_queues_history_run_count(self)`
- `def get_queues_history_run_fail_count(self)`
- `def get_queues_params_and_active_consumers(self)`
  - *获取所有队列的参数和活跃消费者*
- `def cycle_get_queues_params_and_active_consumers_and_report(self, daemon = False)`

##### 📌 `class SingleQueueConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 422*

**Docstring:**
`````
获取单个队列的运行信息，
方法 get_one_queue_params_and_active_consumers 返回信息最丰富
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: str, care_project_name: typing.Optional[str] = None, is_use_local_booster: bool = None)`
  - **Parameters:**
    - `self`
    - `queue_name: str`
    - `care_project_name: typing.Optional[str] = None`
    - `is_use_local_booster: bool = None`

**Public Methods (13):**
- `def get_one_queue_params(self) -> dict`
  - **Docstring:**
  `````
          类似于这样，就是booster_params的字符串json序列化
  
          ```json
          {
    "queue_name": "test_funboost_faas_queue2",
    "broker_kind": "REDIS",
    "project_name": "test_project1",
    "concurrent_mode": "threading",
    "concurrent_num": 50,
    "specify_concurrent_pool": null,
    "specify_async_loop": null,
    "is_auto_start_specify_async_loop_in_child_thread": true,
    "qps": null,
    "is_using_distributed_frequency_control": false,
    "is_send_consumer_heartbeat_to_redis": true,
    "max_retry_times": 3,
    "retry_interval": 0,
    "is_push_to_dlx_queue_when_retry_max_times": false,
    "consuming_function_decorator": null,
    "function_timeout": null,
    "is_support_remote_kill_task": false,
    "log_level": 10,
    "logger_prefix": "",
    "create_logger_file": true,
    "logger_name": "",
    "log_filename": null,
    "is_show_message_get_from_broker": false,
    "is_print_detail_exception": true,
    "publish_msg_log_use_full_msg": false,
    "msg_expire_seconds": null,
    "do_task_filtering": false,
    "task_filtering_expire_seconds": 0,
    "function_result_status_persistance_conf": {
      "is_save_status": false,
      "is_save_result": false,
      "expire_seconds": 604800,
      "is_use_bulk_insert": false
    },
    "user_custom_record_process_info_func": null,
    "is_using_rpc_mode": true,
    "rpc_result_expire_seconds": 1800,
    "rpc_timeout": 1800,
    "delay_task_apscheduler_jobstores_kind": "redis",
    "is_do_not_run_by_specify_time_effect": false,
    "do_not_run_by_specify_time": [
      "10:00:00",
      "22:00:00"
    ],
    "schedule_tasks_on_main_thread": false,
    "is_auto_start_consuming_message": false,
    "booster_group": "test_group1",
    "consuming_function": "<function sub at 0x00000272649BBA60>",
    "consuming_function_raw": "<function sub at 0x00000272649BBA60>",
    "consuming_function_name": "sub",
    "broker_exclusive_config": {
      "redis_bulk_push": 1,
      "pull_msg_batch_size": 100
    },
    "should_check_publish_func_params": true,
    "manual_func_input_params": {
      "is_manual_func_input_params": false,
      "must_arg_name_list": [],
      "optional_arg_name_list": []
    },
    "consumer_override_cls": null,
    "publisher_override_cls": null,
    "consuming_function_kind": "COMMON_FUNCTION",
    "user_options": {
      
    },
    "auto_generate_info": {
      "where_to_instantiate": "D:\codes\funboost\examples\example_faas\task_funs_dir\sub.py:5",
      "final_func_input_params_info": {
        "func_name": "sub",
        "func_position": "<function sub at 0x00000272649BBA60>",
        "is_manual_func_input_params": false,
        "all_arg_name_list": [
          "a",
          "b"
        ],
        "must_arg_name_list": [
          "a",
          "b"
        ],
        "optional_arg_name_list": []
      }
    }
  }
  
  
          ```
          
  `````
- `def get_one_queue_params_use_cache(self) -> dict`
- `def gen_booster_for_faas(self) -> Booster`
- `def gen_publisher_for_faas(self) -> Booster`
- `def generate_aps_job_adder(self, job_store_kind = 'redis', is_auto_start = True, is_auto_paused = True) -> ApsJobAdder`
- `def get_one_queue_pause_flag(self) -> int`
  - *返回队列的暂停状态，-1 表示队列不存在，0 表示队列未暂停，1 表示队列已暂停*
- `def get_one_queue_history_run_count(self) -> int`
- `def get_one_queue_history_run_fail_count(self) -> int`
- `def get_one_queue_msg_num(self, ignore_report_ts = False) -> int`
  - **Docstring:**
  `````
  从上报到redis的心跳信息中获取的消息数量，
  如果 ignore_report_ts 为 True 并且最近一次上报时间是很久之前的，消息数量就不准
  上报线程是随着消费一起自动运行的，如果没有启动消息，就会停止心跳信息上报。
  `````
- `def get_one_queue_msg_num_realtime(self) -> int`
  - *实时从broker获取的消息数量，*
- `def get_one_queue_params_and_active_consumers(self) -> dict`
- `def get_one_queue_time_series_data(self, start_ts = None, end_ts = None, curve_samples_count = None)`
- `def deprecate_queue(self)`
  - **Docstring:**
  `````
  废弃队列 - 从 Redis 中移除队列名
  1. 从 funboost_all_queue_names set 中移除
  2. 从 funboost.project_name:{project_name} set 中移除
  `````

**Class Variables (2):**
- `queue__booster_params_cache: dict = {}`
- `_lock_for_generate_publisher_booster = threading.Lock()`


---



## 🔗 funboost Some File Dependencies Analysis

以下是项目文件之间的依赖关系，帮助 AI 理解代码结构：

### 📊 Internal Dependencies Graph

`````
Core Files (imported by other files, sorted by import count):
  ◆ funboost/__init__.py (imported by 10 files)
  ◆ funboost/constant.py (imported by 9 files)
  ◆ funboost/core/func_params_model.py (imported by 5 files)
  ◆ funboost/funboost_config_deafult.py (imported by 4 files)
  ◆ funboost/core/booster.py (imported by 3 files)
  ◆ funboost/core/msg_result_getter.py (imported by 3 files)
  ◆ funboost/publishers/base_publisher.py (imported by 3 files)
  ◆ funboost/timing_job/timing_push.py (imported by 2 files)
  ◆ funboost/core/current_task.py (imported by 2 files)
  ◆ funboost/core/broker_kind__exclusive_config_default_define.py (imported by 2 files)

`````

### 📋 Detailed Dependencies

#### `funboost/__init__.py`

**Imports from project:**
- `funboost/constant.py`
- `funboost/consumers/base_consumer.py`
- `funboost/core/active_cousumer_info_getter.py`
- `funboost/core/booster.py`
- `funboost/core/cli/discovery_boosters.py`
- `funboost/core/current_task.py`
- `funboost/core/func_params_model.py`
- `funboost/core/msg_result_getter.py`
- `funboost/funboost_config_deafult.py`
- `funboost/publishers/base_publisher.py`
- `funboost/timing_job/timing_push.py`

**Imported by:**
- `funboost/consumers/base_consumer.py`
- `funboost/core/active_cousumer_info_getter.py`
- `funboost/core/booster.py`
- `funboost/core/cli/discovery_boosters.py`
- `funboost/core/current_task.py`
- `funboost/core/func_params_model.py`
- `funboost/core/msg_result_getter.py`
- `funboost/funboost_config_deafult.py`
- `funboost/publishers/base_publisher.py`
- `funboost/timing_job/timing_push.py`

#### `funboost/constant.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/consumers/base_consumer.py`
- `funboost/core/active_cousumer_info_getter.py`
- `funboost/core/booster.py`
- `funboost/core/broker_kind__exclusive_config_default_define.py`
- `funboost/core/func_params_model.py`
- `funboost/core/msg_result_getter.py`
- `funboost/publishers/base_publisher.py`
- `funboost/timing_job/timing_push.py`

#### `funboost/consumers/base_consumer.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`
- `funboost/core/broker_kind__exclusive_config_default_define.py`
- `funboost/core/current_task.py`
- `funboost/core/func_params_model.py`
- `funboost/funboost_config_deafult.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/core/booster.py`

#### `funboost/core/active_cousumer_info_getter.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`
- `funboost/core/booster.py`
- `funboost/core/func_params_model.py`
- `funboost/publishers/base_publisher.py`
- `funboost/timing_job/timing_push.py`

**Imported by:**
- `funboost/__init__.py`

#### `funboost/core/booster.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`
- `funboost/consumers/base_consumer.py`
- `funboost/core/func_params_model.py`
- `funboost/core/msg_result_getter.py`
- `funboost/publishers/base_publisher.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/core/active_cousumer_info_getter.py`
- `funboost/timing_job/timing_push.py`

#### `funboost/core/broker_kind__exclusive_config_default_define.py`

**Imports from project:**
- `funboost/constant.py`

**Imported by:**
- `funboost/consumers/base_consumer.py`
- `funboost/publishers/base_publisher.py`

#### `funboost/core/cli/discovery_boosters.py`

**Imports from project:**
- `funboost/__init__.py`

**Imported by:**
- `funboost/__init__.py`

#### `funboost/core/current_task.py`

**Imports from project:**
- `funboost/__init__.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/consumers/base_consumer.py`

#### `funboost/core/func_params_model.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/consumers/base_consumer.py`
- `funboost/core/active_cousumer_info_getter.py`
- `funboost/core/booster.py`
- `funboost/publishers/base_publisher.py`

#### `funboost/core/msg_result_getter.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/core/booster.py`
- `funboost/publishers/base_publisher.py`

#### `funboost/funboost_config_deafult.py`

**Imports from project:**
- `funboost/__init__.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/consumers/base_consumer.py`
- `funboost/publishers/base_publisher.py`
- `funboost/timing_job/timing_push.py`

#### `funboost/publishers/base_publisher.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`
- `funboost/core/broker_kind__exclusive_config_default_define.py`
- `funboost/core/func_params_model.py`
- `funboost/core/msg_result_getter.py`
- `funboost/funboost_config_deafult.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/core/active_cousumer_info_getter.py`
- `funboost/core/booster.py`

#### `funboost/timing_job/timing_push.py`

**Imports from project:**
- `funboost/__init__.py`
- `funboost/constant.py`
- `funboost/core/booster.py`
- `funboost/funboost_config_deafult.py`

**Imported by:**
- `funboost/__init__.py`
- `funboost/core/active_cousumer_info_getter.py`

### 📦 Third-party Dependencies

项目使用的第三方库：

- `amqpstorm`
- `apscheduler`
- `contextvars`
- `nb_libs`
- `nb_log`
- `pikav1`
- `pydantic`
- `pytz`
- ......以及更多的第三方库......


---
# markdown content namespace: funboost project summary 



- **`boost_spider` = `funboost` 的超跑引擎 + 一套为爬虫量身打造的瑞士军刀。所有仿scrapy api爬虫框架都还是处在变花样造一辆马车**

- `boost_spider` 是增加了3个爬虫常用类，RequestClient  和  SpiderResponse  和 DatasetSink, 由funboost 驱动调度和并发。


## 📋 funboost most core source files metadata (Entry Points)


以下是项目 funboost 最核心的入口文件的结构化元数据，帮助快速理解项目架构：



### the project funboost most core source code files as follows: 
- `boost_spider/__init__.py`
- `boost_spider/http/request_client.py`
- `boost_spider/sink/dataset_sink.py`


### 📄 Python File Metadata: `boost_spider/__init__.py`

#### 📝 Module Docstring

`````
boost_spider
是一款自由奔放写法的爬虫框架，无任何束缚，和用户手写平铺直叙的爬虫函数一样，
是横冲直撞的思维写的, 不需要callback回调解析方法, 不需要继承BaseSpider类, 没有BaseSpider类, 大开大合自由奔放.
只需要加上boost装饰器就可以自动加速并发，控制手段比传统爬虫框架多太多
`````

#### 📦 Imports

- `from boost_spider.http.request_client import RequestClient`
- `from boost_spider.sink.momgo_sink import MongoSink`
- `from boost_spider.sink.mysql_sink import MysqlSink`
- `from funboost import *`
- `import json`
- `import re`


---




### 📄 Python File Metadata: `boost_spider/http/request_client.py`

#### 📝 Module Docstring

`````
改版包装requests的Session类，主要使用的是代理模式
1、支持一键设多种代理ip
2、支持3种类型的cookie添加
3、支持长会话，保持cookie状态, ss = RequestClient() , 一直用这个ss对象就可以自动保持cookie了
4、支持一键设置requests请求重试次数，确保请求成功，默认重试一次。
5、记录下当天的请求到文件，方便统计，同时开放了日志级别设置参数，用于禁止日志。
6、从使用requests修改为使用RequstClient门槛很低，三方包的request方法和此类的方法入参和返回完全100%保持了一致。
7、支持多个代理厂商自动切换。需要将proxy_name设置为一个列表，指定多个代理厂商的名字。
8、支持继承 RequestClient 来增加使用各种代理的请求方法，新增加代理商后，将请求方法名字加到 PROXYNAME__REQUEST_METHED_MAP 中。
`````

#### 📦 Imports

- `import json`
- `import logging`
- `import typing`
- `from enum import Enum`
- `from functools import lru_cache`
- `from pathlib import Path`
- `import nb_log`
- `import copy`
- `import time`
- `from typing import Union`
- `import requests`
- `from requests.cookies import RequestsCookieJar`
- `import urllib3.exceptions`
- `from boost_spider.http.user_agent import rand_get_useragent`
- `from parsel import Selector`
- `import re`

#### 🏛️ Classes (3)

##### 📌 `class HttpStatusError(Exception)`
*Line: 35*

**🔧 Constructor (`__init__`):**
- `def __init__(self, http_status_code)`
  - **Parameters:**
    - `self`
    - `http_status_code`

##### 📌 `class SpiderResponse(requests.Response)`
*Line: 43*

**🔧 Constructor (`__init__`):**
- `def __init__(self, resp: requests.Response)`
  - **Parameters:**
    - `self`
    - `resp: requests.Response`

**Public Methods (4):**
- `def re_search(self, pattern, flags = 0)`
- `def re_findall(self, pattern, flags = 0)`
- `def xpath(self, query)`
- `def css(self, query)`

**Properties (3):**
- `@property selector -> Selector`
- `@property resp_dict -> typing.Dict`
- `@property text -> str`

**Class Variables (1):**
- `re_pattern_map = {}`

##### 📌 `class RequestClient`
*Line: 89*

**🔧 Constructor (`__init__`):**
- `def __init__(self, proxy_name_list = None, ua = None, default_use_pc_ua = True, is_change_ua_every_request = False, timeout: Union[tuple, float] = (30, 40), verify = False, allow_redirects = True, is_close_session = True, request_retry_times = 2, using_platfrom = '')`
  - **Docstring:**
  `````
  :param proxy_name_list: 轮流使用代理服务商名字，可设置为 None,'noproxy', 'kuai', 'abuyun', 'crawlera',为None不使用代理
  :param ua:  useragent，如果不设置就随机分配一个欺骗的
  :param is_change_ua_every_request: 为每次请求设置新的useragent
  :param timeout: 超时设置
  :param verify:  是否校验服务器证书
  :param allow_redirects
  :param is_close_session: 是否在请求后关闭会话，连续型的请求需要cookie保持的，请设置为False，并且一直使用RequestClient实例化后的对象
  :param logger_level:日志级别，10 20 30 40 50
  `````
  - **Parameters:**
    - `self`
    - `proxy_name_list = None`
    - `ua = None`
    - `default_use_pc_ua = True`
    - `is_change_ua_every_request = False`
    - `timeout: Union[tuple, float] = (30, 40)`
    - `verify = False`
    - `allow_redirects = True`
    - `is_close_session = True`
    - `request_retry_times = 2`
    - `using_platfrom = ''`

**Public Methods (9):**
- `def get_cookie_jar(self)`
  - *返回cookiejar*
- `def get_cookie_dict(self)`
  - *返回cookie字典*
- `def get_cookie_str(self)`
  - *返回cookie字典*
- `def add_cookies(self, cookies: Union[str, dict, RequestsCookieJar])`
  - **Docstring:**
  `````
  :param cookies: 浏览器复制的cookie字符串或字典类型或者CookieJar类型
  :return:
  `````
- `def request(self, method: str, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs) -> typing.Optional[SpiderResponse]`
  - **Docstring:**
  `````
  使用指定名字的代理请求,从_proxy_name读取,当请求出错时候轮流使用各种代理ip。
  :param method:
  :param url:
  :param verify:
  :param timeout:
  :param headers:
  :param cookies:
  :param kwargs:
  :param kwargs :可接受一切requests.request方法中的参数
  :return:
  `````
- `def get(self, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs)`
- `def post(self, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs)`
- `def close_session(self)`
- `def save_picture(self, url, pic_path, pic_file = None)`

**Class Variables (5):**
- `logger = request_logger`
- `PROXY_NOPROXY = 'noproxy'`
- `PROXY_ABUYUN = 'abuyun'`
- `PROXY_KUAI = 'kuai'`
- `PROXYNAME__REQUEST_METHED_MAP = {'noproxy': _request_with_no_proxy, 'abuyun': _request_with_abuyun_proxy, 'kuai': _request_with_kuai_proxy}`


---




### 📄 Python File Metadata: `boost_spider/sink/dataset_sink.py`

#### 📝 Module Docstring

`````
dataset 很适合保存一个字典到各种数据库 mysql postgre sqlite
`````

#### 📦 Imports

- `import dataset`

#### 🏛️ Classes (1)

##### 📌 `class DatasetSink`
*Line: 7*

**🔧 Constructor (`__init__`):**
- `def __init__(self, db_url)`
  - **Parameters:**
    - `self`
    - `db_url`

**Public Methods (2):**
- `def save(self, table_name: str, data: dict)`
- `def get_instance(cls, db_url)` `classmethod`

**Class Variables (2):**
- `_instances = {}`
- `_has__init_set = set()`


---



## 🔗 funboost Some File Dependencies Analysis

以下是项目文件之间的依赖关系，帮助 AI 理解代码结构：

### 📊 Internal Dependencies Graph

`````
Entry Points (not imported by other project files):
  ★ boost_spider/__init__.py
  ★ boost_spider/http/request_client.py
  ★ boost_spider/sink/dataset_sink.py

`````

### 📋 Detailed Dependencies


---
# markdown content namespace: funboost examples 


## funboost File Tree (relative dir: `examples`)


`````

└── examples
    ├── example_all_usage.py
    ├── example_easy.py
    └── example_faas
        ├── README.md
        ├── example_fastapi_faas.py
        ├── example_req_fastapi.py
        ├── example_req_timing_api.py
        ├── start_consume.py
        └── task_funs_dir
            ├── __init__.py
            ├── add.py
            ├── base_booster_params.py
            └── sub.py

`````

---


## funboost (relative dir: `examples`)  Included Files (total: 11 files)


- `examples/example_all_usage.py`

- `examples/example_easy.py`

- `examples/example_faas/example_fastapi_faas.py`

- `examples/example_faas/example_req_fastapi.py`

- `examples/example_faas/example_req_timing_api.py`

- `examples/example_faas/README.md`

- `examples/example_faas/start_consume.py`

- `examples/example_faas/task_funs_dir/add.py`

- `examples/example_faas/task_funs_dir/base_booster_params.py`

- `examples/example_faas/task_funs_dir/sub.py`

- `examples/example_faas/task_funs_dir/__init__.py`


---


--- **start of file: examples/example_all_usage.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_all_usage.py`

#### 📝 Module Docstring

`````
funboost 所有用法的使用， demo 例子 演示
这个文件集中演示了 funboost 的 90% 主要功能用法。
`````

#### 📦 Imports

- `import time`
- `import random`
- `import asyncio`
- `import datetime`
- `from funboost import boost`
- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `from funboost import ConcurrentModeEnum`
- `from funboost import TaskOptions`
- `from funboost import ApsJobAdder`
- `from funboost import ctrl_c_recv`
- `from funboost import fct`
- `from funboost import BoostersManager`
- `from funboost import AsyncResult`
- `from funboost import AioAsyncResult`

#### 🔧 Public Functions (11)

- `def task_basic(x, y)` `boost(BoosterParams(queue_name='demo_queue_basic', broker_kind=BrokerEnum.SQLITE_QUEUE, concurrent_num=2))`
  - *Line: 34*

- `def task_retry(n)` `boost(BoosterParams(queue_name='demo_queue_retry', broker_kind=BrokerEnum.MEMORY_QUEUE, max_retry_times=3, retry_interval=1, is_print_detail_exception=False))`
  - *Line: 51*

- `def task_qps(idx)` `boost(BoosterParams(queue_name='demo_queue_qps', broker_kind=BrokerEnum.MEMORY_QUEUE, qps=2))`
  - *Line: 67*

- `async def task_async(url)` `boost(BoosterParams(queue_name='demo_queue_async', broker_kind=BrokerEnum.MEMORY_QUEUE, concurrent_mode=ConcurrentModeEnum.ASYNC, concurrent_num=100, is_using_rpc_mode=True))`
  - *Line: 81*

- `def task_rpc(a, b)` `boost(BoosterParams(queue_name='demo_queue_rpc', broker_kind=BrokerEnum.MEMORY_QUEUE, is_using_rpc_mode=True, rpc_result_expire_seconds=10))`
  - *Line: 99*

- `def task_filter(user_id, user_sex, user_name)` `boost(BoosterParams(queue_name='demo_queue_filter', broker_kind=BrokerEnum.MEMORY_QUEUE, do_task_filtering=True, task_filtering_expire_seconds=60))`
  - *Line: 113*

- `def task_delay(msg)` `boost(BoosterParams(queue_name='demo_queue_delay', broker_kind=BrokerEnum.MEMORY_QUEUE))`
  - *Line: 121*

- `def task_group_a_1(x)` `boost(BoosterParams(queue_name='demo_group_task_1', broker_kind=BrokerEnum.MEMORY_QUEUE, booster_group='my_group_a'))`
  - *Line: 134*

- `def task_group_a_2(x)` `boost(BoosterParams(queue_name='demo_group_task_2', broker_kind=BrokerEnum.MEMORY_QUEUE, booster_group='my_group_a'))`
  - *Line: 142*

- `def task_group_b_1(x)` `boost(BoosterParams(queue_name='demo_group_task_3', broker_kind=BrokerEnum.MEMORY_QUEUE, booster_group='my_group_b'))`
  - *Line: 150*

- `async def rpc_asyncio()`
  - *Line: 251*


---

`````python
# -*- coding: utf-8 -*-

"""
funboost 所有用法的使用， demo 例子 演示
这个文件集中演示了 funboost 的 90% 主要功能用法。
"""

import time
import random
import asyncio
import datetime
from funboost import (
    boost,                  # 核心装饰器
    BoosterParams,          # 参数配置类
    BrokerEnum,             # 中间件枚举
    ConcurrentModeEnum,     # 并发模式枚举
    TaskOptions, # 优先级/延时配置
    ApsJobAdder,            # 定时任务添加器
    ctrl_c_recv,            # 阻塞主线程工具
    fct,                    # 上下文对象 (Funboost Current Task)
    BoostersManager,        # 消费者管理器 (用于分组启动)
    AsyncResult,            # 同步编程生态的异步结果对象
    AioAsyncResult,          # asyncio生态的异步结果对象
)

# ==========================================
# 1. 基础任务 (使用 SQLite 本地文件作为队列，无需安装 Redis/RabbitMQ 即可测试)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_basic",
    broker_kind=BrokerEnum.SQLITE_QUEUE,  # 使用本地 SQLite 文件作为队列
    concurrent_num=2,                     # 线程并发数量
))
def task_basic(x, y):
    print(f"[基础任务] 正在处理: {x} + {y} = {x + y}")
    time.sleep(0.5)
    return x + y


# ==========================================
# 2. 错误重试任务 (演示自动重试机制)
# 2.b 获取taskid和消息发布时间 (演示fct上下文的使用)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_retry",
    broker_kind=BrokerEnum.MEMORY_QUEUE,  # 使用内存队列
    max_retry_times=3,                    # 最大重试 3 次
    retry_interval=1,                     # 重试间隔 1 秒
    is_print_detail_exception=False       # 不打印详细堆栈，保持控制台整洁
))
def task_retry(n):
    # 模拟：只有 n > 8 才会成功，否则报错触发重试
    if n <= 8:
        print(f"[重试任务] 输入 {n} 模拟失败，当前是第 {fct.function_result_status.run_times} 次运行...")
        raise ValueError("模拟出错啦")
    print(f"[重试任务] 输入 {n} 成功处理！,任务id是：{fct.task_id} ,发布时间是：{fct.function_result_status.publish_time_format}")


# ==========================================
# 3. QPS 控频任务 (精准控制每秒执行次数)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_qps",
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    qps=2,  # 限制每秒只执行 2 次，无论并发开多大
))
def task_qps(idx):
    print(f"[QPS任务] {idx} 正在运行 (每秒约2次)... {datetime.datetime.now()}")


# ==========================================
# 4. Asyncio 协程任务 (高性能 IO 密集型)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_async",
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    concurrent_mode=ConcurrentModeEnum.ASYNC, # 开启 Asyncio 模式
    concurrent_num=100,  # 协程并发数可以设置很大
    is_using_rpc_mode = True,
))
async def task_async(url):
    print(f"[Async任务] 开始请求: {url}")
    await asyncio.sleep(1) # 模拟 IO 等待
    print(f"[Async任务] 请求结束: {url}")
    return f'url:{url} ,resp: mock_resp'


# ==========================================
# 5. RPC 任务 (发布端获取消费端结果)
# 注意：RPC模式通常需要 Redis 支持，这里使用 MEMORY_QUEUE 模拟演示(Funboost支持内存模拟)
# 但生产环境强烈建议配置 funboost_config.py 使用 Redis
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_rpc",
    broker_kind=BrokerEnum.MEMORY_QUEUE, 
    is_using_rpc_mode=True,  # 开启 RPC 模式
    rpc_result_expire_seconds=10
))
def task_rpc(a, b):
    time.sleep(1)
    return a * b


# ==========================================
# 6. 任务过滤 (去重)
# ==========================================
@boost(BoosterParams(
    queue_name="demo_queue_filter",
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    do_task_filtering=True,           # 开启过滤
    task_filtering_expire_seconds=60  # 60秒内参数相同的任务只执行一次
))
def task_filter(user_id, user_sex, user_name):
    print(f"[过滤任务] 正在执行: user_id={user_id} name={user_name} sex={user_sex}")


# ==========================================
# 7. 延时任务 (消费者取出后，延迟执行)
# ==========================================
@boost(BoosterParams(queue_name="demo_queue_delay", broker_kind=BrokerEnum.MEMORY_QUEUE))
def task_delay(msg):
    print(f"[延时任务] 终于执行了: {msg} - 当前时间: {datetime.datetime.now()}")


# ==========================================
# 10. Booster Group (分组启动演示)
# 场景：假设你有100个消费函数，只想启动其中属于 'my_group_a' 业务组的函数
# ==========================================
@boost(BoosterParams(
    queue_name="demo_group_task_1", 
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    booster_group="my_group_a"  # 指定分组名称
))
def task_group_a_1(x):
    print(f"[分组任务A-1] 处理: {x}")

@boost(BoosterParams(
    queue_name="demo_group_task_2", 
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    booster_group="my_group_a"  # 指定相同的分组名称
))
def task_group_a_2(x):
    print(f"[分组任务A-2] 处理: {x}")

@boost(BoosterParams(
    queue_name="demo_group_task_3", 
    broker_kind=BrokerEnum.MEMORY_QUEUE,
    booster_group="my_group_b"  # 不同的分组，不会被 my_group_a 启动
))
def task_group_b_1(x):
    print(f"[分组任务B-1] (这个不应该运行，因为没有启动my_group_b分组，也没有启动task_group_b_1消费函数): {x}")


# ==========================================
# 主程序入口
# ==========================================
if __name__ == '__main__':
    # --- 1. 启动常规消费者 ---
    # 启动方式 A: 单个启动
    task_basic.consume()
    task_retry.consume()
    task_qps.consume()
    task_async.consume()
    task_rpc.consume()
    task_filter.consume()
    task_delay.consume()
    
    # 启动方式 B: 多进程启动 (用于 CPU 密集型任务，这里仅做演示)
    # task_basic.multi_process_consume(process_num=2)   # 或者 task_basic.mp_consume(process_num=2) ,mp_consume是multi_process_consume的别名简写

    # 启动方式 C: 分组启动 (新增演示)
    print(">>> 正在启动属于 'my_group_a' 分组的所有消费者...")
    BoostersManager.consume_group("my_group_a")
    # 注意：这里没有启动 task_group_b_1，因为它属于 my_group_b

    print("=== 消费者已启动，开始发布任务 ===")
    time.sleep(1)

    # --- 2. 发布基础任务 ---
    for i in range(5):
        task_basic.push(i, i+1)

    # --- 3. 发布重试任务 ---
    task_retry.push(5) # 这个会失败并重试3次
    task_retry.push(6666) # 这个会成功无需重试

    # --- 4. 发布 QPS 任务 ---
    for i in range(6):
        task_qps.push(i)
    
    # --- 5. 发布 Async 任务 ---
    for i in range(3):
        # 支持异步 push: await task_async.aio_push(...)
        task_async.push(f"http://site-{i}.com")

    # --- 6. RPC 获取结果演示 ---
    print("\n--- RPC 演示 ---")
    # push 返回的是 AsyncResult 对象
    async_result:AsyncResult = task_rpc.push(10, 20) 
    print("RPC 任务已发布，正在等待结果...")
    # result 属性会阻塞当前线程直到获取结果
    print(f"RPC 结果: {async_result.result}") 
    

    # --- 7. 任务过滤演示 ---
    print("\n--- 过滤演示 ---")
    print("如果不指定filter_str， 默认使用函数的所有入参包括 user_id user_sex user_name 来做过滤")
    task_filter.push(1001,"man",user_name="xiaomin")

    # 演示: 指定字符串过滤 (publish 方式 + task_options)
    # 场景：只根据 user_id 过滤，即使其他参数不同，只要 user_id 相同就被过滤
    print("发布 user_id=1001 (第1次)")
    task_filter.publish(
        msg={"user_id": 1001, "user_sex": "man", "user_name": "Tom"},
        task_options=TaskOptions(filter_str="1001")
    )
    
    print("发布 user_id=1001 (第2次, name不同, 但filter_str相同, 应该被过滤)")
    task_filter.publish(
        msg={"user_id": 1001, "user_sex": "man", "user_name": "Jerry"},
        task_options=TaskOptions(filter_str="1001")
    )


    # --- 8. 延时任务演示 ---
    print("\n--- 延时演示 ---")
    print(f"发布延时任务时间: {datetime.datetime.now()}")
    # 使用 publish 方法发布，并携带 task_options
    task_delay.publish(
        msg={"msg": "我是延迟5秒的消息"}, 
        task_options=TaskOptions(countdown=5)
    )

    # --- 9. 定时任务演示 (APScheduler) ---
    print("\n--- 定时演示 (每隔5秒触发一次) ---")
    # 注意：这里是定时“发布”任务到队列，而不是直接运行函数
    ApsJobAdder(task_basic, job_store_kind='memory').add_push_job(
        trigger='interval',
        seconds=5,
        args=(100, 200), # 定时执行 task_basic(100, 200)
        id='my_schedule_job'
    )

    # --- 10. 分组任务发布演示 ---
    print("\n--- 分组任务演示 ---")
    task_group_a_1.push("A1 data")
    task_group_a_2.push("A2 data")
    task_group_b_1.push("B1 data (这条消息不会被消费，因为没启动B组)")

    # --- 11. funboost的asyncio 全链路生态的演示,包括asyncio发布 asyncio消费 asyncio获取结果
    async def rpc_asyncio():
        aio_async_result:AioAsyncResult = await task_async.aio_push("http://site-1.com") # aio_push 返回 AioAsyncResult 对象
        print("RPC 任务已发布，正在asyncio生态等待结果...")
        print(f"aio_async_result RPC 结果: {await aio_async_result.result}") 
    
    loop = asyncio.get_event_loop()
    loop.run_until_complete(rpc_asyncio())


    print("\n=== 所有演示任务已发布，ctrl_c_recv使主线程进入监听状态 (按3次 Ctrl+C 退出) ===\n")
    # ctrl_c_recv 阻塞主线程，防止主线程结束了，最好是加上，因为这可以阻止由于主线程结束了导致守护线程结束。 
    # 因为booster.consume() 是在子线程启动的，所以可以连续多个消费函数.consume()而不阻塞主线程
    ctrl_c_recv()
`````

--- **end of file: examples/example_all_usage.py** (project: funboost) --- 

---


--- **start of file: examples/example_easy.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_easy.py`

#### 📝 Module Docstring

`````
Funboost 最最基础示例
演示如何使用 @boost 装饰器创建分布式任务队列
`````

#### 📦 Imports

- `import time`
- `from funboost import boost`
- `from funboost import BrokerEnum`
- `from funboost import BoosterParams`
- `from funboost import ctrl_c_recv`

#### 🔧 Public Functions (1)

- `def add_task(x, y)` `boost(BoosterParams(queue_name='demo_queue_1', broker_kind=BrokerEnum.SQLITE_QUEUE, qps=5, concurrent_num=10))`
  - *Line: 16*
  - *简单的加法任务*


---

`````python
"""
Funboost 最最基础示例
演示如何使用 @boost 装饰器创建分布式任务队列
"""
import time
from funboost import boost, BrokerEnum, BoosterParams,ctrl_c_recv


# 示例1: 最简单的任务函数
@boost(BoosterParams(
    queue_name="demo_queue_1",
    broker_kind=BrokerEnum.SQLITE_QUEUE,  # 使用 SQLite 作为消息队列，无需额外安装中间件
    qps=5,  # 每秒执行5次
    concurrent_num=10,  # 并发数为10
))
def add_task(x, y):
    """简单的加法任务"""
    print(f'计算: {x} + {y} = {x + y}')
    time.sleep(1)  # 模拟耗时操作
    return x + y


if __name__ == '__main__':
    for i in range(10):
        add_task.push(i, i * 2)
    add_task.consume()
    ctrl_c_recv()
`````

--- **end of file: examples/example_easy.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/example_fastapi_faas.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/example_fastapi_faas.py`

#### 📝 Module Docstring

`````
此模块演示用户如果使用了fastapi，如何轻松一键新增 多个 funbost 的路由接口，
包括 /funboost/publish 和 /funboost/get_result 和 /funboost/get_msg_count 等几十个接口
这样用户就可以避免需要亲自写funboost发布消息和获取结果的的fastapi路由接口


from funboost.faas import fastapi_router
app.include_router(fastapi_router) # 只需要这样，你的fastapi app即可新增多个 funbost 的路由接口
`````

#### 📦 Imports

- `import uvicorn`
- `from fastapi import FastAPI`
- `from funboost.faas import fastapi_router`
- `from funboost.faas import CareProjectNameEnv`

#### 🔧 Public Functions (1)

- `async def index()` `app.get('/')`
  - *Line: 24*


---

`````python
"""
此模块演示用户如果使用了fastapi，如何轻松一键新增 多个 funbost 的路由接口，
包括 /funboost/publish 和 /funboost/get_result 和 /funboost/get_msg_count 等几十个接口
这样用户就可以避免需要亲自写funboost发布消息和获取结果的的fastapi路由接口


from funboost.faas import fastapi_router
app.include_router(fastapi_router) # 只需要这样，你的fastapi app即可新增多个 funbost 的路由接口
"""


import uvicorn
from fastapi import FastAPI

from funboost.faas import fastapi_router,CareProjectNameEnv 


CareProjectNameEnv.set('test_project1') # 可选，只关注指定的test_project1项目下的队列，减少无关队列的干扰。

# Create FastAPI app
app = FastAPI()

@app.get('/')
async def index():
    return "Hello World"

# 2. Include funboost.faas fastapi_router
app.include_router(fastapi_router)  # 这是核心用法


# 4. Run the app
if __name__ == '__main__':
    # The consumer runs in the background threads/processes started by @boost.
    # We run uvicorn to serve the API.
    print("Starting FastAPI app with Funboost Router...")
    
    print("启动 Funboost API 服务...")
    print("接口文档: http://127.0.0.1:8000/docs")
    print("Try POST http://127.0.0.1:8000/funboost/publish with body: {'queue_name': 'test_funboost_faas_queue', 'msg_body': {'x': 1, 'y': 2}, 'need_result': true}")
    uvicorn.run(app, host="0.0.0.0", port=8000)

`````

--- **end of file: examples/example_faas/example_fastapi_faas.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/example_req_fastapi.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/example_req_fastapi.py`

#### 📝 Module Docstring

`````
funboost.faas FastAPI Router 接口测试示例

本示例演示如何使用 funboost.faas 提供个接口：

1. test_publish_and_get_result - 演示发布消息并等待结果（RPC模式）
2. test_get_msg_count - 演示获取队列消息数量
3. test_publish_async_then_get_result - 演示异步发布，先获取task_id，再根据task_id获取结果
4. test_get_all_queues - 演示获取所有已注册的队列名称
`````

#### 📦 Imports

- `import requests`
- `import time`
- `import json`

#### 🔧 Public Functions (4)

- `def test_publish_and_get_result()`
  - *Line: 19*
  - **Docstring:**
  `````
  测试发布消息并等待结果（RPC模式）
  
  接口有对queue_name是否存在的校验，支持校验消息内容是否正确。所以不用担心跨部门用户使用了错误的queue_name，或者消息内容不正确。
  用户可以先通过 /get_queues_config 接口获取所有队列的配置信息，就知道有哪些队列，以及每个队列的消费函数支持的消息内容需要包括哪些入参字段了。
  `````

- `def test_get_msg_count()`
  - *Line: 56*
  - *测试获取队列消息数量*

- `def test_publish_async_then_get_result()`
  - *Line: 84*
  - *测试异步发布，先获取task_id，再根据task_id获取结果*

- `def test_get_all_queues()`
  - *Line: 137*
  - *测试获取所有已注册的队列名称*


---

`````python
"""
funboost.faas FastAPI Router 接口测试示例

本示例演示如何使用 funboost.faas 提供个接口：

1. test_publish_and_get_result - 演示发布消息并等待结果（RPC模式）
2. test_get_msg_count - 演示获取队列消息数量
3. test_publish_async_then_get_result - 演示异步发布，先获取task_id，再根据task_id获取结果
4. test_get_all_queues - 演示获取所有已注册的队列名称

"""

import requests
import time
import json

base_url = "http://127.0.0.1:8000"

def test_publish_and_get_result():
    """测试发布消息并等待结果（RPC模式）

    接口有对queue_name是否存在的校验，支持校验消息内容是否正确。所以不用担心跨部门用户使用了错误的queue_name，或者消息内容不正确。
    用户可以先通过 /get_queues_config 接口获取所有队列的配置信息，就知道有哪些队列，以及每个队列的消费函数支持的消息内容需要包括哪些入参字段了。
    """
    print("=" * 60)
    print("1. Testing publish and get result (RPC mode)...")
    print("=" * 60)
    
    url = f"{base_url}/funboost/publish"
    data = {
        "queue_name": "test_funboost_faas_queue",
        "msg_body": {"x": 10, "y": 20},
        "need_result": True,
        "timeout": 10
    }
    # publish 
    try:
        resp = requests.post(url, json=data)
        print(f"Status Code: {resp.status_code}")
        print(f"Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                task_id = result_data['data']['task_id']
                status_and_result = result_data['data']['status_and_result']
                print(f"\n✅ Success!")
                print(f"Task ID: {task_id}")
                print(f"Result: {status_and_result}")
            else:
                print(f"\n❌ Failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

def test_get_msg_count():
    """测试获取队列消息数量"""
    print("\n" + "=" * 60)
    print("2. Testing get message count...")
    print("=" * 60)
    
    url = f"{base_url}/funboost/get_msg_count"
    params = {"queue_name": "test_funboost_faas_queue"}
    
    try:
        resp = requests.get(url, params=params)
        print(f"Status Code: {resp.status_code}")
        print(f"Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                queue_name = result_data['data']['queue_name']
                count = result_data['data']['count']
                print(f"\n✅ Success!")
                print(f"Queue: {queue_name}")
                print(f"Message Count: {count}")
            else:
                print(f"\n❌ Failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

def test_publish_async_then_get_result():
    """测试异步发布，先获取task_id，再根据task_id获取结果"""
    print("\n" + "=" * 60)
    print("3. Testing publish async then get result by task_id...")
    print("=" * 60)
    
    # 步骤1: 发布消息（不等待结果）
    url_pub = f"{base_url}/funboost/publish"
    data = {
        "queue_name": "test_funboost_faas_queue",
        "msg_body": {"x": 33, "y": 44},
        "need_result": False,  # 不等待结果，立即返回
    }
    
    try:
        resp = requests.post(url_pub, json=data)
        print(f"Publish Status Code: {resp.status_code}")
        print(f"Publish Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                task_id = result_data['data']['task_id']
                print(f"\n✅ Message published!")
                print(f"Task ID: {task_id}")
                
                if task_id:
                    # 步骤2: 根据task_id获取结果
                    print("\nWaiting for task to complete...")
                    time.sleep(0.2)  # 等待一小段时间让任务完成
                    
                    url_get = f"{base_url}/funboost/get_result"
                    params = {"task_id": task_id, "timeout": 5}
                    resp_get = requests.get(url_get, params=params)
                    
                    print(f"\nGet Result Status Code: {resp_get.status_code}")
                    print(f"Get Result Response: {json.dumps(resp_get.json(), indent=2, ensure_ascii=False)}")
                    
                    if resp_get.status_code == 200:
                        get_result_data = resp_get.json()
                        if get_result_data['succ']:
                            # 新格式：数据在 data 字段中
                            status_and_result = get_result_data['data']['status_and_result']
                            print(f"\n✅ Got result!")
                            print(f"Result: {status_and_result}")
                        else:
                            print(f"\n⚠️  {get_result_data['msg']}")
            else:
                print(f"\n❌ Publish failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

def test_get_all_queues():
    """测试获取所有已注册的队列名称"""
    print("\n" + "=" * 60)
    print("4. Testing get all queues...")
    print("=" * 60)
    
    url = f"{base_url}/funboost/get_all_queues"
    
    try:
        resp = requests.get(url)
        print(f"Status Code: {resp.status_code}")
        print(f"Response: {json.dumps(resp.json(), indent=2, ensure_ascii=False)}")
        
        if resp.status_code == 200:
            result_data = resp.json()
            if result_data['succ']:
                # 新格式：数据在 data 字段中
                queues = result_data['data']['queues']
                count = result_data['data']['count']
                print(f"\n✅ Success!")
                print(f"Total Queues: {count}")
                print(f"Queue List:")
                for i, queue in enumerate(queues, 1):
                    print(f"  {i}. {queue}")
            else:
                print(f"\n❌ Failed: {result_data['msg']}")
    except Exception as e:
        print(f"\n❌ Request failed: {e}")

if __name__ == "__main__":
    print("\n" + "🚀 " * 20)
    print("FastAPI Funboost faas  接口测试")
    print("🚀 " * 20)
    
    # 测试所有4个接口
    test_publish_and_get_result()
    test_get_msg_count()
    test_publish_async_then_get_result()
    test_get_all_queues()
    
    print("\n" + "✅ " * 20)
    print("测试完成！")
    print("✅ " * 20 + "\n")

`````

--- **end of file: examples/example_faas/example_req_fastapi.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/example_req_timing_api.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/example_req_timing_api.py`

#### 📝 Module Docstring

`````
这个是演示funboost.faas 的定时任务管理
`````

#### 📦 Imports

- `import requests`


---

`````python
"""
这个是演示funboost.faas 的定时任务管理
"""


import requests

# 添加每10秒执行一次的任务
resp = requests.post("http://127.0.0.1:8000/funboost/add_timing_job", json={
    "queue_name": "test_funboost_faas_queue",
    "trigger": "interval",
    "seconds": 10,
    "job_id": "my_job",
    "kwargs": {"x": 10, "y": 20},
    "job_store_kind": "redis",
    "replace_existing": True,
})
print('add_timing_job',resp.json())

# 获取所有任务
resp = requests.get("http://127.0.0.1:8000/funboost/get_timing_jobs")
print('get_timing_jobs',resp.json())

# 暂停任务
resp = requests.post("http://127.0.0.1:8000/funboost/pause_timing_job", 
    params={"job_id": "my_job", "queue_name": "test_funboost_faas_queue"})
print('pause_timing_job',resp.json())

# # 恢复任务
# resp = requests.post("http://127.0.0.1:8000/funboost/resume_timing_job",
#     params={"job_id": "my_job", "queue_name": "test_funboost_faas_queue"})
# print('resume_timing_job',resp.json())

`````

--- **end of file: examples/example_faas/example_req_timing_api.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/README.md** (project: funboost) --- 

`````markdown
# funboost faas （Function as a Service） 示例

本示例演示如何在funboost faas 用法。

```
funboost faas ,可以单独部署启动消费，用户可以让booster随着web一起启动，也可以单独启动消费。

因为 funboost.faas 是基于funboost注册到redis中的元数据驱动，所以可以动态发现booster，
所以只要消费函数部署上线了，web服务完全无需重启，从http接口马上就能调用了，
相比传统web开发，加一个功能就要加一个接口，然后重启web，funboost faas爽的一逼。
```


## 📁 文件说明

### 1. `task_funs_dir` - 任务函数定义文件夹

**作用**: 定义需要被 Funboost 管理的消费函数（任务函数）

`Project1BoosterParams` 是 `BoosterParams`子类 ，每个消费函数可以直接用这个子类，减少每个装饰器都重复相同入参




### 2. `example_fastapi_faas.py` - FastAPI 应用主入口

**作用**: FastAPI 应用的主程序，展示如何一键集成 Funboost 路由，实现faas

运行 Uvicorn 服务器


**核心代码**:
```python
from funboost.faas import fastapi_router,CareProjectNameEnv

CareProjectNameEnv.set('test_project1') # 可选，只关注指定的test_project1项目下的队列

app = FastAPI()
app.include_router(fastapi_router)  # 核心用法：一行代码集成



if __name__ == '__main__':
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

**访问地址**:
- API 文档: http://127.0.0.1:8000/docs
- 根路径: http://127.0.0.1:8000/

---

### 3. `start_consume.py` - 独立消费者启动脚本

**作用**: 演示如何单独启动 Funboost 消费者，而不随 FastAPI 一起启动



---

### 4. `example_req_fastapi.py` - API 测试客户端

**作用**: 演示如何调用 Funboost FastAPI 路由的各个接口

**包含的测试用例**:

#### 测试 1: `test_publish_and_get_result()`
- **功能**: 发布任务并同步等待结果
- **请求**: `POST /funboost/publish`
- **参数**:
  ```json
  {
    "queue_name": "test_fastapi_router_queue",
    "msg_body": {"x": 10, "y": 20},
    "need_result": true,
    "timeout": 10
  }
  ```
- **特点**: `need_result=True` 时，接口会阻塞等待任务完成并返回结果

#### 测试 2: `test_get_msg_count()`
- **功能**: 获取指定队列的消息数量
- **请求**: `GET /funboost/get_msg_count?queue_name=test_fastapi_router_queue`
- **用途**: 监控队列积压情况

#### 测试 3: `test_publish_async_then_get_result()`
- **功能**: 异步发布任务，先获取 task_id，再通过 task_id 查询结果
- **流程**:
  1. 发布任务（`need_result=False`），立即返回 task_id
  2. 使用 task_id 调用 `GET /funboost/get_result` 获取结果
- **优势**: 不阻塞，适合长时间任务

**运行方式**:
```bash
python example_req_fastapi.py
```

---






`````

--- **end of file: examples/example_faas/README.md** (project: funboost) --- 

---


--- **start of file: examples/example_faas/start_consume.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/start_consume.py`

#### 📝 Module Docstring

`````
可以单独部署启动消费，用户可以让booster随着fastapi一起启动，也可以单独启动消费。

因为 funboost.faas 是基于funboost注册到redis中的元数据，所以可以动态发现booster，
所以只要消费函数部署上线了，web服务完全无需重启，从http接口马上就能调用了，
相比传统web开发，加一个功能就要加一个接口，然后重启web，funboost faas爽的一逼。
`````

#### 📦 Imports

- `from funboost import BoosterDiscovery`
- `from funboost import BoostersManager`


---

`````python
"""
可以单独部署启动消费，用户可以让booster随着fastapi一起启动，也可以单独启动消费。

因为 funboost.faas 是基于funboost注册到redis中的元数据，所以可以动态发现booster，
所以只要消费函数部署上线了，web服务完全无需重启，从http接口马上就能调用了，
相比传统web开发，加一个功能就要加一个接口，然后重启web，funboost faas爽的一逼。
"""

from funboost import BoosterDiscovery,BoostersManager

if __name__ == '__main__':
    # 演示 BoosterDiscovery ，自动扫描注册 @boost，
    # 效果等同于 直接 import task_funs_dir 下的add和sub模块。
    BoosterDiscovery(
        project_root_path=r'D:\codes\funboost',
        booster_dirs=['examples/example_faas/task_funs_dir'],
         ).auto_discovery()

    print(BoostersManager.get_all_queues())

    BoostersManager.consume_group('test_group1')
`````

--- **end of file: examples/example_faas/start_consume.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/add.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/add.py`

#### 📦 Imports

- `from base_booster_params import Project1BoosterParams`
- `from funboost import boost`
- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `import time`

#### 🔧 Public Functions (1)

- `def add(x, y = 10)` `boost(Project1BoosterParams(queue_name='test_funboost_faas_queue'))`
  - *Line: 6*


---

`````python
from .base_booster_params import Project1BoosterParams
from funboost import boost, BoosterParams, BrokerEnum
import time

@boost(Project1BoosterParams(queue_name="test_funboost_faas_queue", ))
def add(x, y=10,):
    time.sleep(1)
    print(f"add {x} + {y} = {x + y}")
    return x + y


`````

--- **end of file: examples/example_faas/task_funs_dir/add.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/base_booster_params.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/base_booster_params.py`

#### 📦 Imports

- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `from funboost import FunctionResultStatusPersistanceConfig`

#### 🏛️ Classes (1)

##### 📌 `class Project1BoosterParams(BoosterParams)`
*Line: 6*

**Class Variables (7):**
- `project_name: str = 'test_project1'`
- `broker_kind: str = BrokerEnum.REDIS`
- `is_send_consumer_heartbeat_to_redis: bool = True`
- `is_using_rpc_mode: bool = True`
- `booster_group: str = 'test_group1'`
- `should_check_publish_func_params: bool = True`
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)`


---

`````python

from funboost import  BoosterParams, BrokerEnum, FunctionResultStatusPersistanceConfig



class Project1BoosterParams(BoosterParams):
    project_name:str = 'test_project1'  # 核心配置，项目名，设置后，web接口就可以只关心某个项目下的队列，减少无关返回信息的干扰。
    broker_kind:str = BrokerEnum.REDIS
    is_send_consumer_heartbeat_to_redis : bool= True # 向redis发送心跳，这样才能从redis获取相关队列的运行信息。
    is_using_rpc_mode:bool = True # 必须设置这一个参数为True，才能支持rpc功能。
    booster_group : str = 'test_group1' # 方便按分组启动消费
    should_check_publish_func_params:bool = True # 发布消息时，是否检查消息内容是否正确，不正确的消息格式立刻从接口返回报错消息内容不正确。
    function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(
        is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False) 
`````

--- **end of file: examples/example_faas/task_funs_dir/base_booster_params.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/sub.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/sub.py`

#### 📦 Imports

- `from base_booster_params import Project1BoosterParams`
- `from funboost import boost`
- `from funboost import BoosterParams`
- `from funboost import BrokerEnum`
- `import time`

#### 🔧 Public Functions (1)

- `def sub(a, b)` `boost(Project1BoosterParams(queue_name='test_funboost_faas_queue2'))`
  - *Line: 6*


---

`````python
from .base_booster_params import Project1BoosterParams
from funboost import boost, BoosterParams, BrokerEnum
import time

@boost(Project1BoosterParams(queue_name="test_funboost_faas_queue2", ))
def sub(a, b):
    time.sleep(1)
    print(f"sub {a} - {b} = {a - b}")
    return a - b

`````

--- **end of file: examples/example_faas/task_funs_dir/sub.py** (project: funboost) --- 

---


--- **start of file: examples/example_faas/task_funs_dir/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `examples/example_faas/task_funs_dir/__init__.py`


---

`````python

`````

--- **end of file: examples/example_faas/task_funs_dir/__init__.py** (project: funboost) --- 

---

# markdown content namespace: funboost codes 


## funboost File Tree (relative dir: `funboost`)


`````

└── funboost
    ├── README.md
    ├── __init__.py
    ├── __init__old.py
    ├── __main__.py
    ├── assist
    │   ├── __init__.py
    │   ├── celery_helper.py
    │   ├── dramatiq_helper.py
    │   ├── faststream_helper.py
    │   ├── grpc_helper
    │   │   ├── client_sample.py
    │   │   ├── funboost_grpc_pb2.py
    │   │   ├── funboost_grpc_pb2_grpc.py
    │   │   ├── generate_pb.py
    │   │   └── server_sample.py
    │   ├── huey_helper.py
    │   ├── rocketry_helper.py
    │   ├── rq_helper.py
    │   ├── rq_windows_worker.py
    │   └── taskiq_helper.py
    ├── beggar_version_implementation
    │   ├── README.md
    │   ├── __init__.py
    │   └── beggar_redis_consumer.py
    ├── concurrent_pool
    │   ├── __init__.py
    │   ├── async_helper.py
    │   ├── async_pool_executor.py
    │   ├── base_pool_type.py
    │   ├── bounded_processpoolexcutor_gt_py37.py
    │   ├── bounded_processpoolexcutor_py36.py
    │   ├── bounded_threadpoolexcutor.py
    │   ├── concurrent_pool_with_multi_process.py
    │   ├── custom_evenlet_pool_executor.py
    │   ├── custom_gevent_pool_executor.py
    │   ├── custom_threadpool_executor.py
    │   ├── custom_threadpool_executor000.py
    │   ├── fixed_thread_pool.py
    │   ├── flexible_thread_pool.py
    │   ├── pool_commons.py
    │   ├── readme.md
    │   └── single_thread_executor.py
    ├── constant.py
    ├── consumers
    │   ├── __init__.py
    │   ├── base_consumer.py
    │   ├── celery_consumer.py
    │   ├── confirm_mixin.py
    │   ├── dramatiq_consumer.py
    │   ├── empty_consumer.py
    │   ├── faststream_consumer.py
    │   ├── grpc_consumer.py
    │   ├── http_consumer.py
    │   ├── http_consumer_aiohttp_old.py
    │   ├── httpsqs_consumer.py
    │   ├── huey_consumer.py
    │   ├── kafka_consumer.py
    │   ├── kafka_consumer_manually_commit.py
    │   ├── kombu_consumer.py
    │   ├── local_python_queue_consumer.py
    │   ├── memory_deque_consumer.py
    │   ├── mongomq_consumer.py
    │   ├── mqtt_consumer.py
    │   ├── mysql_cdc_consumer.py
    │   ├── nameko_consumer.py
    │   ├── nats_consumer.py
    │   ├── nsq_consumer.py
    │   ├── peewee_conusmer.py
    │   ├── persist_queue_consumer.py
    │   ├── pulsar_consumer.py
    │   ├── rabbitmq_amqpstorm_consumer.py
    │   ├── rabbitmq_complex_routing_consumer.py
    │   ├── rabbitmq_pika_consumer.py
    │   ├── rabbitmq_rabbitpy_consumer.py
    │   ├── redis_brpoplpush_consumer.py
    │   ├── redis_consumer.py
    │   ├── redis_consumer_ack_able.py
    │   ├── redis_consumer_ack_using_timeout.py
    │   ├── redis_consumer_priority.py
    │   ├── redis_consumer_simple.py
    │   ├── redis_filter.py
    │   ├── redis_pubsub_consumer.py
    │   ├── redis_stream_consumer.py
    │   ├── rocketmq_consumer.py
    │   ├── rq_consumer.py
    │   ├── sqlachemy_consumer.py
    │   ├── tcp_consumer.py
    │   ├── txt_file_consumer.py
    │   ├── udp_consumer.py
    │   └── zeromq_consumer.py
    ├── contrib
    │   ├── __init__.py
    │   ├── api_publish_msg.py
    │   ├── cdc
    │   │   ├── __init__.py
    │   │   └── mysql2mysql.py
    │   ├── django_db_deco.py
    │   ├── funboost框架的额外贡献功能.md
    │   ├── override_publisher_consumer_cls
    │   │   ├── README.md
    │   │   ├── funboost_otel_mixin.py
    │   │   └── otel_tree_span_exporter.py
    │   ├── queue2queue.py
    │   ├── redis_consume_latest_msg_broker.py
    │   └── save_function_result_status
    │       ├── __init__.py
    │       ├── readme.md
    │       ├── save_result_status_to_sqldb.py
    │       └── save_result_status_use_dataset.py
    ├── core
    │   ├── __init__.py
    │   ├── active_cousumer_info_getter.py
    │   ├── booster.py
    │   ├── broker_kind__exclusive_config_default_define.py
    │   ├── cli
    │   │   ├── __init__.py
    │   │   ├── discovery_boosters.py
    │   │   ├── funboost_cli_user_templ.py
    │   │   └── funboost_fire.py
    │   ├── consuming_func_iniput_params_check.py
    │   ├── current_task.py
    │   ├── exceptions.py
    │   ├── fabric_deploy_helper.py
    │   ├── funboost_config_getter.py
    │   ├── funboost_time.py
    │   ├── func_params_model.py
    │   ├── function_result_status_saver.py
    │   ├── helper_funs.py
    │   ├── kill_remote_task.py
    │   ├── lazy_impoter.py
    │   ├── loggers.py
    │   ├── msg_result_getter.py
    │   ├── muliti_process_enhance.py
    │   ├── pydantic_compatible_base.py
    │   ├── serialization.py
    │   └── task_id_logger.py
    ├── faas
    │   ├── README.md
    │   ├── __init__.py
    │   ├── django_adapter.py
    │   ├── faas_util.py
    │   ├── fastapi_adapter.py
    │   └── flask_adapter.py
    ├── factories
    │   ├── __init__.py
    │   ├── broker_kind__publsiher_consumer_type_map.py
    │   ├── consumer_factory.py
    │   └── publisher_factotry.py
    ├── funboost_config_deafult.py
    ├── funboost_web_manager
    │   ├── app.py
    │   ├── app_debug_start.py
    │   ├── functions.py
    │   └── templates
    │       └── app.py中仍在使用的路由.md
    ├── publishers
    │   ├── __init__.py
    │   ├── base_publisher.py
    │   ├── celery_publisher.py
    │   ├── confluent_kafka_publisher.py
    │   ├── dramatiq_publisher.py
    │   ├── empty_publisher.py
    │   ├── faststream_publisher.py
    │   ├── grpc_publisher.py
    │   ├── http_publisher.py
    │   ├── httpsqs_publisher.py
    │   ├── huey_publisher.py
    │   ├── kafka_publisher.py
    │   ├── kombu_publisher.py
    │   ├── local_python_queue_publisher.py
    │   ├── meomory_deque_publisher.py
    │   ├── mongomq_publisher.py
    │   ├── mqtt_publisher.py
    │   ├── mysql_cdc_publisher.py
    │   ├── nameko_publisher.py
    │   ├── nats_publisher.py
    │   ├── nsq_publisher.py
    │   ├── peewee_publisher.py
    │   ├── persist_queue_publisher.py
    │   ├── pulsar_publisher.py
    │   ├── rabbitmq_amqpstorm_publisher.py
    │   ├── rabbitmq_complex_routing_publisher.py
    │   ├── rabbitmq_pika_publisher.py
    │   ├── rabbitmq_rabbitpy_publisher.py
    │   ├── redis_publisher.py
    │   ├── redis_publisher_lpush.py
    │   ├── redis_publisher_priority.py
    │   ├── redis_publisher_simple.py
    │   ├── redis_pubsub_publisher.py
    │   ├── redis_queue_flush_mixin.py
    │   ├── redis_stream_publisher.py
    │   ├── rocketmq_publisher.py
    │   ├── rq_publisher.py
    │   ├── sqla_queue_publisher.py
    │   ├── tcp_publisher.py
    │   ├── txt_file_publisher.py
    │   ├── udp_publisher.py
    │   └── zeromq_publisher.py
    ├── queues
    │   ├── __init__.py
    │   ├── memory_queues_map.py
    │   ├── peewee_queue.py
    │   └── sqla_queue.py
    ├── set_frame_config.py
    ├── timing_job
    │   ├── __init__.py
    │   ├── apscheduler_use_mysql_store.py
    │   ├── apscheduler_use_redis_store.py
    │   ├── timing_job_base.py
    │   └── timing_push.py
    └── utils
        ├── README.md
        ├── __init__.py
        ├── apscheduler_monkey.py
        ├── block_exit.py
        ├── bulk_operation.py
        ├── class_utils.py
        ├── ctrl_c_end.py
        ├── decorators.py
        ├── develop_log.py
        ├── expire_lock.py
        ├── json_helper.py
        ├── mongo_util.py
        ├── monkey_color_log.py
        ├── monkey_patches.py
        ├── mqtt_util.py
        ├── paramiko_util.py
        ├── rabbitmq_factory.py
        ├── redis_manager.py
        ├── redis_manager_old.py
        ├── resource_monitoring.py
        ├── restart_python.py
        ├── simple_data_class.py
        ├── str_utils.py
        ├── task_dispatcher.py
        ├── time_util.py
        ├── un_strict_json_dumps.py
        └── uuid7.py

`````

---


## funboost (relative dir: `funboost`)  Included Files (total: 219 files)


- `funboost/constant.py`

- `funboost/funboost_config_deafult.py`

- `funboost/README.md`

- `funboost/set_frame_config.py`

- `funboost/__init__.py`

- `funboost/__init__old.py`

- `funboost/__main__.py`

- `funboost/assist/celery_helper.py`

- `funboost/assist/dramatiq_helper.py`

- `funboost/assist/faststream_helper.py`

- `funboost/assist/huey_helper.py`

- `funboost/assist/rocketry_helper.py`

- `funboost/assist/rq_helper.py`

- `funboost/assist/rq_windows_worker.py`

- `funboost/assist/taskiq_helper.py`

- `funboost/assist/__init__.py`

- `funboost/assist/grpc_helper/client_sample.py`

- `funboost/assist/grpc_helper/funboost_grpc_pb2.py`

- `funboost/assist/grpc_helper/funboost_grpc_pb2_grpc.py`

- `funboost/assist/grpc_helper/generate_pb.py`

- `funboost/assist/grpc_helper/server_sample.py`

- `funboost/beggar_version_implementation/beggar_redis_consumer.py`

- `funboost/beggar_version_implementation/README.md`

- `funboost/beggar_version_implementation/__init__.py`

- `funboost/concurrent_pool/async_helper.py`

- `funboost/concurrent_pool/async_pool_executor.py`

- `funboost/concurrent_pool/base_pool_type.py`

- `funboost/concurrent_pool/bounded_processpoolexcutor_gt_py37.py`

- `funboost/concurrent_pool/bounded_processpoolexcutor_py36.py`

- `funboost/concurrent_pool/bounded_threadpoolexcutor.py`

- `funboost/concurrent_pool/concurrent_pool_with_multi_process.py`

- `funboost/concurrent_pool/custom_evenlet_pool_executor.py`

- `funboost/concurrent_pool/custom_gevent_pool_executor.py`

- `funboost/concurrent_pool/custom_threadpool_executor.py`

- `funboost/concurrent_pool/custom_threadpool_executor000.py`

- `funboost/concurrent_pool/fixed_thread_pool.py`

- `funboost/concurrent_pool/flexible_thread_pool.py`

- `funboost/concurrent_pool/pool_commons.py`

- `funboost/concurrent_pool/readme.md`

- `funboost/concurrent_pool/single_thread_executor.py`

- `funboost/concurrent_pool/__init__.py`

- `funboost/consumers/base_consumer.py`

- `funboost/consumers/celery_consumer.py`

- `funboost/consumers/confirm_mixin.py`

- `funboost/consumers/dramatiq_consumer.py`

- `funboost/consumers/empty_consumer.py`

- `funboost/consumers/faststream_consumer.py`

- `funboost/consumers/grpc_consumer.py`

- `funboost/consumers/httpsqs_consumer.py`

- `funboost/consumers/http_consumer.py`

- `funboost/consumers/http_consumer_aiohttp_old.py`

- `funboost/consumers/huey_consumer.py`

- `funboost/consumers/kafka_consumer.py`

- `funboost/consumers/kafka_consumer_manually_commit.py`

- `funboost/consumers/kombu_consumer.py`

- `funboost/consumers/local_python_queue_consumer.py`

- `funboost/consumers/memory_deque_consumer.py`

- `funboost/consumers/mongomq_consumer.py`

- `funboost/consumers/mqtt_consumer.py`

- `funboost/consumers/mysql_cdc_consumer.py`

- `funboost/consumers/nameko_consumer.py`

- `funboost/consumers/nats_consumer.py`

- `funboost/consumers/nsq_consumer.py`

- `funboost/consumers/peewee_conusmer.py`

- `funboost/consumers/persist_queue_consumer.py`

- `funboost/consumers/pulsar_consumer.py`

- `funboost/consumers/rabbitmq_amqpstorm_consumer.py`

- `funboost/consumers/rabbitmq_complex_routing_consumer.py`

- `funboost/consumers/rabbitmq_pika_consumer.py`

- `funboost/consumers/rabbitmq_rabbitpy_consumer.py`

- `funboost/consumers/redis_brpoplpush_consumer.py`

- `funboost/consumers/redis_consumer.py`

- `funboost/consumers/redis_consumer_ack_able.py`

- `funboost/consumers/redis_consumer_ack_using_timeout.py`

- `funboost/consumers/redis_consumer_priority.py`

- `funboost/consumers/redis_consumer_simple.py`

- `funboost/consumers/redis_filter.py`

- `funboost/consumers/redis_pubsub_consumer.py`

- `funboost/consumers/redis_stream_consumer.py`

- `funboost/consumers/rocketmq_consumer.py`

- `funboost/consumers/rq_consumer.py`

- `funboost/consumers/sqlachemy_consumer.py`

- `funboost/consumers/tcp_consumer.py`

- `funboost/consumers/txt_file_consumer.py`

- `funboost/consumers/udp_consumer.py`

- `funboost/consumers/zeromq_consumer.py`

- `funboost/consumers/__init__.py`

- `funboost/contrib/api_publish_msg.py`

- `funboost/contrib/django_db_deco.py`

- `funboost/contrib/funboost框架的额外贡献功能.md`

- `funboost/contrib/queue2queue.py`

- `funboost/contrib/redis_consume_latest_msg_broker.py`

- `funboost/contrib/__init__.py`

- `funboost/contrib/cdc/mysql2mysql.py`

- `funboost/contrib/cdc/__init__.py`

- `funboost/contrib/override_publisher_consumer_cls/funboost_otel_mixin.py`

- `funboost/contrib/override_publisher_consumer_cls/otel_tree_span_exporter.py`

- `funboost/contrib/override_publisher_consumer_cls/README.md`

- `funboost/contrib/save_function_result_status/readme.md`

- `funboost/contrib/save_function_result_status/save_result_status_to_sqldb.py`

- `funboost/contrib/save_function_result_status/save_result_status_use_dataset.py`

- `funboost/contrib/save_function_result_status/__init__.py`

- `funboost/core/active_cousumer_info_getter.py`

- `funboost/core/booster.py`

- `funboost/core/broker_kind__exclusive_config_default_define.py`

- `funboost/core/consuming_func_iniput_params_check.py`

- `funboost/core/current_task.py`

- `funboost/core/exceptions.py`

- `funboost/core/fabric_deploy_helper.py`

- `funboost/core/funboost_config_getter.py`

- `funboost/core/funboost_time.py`

- `funboost/core/function_result_status_saver.py`

- `funboost/core/func_params_model.py`

- `funboost/core/helper_funs.py`

- `funboost/core/kill_remote_task.py`

- `funboost/core/lazy_impoter.py`

- `funboost/core/loggers.py`

- `funboost/core/msg_result_getter.py`

- `funboost/core/muliti_process_enhance.py`

- `funboost/core/pydantic_compatible_base.py`

- `funboost/core/serialization.py`

- `funboost/core/task_id_logger.py`

- `funboost/core/__init__.py`

- `funboost/core/cli/discovery_boosters.py`

- `funboost/core/cli/funboost_cli_user_templ.py`

- `funboost/core/cli/funboost_fire.py`

- `funboost/core/cli/__init__.py`

- `funboost/faas/django_adapter.py`

- `funboost/faas/faas_util.py`

- `funboost/faas/fastapi_adapter.py`

- `funboost/faas/flask_adapter.py`

- `funboost/faas/README.md`

- `funboost/faas/__init__.py`

- `funboost/factories/broker_kind__publsiher_consumer_type_map.py`

- `funboost/factories/consumer_factory.py`

- `funboost/factories/publisher_factotry.py`

- `funboost/factories/__init__.py`

- `funboost/funboost_web_manager/app.py`

- `funboost/funboost_web_manager/app_debug_start.py`

- `funboost/funboost_web_manager/functions.py`

- `funboost/funboost_web_manager/templates/app.py中仍在使用的路由.md`

- `funboost/publishers/base_publisher.py`

- `funboost/publishers/celery_publisher.py`

- `funboost/publishers/confluent_kafka_publisher.py`

- `funboost/publishers/dramatiq_publisher.py`

- `funboost/publishers/empty_publisher.py`

- `funboost/publishers/faststream_publisher.py`

- `funboost/publishers/grpc_publisher.py`

- `funboost/publishers/httpsqs_publisher.py`

- `funboost/publishers/http_publisher.py`

- `funboost/publishers/huey_publisher.py`

- `funboost/publishers/kafka_publisher.py`

- `funboost/publishers/kombu_publisher.py`

- `funboost/publishers/local_python_queue_publisher.py`

- `funboost/publishers/meomory_deque_publisher.py`

- `funboost/publishers/mongomq_publisher.py`

- `funboost/publishers/mqtt_publisher.py`

- `funboost/publishers/mysql_cdc_publisher.py`

- `funboost/publishers/nameko_publisher.py`

- `funboost/publishers/nats_publisher.py`

- `funboost/publishers/nsq_publisher.py`

- `funboost/publishers/peewee_publisher.py`

- `funboost/publishers/persist_queue_publisher.py`

- `funboost/publishers/pulsar_publisher.py`

- `funboost/publishers/rabbitmq_amqpstorm_publisher.py`

- `funboost/publishers/rabbitmq_complex_routing_publisher.py`

- `funboost/publishers/rabbitmq_pika_publisher.py`

- `funboost/publishers/rabbitmq_rabbitpy_publisher.py`

- `funboost/publishers/redis_publisher.py`

- `funboost/publishers/redis_publisher_lpush.py`

- `funboost/publishers/redis_publisher_priority.py`

- `funboost/publishers/redis_publisher_simple.py`

- `funboost/publishers/redis_pubsub_publisher.py`

- `funboost/publishers/redis_queue_flush_mixin.py`

- `funboost/publishers/redis_stream_publisher.py`

- `funboost/publishers/rocketmq_publisher.py`

- `funboost/publishers/rq_publisher.py`

- `funboost/publishers/sqla_queue_publisher.py`

- `funboost/publishers/tcp_publisher.py`

- `funboost/publishers/txt_file_publisher.py`

- `funboost/publishers/udp_publisher.py`

- `funboost/publishers/zeromq_publisher.py`

- `funboost/publishers/__init__.py`

- `funboost/queues/memory_queues_map.py`

- `funboost/queues/peewee_queue.py`

- `funboost/queues/sqla_queue.py`

- `funboost/queues/__init__.py`

- `funboost/timing_job/apscheduler_use_mysql_store.py`

- `funboost/timing_job/apscheduler_use_redis_store.py`

- `funboost/timing_job/timing_job_base.py`

- `funboost/timing_job/timing_push.py`

- `funboost/timing_job/__init__.py`

- `funboost/utils/apscheduler_monkey.py`

- `funboost/utils/block_exit.py`

- `funboost/utils/bulk_operation.py`

- `funboost/utils/class_utils.py`

- `funboost/utils/ctrl_c_end.py`

- `funboost/utils/decorators.py`

- `funboost/utils/develop_log.py`

- `funboost/utils/expire_lock.py`

- `funboost/utils/json_helper.py`

- `funboost/utils/mongo_util.py`

- `funboost/utils/monkey_color_log.py`

- `funboost/utils/monkey_patches.py`

- `funboost/utils/mqtt_util.py`

- `funboost/utils/paramiko_util.py`

- `funboost/utils/rabbitmq_factory.py`

- `funboost/utils/README.md`

- `funboost/utils/redis_manager.py`

- `funboost/utils/redis_manager_old.py`

- `funboost/utils/resource_monitoring.py`

- `funboost/utils/restart_python.py`

- `funboost/utils/simple_data_class.py`

- `funboost/utils/str_utils.py`

- `funboost/utils/task_dispatcher.py`

- `funboost/utils/time_util.py`

- `funboost/utils/un_strict_json_dumps.py`

- `funboost/utils/uuid7.py`

- `funboost/utils/__init__.py`


---


--- **start of file: funboost/constant.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/constant.py`

#### 🏛️ Classes (9)

##### 📌 `class BrokerEnum`
*Line: 5*

**Docstring:**
`````
在funboost中万物皆可为消息队列broker,funboost内置了所有 知名的正经经典消息队列作为broker,
也支持了基于 内存 各种数据库 文件系统 tcp/udp/http这些socket 模拟作为broker.
funboost也内置支持了各种python三方包和消费框架作为broker,例如 sqlachemy kombu celery rq dramtiq huey nameko 等等

用户也可以按照文档4.21章节,轻松扩展任何物质概念作为funboost的broker.
`````

**Class Variables (43):**
- `EMPTY = 'EMPTY'`
- `RABBITMQ_AMQPSTORM = 'RABBITMQ_AMQPSTORM'`
- `RABBITMQ = RABBITMQ_AMQPSTORM`
- `RABBITMQ_COMPLEX_ROUTING = 'RABBITMQ_COMPLEX_ROUTING'`
- `RABBITMQ_RABBITPY = 'RABBITMQ_RABBITPY'`
- `REDIS = 'REDIS'`
- `REDIS_ACK_ABLE = 'REDIS_ACK_ABLE'`
- `REIDS_ACK_USING_TIMEOUT = 'reids_ack_using_timeout'`
- `REDIS_PRIORITY = 'REDIS_PRIORITY'`
- `REDIS_STREAM = 'REDIS_STREAM'`
- `RedisBrpopLpush = 'RedisBrpopLpush'`
- `REDIS_PUBSUB = 'REDIS_PUBSUB'`
- `MEMORY_QUEUE = 'MEMORY_QUEUE'`
- `LOCAL_PYTHON_QUEUE = MEMORY_QUEUE`
- `RABBITMQ_PIKA = 'RABBITMQ_PIKA'`
- `MONGOMQ = 'MONGOMQ'`
- `SQLITE_QUEUE = 'sqlite3'`
- `PERSISTQUEUE = SQLITE_QUEUE`
- `NSQ = 'NSQ'`
- `KAFKA = 'KAFKA'`
- `KAFKA_CONFLUENT = 'KAFKA_CONFLUENT'`
- `CONFLUENT_KAFKA = KAFKA_CONFLUENT`
- `KAFKA_CONFLUENT_SASlPlAIN = 'KAFKA_CONFLUENT_SASlPlAIN'`
- `SQLACHEMY = 'SQLACHEMY'`
- `ROCKETMQ = 'ROCKETMQ'`
- `ZEROMQ = 'ZEROMQ'`
- `KOMBU = 'KOMBU'`
- `MQTT = 'MQTT'`
- `HTTPSQS = 'HTTPSQS'`
- `PULSAR = 'PULSAR'`
- `UDP = 'UDP'`
- `TCP = 'TCP'`
- `HTTP = 'HTTP'`
- `GRPC = 'GRPC'`
- `NATS = 'NATS'`
- `TXT_FILE = 'TXT_FILE'`
- `PEEWEE = 'PEEWEE'`
- `CELERY = 'CELERY'`
- `DRAMATIQ = 'DRAMATIQ'`
- `HUEY = 'HUEY'`
- `RQ = 'RQ'`
- `NAMEKO = 'NAMEKO'`
- `MYSQL_CDC = 'MYSQL_CDC'`

##### 📌 `class ConcurrentModeEnum`
*Line: 150*

**Class Variables (6):**
- `THREADING = 'threading'`
- `GEVENT = 'gevent'`
- `EVENTLET = 'eventlet'`
- `ASYNC = 'async'`
- `SINGLE_THREAD = 'single_thread'`
- `SOLO = SINGLE_THREAD`

##### 📌 `class FunctionKind`
*Line: 161*

**Class Variables (4):**
- `CLASS_METHOD = 'CLASS_METHOD'`
- `INSTANCE_METHOD = 'INSTANCE_METHOD'`
- `STATIC_METHOD = 'STATIC_METHOD'`
- `COMMON_FUNCTION = 'COMMON_FUNCTION'`

##### 📌 `class ConstStrForClassMethod`
*Line: 168*

**Class Variables (5):**
- `FIRST_PARAM_NAME = 'first_param_name'`
- `CLS_NAME = 'cls_name'`
- `OBJ_INIT_PARAMS = 'obj_init_params'`
- `CLS_MODULE = 'cls_module'`
- `CLS_FILE = 'cls_file'`

##### 📌 `class RedisKeys`
*Line: 176*

**Public Methods (7):**
- `def gen_funboost_apscheduler_redis_lock_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_hearbeat_queue__dict_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_hearbeat_server__dict_key_by_ip(ip)` `staticmethod`
- `def gen_funboost_queue_time_series_data_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_redis_apscheduler_jobs_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_redis_apscheduler_run_times_key_by_queue_name(queue_name)` `staticmethod`
- `def gen_funboost_project_name_key(project_name)` `staticmethod`

**Class Variables (12):**
- `REDIS_KEY_PAUSE_FLAG = 'funboost_pause_flag'`
- `REDIS_KEY_STOP_FLAG = 'funboost_stop_flag'`
- `QUEUE__MSG_COUNT_MAP = 'funboost_queue__msg_count_map'`
- `FUNBOOST_QUEUE__CONSUMER_PARAMS = 'funboost_queue__consumer_parmas'`
- `FUNBOOST_QUEUE__RUN_COUNT_MAP = 'funboost_queue__run_count_map'`
- `FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP = 'funboost_queue__run_fail_count_map'`
- `FUNBOOST_ALL_QUEUE_NAMES = 'funboost_all_queue_names'`
- `FUNBOOST_ALL_IPS = 'funboost_all_ips'`
- `FUNBOOST_ALL_PROJECT_NAMES = 'funboost_all_project_names'`
- `FUNBOOST_LAST_GET_QUEUES_PARAMS_AND_ACTIVE_CONSUMERS_AND_REPORT__UUID_TS = 'funboost_last_get_queues_params_and_active_consumers_and_report__uuid_ts'`
- `FUNBOOST_HEARTBEAT_QUEUE__DICT_PREFIX = 'funboost_hearbeat_queue__dict:'`
- `FUNBOOST_HEARTBEAT_SERVER__DICT_PREFIX = 'funboost_hearbeat_server__dict:'`

##### 📌 `class ConsumingFuncInputParamsCheckerField`
*Line: 224*

**Class Variables (6):**
- `is_manual_func_input_params = 'is_manual_func_input_params'`
- `all_arg_name_list = 'all_arg_name_list'`
- `must_arg_name_list = 'must_arg_name_list'`
- `optional_arg_name_list = 'optional_arg_name_list'`
- `func_name = 'func_name'`
- `func_position = 'func_position'`

##### 📌 `class MongoDbName`
*Line: 233*

**Class Variables (2):**
- `TASK_STATUS_DB = 'funboost_task_status'`
- `MONGOMQ_DB = 'funboost_mongomq'`

##### 📌 `class StrConst`
*Line: 237*

**Class Variables (1):**
- `BOOSTER_REGISTRY_NAME_DEFAULT = 'booster_registry_default'`

##### 📌 `class EnvConst`
*Line: 240*

**Class Variables (2):**
- `FUNBOOST_FAAS_CARE_PROJECT_NAME = 'funboost.faas.care_project_name'`
- `FUNBOOST_FAAS_IS_USE_LOCAL_BOOSTER = 'funboost.faas.is_use_local_booster'`


---

`````python
# coding= utf-8



class  BrokerEnum:
    """
    在funboost中万物皆可为消息队列broker,funboost内置了所有 知名的正经经典消息队列作为broker,
    也支持了基于 内存 各种数据库 文件系统 tcp/udp/http这些socket 模拟作为broker.
    funboost也内置支持了各种python三方包和消费框架作为broker,例如 sqlachemy kombu celery rq dramtiq huey nameko 等等

    用户也可以按照文档4.21章节,轻松扩展任何物质概念作为funboost的broker.
    """
    
    # funboost框架能轻松兼容消息队列各种工作模式, 拉模式/推模式/轮询模式，单条获取 批量获取
    """
    funboost 的 consumer的 _dispatch_task 非常灵活，用户实现把从消息队列取出的消息通过_submit_task方法
    丢到并发池，他不是强制用户重写实现怎么取一条消息，例如强制你实现一个 _get_one_message的法，
    那就不灵活和限制扩展任意东西作为broker了，而是用户完全自己来写灵活代码。
    所以无论获取消息是 拉模式 还是推模式 还是轮询模式，是单条获取 还是多条批量获取，
    不管你的新中间件和rabbitmq api用法差别有多么巨大，都能轻松扩展任意东西作为funboost的中间件。 
    所以你能看到funboost源码中能轻松实现任物质概念作为funboost的broker。
    """


    EMPTY = 'EMPTY'  # 空的实现，需要搭配 boost入参的 consumer_override_cls 和 publisher_override_cls使用，或者被继承。

    RABBITMQ_AMQPSTORM = 'RABBITMQ_AMQPSTORM'  # 使用 amqpstorm 包操作rabbitmq  作为 分布式消息队列，支持消费确认.强烈推荐这个作为funboost中间件。
    RABBITMQ = RABBITMQ_AMQPSTORM

    # 2025-10 内置新增, 支持rabbitmq 所有路由模式,包括 fanout,direct,topic,headers. 使用概念更复杂
    # 用法见 test_frame/test_broker_rabbitmq/test_rabbitmq_complex_routing 中的demo代码.
    RABBITMQ_COMPLEX_ROUTING = 'RABBITMQ_COMPLEX_ROUTING'

    RABBITMQ_RABBITPY = 'RABBITMQ_RABBITPY'  # 使用 rabbitpy 包操作rabbitmq  作为 分布式消息队列，支持消费确认，不建议使用

    """
    以下是各种redis数据结构和各种方式来实现作为消息队列的,redis简直被作者玩出花来了.
    因为redis本身是缓存数据库,不是消息队列,redis没有实现经典AMQP协议,所以redis是模拟消息队列不是真消息队列.
    例如要实现消费确认,随意重启但消息万无一失,你搞个简单的 redis.blpop 弹出删除消息,那就压根不行.重启就丢失了,但消息可能还没开始运行或者正在运行中.
    
    redis做ack挑战难点不是怎么实现确认消费本身,而是何时应该把关闭或宕机进程的消费者的待确认消费的孤儿消息重回队列.  
    在 Redis 上实现 ACK 的真正难点，根本不在于“确认”这个动作本身，而在于建立一套可靠的、能够准确判断“何时可以安全地及时地进行任务恢复”的分布式故障检测机制。
    所以你以为只要使用 brpoplpush 或者 REDIS_STREAM 就能自动轻易解决ack问题,那就太天真了,因为redis服务端不能像rabbitmq服务端那样天生自带自动重回宕机消费者的消息机制,需要你在redis客户端来维护实现这套机制.
    """
    REDIS = 'REDIS'  # 使用 redis 的 list结构，brpop 作为分布式消息队列。随意重启和关闭会丢失大量消息，不支持消费确认。注重性能不在乎丢失消息可以选这个redis方案。
    REDIS_ACK_ABLE = 'REDIS_ACK_ABLE'  # 基于redis的 list + 临时unack的set队列，采用了 lua脚本操持了取任务和加到pengding为原子性，,基于进程心跳消失判断消息是否为掉线进程的，随意重启和掉线不会丢失任务。
    REIDS_ACK_USING_TIMEOUT = 'reids_ack_using_timeout'  # 基于redis的 list + 临时unack的set队列，使用超时多少秒没确认消费就自动重回队列，请注意 ack_timeout的设置值和函数耗时大小，否则会发生反复重回队列的后果,boost可以设置ack超时，broker_exclusive_config={'ack_timeout': 1800}.缺点是无法区分执行太慢还是真宕机
    REDIS_PRIORITY = 'REDIS_PRIORITY'  # # 基于redis的多 list + 临时unack的set队列，blpop监听多个key，和rabbitmq的x-max-priority属性一样，支持任务优先级。看文档4.29优先级队列说明。
    REDIS_STREAM = 'REDIS_STREAM'  # 基于redis 5.0 版本以后，使用 stream 数据结构作为分布式消息队列，支持消费确认和持久化和分组消费，是redis官方推荐的消息队列形式，比list结构更适合。
    RedisBrpopLpush = 'RedisBrpopLpush'  # 基于redis的list结构但是采用 brpoplpush 双队列形式，和 redis_ack_able的实现差不多，实现上采用了原生命令就不需要lua脚本来实现取出和加入unack了。
    REDIS_PUBSUB = 'REDIS_PUBSUB'  # 基于redis 发布订阅的，发布一个消息多个消费者都能收到同一条消息，但不支持持久化

    MEMORY_QUEUE = 'MEMORY_QUEUE'  # 使用python queue.Queue实现的基于当前python进程的消息队列，不支持跨进程 跨脚本 跨机器共享任务，不支持持久化，适合一次性短期简单任务。
    LOCAL_PYTHON_QUEUE = MEMORY_QUEUE  # 别名，python本地queue就是基于python自带的语言的queue.Queue，消息存在python程序的内存中，不支持重启断点接续。

    RABBITMQ_PIKA = 'RABBITMQ_PIKA'  # 使用pika包操作rabbitmq  作为 分布式消息队列。，不建议使用

    MONGOMQ = 'MONGOMQ'  # 使用mongo的表中的行模拟的 作为分布式消息队列，支持消费确认。

    SQLITE_QUEUE = 'sqlite3'  # 使用基于sqlite3模拟消息队列，支持消费确认和持久化，但不支持跨机器共享任务，可以基于本机单机跨脚本和跨进程共享任务，好处是不需要安装中间件。
    PERSISTQUEUE = SQLITE_QUEUE  # PERSISTQUEUE的别名

    NSQ = 'NSQ'  # 基于nsq作为分布式消息队列，支持消费确认。

    KAFKA = 'KAFKA'  # 基于kafka作为分布式消息队列，如果随意重启会丢失消息，建议使用BrokerEnum.CONFLUENT_KAFKA。

    """基于confluent-kafka包，包的性能比kafka-python提升10倍。同时应对反复随意重启部署消费代码的场景，此消费者实现至少消费一次，第8种BrokerEnum.KAFKA是最多消费一次。"""
    KAFKA_CONFLUENT = 'KAFKA_CONFLUENT'
    CONFLUENT_KAFKA = KAFKA_CONFLUENT

    KAFKA_CONFLUENT_SASlPlAIN = 'KAFKA_CONFLUENT_SASlPlAIN'  # 可以设置账号密码的kafka

    SQLACHEMY = 'SQLACHEMY'  # 基于SQLACHEMY 的连接作为分布式消息队列中间件支持持久化和消费确认。支持mysql oracle sqlserver等5种数据库。

    ROCKETMQ = 'ROCKETMQ'  # 基于 rocketmq 作为分布式消息队列，这个中间件必须在linux下运行，win不支持。

    ZEROMQ = 'ZEROMQ'  # 基于zeromq作为分布式消息队列，不需要安装中间件，可以支持跨机器但不支持持久化。


    """
    kombu 和 celery 都是 funboost中的神级别broker_kind。
    使得funboost以逸待劳，支持kombu的所有现有和未来的消息队列。
    通过直接支持 kombu，funboost 相当于一瞬间就继承了 `kombu` 支持的所有现有和未来的消息队列能力。无论 kombu 社区未来增加了对哪种新的云消息服务（如 Google
    Pub/Sub、Azure Service Bus）或小众 MQ 的支持，funboost 无需修改自身代码，就能自动获得这种能力。这
    是一种“以逸待劳”的策略，极大地扩展了 funboost 的适用范围。

    kombu 包可以作为funboost的broker，这个包也是celery的中间件依赖包，这个包可以操作10种中间件(例如rabbitmq redis)，但没包括分布式函数调度框架的kafka nsq zeromq 等。
    同时 kombu 包的性能非常差，可以用原生redis的lpush和kombu的publish测试发布，使用brpop 和 kombu 的 drain_events测试消费，对比差距相差了5到10倍。
    由于性能差，除非是分布式函数调度框架没实现的中间件才选kombu方式(例如kombu支持亚马逊队列  qpid pyro 队列)，否则强烈建议使用此框架的操作中间件方式而不是使用kombu。
    """
    KOMBU = 'KOMBU'

    """ 基于emq作为中间件的。这个和上面的中间件有很大不同，服务端不存储消息。所以不能先发布几十万个消息，然后再启动消费。mqtt优点是web前后端能交互，
    前端不能操作redis rabbitmq kafka，但很方便操作mqtt。这种使用场景是高实时的互联网接口。
    """
    MQTT = 'MQTT'

    HTTPSQS = 'HTTPSQS'  # httpsqs中间件实现的，基于http协议操作，dcoker安装此中间件简单。

    PULSAR = 'PULSAR'  # 最有潜力的下一代分布式消息系统。5年后会同时取代rabbitmq和kafka。

    UDP = 'UDP'  # 基于socket udp 实现的，需要先启动消费端再启动发布，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。

    TCP = 'TCP'  # 基于socket tcp 实现的，需要先启动消费端再启动发布，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。

    HTTP = 'HTTP'  # 基于http实现的，发布使用的urllib3，消费服务端使用的aiohttp.server实现的，支持分布式但不支持持久化，好处是不需要安装消息队列中间件软件。

    GRPC = 'GRPC' # 使用知名grpc作为broker,可以使用 sync_call 方法同步获取grpc的结果, 简单程度暴击用户手写原生的 grpc客户端 服务端

    NATS = 'NATS'  # 高性能中间件nats,中间件服务端性能很好,。

    TXT_FILE = 'TXT_FILE'  # 磁盘txt文件作为消息队列，支持单机持久化，不支持多机分布式。不建议这个，用sqlite。

    PEEWEE = 'PEEWEE'  # peewee包操作mysql，使用表模拟消息队列

    CELERY = 'CELERY'  # funboost支持celery框架来发布和消费任务，由celery框架来调度执行任务，但是写法简单远远暴击用户亲自使用celery的麻烦程度，
    # 用户永无无需关心和操作Celery对象实例,无需关心celery的task_routes和includes配置,funboost来自动化设置这些celery配置。
    # funboost将Celery本身纳入了自己的Broker体系。能“吞下”另一个大型框架，简直太妙了。本身就证明了funboost架构的包容性和精妙性和复杂性。

    DRAMATIQ = 'DRAMATIQ'  # funboost使用 dramatiq 框架作为消息队列，dramatiq类似celery也是任务队列框架。用户使用funboost api来操作dramatiq核心调度。

    HUEY = 'HUEY'  # huey任务队列框架作为funboost调度核心

    RQ = 'RQ'  # rq任务队列框架作为funboost调度核心

    NAMEKO = 'NAMEKO'  # funboost支持python微服务框架nameko，用户无需掌握nameko api语法，就玩转python nameko微服务

    
    """
    MYSQL_CDC 是 funboost 中 神奇 的 与众不同的 broker 中间件
    mysql binlog cdc 自动作为消息,用户无需手动发布消息,只需要写处理binlog内容的逻辑, 
    一行代码就能轻量级实现 mysql2mysql mysql2kafka mysql2rabbitmq 等等.
    这个是与其他中间件不同,不需要手工发布消息, 任何对数据库的 insert update delete 会自动作为 funboost 的消息.
    几乎是轻量级平替 canal  flinkcdc 的作用.
    
    以此类推, 日志文件也能扩展作为broker,只要另外一个程序写入了文件日志,就能触发funboost消费,
    然后自己在函数逻辑把消息发到kafka,(虽然是已经有大名鼎鼎elk,这只是举个场景例子,说明funboost broker的灵活性)

    日志文件、文件系统变更（inotify）、甚至是硬件传感器的信号，按照4.21章节文档，都可以被封装成一个 funboost 的 Broker。

    充分说明 funboost 有能力化身为 通用的、事件驱动的函数调度平台,而非仅仅是celery这种传统的消息驱动.
    """
    """
    funboost 有能力消费canal发到kafka的binlog消息,也能不依赖canal,自己捕获cdc数据
    """
    MYSQL_CDC = 'MYSQL_CDC'



class ConcurrentModeEnum:
    THREADING = 'threading'  # 线程方式运行，兼容支持 async def 的异步函数。
    GEVENT = 'gevent'
    EVENTLET = 'eventlet'
    ASYNC = 'async'  # asyncio并发，适用于async def定义的函数。
    SINGLE_THREAD = 'single_thread'  # 如果你不想并发，不想预先从消息队列中间件拉取消息到python程序的内存queue队列缓冲中，那么就适合使用此并发模式。
    SOLO = SINGLE_THREAD


# is_fsdf_remote_run = 0

class FunctionKind:
    CLASS_METHOD = 'CLASS_METHOD'
    INSTANCE_METHOD = 'INSTANCE_METHOD'
    STATIC_METHOD = 'STATIC_METHOD'
    COMMON_FUNCTION = 'COMMON_FUNCTION'


class ConstStrForClassMethod:
    FIRST_PARAM_NAME = 'first_param_name'
    CLS_NAME = 'cls_name'
    OBJ_INIT_PARAMS = 'obj_init_params'
    CLS_MODULE = 'cls_module'
    CLS_FILE = 'cls_file'


class RedisKeys:

    REDIS_KEY_PAUSE_FLAG  = 'funboost_pause_flag' 
    REDIS_KEY_STOP_FLAG = 'funboost_stop_flag'
    QUEUE__MSG_COUNT_MAP = 'funboost_queue__msg_count_map'
    FUNBOOST_QUEUE__CONSUMER_PARAMS= 'funboost_queue__consumer_parmas'
    FUNBOOST_QUEUE__RUN_COUNT_MAP = 'funboost_queue__run_count_map'
    FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP = 'funboost_queue__run_fail_count_map'
    FUNBOOST_ALL_QUEUE_NAMES = 'funboost_all_queue_names'
    FUNBOOST_ALL_IPS = 'funboost_all_ips'
    FUNBOOST_ALL_PROJECT_NAMES = 'funboost_all_project_names'
    FUNBOOST_LAST_GET_QUEUES_PARAMS_AND_ACTIVE_CONSUMERS_AND_REPORT__UUID_TS = 'funboost_last_get_queues_params_and_active_consumers_and_report__uuid_ts'

    FUNBOOST_HEARTBEAT_QUEUE__DICT_PREFIX = 'funboost_hearbeat_queue__dict:'
    FUNBOOST_HEARTBEAT_SERVER__DICT_PREFIX = 'funboost_hearbeat_server__dict:'


    @staticmethod
    def gen_funboost_apscheduler_redis_lock_key_by_queue_name(queue_name):
        return f'funboost.BackgroundSchedulerProcessJobsWithinRedisLock:{queue_name}'

    @staticmethod
    def gen_funboost_hearbeat_queue__dict_key_by_queue_name(queue_name):
        return f'{RedisKeys.FUNBOOST_HEARTBEAT_QUEUE__DICT_PREFIX}{queue_name}'

    @staticmethod
    def gen_funboost_hearbeat_server__dict_key_by_ip(ip):
        return f'{RedisKeys.FUNBOOST_HEARTBEAT_SERVER__DICT_PREFIX}{ip}'
    
    @staticmethod
    def gen_funboost_queue_time_series_data_key_by_queue_name(queue_name):
        return f'funboost_queue_time_series_data:{queue_name}'
    
    @staticmethod
    def gen_funboost_redis_apscheduler_jobs_key_by_queue_name(queue_name):
        jobs_key=f'funboost.apscheduler.jobs:{queue_name}'
        return jobs_key
    
    @staticmethod
    def gen_funboost_redis_apscheduler_run_times_key_by_queue_name(queue_name):
        run_times_key=f'funboost.apscheduler.run_times:{queue_name}'
        return run_times_key

    @staticmethod
    def gen_funboost_project_name_key(project_name):
        prject_name_key = f'funboost.project_name:{project_name}'
        return prject_name_key

class ConsumingFuncInputParamsCheckerField:
    is_manual_func_input_params = 'is_manual_func_input_params'
    all_arg_name_list = 'all_arg_name_list'
    must_arg_name_list = 'must_arg_name_list'
    optional_arg_name_list = 'optional_arg_name_list'
    func_name = 'func_name' 
    func_position = 'func_position'
    

class MongoDbName:
    TASK_STATUS_DB = 'funboost_task_status'
    MONGOMQ_DB ='funboost_mongomq'

class StrConst:
    BOOSTER_REGISTRY_NAME_DEFAULT = 'booster_registry_default'

class EnvConst:
    FUNBOOST_FAAS_CARE_PROJECT_NAME = 'funboost.faas.care_project_name'
    FUNBOOST_FAAS_IS_USE_LOCAL_BOOSTER = 'funboost.faas.is_use_local_booster'
`````

--- **end of file: funboost/constant.py** (project: funboost) --- 

---


--- **start of file: funboost/funboost_config_deafult.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/funboost_config_deafult.py`

#### 📦 Imports

- `import logging`
- `from pathlib import Path`
- `from funboost.utils.simple_data_class import DataClassBase`
- `from nb_log import nb_log_config_default`

#### 🏛️ Classes (2)

##### 📌 `class BrokerConnConfig(DataClassBase)`
*Line: 21*

**Docstring:**
`````
中间件连接配置
此文件按需修改，例如你使用redis中间件作为消息队列，可以不用管rabbitmq mongodb kafka啥的配置。
但有3个功能例外，如果你需要使用rpc模式或者分布式控频或者任务过滤功能，无论设置使用何种消息队列中间件都需要把redis连接配置好，
如果@boost装饰器设置is_using_rpc_mode为True或者 is_using_distributed_frequency_control为True或do_task_filtering=True则需要把redis连接配置好，默认是False不强迫用户安装redis。
`````

**Class Variables (40):**
- `MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'`
- `RABBITMQ_USER = 'rabbitmq_user'`
- `RABBITMQ_PASS = 'rabbitmq_pass'`
- `RABBITMQ_HOST = '127.0.0.1'`
- `RABBITMQ_PORT = 5672`
- `RABBITMQ_VIRTUAL_HOST = ''`
- `RABBITMQ_URL = f'amqp://{RABBITMQ_USER}:{RABBITMQ_PASS}@{RABBITMQ_HOST}:{RABBITMQ_PORT}/{RABBITMQ_VIRTUAL_HOST}'`
- `REDIS_HOST = '127.0.0.1'`
- `REDIS_USERNAME = ''`
- `REDIS_PASSWORD = ''`
- `REDIS_PORT = 6379`
- `REDIS_DB = 7`
- `REDIS_DB_FILTER_AND_RPC_RESULT = 8`
- `REDIS_SSL = False`
- `REDIS_URL = f"{('rediss' if REDIS_SSL else 'redis')}://{REDIS_USERNAME}:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}"`
- `NSQD_TCP_ADDRESSES = ['127.0.0.1:4150']`
- `NSQD_HTTP_CLIENT_HOST = '127.0.0.1'`
- `NSQD_HTTP_CLIENT_PORT = 4151`
- `KAFKA_BOOTSTRAP_SERVERS = ['127.0.0.1:9092']`
- `KFFKA_SASL_CONFIG = {'bootstrap_servers': KAFKA_BOOTSTRAP_SERVERS, 'sasl_plain_username': '', 'sasl_plain_password': '', 'sasl_mechanism': 'SCRAM-SHA-256', 'security_protocol': 'SASL_PLAINTEXT'}`
- `SQLACHEMY_ENGINE_URL = 'sqlite:////sqlachemy_queues/queues.db'`
- `MYSQL_HOST = '127.0.0.1'`
- `MYSQL_PORT = 3306`
- `MYSQL_USER = 'root'`
- `MYSQL_PASSWORD = '123456'`
- `MYSQL_DATABASE = 'testdb6'`
- `SQLLITE_QUEUES_PATH = '/sqllite_queues'`
- `TXT_FILE_PATH = Path(__file__).parent / 'txt_queues'`
- `ROCKETMQ_NAMESRV_ADDR = '192.168.199.202:9876'`
- `MQTT_HOST = '127.0.0.1'`
- `MQTT_TCP_PORT = 1883`
- `HTTPSQS_HOST = '127.0.0.1'`
- `HTTPSQS_PORT = 1218`
- `HTTPSQS_AUTH = '123456'`
- `NATS_URL = 'nats://192.168.6.134:4222'`
- `KOMBU_URL = 'redis://127.0.0.1:6379/9'`
- `CELERY_BROKER_URL = 'redis://127.0.0.1:6379/12'`
- `CELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/13'`
- `DRAMATIQ_URL = RABBITMQ_URL`
- `PULSAR_URL = 'pulsar://192.168.70.128:6650'`

##### 📌 `class FunboostCommonConfig(DataClassBase)`
*Line: 96*

**Class Variables (5):**
- `NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = logging.Formatter(f'%(asctime)s-({nb_log_config_default.computer_ip},{nb_log_config_default.computer_name})-[p%(process)d_t%(thread)d] - %(name)s - "%(filename)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(task_id)s - %(message)s', '%Y-%m-%d %H:%M:%S')`
- `TIMEZONE = 'Asia/Shanghai'`
- `SHOW_HOW_FUNBOOST_CONFIG_SETTINGS = True`
- `FUNBOOST_PROMPT_LOG_LEVEL = logging.DEBUG`
- `KEEPALIVETIMETHREAD_LOG_LEVEL = logging.DEBUG`


---

`````python
# -*- coding: utf-8 -*-
import logging
from pathlib import Path
from funboost.utils.simple_data_class import DataClassBase
from nb_log import nb_log_config_default

'''
funboost_config.py 文件是第一次运行框架自动生成到你的项目根目录的，不需要用由户手动创建。
此文件里面可以写任意python代码。例如 中间件 帐号 密码自己完全可以从apola配置中心获取或者从环境变量获取。
'''

'''
你项目根目录下自动生成的 funboost_config.py 文件中修改配置，会被自动读取到。
用户不要动修改框架的源码 funboost/funboost_config_deafult.py 中的代码，此模块的变量会自动被 funboost_config.py 覆盖。
funboost/funboost_config_deafult.py配置覆盖逻辑可看funboost/set_frame_config.py中的代码.

框架使用文档是 https://funboost.readthedocs.io/zh_CN/latest/
'''


class BrokerConnConfig(DataClassBase):
    """
    中间件连接配置
    此文件按需修改，例如你使用redis中间件作为消息队列，可以不用管rabbitmq mongodb kafka啥的配置。
    但有3个功能例外，如果你需要使用rpc模式或者分布式控频或者任务过滤功能，无论设置使用何种消息队列中间件都需要把redis连接配置好，
    如果@boost装饰器设置is_using_rpc_mode为True或者 is_using_distributed_frequency_control为True或do_task_filtering=True则需要把redis连接配置好，默认是False不强迫用户安装redis。
    """

    MONGO_CONNECT_URL = f'mongodb://127.0.0.1:27017'  # 如果有密码连接 'mongodb://myUserAdmin:XXXXX@192.168.199.202:27016/'   authSource 指定鉴权db，MONGO_CONNECT_URL = 'mongodb://root:123456@192.168.64.151:27017?authSource=admin'

    RABBITMQ_USER = 'rabbitmq_user'
    RABBITMQ_PASS = 'rabbitmq_pass'
    RABBITMQ_HOST = '127.0.0.1'
    RABBITMQ_PORT = 5672
    RABBITMQ_VIRTUAL_HOST = ''  # my_host # 这个是rabbitmq的虚拟子host用户自己创建的，如果你想直接用rabbitmq的根host而不是使用虚拟子host，这里写 空字符串 即可。
    RABBITMQ_URL = f'amqp://{RABBITMQ_USER}:{RABBITMQ_PASS}@{RABBITMQ_HOST}:{RABBITMQ_PORT}/{RABBITMQ_VIRTUAL_HOST}'

    REDIS_HOST = '127.0.0.1'
    REDIS_USERNAME = ''
    REDIS_PASSWORD = ''
    REDIS_PORT = 6379
    REDIS_DB = 7  # redis消息队列所在db，请不要在这个db放太多其他键值对，以及方便你自己可视化查看你的redis db，框架里面有的功能会scan扫描unacked的键名，使用单独的db。
    REDIS_DB_FILTER_AND_RPC_RESULT = 8  # 如果函数做任务参数过滤 或者使用rpc获取结果，使用这个db，因为这个db的键值对多，和redis消息队列db分开
    REDIS_SSL = False # 是否使用ssl加密,默认是False
    REDIS_URL = f'{"rediss" if REDIS_SSL else "redis"}://{REDIS_USERNAME}:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'

    NSQD_TCP_ADDRESSES = ['127.0.0.1:4150']
    NSQD_HTTP_CLIENT_HOST = '127.0.0.1'
    NSQD_HTTP_CLIENT_PORT = 4151

    KAFKA_BOOTSTRAP_SERVERS = ['127.0.0.1:9092']
    KFFKA_SASL_CONFIG = {
        "bootstrap_servers": KAFKA_BOOTSTRAP_SERVERS,
        "sasl_plain_username": "",
        "sasl_plain_password": "",
        "sasl_mechanism": "SCRAM-SHA-256",
        "security_protocol": "SASL_PLAINTEXT",
    }

    SQLACHEMY_ENGINE_URL = 'sqlite:////sqlachemy_queues/queues.db'

    # 如果broker_kind 使用 peewee 中间件模式会使用mysql配置
    MYSQL_HOST = '127.0.0.1'
    MYSQL_PORT = 3306
    MYSQL_USER = 'root'
    MYSQL_PASSWORD = '123456'
    MYSQL_DATABASE = 'testdb6'

    # persist_quque中间件时候采用本机sqlite的方式，数据库文件生成的位置,如果linux账号在根目录没权限建文件夹，可以换文件夹。
    SQLLITE_QUEUES_PATH = '/sqllite_queues'

    TXT_FILE_PATH = Path(__file__).parent / 'txt_queues'  # 不建议使用这个txt模拟消息队列中间件，本地持久化优先选择 PERSIST_QUQUE 中间件。

    ROCKETMQ_NAMESRV_ADDR = '192.168.199.202:9876'

    MQTT_HOST = '127.0.0.1'
    MQTT_TCP_PORT = 1883

    HTTPSQS_HOST = '127.0.0.1'
    HTTPSQS_PORT = 1218
    HTTPSQS_AUTH = '123456'

    NATS_URL = 'nats://192.168.6.134:4222'

    KOMBU_URL = 'redis://127.0.0.1:6379/9'  # 这个就是celery依赖包kombu使用的消息队列格式，所以funboost支持一切celery支持的消息队列种类。
    # KOMBU_URL =  'sqla+sqlite:////dssf_kombu_sqlite.sqlite'  # 4个//// 代表磁盘根目录下生成一个文件。推荐绝对路径。3个///是相对路径。

    CELERY_BROKER_URL = 'redis://127.0.0.1:6379/12'  # 使用celery作为中间件。funboost新增支持celery框架来运行函数,url内容就是celery的broker形式.
    CELERY_RESULT_BACKEND = 'redis://127.0.0.1:6379/13'  # celery结果存放，可以为None

    DRAMATIQ_URL = RABBITMQ_URL

    PULSAR_URL = 'pulsar://192.168.70.128:6650'


class FunboostCommonConfig(DataClassBase):
    # nb_log包的第几个日志模板，内置了7个模板，可以在你当前项目根目录下的nb_log_config.py文件扩展模板。
    # NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = 11  # 7是简短的不可跳转，5是可点击跳转的，11是可显示ip 进程 线程的模板,也可以亲自设置日志模板不传递数字。
    NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER = logging.Formatter(
        f'%(asctime)s-({nb_log_config_default.computer_ip},{nb_log_config_default.computer_name})-[p%(process)d_t%(thread)d] - %(name)s - "%(filename)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(task_id)s - %(message)s',
        "%Y-%m-%d %H:%M:%S",)   # 这个是带task_id的日志模板,日志可以显示task_id,方便用户串联起来排查某一个任务消息的所有日志.

    TIMEZONE = 'Asia/Shanghai'  # 时区

    # 以下配置是修改funboost的一些命名空间和启动时候的日志级别,新手不熟练就别去屏蔽日志了
    SHOW_HOW_FUNBOOST_CONFIG_SETTINGS = True  # 如果你单纯想屏蔽 "分布式函数调度框架会自动导入funboost_config模块当第一次运行脚本时候，函数调度框架会在你的python当前项目的根目录下 ...... "  这句话,
    FUNBOOST_PROMPT_LOG_LEVEL = logging.DEBUG  # funboost启动时候的相关提示语,用户可以设置这个命名空间的日志级别来调整
    KEEPALIVETIMETHREAD_LOG_LEVEL = logging.DEBUG  # funboost的作者发明的可缩小自适应线程池,用户对可变线程池的线程创建和销毁线程完全无兴趣,可以提高日志级别.

`````

--- **end of file: funboost/funboost_config_deafult.py** (project: funboost) --- 

---


--- **start of file: funboost/README.md** (project: funboost) --- 

`````markdown
用法见README.md和test_frame的例子。
`````

--- **end of file: funboost/README.md** (project: funboost) --- 

---


--- **start of file: funboost/set_frame_config.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/set_frame_config.py`

#### 📝 Module Docstring

`````
使用覆盖的方式，做配置。
`````

#### 📦 Imports

- `import sys`
- `import time`
- `import importlib`
- `import json`
- `from pathlib import Path`
- `from shutil import copyfile`
- `from funboost.core.funboost_config_getter import _try_get_user_funboost_common_config`
- `from funboost.core.loggers import flogger`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.loggers import logger_prompt`
- `from nb_log import nb_print`
- `from nb_log import stderr_write`
- `from nb_log import stdout_write`
- `from nb_log.monkey_print import is_main_process`
- `from nb_log.monkey_print import only_print_on_main_process`
- `from funboost import funboost_config_deafult`

#### 🔧 Public Functions (4)

- `def show_funboost_flag()`
  - *Line: 22*

- `def dict2json(dictx: dict, indent = 4)`
  - *Line: 72*

- `def show_frame_config()`
  - *Line: 83*

- `def use_config_form_funboost_config_module()`
  - *Line: 109*
  - **Docstring:**
  `````
  自动读取配置。会优先读取启动脚本的目录的funboost_config.py文件。没有则读取项目根目录下的funboost_config.py
  :return:
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/4/11 0011 0:56
"""

使用覆盖的方式，做配置。
"""
import sys
import time
import importlib
import json
from pathlib import Path
from shutil import copyfile

from funboost.core.funboost_config_getter import _try_get_user_funboost_common_config
from funboost.core.loggers import flogger, get_funboost_file_logger, logger_prompt
from nb_log import nb_print, stderr_write, stdout_write
from nb_log.monkey_print import is_main_process, only_print_on_main_process
from funboost import funboost_config_deafult


def show_funboost_flag():
    funboost_flag_str = '''


    FFFFFFFFFFFFFFFFFFFFFF     UUUUUUUU     UUUUUUUU     NNNNNNNN        NNNNNNNN     BBBBBBBBBBBBBBBBB             OOOOOOOOO               OOOOOOOOO             SSSSSSSSSSSSSSS      TTTTTTTTTTTTTTTTTTTTTTT
    F::::::::::::::::::::F     U::::::U     U::::::U     N:::::::N       N::::::N     B::::::::::::::::B          OO:::::::::OO           OO:::::::::OO         SS:::::::::::::::S     T:::::::::::::::::::::T
    F::::::::::::::::::::F     U::::::U     U::::::U     N::::::::N      N::::::N     B::::::BBBBBB:::::B       OO:::::::::::::OO       OO:::::::::::::OO      S:::::SSSSSS::::::S     T:::::::::::::::::::::T
    FF::::::FFFFFFFFF::::F     UU:::::U     U:::::UU     N:::::::::N     N::::::N     BB:::::B     B:::::B     O:::::::OOO:::::::O     O:::::::OOO:::::::O     S:::::S     SSSSSSS     T:::::TT:::::::TT:::::T
      F:::::F       FFFFFF      U:::::U     U:::::U      N::::::::::N    N::::::N       B::::B     B:::::B     O::::::O   O::::::O     O::::::O   O::::::O     S:::::S                 TTTTTT  T:::::T  TTTTTT
      F:::::F                   U:::::D     D:::::U      N:::::::::::N   N::::::N       B::::B     B:::::B     O:::::O     O:::::O     O:::::O     O:::::O     S:::::S                         T:::::T        
      F::::::FFFFFFFFFF         U:::::D     D:::::U      N:::::::N::::N  N::::::N       B::::BBBBBB:::::B      O:::::O     O:::::O     O:::::O     O:::::O      S::::SSSS                      T:::::T        
      F:::::::::::::::F         U:::::D     D:::::U      N::::::N N::::N N::::::N       B:::::::::::::BB       O:::::O     O:::::O     O:::::O     O:::::O       SS::::::SSSSS                 T:::::T        
      F:::::::::::::::F         U:::::D     D:::::U      N::::::N  N::::N:::::::N       B::::BBBBBB:::::B      O:::::O     O:::::O     O:::::O     O:::::O         SSS::::::::SS               T:::::T        
      F::::::FFFFFFFFFF         U:::::D     D:::::U      N::::::N   N:::::::::::N       B::::B     B:::::B     O:::::O     O:::::O     O:::::O     O:::::O            SSSSSS::::S              T:::::T        
      F:::::F                   U:::::D     D:::::U      N::::::N    N::::::::::N       B::::B     B:::::B     O:::::O     O:::::O     O:::::O     O:::::O                 S:::::S             T:::::T        
      F:::::F                   U::::::U   U::::::U      N::::::N     N:::::::::N       B::::B     B:::::B     O::::::O   O::::::O     O::::::O   O::::::O                 S:::::S             T:::::T        
    FF:::::::FF                 U:::::::UUU:::::::U      N::::::N      N::::::::N     BB:::::BBBBBB::::::B     O:::::::OOO:::::::O     O:::::::OOO:::::::O     SSSSSSS     S:::::S           TT:::::::TT      
    F::::::::FF                  UU:::::::::::::UU       N::::::N       N:::::::N     B:::::::::::::::::B       OO:::::::::::::OO       OO:::::::::::::OO      S::::::SSSSSS:::::S           T:::::::::T      
    F::::::::FF                    UU:::::::::UU         N::::::N        N::::::N     B::::::::::::::::B          OO:::::::::OO           OO:::::::::OO        S:::::::::::::::SS            T:::::::::T      
    FFFFFFFFFFF                      UUUUUUUUU           NNNNNNNN         NNNNNNN     BBBBBBBBBBBBBBBBB             OOOOOOOOO               OOOOOOOOO           SSSSSSSSSSSSSSS              TTTTTTTTTTT      


    '''

    funboost_flag_str2 = r'''

          ___                  ___                    ___                                           ___                    ___                    ___                          
         /  /\                /__/\                  /__/\                  _____                  /  /\                  /  /\                  /  /\                   ___   
        /  /:/_               \  \:\                 \  \:\                /  /::\                /  /::\                /  /::\                /  /:/_                 /  /\  
       /  /:/ /\               \  \:\                 \  \:\              /  /:/\:\              /  /:/\:\              /  /:/\:\              /  /:/ /\               /  /:/  
      /  /:/ /:/           ___  \  \:\            _____\__\:\            /  /:/~/::\            /  /:/  \:\            /  /:/  \:\            /  /:/ /::\             /  /:/   
     /__/:/ /:/           /__/\  \__\:\          /__/::::::::\          /__/:/ /:/\:|          /__/:/ \__\:\          /__/:/ \__\:\          /__/:/ /:/\:\           /  /::\   
     \  \:\/:/            \  \:\ /  /:/          \  \:\~~\~~\/          \  \:\/:/~/:/          \  \:\ /  /:/          \  \:\ /  /:/          \  \:\/:/~/:/          /__/:/\:\  
      \  \::/              \  \:\  /:/            \  \:\  ~~~            \  \::/ /:/            \  \:\  /:/            \  \:\  /:/            \  \::/ /:/           \__\/  \:\ 
       \  \:\               \  \:\/:/              \  \:\                 \  \:\/:/              \  \:\/:/              \  \:\/:/              \__\/ /:/                 \  \:\
        \  \:\               \  \::/                \  \:\                 \  \::/                \  \::/                \  \::/                 /__/:/                   \__\/
         \__\/                \__\/                  \__\/                  \__\/                  \__\/                  \__\/                  \__\/                         



    '''

    logger_prompt.debug('\033[0m' + funboost_flag_str2 + '\033[0m')

    logger_prompt.debug(f'''分布式函数调度框架funboost文档地址：  \033[0m https://funboost.readthedocs.io/zh-cn/latest/ \033[0m ''')


show_funboost_flag()


def dict2json(dictx: dict, indent=4):
    dict_new = {}
    for k, v in dictx.items():
        # only_print_on_main_process(f'{k} :  {v}')
        if isinstance(v, (bool, tuple, dict, float, int)):
            dict_new[k] = v
        else:
            dict_new[k] = str(v)
    return json.dumps(dict_new, ensure_ascii=False, indent=indent)


def show_frame_config():
    if is_main_process():
        logger_prompt.debug('显示当前的项目中间件配置参数')
        # for var_name in dir(funboost_config_deafult):
        #     if var_name.isupper():
        #         var_value = getattr(funboost_config_deafult, var_name)
        #         if var_name == 'MONGO_CONNECT_URL':
        #             if re.match('mongodb://.*?:.*?@.*?/.*', var_value):
        #                 mongo_pass = re.search('mongodb://.*?:(.*?)@', var_value).group(1)
        #                 mongo_pass_encryption = f'{"*" * (len(mongo_pass) - 2)}{mongo_pass[-1]}' if len(
        #                     mongo_pass) > 3 else mongo_pass
        #                 var_value_encryption = re.sub(r':(\w+)@', f':{mongo_pass_encryption}@', var_value)
        #                 only_print_on_main_process(f'{var_name}:             {var_value_encryption}')
        #                 continue
        #         if 'PASS' in var_name and var_value is not None and len(var_value) > 3:  # 对密码打*
        #             only_print_on_main_process(f'{var_name}:                {var_value[0]}{"*" * (len(var_value) - 2)}{var_value[-1]}')
        #         else:
        #             only_print_on_main_process(f'{var_name}:                {var_value}')
        logger_prompt.debug(f'''读取的 BrokerConnConfig 配置是:\n {funboost_config_deafult.BrokerConnConfig().get_pwd_enc_json(indent=4)} ''')

        logger_prompt.debug(f'''读取的 FunboostCommonConfig 配置是:\n  {funboost_config_deafult.FunboostCommonConfig().get_json(indent=4)} ''')

    # only_print_on_main_process(f'读取的 BoostDecoratorDefaultParams 默认 @boost 装饰器入参的默认全局配置是： \n  '
    #                            f'{funboost_config_deafult.BoostDecoratorDefaultParams().get_json()}')


def use_config_form_funboost_config_module():
    """
    自动读取配置。会优先读取启动脚本的目录的funboost_config.py文件。没有则读取项目根目录下的funboost_config.py
    :return:
    """
    current_script_path = sys.path[0].replace('\\', '/')
    project_root_path = sys.path[1].replace('\\', '/')
    inspect_msg = f"""
    分布式函数调度框架会自动导入funboost_config模块
    当第一次运行脚本时候，函数调度框架会在你的python当前项目的根目录下 {project_root_path} 下，创建一个名为 funboost_config.py 的文件。
    自动读取配置，会优先读取启动脚本的所在目录 {current_script_path} 的funboost_config.py文件，
    如果没有 {current_script_path}/funboost_config.py 文件，则读取项目根目录 {project_root_path} 下的funboost_config.py做配置。
    只要 funboost_config.py 在任意 PYTHONPATH 的文件夹下，就能自动读取到。
    在 "{project_root_path}/funboost_config.py:1" 文件中，需要按需重新设置要使用到的中间件的键和值，例如没有使用rabbitmq而是使用redis做中间件，则不需要配置rabbitmq。
    """
    # sys.stdout.write(f'\033[0;33m{time.strftime("%H:%M:%S")}\033[0m  "{__file__}:{sys._getframe().f_lineno}"   \033[0;30;43m{inspect_msg}\033[0m\n')
    # noinspection PyProtectedMember
    if is_main_process() and _try_get_user_funboost_common_config('SHOW_HOW_FUNBOOST_CONFIG_SETTINGS') in (True, None):
        logger_prompt.debug(f'\033[0;93m{time.strftime("%H:%M:%S")}\033[0m  "{__file__}:{sys._getframe().f_lineno}"   \033[0;93;100m{inspect_msg}\033[0m\n')
    try:
        # noinspection PyUnresolvedReferences
        # import funboost_config
        m = importlib.import_module('funboost_config')
        importlib.reload(m)  # 这行是防止用户在导入框架之前，写了 from funboost_config import REDIS_HOST 这种，导致 m.__dict__.items() 不包括所有配置变量了。
        # print(dir(m))
        # nb_print(m.__dict__.items())
        if is_main_process():
            logger_prompt.debug(f'分布式函数调度框架 读取到\n "{m.__file__}:1" 文件里面的变量作为优先配置了\n')
        if not hasattr(m, 'BrokerConnConfig'):
            raise EnvironmentError(f'funboost 30.0版本升级了配置文件，中间件配置写成了类，请删除原来老的funboost_config.py配置文件:\n "{m.__file__}:1"')
        funboost_config_deafult.BrokerConnConfig.update_cls_attribute(**m.BrokerConnConfig().get_dict())
        funboost_config_deafult.FunboostCommonConfig.update_cls_attribute(**m.FunboostCommonConfig().get_dict())
        # funboost_config_deafult.BoostDecoratorDefaultParams.update_cls_attribute(**m.BoostDecoratorDefaultParams().get_dict())
        if hasattr(m, 'BoostDecoratorDefaultParams'):
            raise ValueError('funboost 40.0版本之后，采用 pydantic model BoostParams类或子类入参，不支持 funboost_config.py的 BoostDecoratorDefaultParams 配置,请删除掉 BoostDecoratorDefaultParams 这个配置')


    except ModuleNotFoundError:
        nb_print(
            f'''分布式函数调度框架检测到 你的项目根目录 {project_root_path} 和当前文件夹 {current_script_path}  下没有 funboost_config.py 文件，\n''')
        _auto_creat_config_file_to_project_root_path()
    else:
        show_frame_config()
        # print(getattr(m,'BoostDecoratorDefaultParams')().get_dict())


def _auto_creat_config_file_to_project_root_path():
    """
    在没有使用pycahrm运行代码时候，如果实在cmd 或者 linux 运行， python xx.py，
    请在临时会话窗口设置linux export PYTHONPATH=你的项目根目录 ，winwdos set PYTHONPATH=你的项目根目录
    :return:
    """
    # print(Path(sys.path[1]).as_posix())
    # print((Path(__file__).parent.parent).absolute().as_posix())
    # if Path(sys.path[1]).as_posix() in Path(__file__).parent.parent.absolute().as_posix():
    #     nb_print('不希望在本项目里面创建')
    #     return
    if '/lib/python' in sys.path[1] or r'\lib\python' in sys.path[1] or '.zip' in sys.path[1]:
        raise EnvironmentError(f'''如果是cmd 或者shell启动而不是pycharm 这种ide启动脚本，请先在会话窗口设置临时PYTHONPATH为你的项目路径，
                               windwos cmd 使用 set PYTHONNPATH=你的当前python项目根目录,
                               windows powershell 使用 $env:PYTHONPATH=你的当前python项目根目录,
                               linux 使用 export PYTHONPATH=你的当前你python项目根目录,
                               PYTHONPATH 作用是python的基本常识，请百度一下。
                               需要在会话窗口命令行设置临时的环境变量，而不是修改linux配置文件的方式设置永久环境变量，每个python项目的PYTHONPATH都要不一样，不要在配置文件写死
                               
                               懂PYTHONPATH 的重要性和妙用见： https://github.com/ydf0509/pythonpathdemo
                               ''')
        return  # 当没设置pythonpath时候，也不要在 /lib/python36.zip这样的地方创建配置文件。

    file_name = Path(sys.path[1]) / Path('funboost_config.py')
    copyfile(Path(__file__).absolute().parent / Path('funboost_config_deafult.py'), file_name)
    nb_print(f'在  {Path(sys.path[1])} 目录下自动生成了一个文件， 请刷新文件夹查看或修改 \n "{file_name}:1" 文件')
    # with (file_name).open(mode='w', encoding='utf8') as f:
    #     nb_print(f'在 {file_name} 目录下自动生成了一个文件， 请查看或修改 \n "{file_name}:1" 文件')
    #     f.write(config_file_content)

    file_name = Path(sys.path[1]) / Path('funboost_cli_user.py')
    copyfile(Path(__file__).absolute().parent / Path('core/cli/funboost_cli_user_templ.py'), file_name)


use_config_form_funboost_config_module()

`````

--- **end of file: funboost/set_frame_config.py** (project: funboost) --- 

---


--- **start of file: funboost/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/__init__.py`

#### 📦 Imports

- `import atexit`
- `import nb_log`
- `from nb_log import nb_print`
- `from funboost.set_frame_config import show_frame_config`
- `from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath as _`
- `from funboost.utils import monkey_patches as _`
- `from funboost.core.loggers import get_logger`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import FunboostMetaTypeFileLogger`
- `from funboost.core.loggers import flogger`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import BoosterParamsComplete`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParamsComplete`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.utils.paramiko_util import ParamikoFolderUploader`
- `from funboost.consumers.base_consumer import wait_for_possible_has_finish_all_tasks_by_conusmer_list`
- `from funboost.consumers.base_consumer import FunctionResultStatus`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.consumers.empty_consumer import EmptyConsumer`
- `from funboost.core.exceptions import ExceptionForRetry`
- `from funboost.core.exceptions import ExceptionForRequeue`
- `from funboost.core.exceptions import ExceptionForPushToDlxqueue`
- `from funboost.core.active_cousumer_info_getter import ActiveCousumerProcessInfoGetter`
- `from funboost.core.msg_result_getter import HasNotAsyncResult`
- `from funboost.core.msg_result_getter import ResultFromMongo`
- `from funboost.publishers.base_publisher import TaskOptions`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import AsyncResult`
- `from funboost.publishers.base_publisher import AioAsyncResult`
- `from funboost.publishers.empty_publisher import EmptyPublisher`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import register_custom_broker`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.factories.consumer_factory import get_consumer`
- `from funboost.timing_job import funboost_aps_scheduler`
- `from funboost.timing_job.timing_push import ApsJobAdder`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.core.booster import boost`
- `from funboost.core.booster import Booster`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.kill_remote_task import RemoteTaskKiller`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.core.cli.discovery_boosters import BoosterDiscovery`
- `from funboost.core.helper_funs import run_forever`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.concurrent_pool.custom_threadpool_executor import show_current_threads_num`
- `from funboost.core.current_task import funboost_current_task`
- `from funboost.core.current_task import fct`
- `from funboost.core.current_task import get_current_taskid`


---

`````python
# noinspection PyUnresolvedReferences
import atexit

import nb_log
# noinspection PyUnresolvedReferences
from nb_log import nb_print

'''
set_frame_config 这行要放在所有导入其他代码之前最好,以便防止其他项目提前 from funboost.funboost_config_deafult import xx ,
如果是 from funboost import funboost_config_deafult,在函数内部使用他的配置就没事,但最后不要让其他模块在 set_frame_config 之前导入.
set_frame_config这个模块的 use_config_form_funboost_config_module() 是核心,把用户的funboost_config.py的配置覆盖到funboost_config_deafult模块了

这段注释说明和使用的用户无关,只和框架开发人员有关.
'''

__version__ = "53.0"

from funboost.set_frame_config import show_frame_config

# noinspection PyUnresolvedReferences
from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath as _  # 这是把 dependency_packages_in_pythonpath 添加到 PYTHONPATH了。
from funboost.utils import monkey_patches as _

from funboost.core.loggers import get_logger, get_funboost_file_logger, FunboostFileLoggerMixin, FunboostMetaTypeFileLogger, flogger
from funboost.core.func_params_model import (BoosterParams, BoosterParamsComplete, FunctionResultStatusPersistanceConfig,
                                             TaskOptions, PublisherParams, BoosterParamsComplete)
from funboost.funboost_config_deafult import FunboostCommonConfig, BrokerConnConfig

# from funboost.core.fabric_deploy_helper import fabric_deploy, kill_all_remote_tasks # fabric2还没适配python3.12以上版本，不在这里导入，否则高版本python报错。
from funboost.utils.paramiko_util import ParamikoFolderUploader

from funboost.consumers.base_consumer import (wait_for_possible_has_finish_all_tasks_by_conusmer_list,
                                              FunctionResultStatus, AbstractConsumer)
from funboost.consumers.empty_consumer import EmptyConsumer
from funboost.core.exceptions import ExceptionForRetry, ExceptionForRequeue, ExceptionForPushToDlxqueue
from funboost.core.active_cousumer_info_getter import ActiveCousumerProcessInfoGetter
from funboost.core.msg_result_getter import HasNotAsyncResult, ResultFromMongo
from funboost.publishers.base_publisher import (TaskOptions,
                                                AbstractPublisher, AsyncResult, AioAsyncResult)
from funboost.publishers.empty_publisher import EmptyPublisher
from funboost.factories.broker_kind__publsiher_consumer_type_map import register_custom_broker
from funboost.factories.publisher_factotry import get_publisher
from funboost.factories.consumer_factory import get_consumer

from funboost.timing_job import funboost_aps_scheduler #,ApsJobAdder
from funboost.timing_job.timing_push import ApsJobAdder

from funboost.constant import BrokerEnum, ConcurrentModeEnum

from funboost.core.booster import boost, Booster, BoostersManager
# from funboost.core.get_booster import get_booster, get_or_create_booster, get_boost_params_and_consuming_function
from funboost.core.kill_remote_task import RemoteTaskKiller
from funboost.funboost_config_deafult import BrokerConnConfig, FunboostCommonConfig
from funboost.core.cli.discovery_boosters import BoosterDiscovery

# from funboost.core.exit_signal import set_interrupt_signal_handler
from funboost.core.helper_funs import run_forever

from funboost.utils.ctrl_c_end import ctrl_c_recv
from funboost.utils.redis_manager import RedisMixin
from funboost.concurrent_pool.custom_threadpool_executor import show_current_threads_num

from funboost.core.current_task import funboost_current_task,fct,get_current_taskid






`````

--- **end of file: funboost/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/__init__old.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/__init__old.py`


---

`````python
# # noinspection PyUnresolvedReferences
# import types
#
# # noinspection PyUnresolvedReferences
# from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath
#
# import typing
# # noinspection PyUnresolvedReferences
# from functools import update_wrapper, wraps, partial
# import copy
# # noinspection PyUnresolvedReferences
# import nb_log
# from funboost.funboost_config_deafult import BoostDecoratorDefaultParams
# from funboost.helpers import (multi_process_pub_params_list,
#                               run_consumer_with_multi_process, )
# from funboost.core.global_boosters import GlobalBoosters
# from funboost.core.fabric_deploy_helper import fabric_deploy
#
# from funboost.consumers.base_consumer import (AbstractConsumer, FunctionResultStatusPersistanceConfig)
# from funboost.publishers.base_publisher import (AbstractPublisher)
# from funboost.factories.consumer_factory import get_consumer
#
# # noinspection PyUnresolvedReferences
# from funboost.utils import nb_print, patch_print, LogManager, get_logger, LoggerMixin
#
#
# # 有的包默认没加handlers，原始的日志不漂亮且不可跳转不知道哪里发生的。这里把warnning级别以上的日志默认加上handlers。
# # nb_log.get_logger(name='', log_level_int=30, _log_filename='pywarning.log')
#
#
# class Booster(LoggerMixin):
#     """
#     为了被装饰的消费函数的敲代码时候的被pycharm自动补全而写的类。
#     """
#
#     def __init__(self, consuming_func_decorated: callable):
#         """
#         :param consuming_func_decorated:   传入被boost装饰的函数
#
#         此框架非常非常注重，公有函数、方法、类 的名字和入参在ide开发环境下面的自动提示补全效果，如果不是为了这一点，框架能减少很多重复地方。
#         此类是防止用户调用打错字母或者不知道怎么敲代码不知道有哪些入参。所以才有这个类。
#
#         这个类是个补全类，能够使pycharm自动补全方法名字和入参。可以用，可以不用，用了后在pycharm里面补全效果会起作用。
#
#
#        from funboost import boost, IdeAutoCompleteHelper
#
#        @boost('queue_test_f01', qps=2, broker_kind=3)
#        def f(a, b):
#            print(f'{a} + {b} = {a + b}')
#
#
#        if __name__ == '__main__':
#            f(1000, 2000)
#            IdeAutoCompleteHelper(f).clear()  # f.clear()
#            for i in range(100, 200):
#                f.pub(dict(a=i, b=i * 2))  # f.sub方法是强行用元编程加到f上去的，是运行时状态，pycharm只能补全非运行时态的静态东西。
#                IdeAutoCompleteHelper(f).pub({'a': i * 3, 'b': i * 4})  # 和上面的发布等效，但可以自动补全方法名字和入参。
#                f.push(a=i, b=i * 2)
#                IdeAutoCompleteHelper(f).delay(i * 3,  i * 4)
#
#            IdeAutoCompleteHelper(f).start_consuming_message()  # 和 f.consume()等效
#
#         """
#         wraps(consuming_func_decorated)(self)
#         self.init_params: dict = consuming_func_decorated.init_params
#         self.is_decorated_as_consume_function = consuming_func_decorated.is_decorated_as_consume_function
#         self.consuming_func_decorated = consuming_func_decorated
#
#         self.queue_name = consuming_func_decorated.queue_name
#
#         self.consumer = consuming_func_decorated.consumer  # type: AbstractConsumer
#
#         self.publisher = consuming_func_decorated.publisher  # type: AbstractPublisher
#         self.publish = self.pub = self.apply_async = self.publisher.publish  # type: AbstractPublisher.publish
#         self.push = self.delay = self.publisher.push  # type: AbstractPublisher.push
#         self.clear = self.clear_queue = self.publisher.clear  # type: AbstractPublisher.clear
#         self.get_message_count = self.publisher.get_message_count
#
#         self.start_consuming_message = self.consume = self.start = self.consumer.start_consuming_message
#
#         self.clear_filter_tasks = self.consumer.clear_filter_tasks
#
#         self.wait_for_possible_has_finish_all_tasks = self.consumer.wait_for_possible_has_finish_all_tasks
#
#         # self.pause = self.pause_consume = self.consumer.pause_consume
#         self.continue_consume = self.consumer.continue_consume
#
#         for k, v in consuming_func_decorated.__dict__.items():
#             ''' 上面那些手动的是为了代码补全方便 ，这个是自动的补充所有'''
#             if not k.startswith('_'):
#                 setattr(self, k, v)
#
#     def multi_process_consume(self, process_num=1):
#         """超高速多进程消费"""
#         run_consumer_with_multi_process(self.consuming_func_decorated, process_num)
#
#     multi_process_start = multi_process_consume
#
#     def multi_process_pub_params_list(self, params_list, process_num=16):
#         """超高速多进程发布，例如先快速发布1000万个任务到中间件，以后慢慢消费"""
#         """
#         用法例如，快速20进程发布1000万任务，充分利用多核加大cpu使用率。
#         @boost('test_queue66c', qps=1/30,broker_kind=BrokerEnum.KAFKA_CONFLUENT)
#         def f(x, y):
#             print(f'函数开始执行时间 {time.strftime("%H:%M:%S")}')
#         if __name__ == '__main__':
#             f.multi_process_pub_params_list([{'x':i,'y':i*3}  for i in range(10000000)],process_num=20)
#             f.consume()
#         """
#         multi_process_pub_params_list(self.consuming_func_decorated, params_list=params_list, process_num=process_num)
#
#     # noinspection PyDefaultArgument
#     def fabric_deploy(self, host, port, user, password,
#                       path_pattern_exluded_tuple=('/.git/', '/.idea/', '/dist/', '/build/'),
#                       file_suffix_tuple_exluded=('.pyc', '.log', '.gz'),
#                       only_upload_within_the_last_modify_time=3650 * 24 * 60 * 60,
#                       file_volume_limit=1000 * 1000, sftp_log_level=20, extra_shell_str='',
#                       invoke_runner_kwargs={'hide': None, 'pty': True, 'warn': False},
#                       python_interpreter='python3',
#                       process_num=1):
#         """
#         入参见 fabric_deploy 函数。这里重复入参是为了代码在pycharm补全提示。
#         """
#         in_kwargs = locals()
#         in_kwargs.pop('self')
#         fabric_deploy(self.consuming_func_decorated, **in_kwargs)
#
#     def __call__(self, *args, **kwargs):
#         return self.consuming_func_decorated(*args, **kwargs)
#
#     def __get__(self, instance, cls):
#         """ https://python3-cookbook.readthedocs.io/zh_CN/latest/c09/p09_define_decorators_as_classes.html """
#         if instance is None:
#             return self
#         else:
#             return types.MethodType(self, instance)
#
#
# IdeAutoCompleteHelper = Booster  # 兼容
#
#
# class _Undefined:
#     pass
#
#
# def boost(queue_name,
#           *,
#           consuming_function_decorator: typing.Callable = _Undefined,
#           function_timeout: float = _Undefined,
#           concurrent_num: int = _Undefined,
#           specify_concurrent_pool=_Undefined,
#           specify_async_loop=_Undefined,
#           concurrent_mode: int = _Undefined,
#           max_retry_times: int = _Undefined,
#           is_push_to_dlx_queue_when_retry_max_times: bool = _Undefined,
#           log_level: int = _Undefined,
#           is_print_detail_exception: bool = _Undefined,
#           is_show_message_get_from_broker: bool = _Undefined,
#           qps: float = _Undefined,
#           is_using_distributed_frequency_control: bool = _Undefined,
#           msg_expire_seconds: float = _Undefined,
#           is_send_consumer_heartbeat_to_redis: bool = _Undefined,
#           logger_prefix: str = _Undefined,
#           create_logger_file: bool = _Undefined,
#           do_task_filtering: bool = _Undefined,
#           task_filtering_expire_seconds: float = _Undefined,
#           is_do_not_run_by_specify_time_effect: bool = _Undefined,
#           do_not_run_by_specify_time: bool = _Undefined,
#           schedule_tasks_on_main_thread: bool = _Undefined,
#           function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = _Undefined,
#           user_custom_record_process_info_func: typing.Union[typing.Callable, None] = _Undefined,
#           is_using_rpc_mode: bool = _Undefined,
#           broker_exclusive_config: dict = _Undefined,
#           broker_kind: int = _Undefined,
#           boost_decorator_default_params=BoostDecoratorDefaultParams()
#           ):
#     """
#     funboost.funboost_config_deafult.BoostDecoratorDefaultParams 的值会自动被你项目根目录下的funboost_config.BoostDecoratorDefaultParams的值覆盖，
#     如果boost装饰器不传参，默认使用funboost_config.BoostDecoratorDefaultParams的配置
#
#     入参也可以看文档 https://funboost.readthedocs.io/zh-cn/latest/articles/c3.html   3.3章节。
#
#     # 为了代码提示好，这里重复一次入参意义。被此装饰器装饰的函数f，函数f对象本身自动加了一些方法，例如f.push 、 f.consume等。
#     :param queue_name: 队列名字。
#     :param consuming_function_decorator : 函数的装饰器。因为此框架做参数自动转指点，需要获取精准的入参名称，不支持在消费函数上叠加 @ *args  **kwargs的装饰器，如果想用装饰器可以这里指定。
#     :param function_timeout : 超时秒数，函数运行超过这个时间，则自动杀死函数。为0是不限制。设置后代码性能会变差，非必要不要轻易设置。
#     # 如果设置了qps，并且cocurrent_num是默认的50，会自动开了500并发，由于是采用的智能线程池任务少时候不会真开那么多线程而且会自动缩小线程数量。具体看ThreadPoolExecutorShrinkAble的说明
#     # 由于有很好用的qps控制运行频率和智能扩大缩小的线程池，此框架建议不需要理会和设置并发数量只需要关心qps就行了，框架的并发是自适应并发数量，这一点很强很好用。
#     :param concurrent_num:并发数量
#     :param specify_concurrent_pool:使用指定的线程池（协程池），可以多个消费者共使用一个线程池，不为None时候。threads_num失效
#     :param specify_async_loop:指定的async的loop循环，设置并发模式为async才能起作用。
#     :param concurrent_mode:并发模式，1线程(ConcurrentModeEnum.THREADING) 2gevent(ConcurrentModeEnum.GEVENT)
#                               3eventlet(ConcurrentModeEnum.EVENTLET) 4 asyncio(ConcurrentModeEnum.ASYNC) 5单线程(ConcurrentModeEnum.SINGLE_THREAD)
#     :param max_retry_times: 最大自动重试次数，当函数发生错误，立即自动重试运行n次，对一些特殊不稳定情况会有效果。
#            可以在函数中主动抛出重试的异常ExceptionForRetry，框架也会立即自动重试。
#            主动抛出ExceptionForRequeue异常，则当前 消息会重返中间件，
#            主动抛出 ExceptionForPushToDlxqueue  异常，可以使消息发送到单独的死信队列中，死信队列的名字是 队列名字 + _dlx。
#            。
#     :param is_push_to_dlx_queue_when_retry_max_times : 函数达到最大重试次数仍然没成功，是否发送到死信队列,死信队列的名字是 队列名字 + _dlx。
#     :param log_level:框架的日志级别。logging.DEBUG(10)  logging.DEBUG(10) logging.INFO(20) logging.WARNING(30) logging.ERROR(40) logging.CRITICAL(50)
#     :param is_print_detail_exception:是否打印详细的堆栈错误。为0则打印简略的错误占用控制台屏幕行数少。
#     :param is_show_message_get_from_broker: 从中间件取出消息时候时候打印显示出来
#     :param qps:指定1秒内的函数执行次数，例如可以是小数0.01代表每100秒执行一次，也可以是50代表1秒执行50次.为0则不控频。
#     :param msg_expire_seconds:消息过期时间，为0永不过期，为10则代表，10秒之前发布的任务如果现在才轮到消费则丢弃任务。
#     :param is_using_distributed_frequency_control: 是否使用分布式空频（依赖redis统计消费者数量，然后频率平分），默认只对当前实例化的消费者空频有效。
#             假如实例化了2个qps为10的使用同一队列名的消费者，并且都启动，则每秒运行次数会达到20。如果使用分布式空频则所有消费者加起来的总运行次数是10。
#     :param is_send_consumer_heartbeat_to_redis   是否将发布者的心跳发送到redis，有些功能的实现需要统计活跃消费者。因为有的中间件不是真mq。
#     :param logger_prefix: 日志前缀，可使不同的消费者生成不同的日志前缀
#     :param create_logger_file : 是否创建文件日志
#     :param do_task_filtering :是否执行基于函数参数的任务过滤
#     :param task_filtering_expire_seconds:任务过滤的失效期，为0则永久性过滤任务。例如设置过滤过期时间是1800秒 ，
#            30分钟前发布过1 + 2 的任务，现在仍然执行，
#            如果是30分钟以内发布过这个任务，则不执行1 + 2，现在把这个逻辑集成到框架，一般用于接口价格缓存。
#     :param is_do_not_run_by_specify_time_effect :是否使不运行的时间段生效
#     :param do_not_run_by_specify_time   :不运行的时间段
#     :param schedule_tasks_on_main_thread :直接在主线程调度任务，意味着不能直接在当前主线程同时开启两个消费者。fun.consume()就阻塞了，这之后的代码不会运行
#     :param function_result_status_persistance_conf   :配置。是否保存函数的入参，运行结果和运行状态到mongodb。
#            这一步用于后续的参数追溯，任务统计和web展示，需要安装mongo。
#     :param user_custom_record_process_info_func  提供一个用户自定义的保存消息处理记录到某个地方例如mysql数据库的函数，函数仅仅接受一个入参，入参类型是 FunctionResultStatus，用户可以打印参数
#     :param is_using_rpc_mode 是否使用rpc模式，可以在发布端获取消费端的结果回调，但消耗一定性能，使用async_result.result时候会等待阻塞住当前线程。。
#     :param broker_exclusive_config 加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，
#             例如kafka支持消费者组，rabbitmq也支持各种独特概念例如各种ack机制 复杂路由机制，每一种消息队列都有独特的配置参数意义，可以通过这里传递。
#     :param broker_kind:中间件种类，支持30种消息队列。 入参见 BrokerEnum枚举类的属性。
#     :param boost_decorator_default_params: oostDecoratorDefaultParams是
#             @boost装饰器默认的全局入参。如果boost没有亲自指定某个入参，就自动使用funboost_config.py的BoostDecoratorDefaultParams中的配置。
#                     如果你嫌弃每个 boost 装饰器相同入参太多重复了，可以在 funboost_config.py 文件中设置boost装饰器的全局默认值。
#             BoostDecoratorDefaultParams() 实例化时候也可以传递这个boost装饰器任何的入参，BoostDecoratorDefaultParams是个数据类，百度python3.7dataclass的概念，类似。
#
#             funboost.funboost_config_deafult.BoostDecoratorDefaultParams 的值会自动被你项目根目录下的funboost_config.BoostDecoratorDefaultParams的值覆盖
#
#     """
#
#     """
#     这是此框架最重要的一个函数，必须看懂里面的入参有哪些。
#     此函数的入参意义请查看 get_consumer的入参注释。
#
#     本来是这样定义的，def boost(queue_name, **consumer_init_kwargs):
#     为了更好的ide智能补全，重复写全函数入参。
#
#     装饰器方式注册消费任务，如果有人过于喜欢装饰器方式，例如celery 装饰器方式的任务注册，觉得黑科技，那就可以使用这个装饰器。
#     假如你的函数名是f,那么可以调用f.publish或f.pub来发布任务。调用f.start_consuming_message 或 f.consume 或 f.start消费任务。
#     必要时候调用f.publisher.funcxx   和 f.conusmer.funcyy。
#
#
#     装饰器版，使用方式例如：
#     '''
#     @boost('queue_test_f01', qps=0.2, broker_kind=2)
#     def f(a, b):
#         print(a + b)
#
#     for i in range(10, 20):
#         f.pub(dict(a=i, b=i * 2))
#         f.push(i, i * 2)
#     f.consume()
#     # f.multi_process_conusme(8)             # # 这个是新加的方法，细粒度 线程 协程并发 同时叠加8个进程，速度炸裂。主要是无需导入run_consumer_with_multi_process函数。
#     # run_consumer_with_multi_process(f,8)   # 这个是细粒度 线程 协程并发 同时叠加8个进程，速度炸裂。
#     '''
#
#     常规方式，使用方式如下
#     '''
#     def f(a, b):
#         print(a + b)
#
#     consumer = get_consumer('queue_test_f01', consuming_function=f,qps=0.2, broker_kind=2)
#     # 需要手动指定consuming_function入参的值。
#     for i in range(10, 20):
#         consumer.publisher_of_same_queue.publish(dict(a=i, b=i * 2))
#     consumer.start_consuming_message()
#
#     '''
#
#     装饰器版本的 boost 入参 和 get_consumer 入参99%一致，唯一不同的是 装饰器版本加在了函数上自动知道消费函数了，
#     所以不需要传consuming_function参数。
#     """
#     # 装饰器版本能够自动知道消费函数，防止boost按照get_consumer的入参重复传参了consuming_function。
#     consumer_init_params_include_boost_decorator_default_params = copy.copy(locals())
#     consumer_init_params0 = copy.copy(consumer_init_params_include_boost_decorator_default_params)
#     consumer_init_params0.pop('boost_decorator_default_params')
#     consumer_init_params = copy.copy(consumer_init_params0)
#     for k, v in consumer_init_params0.items():
#         if v == _Undefined:
#             # print(k,v,boost_decorator_default_params[k])
#             consumer_init_params[k] = boost_decorator_default_params[k]  # boost装饰器没有亲指定某个传参，就使用funboost_config.py的BoostDecoratorDefaultParams的全局配置。
#
#     # print(consumer_init_params)
#     def _deco(func) -> Booster:  # 加这个-> 可以实现pycahrm动态补全
#
#         func.init_params = consumer_init_params
#         consumer = get_consumer(consuming_function=func, **consumer_init_params)  # type: AbstractConsumer
#         func.is_decorated_as_consume_function = True
#         func.consumer = consumer
#         func.queue_name = queue_name
#
#         func.publisher = consumer.publisher_of_same_queue
#         func.publish = func.pub = func.apply_async = consumer.publisher_of_same_queue.publish
#         func.push = func.delay = consumer.publisher_of_same_queue.push
#         func.multi_process_pub_params_list = partial(multi_process_pub_params_list, func)
#         func.clear = func.clear_queue = consumer.publisher_of_same_queue.clear
#         func.get_message_count = consumer.publisher_of_same_queue.get_message_count
#
#         func.start_consuming_message = func.consume = func.start = consumer.start_consuming_message
#         func.multi_process_start = func.multi_process_consume = partial(run_consumer_with_multi_process, func)
#
#         func.fabric_deploy = partial(fabric_deploy, func)
#
#         func.clear_filter_tasks = consumer.clear_filter_tasks
#
#         func.wait_for_possible_has_finish_all_tasks = consumer.wait_for_possible_has_finish_all_tasks
#
#         func.pause = func.pause_consume = consumer.pause_consume
#         func.continue_consume = consumer.continue_consume
#
#         GlobalBoosters.regist(queue_name,func)
#
#         # @wraps(func)
#         # def __deco(*args, **kwargs):  # 这样函数的id变化了，导致win在装饰器内部开多进程不方便。
#         #     return func(*args, **kwargs)
#         return func
#
#         # return __deco  # noqa # 两种方式都可以
#         # return update_wrapper(__deco, func)
#
#     return _deco  # noqa
#
#
# task_deco = boost  # 两个装饰器名字都可以。task_deco是原来名字，兼容一下。

`````

--- **end of file: funboost/__init__old.py** (project: funboost) --- 

---


--- **start of file: funboost/__main__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/__main__.py`

#### 📦 Imports

- `import sys`
- `import fire`
- `from funboost.core.cli.funboost_fire import BoosterFire`
- `from funboost.core.cli.funboost_fire import env_dict`

#### 🔧 Public Functions (1)

- `def main()`
  - *Line: 19*


---

`````python
import sys

import fire
from funboost.core.cli.funboost_fire import BoosterFire, env_dict


def _check_pass_params():
    has_passing_arguments_project_root_path = False
    for a in sys.argv:
        if '--project_root_path=' in a:
            has_passing_arguments_project_root_path = True
            project_root_path = a.split('=')[-1]
            sys.path.insert(1, project_root_path)
            env_dict['project_root_path'] = project_root_path
    if has_passing_arguments_project_root_path is False:
        raise Exception('命令行没有传参 --project_root_path=')


def main():
    _check_pass_params()
    

    fire.Fire(BoosterFire, )


if __name__ == '__main__':
    main()

'''
python -m funboost  --project_root_path=/codes/funboost   --booster_dirs_str=test_frame/test_funboost_cli/test_find_boosters --max_depth=2  show_all_queues

python -m funboost  --project_root_path=/codes/funboost   --booster_dirs_str=test_frame/test_funboost_cli/test_find_boosters --max_depth=2  push test_find_queue1 --x=1 --y=2


python -m funboost  --project_root_path=/codes/funboost  start_web
'''

`````

--- **end of file: funboost/__main__.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/celery_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/celery_helper.py`

#### 📦 Imports

- `import copy`
- `import json`
- `import logging`
- `import os`
- `import sys`
- `import threading`
- `from functools import partial`
- `import celery`
- `from celery.app.task import Task`
- `import nb_log`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost import ConcurrentModeEnum`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.loggers import get_logger`
- `from funboost import BoostersManager`

#### 🏛️ Classes (1)

##### 📌 `class CeleryHelper`
*Line: 31*

**Public Methods (7):**
- `def update_celery_app_conf(celery_app_conf: dict)` `staticmethod`
  - **Docstring:**
  `````
  更新celery app的配置，celery app配置大全见 https://docs.celeryq.dev/en/stable/userguide/configuration.html
  :param celery_app_conf: celery app 配置，字典
  :return:
  `````
- `def show_celery_app_conf()` `staticmethod`
- `def celery_start_beat(beat_schedule: dict)` `staticmethod`
- `def start_flower(port = 5555)` `staticmethod`
- `def add_start_work_celery_queue_name(cls, queue_name)` `classmethod`
- `def realy_start_celery_worker(cls, worker_name = None, loglevel = 'INFO', worker_concurrency = 200, start_consume_queue_name_list: list = None, is_start_consume_all_queues: bool = False)` `classmethod`
- `def use_nb_log_instead_celery_log(log_level: int = logging.INFO, log_filename = 'celery.log', formatter_template = 7)` `staticmethod`
  - *使用nb_log的日志来取代celery的日志*

**Class Variables (3):**
- `celery_app = celery_app`
- `to_be_start_work_celery_queue_name_set = set()`
- `concurrent_mode = None`


---

`````python
import copy

import json
import logging
import os
import sys
import threading
from functools import partial

import celery
from celery.app.task import Task
import nb_log
from funboost.funboost_config_deafult import BrokerConnConfig,FunboostCommonConfig
from funboost import  ConcurrentModeEnum
from funboost.core.loggers import get_funboost_file_logger,get_logger

celery_app = celery.Celery(main='funboost_celery', broker=BrokerConnConfig.CELERY_BROKER_URL,
                           backend=BrokerConnConfig.CELERY_RESULT_BACKEND,
                           task_routes={}, timezone=FunboostCommonConfig.TIMEZONE, enable_utc=False, )

celery_app.conf.task_acks_late = True
celery_app.conf.update({
    'worker_redirect_stdouts': False,
    'worker_concurrency': 200
}
)

logger = get_funboost_file_logger('funboost.CeleryHelper')


class CeleryHelper:
    celery_app = celery_app
    to_be_start_work_celery_queue_name_set = set()  # start_consuming_message时候，添加需要worker运行的queue name。

    concurrent_mode = None

    @staticmethod
    def update_celery_app_conf(celery_app_conf: dict):
        """
        更新celery app的配置，celery app配置大全见 https://docs.celeryq.dev/en/stable/userguide/configuration.html
        :param celery_app_conf: celery app 配置，字典
        :return:
        """
        celery_app.conf.update(celery_app_conf)
        # 例如  celery_app.conf.update({'broker_transport_options':{'visibility_timeout': 18000,'max_retries':5}})

    @staticmethod
    def show_celery_app_conf():
        logger.debug('展示celery app的配置')
        conf_dict_json_able = {}
        for k, v in celery_app.conf.items():
            conf_dict_json_able[k] = str(v)
            # print(k, ' : ', v)
        print('celery app 的配置是：', json.dumps(conf_dict_json_able, ensure_ascii=False, indent=4))

    @staticmethod
    def celery_start_beat(beat_schedule: dict):
        celery_app.conf.beat_schedule = beat_schedule  # 配置celery定时任务

        def _f():
            beat = partial(celery_app.Beat, loglevel='INFO', )
            beat().run()

        threading.Thread(target=_f).start()  # 使得可以很方便启动定时任务，继续启动函数消费

    @staticmethod
    def start_flower(port=5555):
        def _f():
            python_executable = sys.executable
            # print(python_executable)
            # cmd = f'''{python_executable} -m celery -A  funboost.assist.celery_helper  --broker={funboost_config_deafult.CELERY_BROKER_URL}  --result-backend={funboost_config_deafult.CELERY_RESULT_BACKEND}   flower --address=0.0.0.0 --port={port}  --auto_refresh=True '''
            cmd = f'''{python_executable} -m celery   --broker={BrokerConnConfig.CELERY_BROKER_URL}  --result-backend={BrokerConnConfig.CELERY_RESULT_BACKEND}   flower --address=0.0.0.0 --port={port}  --auto_refresh=True '''

            logger.info(f'启动flower命令:   {cmd}')
            os.system(cmd)

        threading.Thread(target=_f).start()

    @classmethod
    def add_start_work_celery_queue_name(cls, queue_name):
        cls.to_be_start_work_celery_queue_name_set.add(queue_name)

    @classmethod
    def realy_start_celery_worker(cls, worker_name=None, loglevel='INFO',worker_concurrency=200,start_consume_queue_name_list:list=None,is_start_consume_all_queues:bool=False):

        if is_start_consume_all_queues is False:
            to_be_start_work_celery_queue_name_set_new = copy.copy(cls.to_be_start_work_celery_queue_name_set)
            to_be_start_work_celery_queue_name_set_new.update(set(start_consume_queue_name_list or []))
        else:
            from funboost import BoostersManager
            # print(BoostersManager.get_all_queues())
            to_be_start_work_celery_queue_name_set_new = set(BoostersManager.get_all_queues())
        queue_names_str = ','.join(list(to_be_start_work_celery_queue_name_set_new))
        if not to_be_start_work_celery_queue_name_set_new:
            raise Exception('celery worker 没有需要运行的queue')
        # '--concurrency=200',
        # '--autoscale=5,500' threads 并发模式不支持自动扩大缩小并发数量,
        worker_name = worker_name or f'pid_{os.getpid()}'
        pool_name = 'threads'
        if cls.concurrent_mode == ConcurrentModeEnum.GEVENT:
            pool_name = 'gevent'
        if cls.concurrent_mode == ConcurrentModeEnum.EVENTLET:
            pool_name = 'eventlet'
        '''
        并发数量在app配置中已经制定了。自己用 update_celery_app_conf 方法更新就好了。
        celery_app.conf.update({
             # 'worker_redirect_stdouts': False,
             'worker_concurrency': 200
         }
         或
         CeleryHelper.update_celery_app_conf({ 'worker_concurrency': 500})
        '''
        cls.update_celery_app_conf({'worker_concurrency':worker_concurrency})
        argv = ['worker', f'--pool={pool_name}',
                '-n', f'worker_funboost_{worker_name}@%h', f'--loglevel={loglevel}',
                f'--queues={queue_names_str}',  # 并发数量是 在app配置中已经制定了。自己用 update_celery_app_conf 方法更新就好了。
                ]
        logger.info(f'celery 启动work参数 {argv}')
        celery_app.worker_main(argv)

    @staticmethod
    def use_nb_log_instead_celery_log(log_level: int = logging.INFO, log_filename='celery.log', formatter_template=7):
        """
        使用nb_log的日志来取代celery的日志
        """
        celery_app.conf.worker_hijack_root_logger = False
        # logging.getLogger('celery').handlers=[]
        # logging.getLogger('celery.worker.strategy').handlers = []
        # logging.getLogger('celery.app.trace').handlers = []
        # logging.getLogger('celery.worker').handlers = []
        # logging.getLogger('celery.app').handlers = []
        # logging.getLogger().handlers=[]
        get_logger('celery', log_level_int=log_level, log_filename=log_filename, formatter_template=formatter_template, )
        get_logger(None, log_level_int=logging.WARNING, log_filename=log_filename, formatter_template=formatter_template, )
        for name in ['celery','celery.worker.strategy','celery.app.trace','celery.worker','celery.app',None]:
            nb_log.LogManager(name).prevent_add_handlers()
        nb_log.LogManager(None).preset_log_level(logging.WARNING)

`````

--- **end of file: funboost/assist/celery_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/dramatiq_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/dramatiq_helper.py`

#### 📦 Imports

- `import argparse`
- `from funboost.core.loggers import FunboostMetaTypeFileLogger`
- `import dramatiq`
- `from dramatiq.cli import main`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from dramatiq.brokers.redis import RedisBroker`
- `from dramatiq.brokers.rabbitmq import RabbitmqBroker`

#### 🏛️ Classes (1)

##### 📌 `class DramatiqHelper`
*Line: 22*

**Public Methods (1):**
- `def realy_start_dramatiq_worker(cls)` `classmethod`

**Class Variables (3):**
- `broker = dramatiq.get_broker()`
- `to_be_start_work_celery_queue_name_set = set()`
- `queue_name__actor_map = {}`


---

`````python
import argparse
from funboost.core.loggers import FunboostMetaTypeFileLogger
import dramatiq
from dramatiq.cli import main
from funboost.funboost_config_deafult import BrokerConnConfig
from dramatiq.brokers.redis import RedisBroker
from dramatiq.brokers.rabbitmq import RabbitmqBroker

if BrokerConnConfig.DRAMATIQ_URL.startswith('redis'):
    broker = RedisBroker(url=BrokerConnConfig.DRAMATIQ_URL)
elif BrokerConnConfig.DRAMATIQ_URL.startswith('amqp'):
    broker = RabbitmqBroker(url=BrokerConnConfig.DRAMATIQ_URL)
else:
    raise ValueError('DRAMATIQ_URL 配置错误，需要配置成url连接形式，例如 amqp://rabbitmq_user:rabbitmq_pass@127.0.0.1:5672/ 或者 redis://:passwd@192.168.64.151:6378/7 ')
dramatiq.set_broker(broker)

"""
 {'max_age', 'throws', 'pipe_target', 'pipe_ignore', 'on_success', 'retry_when', 'time_limit', 'min_backoff', 'max_retries', 'max_backoff', 'notify_shutdown', 'on_failure'}
"""


class DramatiqHelper(metaclass=FunboostMetaTypeFileLogger):

    broker = dramatiq.get_broker()
    to_be_start_work_celery_queue_name_set = set()  # 存放需要worker运行的queue name。

    queue_name__actor_map = {}

    @classmethod
    def realy_start_dramatiq_worker(cls):
        p = argparse.ArgumentParser()
        pa = p.parse_args()

        pa.broker = 'funboost.assist.dramatiq_helper'
        pa.modules = []
        pa.processes = 1
        pa.threads = 200
        pa.path = ''
        pa.queues = list(cls.to_be_start_work_celery_queue_name_set)
        pa.log_file = None
        pa.skip_logging = False
        pa.use_spawn = False
        pa.forks = []
        pa.worker_shutdown_timeout = 600000
        pa.verbose = 0
        pa.pid_file = None

        cls.logger.warning(f'dramatiq 命令行启动参数 {pa}')
        main(pa)


'''
Namespace(broker='test_dramatiq_raw', modules=[], processes=1, threads=8, path='.', queues=None, pid_file=None, log_file=None, skip_logging=False, use_spawn=False, forks=[], worker_shutdown_timeout=600000, verbose=0)
python -m dramatiq test_dramatiq_raw -p 1
'''

`````

--- **end of file: funboost/assist/dramatiq_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/faststream_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/faststream_helper.py`

#### 📦 Imports

- `import asyncio`
- `from faststream import FastStream`
- `from faststream.rabbit import RabbitBroker`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🔧 Public Functions (1)

- `def get_broker(max_consumers = None)`
  - *Line: 17*


---

`````python
import asyncio

from faststream import FastStream
from faststream.rabbit import RabbitBroker
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.core.loggers import get_funboost_file_logger

get_funboost_file_logger('faststream.access.rabbit')

broker = RabbitBroker(BrokerConnConfig.RABBITMQ_URL, max_consumers=20)
app = FastStream(broker)

# asyncio.get_event_loop().run_until_complete(broker.connect())
#
# asyncio.get_event_loop().run_until_complete(broker.start())

def get_broker(max_consumers=None):
    return RabbitBroker(BrokerConnConfig.RABBITMQ_URL, max_consumers=max_consumers)
`````

--- **end of file: funboost/assist/faststream_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/huey_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/huey_helper.py`

#### 📦 Imports

- `import multiprocessing`
- `import threading`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from huey import RedisHuey`
- `from huey.consumer import Consumer`

#### 🏛️ Classes (1)

##### 📌 `class HueyHelper`
*Line: 10*

**Public Methods (1):**
- `def realy_start_huey_consume(cls)` `classmethod`
  - *huey 启动所有函数开始消费*

**Class Variables (3):**
- `huey_obj = huey_obj`
- `queue_name__huey_task_fun_map = {}`
- `to_be_start_huey_queue_name_set = set()`


---

`````python
import multiprocessing
import threading

from funboost.funboost_config_deafult import BrokerConnConfig
from huey import RedisHuey
from huey.consumer import Consumer

huey_obj = RedisHuey('funboost_huey', url=BrokerConnConfig.REDIS_URL,)

class HueyHelper:
    huey_obj = huey_obj
    queue_name__huey_task_fun_map = {}
    to_be_start_huey_queue_name_set= set()

    # @classmethod
    # def realy_start_huey_consume(cls):
    #     for queue_name in list(cls.to_be_start_huey_queue_name_set):
    #         multiprocessing.Process(target=cls._start_huey,args=(queue_name,)).start()  # huey的consumer的run方法无法在子线程运行，必须是主线程。
    #
    # @classmethod
    # def _start_huey(cls,queue_name):
    #     consumer_kwargs = {'huey': HueyHelper.queue_name__huey_obj_map[queue_name], 'workers': 200, 'periodic': True, 'initial_delay': 0.1, 'backoff': 1.15, 'max_delay': 10.0, 'scheduler_interval': 1, 'worker_type': 'thread', 'check_worker_health': True, 'health_check_interval': 10, 'flush_locks': False, 'extra_locks': None}
    #     huey_consumer = Consumer(**consumer_kwargs)
    #     huey_consumer.run()

    @classmethod
    def realy_start_huey_consume(cls):
        """ huey 启动所有函数开始消费"""
        consumer_kwargs = {'huey': huey_obj, 'workers': 200, 'periodic': True,
                           'initial_delay': 0.1, 'backoff': 1.15, 'max_delay': 10.0,
                           'scheduler_interval': 1, 'worker_type': 'thread',
                           'check_worker_health': True, 'health_check_interval': 10,
                           'flush_locks': False, 'extra_locks': None}
        huey_consumer = Consumer(**consumer_kwargs)
        huey_consumer.run()







`````

--- **end of file: funboost/assist/huey_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/rocketry_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/rocketry_helper.py`


---

`````python

`````

--- **end of file: funboost/assist/rocketry_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/rq_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/rq_helper.py`

#### 📦 Imports

- `import threading`
- `import os`
- `import uuid`
- `from rq.worker import RandomWorker`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from redis3 import Redis`
- `from rq import Worker`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.assist.rq_windows_worker import WindowsWorker`

#### 🏛️ Classes (2)

##### 📌 `class RandomWindowsWorker(RandomWorker, WindowsWorker)`
*Line: 20*

**Docstring:**
`````
这个是为了 每个队列都有机会同时拉取，默认是前面的队列先消费完才会消费下一个队列名
`````

##### 📌 `class RqHelper`
*Line: 26*

**Public Methods (2):**
- `def realy_start_rq_worker(cls, threads_num = 50)` `classmethod`
- `def add_nb_log_handler_to_rq()` `staticmethod`

**Class Variables (3):**
- `redis_conn = Redis.from_url(BrokerConnConfig.REDIS_URL)`
- `queue_name__rq_job_map = {}`
- `to_be_start_work_rq_queue_name_set = set()`


---

`````python
import threading
import os
import uuid
from rq.worker import RandomWorker
from funboost.core.loggers import get_funboost_file_logger
from redis3 import Redis
from rq import Worker
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.assist.rq_windows_worker import WindowsWorker


def _install_signal_handlers_monkey(self):
    """ 不能在非主线程中操作信号"""
    pass


Worker._install_signal_handlers = _install_signal_handlers_monkey


class RandomWindowsWorker(RandomWorker, WindowsWorker):
    """ 这个是为了 每个队列都有机会同时拉取，默认是前面的队列先消费完才会消费下一个队列名"""

    pass


class RqHelper:
    redis_conn = Redis.from_url(BrokerConnConfig.REDIS_URL)

    queue_name__rq_job_map = {}
    to_be_start_work_rq_queue_name_set = set()

    @classmethod
    def realy_start_rq_worker(cls, threads_num=50):
        threads = []
        for i in range(threads_num):
            t = threading.Thread(target=cls.__rq_work)
            threads.append(t)
            t.start()
        for t in threads:
            t.join()

    @classmethod
    def __rq_work(cls):
        worker_cls = RandomWindowsWorker if os.name == 'nt' else RandomWorker
        worker = worker_cls(queues=list(cls.to_be_start_work_rq_queue_name_set), connection=cls.redis_conn, name=uuid.uuid4().hex)
        worker.work()

    @staticmethod
    def add_nb_log_handler_to_rq():
        get_funboost_file_logger('rq', log_level_int=20,)

`````

--- **end of file: funboost/assist/rq_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/rq_windows_worker.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/rq_windows_worker.py`

#### 📦 Imports

- `import time`
- `import sys`
- `import random`
- `from funboost.utils import times`
- `import rq`
- `import rq.job`
- `import rq.compat`
- `import rq.worker`
- `from rq.defaults import DEFAULT_LOGGING_FORMAT`
- `from rq.defaults import DEFAULT_LOGGING_DATE_FORMAT`

#### 🏛️ Classes (1)

##### 📌 `class WindowsWorker(rq.Worker)`
*Line: 14*

**Docstring:**
`````
An extension of the RQ worker class
that works on Windows.

Does not support task timeouts
and will probably crash if the task goes badly,
due to not using fork().
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, *args, **kwargs)`
  - **Parameters:**
    - `self`
    - `*args`
    - `**kwargs`

**Public Methods (4):**
- `def work(self, burst = False, logging_level = 'INFO', date_format = DEFAULT_LOGGING_DATE_FORMAT, log_format = DEFAULT_LOGGING_FORMAT, max_jobs = None, with_scheduler = False)`
  - **Docstring:**
  `````
  Starts the work loop.
  
  Pops and performs all jobs on the current list of queues.  When all
  queues are empty, block and wait for new jobs to arrive on any of the
  queues, unless `burst` mode is enabled.
  
  The return value indicates whether any jobs were processed.
  `````
- `def execute_job(self, job, queue)`
  - **Docstring:**
  `````
  Spawns a work horse to perform the actual work and passes it a job.
  The worker will wait for the work horse and make sure it executes
  within the given timeout bounds, or will end the work horse with
  SIGALRM.
  `````
- `def main_work_horse(self, job, queue)`
  - *This is the entry point of the newly spawned work horse.*
- `def perform_job(self, job, queue, heartbeat_ttl = None)`
  - **Docstring:**
  `````
  Performs the actual work of a job.  Will/should only be called
  inside the work horse's process.
  `````


---

`````python
import time
import sys
import random

from funboost.utils import times
import rq
import rq.job
import rq.compat
import rq.worker

from rq.defaults import (DEFAULT_LOGGING_FORMAT, DEFAULT_LOGGING_DATE_FORMAT)


class WindowsWorker(rq.Worker):
    """
    An extension of the RQ worker class
    that works on Windows.

    Does not support task timeouts
    and will probably crash if the task goes badly,
    due to not using fork().
    """

    def __init__(self, *args, **kwargs):
        if kwargs.get('default_worker_ttl', None) is None:
            # Force a small worker_ttl,
            # Otherwise the process seems to hang somewhere within connection.lpop and
            # you can't kill the worker with Ctrl+C until the timeout expires (Ctrl+Break works, though).
            # The default timeout is 420, however, which is too long.
            kwargs['default_worker_ttl'] = 2
        super(WindowsWorker, self).__init__(*args, **kwargs)

    def work(self, burst=False, logging_level="INFO", date_format=DEFAULT_LOGGING_DATE_FORMAT,
             log_format=DEFAULT_LOGGING_FORMAT, max_jobs=None, with_scheduler=False):
        """Starts the work loop.

        Pops and performs all jobs on the current list of queues.  When all
        queues are empty, block and wait for new jobs to arrive on any of the
        queues, unless `burst` mode is enabled.

        The return value indicates whether any jobs were processed.
        """
        self.log.info('Using rq_win.WindowsWorker (experimental)')
        self.default_worker_ttl=2
        return super(WindowsWorker, self).work(
            burst=burst,
            logging_level=logging_level,
            date_format=date_format,
            log_format=log_format,
            max_jobs=max_jobs,
            with_scheduler=with_scheduler
        )


    def execute_job(self, job, queue):
        """Spawns a work horse to perform the actual work and passes it a job.
        The worker will wait for the work horse and make sure it executes
        within the given timeout bounds, or will end the work horse with
        SIGALRM.
        """
        self.main_work_horse(job, queue)

    def main_work_horse(self, job, queue):
        """This is the entry point of the newly spawned work horse."""
        # After fork()'ing, always assure we are generating random sequences
        # that are different from the worker.
        random.seed()

        self._is_horse = True

        success = self.perform_job(job, queue)

        self._is_horse = False

    def perform_job(self, job, queue, heartbeat_ttl=None):
        """Performs the actual work of a job.  Will/should only be called
        inside the work horse's process.
        """
        self.prepare_job_execution(job)

        self.procline('Processing %s from %s since %s' % (
            job.func_name,
            job.origin, time.time()))

        try:
            job.started_at = times.now()

            # I have DISABLED the time limit!
            rv = job.perform()

            # Pickle the result in the same try-except block since we need to
            # use the same exc handling when pickling fails
            job._result = rv
            job._status = rq.job.JobStatus.FINISHED
            job.ended_at = times.now()

            #
            # Using the code from Worker.handle_job_success
            #
            with self.connection.pipeline() as pipeline:
                pipeline.watch(job.dependents_key)
                queue.enqueue_dependents(job, pipeline=pipeline)

                self.set_current_job_id(None, pipeline=pipeline)
                self.increment_successful_job_count(pipeline=pipeline)

                result_ttl = job.get_result_ttl(self.default_result_ttl)
                if result_ttl != 0:
                    job.save(pipeline=pipeline, include_meta=False)

                job.cleanup(result_ttl, pipeline=pipeline,
                            remove_from_queue=False)

                pipeline.execute()

        except:
            # Use the public setter here, to immediately update Redis
            job.status = rq.job.JobStatus.FAILED
            self.handle_exception(job, *sys.exc_info())
            return False

        if rv is None:
            self.log.info('Job OK')
        else:
            self.log.info('Job OK, result = %s' % (rq.worker.yellow(rq.compat.text_type(rv)),))

        if result_ttl == 0:
            self.log.info('Result discarded immediately.')
        elif result_ttl > 0:
            self.log.info('Result is kept for %d seconds.' % result_ttl)
        else:
            self.log.warning('Result will never expire, clean up result key manually.')

        return True
`````

--- **end of file: funboost/assist/rq_windows_worker.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/taskiq_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/taskiq_helper.py`


---

`````python


`````

--- **end of file: funboost/assist/taskiq_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/__init__.py`


---

`````python

`````

--- **end of file: funboost/assist/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/grpc_helper/client_sample.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/grpc_helper/client_sample.py`

#### 📦 Imports

- `import grpc`
- `import funboost_grpc_pb2`
- `import funboost_grpc_pb2_grpc`
- `import time`

#### 🔧 Public Functions (1)

- `def run_client()`
  - *Line: 11*
  - *运行 gRPC 客户端*


---

`````python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import grpc

# 导入生成的 protobuf 文件
import funboost_grpc_pb2
import funboost_grpc_pb2_grpc
import time

def run_client():
    """
    运行 gRPC 客户端
    """
    # 连接到服务器
    with grpc.insecure_channel('localhost:50051') as channel:
        # 创建 stub
        stub = funboost_grpc_pb2_grpc.FunboostBrokerServiceStub(channel)
        time_start = time.time()
        for i in range(10000):
            # 创建请求
            request = funboost_grpc_pb2.FunboostGrpcRequest(json_req='{"b":2}')
            
            try:
                # 调用远程方法
                response = stub.Call(request)
                print(f"服务器响应: {response.json_resp}")
            except grpc.RpcError as e:
                print(f"gRPC 调用失败: {e}")
        time_end = time.time()
        print(f"gRPC 调用时间: {time_end - time_start} 秒")







if __name__ == '__main__':
    print("=== gRPC 客户端测试 ===")
    print("1. 简单测试")
   
    run_client()
    
    # print("\n2. 交互式测试")
    # interactive_client()

`````

--- **end of file: funboost/assist/grpc_helper/client_sample.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/grpc_helper/funboost_grpc_pb2.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/grpc_helper/funboost_grpc_pb2.py`

#### 📝 Module Docstring

`````
Generated protocol buffer code.
`````

#### 📦 Imports

- `from google.protobuf import descriptor as _descriptor`
- `from google.protobuf import descriptor_pool as _descriptor_pool`
- `from google.protobuf import symbol_database as _symbol_database`
- `from google.protobuf.internal import builder as _builder`


---

`````python
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: funboost_grpc.proto
# Protobuf Python Version: 4.25.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x13\x66unboost_grpc.proto\x12\rfunboost_grpc\":\n\x13\x46unboostGrpcRequest\x12\x10\n\x08json_req\x18\x01 \x01(\t\x12\x11\n\tcall_type\x18\x02 \x01(\t\")\n\x14\x46unboostGrpcResponse\x12\x11\n\tjson_resp\x18\x01 \x01(\t2h\n\x15\x46unboostBrokerService\x12O\n\x04\x43\x61ll\x12\".funboost_grpc.FunboostGrpcRequest\x1a#.funboost_grpc.FunboostGrpcResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'funboost_grpc_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_FUNBOOSTGRPCREQUEST']._serialized_start=38
  _globals['_FUNBOOSTGRPCREQUEST']._serialized_end=96
  _globals['_FUNBOOSTGRPCRESPONSE']._serialized_start=98
  _globals['_FUNBOOSTGRPCRESPONSE']._serialized_end=139
  _globals['_FUNBOOSTBROKERSERVICE']._serialized_start=141
  _globals['_FUNBOOSTBROKERSERVICE']._serialized_end=245
# @@protoc_insertion_point(module_scope)

`````

--- **end of file: funboost/assist/grpc_helper/funboost_grpc_pb2.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/grpc_helper/funboost_grpc_pb2_grpc.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/grpc_helper/funboost_grpc_pb2_grpc.py`

#### 📝 Module Docstring

`````
Client and server classes corresponding to protobuf-defined services.
`````

#### 📦 Imports

- `import grpc`
- `import funboost.assist.grpc_helper.funboost_grpc_pb2 as funboost__grpc__pb2`

#### 🏛️ Classes (3)

##### 📌 `class FunboostBrokerServiceStub(object)`
*Line: 8*

**Docstring:**
`````
定义服务
    
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, channel)`
  - **Docstring:**
  `````
  Constructor.
  
  Args:
      channel: A grpc.Channel.
  `````
  - **Parameters:**
    - `self`
    - `channel`

##### 📌 `class FunboostBrokerServiceServicer(object)`
*Line: 25*

**Docstring:**
`````
定义服务
    
`````

**Public Methods (1):**
- `def Call(self, request, context)`
  - **Docstring:**
  `````
  简单的问候方法
          
  `````

##### 📌 `class FunboostBrokerService(object)`
*Line: 51*

**Docstring:**
`````
定义服务
    
`````

**Public Methods (1):**
- `def Call(request, target, options = (), channel_credentials = None, call_credentials = None, insecure = False, compression = None, wait_for_ready = None, timeout = None, metadata = None)` `staticmethod`

#### 🔧 Public Functions (1)

- `def add_FunboostBrokerServiceServicer_to_server(servicer, server)`
  - *Line: 37*


---

`````python
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

import funboost.assist.grpc_helper.funboost_grpc_pb2 as funboost__grpc__pb2


class FunboostBrokerServiceStub(object):
    """定义服务
    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.Call = channel.unary_unary(
                '/funboost_grpc.FunboostBrokerService/Call',
                request_serializer=funboost__grpc__pb2.FunboostGrpcRequest.SerializeToString,
                response_deserializer=funboost__grpc__pb2.FunboostGrpcResponse.FromString,
                )


class FunboostBrokerServiceServicer(object):
    """定义服务
    """

    def Call(self, request, context):
        """简单的问候方法
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_FunboostBrokerServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'Call': grpc.unary_unary_rpc_method_handler(
                    servicer.Call,
                    request_deserializer=funboost__grpc__pb2.FunboostGrpcRequest.FromString,
                    response_serializer=funboost__grpc__pb2.FunboostGrpcResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'funboost_grpc.FunboostBrokerService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class FunboostBrokerService(object):
    """定义服务
    """

    @staticmethod
    def Call(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/funboost_grpc.FunboostBrokerService/Call',
            funboost__grpc__pb2.FunboostGrpcRequest.SerializeToString,
            funboost__grpc__pb2.FunboostGrpcResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

`````

--- **end of file: funboost/assist/grpc_helper/funboost_grpc_pb2_grpc.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/grpc_helper/generate_pb.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/grpc_helper/generate_pb.py`

#### 📝 Module Docstring

`````
生成 protobuf 文件的脚本
运行此脚本来生成 funboost_grpc_pb2.py 和 funboost_grpc_pb2_grpc.py 文件
`````

#### 📦 Imports

- `import subprocess`
- `import sys`
- `import os`

#### 🔧 Public Functions (1)

- `def generate_protobuf()`
  - *Line: 14*
  - *生成 protobuf 文件*


---

`````python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
生成 protobuf 文件的脚本
运行此脚本来生成 funboost_grpc_pb2.py 和 funboost_grpc_pb2_grpc.py 文件
"""

import subprocess
import sys
import os


def generate_protobuf():
    """
    生成 protobuf 文件
    """
    try:
        # 执行 protoc 命令
        cmd = [
            sys.executable, '-m', 'grpc_tools.protoc',
            '--proto_path=.',
            '--python_out=.',
            '--grpc_python_out=.',
            'funboost_grpc.proto'
        ]
        
        print("正在生成 protobuf 文件...")
        print(f"执行命令: {' '.join(cmd)}")
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print("✅ protobuf 文件生成成功！")
            print("生成的文件:")
            if os.path.exists('funboost_grpc_pb2.py'):
                print("  - funboost_grpc_pb2.py")
            if os.path.exists('funboost_grpc_pb2_grpc.py'):
                print("  - funboost_grpc_pb2_grpc.py")
        else:
            print("❌ protobuf 文件生成失败！")
            print(f"错误信息: {result.stderr}")
            
    except Exception as e:
        print(f"❌ 生成过程中出现异常: {e}")


if __name__ == '__main__':
    generate_protobuf()

`````

--- **end of file: funboost/assist/grpc_helper/generate_pb.py** (project: funboost) --- 

---


--- **start of file: funboost/assist/grpc_helper/server_sample.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/assist/grpc_helper/server_sample.py`

#### 📦 Imports

- `import threading`
- `import grpc`
- `from concurrent import futures`
- `import time`
- `import funboost_grpc_pb2`
- `import funboost_grpc_pb2_grpc`

#### 🏛️ Classes (1)

##### 📌 `class FunboostGrpcServicer(funboost_grpc_pb2_grpc.FunboostBrokerServiceServicer)`
*Line: 14*

**Docstring:**
`````
HelloService 的实现类
`````

**Public Methods (1):**
- `def Call(self, request, context)`
  - *实现 SayHello 方法*

#### 🔧 Public Functions (2)

- `def process_msg(x, event: threading.Event)`
  - *Line: 30*

- `def serve()`
  - *Line: 36*
  - *启动 gRPC 服务器*


---

`````python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import threading

import grpc
from concurrent import futures
import time

# 导入生成的 protobuf 文件
import funboost_grpc_pb2
import funboost_grpc_pb2_grpc


class FunboostGrpcServicer(funboost_grpc_pb2_grpc.FunboostBrokerServiceServicer):
    """
    HelloService 的实现类
    """
    
    def Call(self, request, context):
        """
        实现 SayHello 方法
        """
        event = threading.Event()
        res = process_msg(request.json_req,event)
        event.wait(600)

        return funboost_grpc_pb2.FunboostGrpcResponse(json_resp=res)


def process_msg(x,event:threading.Event):
    time.sleep(3)
    event.set()
    return f'{{"respx":{x}}}'


def serve():
    """
    启动 gRPC 服务器
    """
    # 创建服务器
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    
    # 添加服务
    funboost_grpc_pb2_grpc.add_FunboostBrokerServiceServicer_to_server(FunboostGrpcServicer(), server)
    
    # 绑定端口
    listen_addr = '[::]:50051'
    server.add_insecure_port(listen_addr)
    
    # 启动服务器
    server.start()
    print(f"gRPC 服务器已启动，监听地址: {listen_addr}")
    
    try:
        while True:
            time.sleep(86400)  # 保持服务器运行
    except KeyboardInterrupt:
        print("正在关闭服务器...")
        server.stop(0)


if __name__ == '__main__':
    serve()

`````

--- **end of file: funboost/assist/grpc_helper/server_sample.py** (project: funboost) --- 

---


--- **start of file: funboost/beggar_version_implementation/beggar_redis_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/beggar_version_implementation/beggar_redis_consumer.py`

#### 📝 Module Docstring

`````
这里是最精简的乞丐版的基于redis的分布式函数执行的实现。相对于完整版，砍掉所有功能，只是演示框架的最精简最本质的实现。
主要是砍掉很多功能，大大简化代码行数，演示框架思路是如何分布式执行python
函数的，这个只做精简演示，不要亲自去使用这里，功能太弱。

完整版支持3种并发类型，乞丐版只支持多线程并发。完整版的线程池是有界队列，线程大小动态伸缩，乞丐版线程池的线程数量只会增加不能主动主动缩小。

完整版支持15种函数辅助控制，包括控频、超时杀死、消费确认 等15种功能，
乞丐版为了简化代码演示，全部不支持。

完整版支持10种消息队列中间件，这里只演示大家喜欢的redis作为中间件。
`````

#### 📦 Imports

- `import json`
- `import redis`
- `from concurrent.futures import ThreadPoolExecutor`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `import time`

#### 🏛️ Classes (1)

##### 📌 `class BeggarRedisConsumer`
*Line: 27*

**Docstring:**
`````
保持和完整版差不多的代码形态。如果仅仅是像这里的十分简化的版本，一个函数实现也可以了。例如下面的函数。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name, consume_function, threads_num)`
  - **Parameters:**
    - `self`
    - `queue_name`
    - `consume_function`
    - `threads_num`

**Public Methods (1):**
- `def start_consuming_message(self)`

#### 🔧 Public Functions (2)

- `def start_consuming_message(queue_name, consume_function, threads_num = 50)`
  - *Line: 50*
  - **Docstring:**
  `````
  本例子实现的功能和中间件过于简单，单一函数最好了。
  看不懂有类的代码，不用看上面那个类，看这个函数就可以，使用一个10行代码的函数实现乞丐版分布式函数执行框架。
  `````

- `def add(x, y)`
  - *Line: 74*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/12/18 0018 10:06
"""
这里是最精简的乞丐版的基于redis的分布式函数执行的实现。相对于完整版，砍掉所有功能，只是演示框架的最精简最本质的实现。
主要是砍掉很多功能，大大简化代码行数，演示框架思路是如何分布式执行python
函数的，这个只做精简演示，不要亲自去使用这里，功能太弱。

完整版支持3种并发类型，乞丐版只支持多线程并发。完整版的线程池是有界队列，线程大小动态伸缩，乞丐版线程池的线程数量只会增加不能主动主动缩小。

完整版支持15种函数辅助控制，包括控频、超时杀死、消费确认 等15种功能，
乞丐版为了简化代码演示，全部不支持。

完整版支持10种消息队列中间件，这里只演示大家喜欢的redis作为中间件。
"""
import json
import redis
from concurrent.futures import ThreadPoolExecutor
from funboost.funboost_config_deafult import BrokerConnConfig

redis_db_frame = redis.Redis(host=BrokerConnConfig.REDIS_HOST, password=BrokerConnConfig.REDIS_PASSWORD,
                             port=BrokerConnConfig.REDIS_PORT, db=BrokerConnConfig.REDIS_DB,
                             ssl=BrokerConnConfig.REDIS_USE_SSL,
                             decode_responses=True)


class BeggarRedisConsumer:
    """保持和完整版差不多的代码形态。如果仅仅是像这里的十分简化的版本，一个函数实现也可以了。例如下面的函数。"""

    def __init__(self, queue_name, consume_function, threads_num):
        self.pool = ThreadPoolExecutor(threads_num)  # 最好是使用BoundedThreadpoolexecutor或customThreadpoolexecutor。无界队列会迅速取完redis消息。
        self.consume_function = consume_function
        self.queue_name = queue_name

    def start_consuming_message(self):
        while True:
            try:
                redis_task = redis_db_frame.blpop(self.queue_name, timeout=60)
                if redis_task:
                    task_str = redis_task[1]
                    print(f'从redis的 [{self.queue_name}] 队列中 取出的消息是： {task_str}  ')
                    task_dict = json.loads(task_str)
                    self.pool.submit(self.consume_function, **task_dict)
                else:
                    print(f'redis的 {self.queue_name} 队列中没有任务')
            except redis.RedisError as e:
                print(e)


def start_consuming_message(queue_name, consume_function, threads_num=50):
    """
    本例子实现的功能和中间件过于简单，单一函数最好了。
    看不懂有类的代码，不用看上面那个类，看这个函数就可以，使用一个10行代码的函数实现乞丐版分布式函数执行框架。

    """
    pool = ThreadPoolExecutor(threads_num)
    while True:
        try:
            redis_task = redis_db_frame.brpop(queue_name, timeout=60)
            if redis_task:
                task_str = redis_task[1]
                # print(f'从redis的 {queue_name} 队列中 取出的消息是： {task_str}')
                pool.submit(consume_function, **json.loads(task_str))
            else:
                print(f'redis的 {queue_name} 队列中没有任务')
        except redis.RedisError as e:
            print(e)


if __name__ == '__main__':
    import time


    def add(x, y):
        time.sleep(5)
        print(f'{x} + {y} 的结果是 {x + y}')


    # 推送任务
    for i in range(100):
        print(i)
        redis_db_frame.lpush('test_beggar_redis_consumer_queue', json.dumps(dict(x=i, y=i * 2)))

    # 消费任务
    # consumer = BeggarRedisConsumer('test_beggar_redis_consumer_queue', consume_function=add, threads_num=100)
    # consumer.start_consuming_message()

    start_consuming_message('test_beggar_redis_consumer_queue', consume_function=add, threads_num=10)

`````

--- **end of file: funboost/beggar_version_implementation/beggar_redis_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/beggar_version_implementation/README.md** (project: funboost) --- 

`````markdown
# 这是乞丐版代码实现

主要是砍掉很多功能，大大简化代码行数，演示框架思路是如何分布式执行python
函数的，不要亲自去使用这里，功能太弱。

完整版支持5种并发类型，乞丐版只支持多线程并发。

完整版支持20种函数辅助控制，包括控频、超时杀死、消费确认 等15种功能，
乞丐版为了简化代码演示，全部不支持。

完整版支持30种消息队列中间件，这里只演示大家喜欢的redis作为中间件。
`````

--- **end of file: funboost/beggar_version_implementation/README.md** (project: funboost) --- 

---


--- **start of file: funboost/beggar_version_implementation/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/beggar_version_implementation/__init__.py`


---

`````python

`````

--- **end of file: funboost/beggar_version_implementation/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/async_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/async_helper.py`

#### 📦 Imports

- `from functools import partial`
- `import asyncio`
- `from concurrent.futures import Executor`
- `from funboost.concurrent_pool.custom_threadpool_executor import ThreadPoolExecutorShrinkAble`
- `import time`
- `import requests`

#### 🔧 Public Functions (4)

- `def get_or_create_event_loop()`
  - *Line: 12*
  - **Docstring:**
  `````
  Python 3.7 风格的 get_event_loop。
  作用：
  - 有 running loop → 返回当前 loop
  - 没有 loop → 自动创建一个新的 loop 并 set
  python3.10后的get_event_loop和python3.7的区别很大
  `````

- `async def simple_run_in_executor(f, *args, **kwargs)`
  - *Line: 34*
  - **Docstring:**
  `````
  一个很强的函数，使任意同步同步函数f，转化成asyncio异步api语法，
  例如 r = await  simple_run_in_executor(block_fun, 20)，可以不阻塞事件循环。
  
  asyncio.run_coroutine_threadsafe 和 run_in_executor 是一对反义词。
  
  asyncio.run_coroutine_threadsafe 是在非异步的上下文环境(也就是正常的同步语法的函数里面)下调用异步函数对象（协程），
  因为当前函数定义没有被async修饰，就不能在函数里面使用await，必须使用这。这个是将asyncio包的future对象转化返回一个concurrent.futures包的future对象。
  
  run_in_executor 是在异步环境（被async修饰的异步函数）里面，调用同步函数，将函数放到线程池运行防止阻塞整个事件循环的其他任务。
  这个是将 一个concurrent.futures包的future对象 转化为 asyncio包的future对象，
  asyncio包的future对象是一个asyncio包的awaitable对象，所以可以被await，concurrent.futures.Future对象不能被await。
  
  
  :param f:  f是一个同步的阻塞函数，f前面不能是由async定义的。
  :param args: f函数的位置方式入参
  :async_executor: 线程池
  :param async_loop: async的loop对象
  :param kwargs:f函数的关键字方式入参
  :return:
  `````

- `def block_fun(x)`
  - *Line: 72*

- `async def enter_fun(xx)`
  - *Line: 78*


---

`````python
from functools import partial
import asyncio
from concurrent.futures import Executor
from funboost.concurrent_pool.custom_threadpool_executor import ThreadPoolExecutorShrinkAble
# from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool

# 没有使用内置的concurrent.futures.ThreadpoolExecutor线程池，而是使用智能伸缩线程池。
async_executor_default = ThreadPoolExecutorShrinkAble(500)
# async_executor_default = FlexibleThreadPool(50)  # 这个不支持future特性


def get_or_create_event_loop():
    """
    Python 3.7 风格的 get_event_loop。
    作用：
    - 有 running loop → 返回当前 loop
    - 没有 loop → 自动创建一个新的 loop 并 set
    python3.10后的get_event_loop和python3.7的区别很大
    """
    try:
        # Python 3.7+
        return asyncio.get_running_loop()
    except RuntimeError:
        # 没有正在运行的 loop
        try:
            # Python 3.6~3.9：get_event_loop 会自动创建
            return asyncio.get_event_loop()
        except RuntimeError:
            # Python 3.10+：get_event_loop 不再自动创建
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            return loop
        
async def simple_run_in_executor(f, *args, async_executor: Executor = None, async_loop=None, **kwargs):
    """
    一个很强的函数，使任意同步同步函数f，转化成asyncio异步api语法，
    例如 r = await  simple_run_in_executor(block_fun, 20)，可以不阻塞事件循环。

    asyncio.run_coroutine_threadsafe 和 run_in_executor 是一对反义词。

    asyncio.run_coroutine_threadsafe 是在非异步的上下文环境(也就是正常的同步语法的函数里面)下调用异步函数对象（协程），
    因为当前函数定义没有被async修饰，就不能在函数里面使用await，必须使用这。这个是将asyncio包的future对象转化返回一个concurrent.futures包的future对象。

    run_in_executor 是在异步环境（被async修饰的异步函数）里面，调用同步函数，将函数放到线程池运行防止阻塞整个事件循环的其他任务。
    这个是将 一个concurrent.futures包的future对象 转化为 asyncio包的future对象，
    asyncio包的future对象是一个asyncio包的awaitable对象，所以可以被await，concurrent.futures.Future对象不能被await。


    :param f:  f是一个同步的阻塞函数，f前面不能是由async定义的。
    :param args: f函数的位置方式入参
    :async_executor: 线程池
    :param async_loop: async的loop对象
    :param kwargs:f函数的关键字方式入参
    :return:
    """
    loopx = async_loop or get_or_create_event_loop()
    async_executorx = async_executor or async_executor_default
    # print(id(loopx))
    result = await loopx.run_in_executor(async_executorx, partial(f, *args, **kwargs))
    return result






if __name__ == '__main__':
    import time
    import requests


    def block_fun(x):
        print(x)
        time.sleep(5)
        return x * 10


    async def enter_fun(xx):  # 入口函数，模拟一旦异步，必须处处异步。不能直接调用block_fun，否则阻塞其他任务。
        await asyncio.sleep(1)
        # r = block_fun(xx)  # 如果这么用就完蛋了，阻塞事件循环， 运行完所有任务需要更久。
        r = await  simple_run_in_executor(block_fun, xx)
        print(r)


    loopy = asyncio.get_event_loop()
    print(id(loopy))
    tasks = []
    tasks.append(simple_run_in_executor(requests.get, url='http://www.baidu.com', timeout=10))  # 同步变异步用法。

    tasks.append(simple_run_in_executor(block_fun, 1))
    tasks.append(simple_run_in_executor(block_fun, 2))
    tasks.append(simple_run_in_executor(block_fun, 3))
    tasks.append(simple_run_in_executor(time.sleep, 8))

    tasks.append(enter_fun(4))
    tasks.append(enter_fun(5))
    tasks.append(enter_fun(6))

    print('开始')
    loopy.run_until_complete(asyncio.wait(tasks))
    print('结束')

    time.sleep(200)

`````

--- **end of file: funboost/concurrent_pool/async_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/async_pool_executor.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/async_pool_executor.py`

#### 📦 Imports

- `import sys`
- `import atexit`
- `import asyncio`
- `import threading`
- `import time`
- `import traceback`
- `from threading import Thread`
- `import traceback`
- `from funboost.concurrent_pool.base_pool_type import FunboostBaseConcurrentPool`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `import selectors`
- `from funboost.concurrent_pool import CustomThreadPoolExecutor as ThreadPoolExecutor`

#### 🏛️ Classes (1)

##### 📌 `class AsyncPoolExecutor(FunboostFileLoggerMixin, FunboostBaseConcurrentPool)`
*Line: 52*

**Docstring:**
`````
使api和线程池一样，最好的性能做法是submit也弄成 async def，生产和消费在同一个线程同一个loop一起运行，但会对调用链路的兼容性产生破坏，从而调用方式不兼容线程池。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, size, specify_async_loop = None, is_auto_start_specify_async_loop_in_child_thread = True)`
  - **Docstring:**
  `````
  :param size: 同时并发运行的协程任务数量。
  :param specify_loop: 可以指定loop,异步三方包的连接池发请求不能使用不同的loop去使用连接池.
  `````
  - **Parameters:**
    - `self`
    - `size`
    - `specify_async_loop = None`
    - `is_auto_start_specify_async_loop_in_child_thread = True`

**Public Methods (1):**
- `def submit(self, func, *args, **kwargs)`

#### 🔧 Public Functions (3)

- `def test_async_pool_executor()`
  - *Line: 157*

- `async def f(x)`
  - *Line: 161*

- `def f2(x)`
  - *Line: 168*


---

`````python
import sys

import atexit
import asyncio
import threading
import time
import traceback
from threading import Thread
import traceback

from funboost.concurrent_pool.base_pool_type import FunboostBaseConcurrentPool
from funboost.core.loggers import FunboostFileLoggerMixin

# if os.name == 'posix':
#     import uvloop
#
#     asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())  # 打猴子补丁最好放在代码顶层，否则很大机会出问题。

"""
# 也可以采用 janus 的 线程安全的queue方式来实现异步池，此queue性能和本模块实现的生产 消费相比，性能并没有提高，所以就不重新用这这个包来实现一次了。
import janus
import asyncio
import time
import threading
import nb_log
queue = janus.Queue(maxsize=6000)

async def consume():
    while 1:
        # time.sleep(1)
        val = await queue.async_q.get() # 这是async，不要看错了
        print(val)

def push():
    for i in range(50000):
        # time.sleep(0.2)
        # print(i)
        queue.sync_q.put(i)  # 这是sync。不要看错了。


if __name__ == '__main__':
    threading.Thread(target=push).start()
    loop = asyncio.get_event_loop()
    loop.create_task(consume())
    loop.run_forever()
"""

if sys.platform == "darwin":  # mac 上会出错
      import selectors
      selectors.DefaultSelector = selectors.PollSelector

class AsyncPoolExecutor(FunboostFileLoggerMixin,FunboostBaseConcurrentPool):
    """
    使api和线程池一样，最好的性能做法是submit也弄成 async def，生产和消费在同一个线程同一个loop一起运行，但会对调用链路的兼容性产生破坏，从而调用方式不兼容线程池。
    """

    def __init__(self, size, specify_async_loop=None,
                 is_auto_start_specify_async_loop_in_child_thread=True):
        """

        :param size: 同时并发运行的协程任务数量。
        :param specify_loop: 可以指定loop,异步三方包的连接池发请求不能使用不同的loop去使用连接池.
        """
        self._size = size
        self._specify_async_loop = specify_async_loop
        self._is_auto_start_specify_async_loop_in_child_thread = is_auto_start_specify_async_loop_in_child_thread
        self.loop = specify_async_loop or asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        self._diff_init()
        # self._lock = threading.Lock()
        t = Thread(target=self._start_loop_in_new_thread, daemon=False)
        # t.setDaemon(True)  # 设置守护线程是为了有机会触发atexit，使程序自动结束，不用手动调用shutdown
        t.start()
     

    # def submit000(self, func, *args, **kwargs):
    #     # 这个性能比下面的采用 run_coroutine_threadsafe + result返回快了3倍多。
    #     with self._lock:
    #         while 1:
    #             if not self._queue.full():
    #                 self.loop.call_soon_threadsafe(self._queue.put_nowait, (func, args, kwargs))
    #                 break
    #             else:
    #                 time.sleep(0.01)

    def _diff_init(self):
        if sys.version_info.minor < 10:
            # self._sem = asyncio.Semaphore(self._size, loop=self.loop)
            self._queue = asyncio.Queue(maxsize=self._size, loop=self.loop)
        else:
            # self._sem = asyncio.Semaphore(self._size) # python3.10后，很多类和方法都删除了loop传参
            self._queue = asyncio.Queue(maxsize=self._size)


    def submit(self, func, *args, **kwargs):
        future = asyncio.run_coroutine_threadsafe(self._produce(func, *args, **kwargs), self.loop)  # 这个 run_coroutine_threadsafe 方法也有缺点，消耗的性能巨大。
        future.result()  # 阻止过快放入，放入超过队列大小后，使submit阻塞。 背压是为了防止 迅速掏空消息队列几千万消息到内存.

    async def _produce(self, func, *args, **kwargs):
        await self._queue.put((func, args, kwargs))

    async def _consume(self):
        while True:
            func, args, kwargs = await self._queue.get()
            if isinstance(func, str) and func.startswith('stop'):
                # self.logger.debug(func)
                break
            # noinspection PyBroadException,PyUnusedLocal
            try:
                await func(*args, **kwargs)
            except BaseException as e:
                self.logger.exception(f'func:{func}, args:{args}, kwargs:{kwargs} exc_type:{type(e)}  traceback_exc:{traceback.format_exc()}')
            # self._queue.task_done()

    async def __run(self):
        for _ in range(self._size):
            asyncio.ensure_future(self._consume())

    def _start_loop_in_new_thread(self, ):
        # self._loop.run_until_complete(self.__run())  # 这种也可以。
        # self._loop.run_forever()

        # asyncio.set_event_loop(self.loop)
        # self.loop.run_until_complete(asyncio.wait([self._consume() for _ in range(self._size)], loop=self.loop))
        # self._can_be_closed_flag = True
        if self._specify_async_loop is None:
            for _ in range(self._size):
                self.loop.create_task(self._consume())
        else:
            for _ in range(self._size):
                asyncio.run_coroutine_threadsafe(self._consume(),self.loop) # 这是 asyncio 专门提供的用于从其他线程向事件循环安全提交任务的函数。
        if self._specify_async_loop is None:
            self.loop.run_forever()
        else:
            if self._is_auto_start_specify_async_loop_in_child_thread:
                try:
                    self.loop.run_forever() #如果是指定的loop不能多次启动一个loop.
                except Exception as e:
                    self.logger.warning(f'{e} {traceback.format_exc()}')   # 如果多个线程使用一个loop，不能重复启动loop，否则会报错。
            else:
                pass # 用户需要自己在自己的业务代码中去手动启动loop.run_forever() 


    # def shutdown(self):
    #     if self.loop.is_running():  # 这个可能是atregster触发，也可能是用户手动调用，需要判断一下，不能关闭两次。
    #         for i in range(self._size):
    #             self.submit(f'stop{i}', )
    #         while not self._can_be_closed_flag:
    #             time.sleep(0.1)
    #         self.loop.stop()
    #         self.loop.close()
    #         print('关闭循环')



if __name__ == '__main__':
    def test_async_pool_executor():
        from funboost.concurrent_pool import CustomThreadPoolExecutor as ThreadPoolExecutor
        # from concurrent.futures.thread import ThreadPoolExecutor
        # noinspection PyUnusedLocal
        async def f(x):
            await asyncio.sleep(1)
            pass
            print('打印', x)
            # await asyncio.sleep(1)
            # raise Exception('aaa')

        def f2(x):
            pass
            # time.sleep(0.001)
            print('打印', x)

        print(1111)

        t1 = time.time()
        pool = AsyncPoolExecutor(20)
        # pool = ThreadPoolExecutor(200)  # 协程不能用线程池运行，否则压根不会执行print打印，对于一部函数 f(x)得到的是一个协程，必须进一步把协程编排成任务放在loop循环里面运行。
        for i in range(1, 501):
            print('放入', i)
            pool.submit(f, i)
        # time.sleep(5)
        # pool.submit(f, 'hi')
        # pool.submit(f, 'hi2')
        # pool.submit(f, 'hi3')
        # print(2222)
        pool.shutdown()
        print(time.time() - t1)


    test_async_pool_executor()
    # test_async_producer_consumer()

    print(sys.version_info)

`````

--- **end of file: funboost/concurrent_pool/async_pool_executor.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/base_pool_type.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/base_pool_type.py`

#### 🏛️ Classes (1)

##### 📌 `class FunboostBaseConcurrentPool`
*Line: 3*


---

`````python


class FunboostBaseConcurrentPool:

    def __deepcopy__(self, memodict={}):
        """
        pydantic 的默认类型声明，对象需要能deepcopy
        """
        return self
`````

--- **end of file: funboost/concurrent_pool/base_pool_type.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/bounded_processpoolexcutor_gt_py37.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/bounded_processpoolexcutor_gt_py37.py`

#### 📦 Imports

- `import multiprocessing`
- `import concurrent.futures`
- `import sys`
- `import threading`
- `from concurrent.futures import _base`
- `from concurrent.futures.process import _ExceptionWithTraceback`
- `from concurrent.futures.process import _ResultItem`
- `from functools import wraps`
- `import os`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from concurrent.futures.process import _sendback_result`

#### 🏛️ Classes (3)

##### 📌 `class _BoundedPoolExecutor`
*Line: 102*

**Public Methods (3):**
- `def acquire(self)`
- `def release(self, fn)`
- `def submit(self, fn, *args, **kwargs)`

**Class Variables (1):**
- `semaphore = None`

##### 📌 `class BoundedProcessPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ProcessPoolExecutor)`
*Line: 119*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = None)`
  - **Parameters:**
    - `self`
    - `max_workers = None`

##### 📌 `class BoundedThreadPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ThreadPoolExecutor)`
*Line: 132*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = None)`
  - **Parameters:**
    - `self`
    - `max_workers = None`


---

`````python
import multiprocessing
import concurrent.futures
import sys
import threading
from concurrent.futures import _base
from concurrent.futures.process import _ExceptionWithTraceback, _ResultItem  # noqa
from functools import wraps
import os

from funboost.core.loggers import get_funboost_file_logger

name = 'bounded_pool_executor'

logger = get_funboost_file_logger('BoundedProcessPoolExecutor')


def _process_worker(call_queue, result_queue):
    """Evaluates calls from call_queue and places the results in result_queue.

    This worker is run in a separate process.

    Args:
        call_queue: A multiprocessing.Queue of _CallItems that will be read and
            evaluated by the worker.
        result_queue: A multiprocessing.Queue of _ResultItems that will written
            to by the worker.
        shutdown: A multiprocessing.Event that will be set as a signal to the
            worker that it should exit when call_queue is empty.
    """
    while True:
        call_item = call_queue.get(block=True)
        if call_item is None:
            # Wake up queue management thread
            result_queue.put(os.getpid())
            return
        try:
            r = call_item.fn(*call_item.args, **call_item.kwargs)
        except BaseException as e:
            exc = _ExceptionWithTraceback(e, e.__traceback__)
            result_queue.put(_ResultItem(call_item.work_id, exception=exc))
            logger.exception(e)  # 主要是直接显示错误。
        else:
            result_queue.put(_ResultItem(call_item.work_id,
                                         result=r))


def _process_worker_grater_than_py37(call_queue, result_queue, initializer, initargs):
    """Evaluates calls from call_queue and places the results in result_queue.

    This worker is run in a separate process.

    Args:
        call_queue: A ctx.Queue of _CallItems that will be read and
            evaluated by the worker.
        result_queue: A ctx.Queue of _ResultItems that will written
            to by the worker.
        initializer: A callable initializer, or None
        initargs: A tuple of args for the initializer
    """
    from concurrent.futures.process import _sendback_result
    if initializer is not None:
        try:
            initializer(*initargs)
        except BaseException:
            _base.LOGGER.critical('Exception in initializer:', exc_info=True)
            # The parent will notice that the process stopped and
            # mark the pool broken
            return
    while True:
        call_item = call_queue.get(block=True)
        # print(call_item)
        if call_item is None:
            # Wake up queue management thread
            result_queue.put(os.getpid())
            return
        try:
            r = call_item.fn(*call_item.args, **call_item.kwargs)
        except BaseException as e:
            exc = _ExceptionWithTraceback(e, e.__traceback__)
            _sendback_result(result_queue, call_item.work_id, exception=exc)
            logger.exception(e)  # 主要是直接显示错误。
        else:
            _sendback_result(result_queue, call_item.work_id, result=r)
            del r

        # Liberate the resource as soon as possible, to avoid holding onto
        # open files or shared memory that is not needed anymore
        del call_item


def _deco(f):
    @wraps(f)
    def __deco(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except BaseException as e:
            logger.exception(e)

    return __deco


class _BoundedPoolExecutor:
    semaphore = None

    def acquire(self):
        self.semaphore.acquire()

    def release(self, fn):
        self.semaphore.release()

    def submit(self, fn, *args, **kwargs):
        self.acquire()
        future = super().submit(fn, *args, **kwargs)  # noqa
        future.add_done_callback(self.release)

        return future


class BoundedProcessPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ProcessPoolExecutor):

    def __init__(self, max_workers=None):

        if sys.version >= '3.7':
            # print(sys.version)
            concurrent.futures.process._process_worker = _process_worker_grater_than_py37
        else:
            concurrent.futures.process._process_worker = _process_worker
        super().__init__(max_workers)
        self.semaphore = multiprocessing.BoundedSemaphore(max_workers)


class BoundedThreadPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ThreadPoolExecutor):

    def __init__(self, max_workers=None):
        super().__init__(max_workers)
        self.semaphore = threading.BoundedSemaphore(max_workers)






`````

--- **end of file: funboost/concurrent_pool/bounded_processpoolexcutor_gt_py37.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/bounded_processpoolexcutor_py36.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/bounded_processpoolexcutor_py36.py`

#### 📦 Imports

- `import multiprocessing`
- `import concurrent.futures`
- `import threading`
- `from concurrent.futures.process import _ExceptionWithTraceback`
- `from concurrent.futures.process import _ResultItem`
- `from functools import wraps`
- `import os`
- `from funboost.core.loggers import get_funboost_file_logger`
- `import time`
- `import nb_log`

#### 🏛️ Classes (3)

##### 📌 `class _BoundedPoolExecutor`
*Line: 56*

**Public Methods (3):**
- `def acquire(self)`
- `def release(self, fn)`
- `def submit(self, fn, *args, **kwargs)`

**Class Variables (1):**
- `semaphore = None`

##### 📌 `class BoundedProcessPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ProcessPoolExecutor)`
*Line: 73*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = None)`
  - **Parameters:**
    - `self`
    - `max_workers = None`

##### 📌 `class BoundedThreadPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ThreadPoolExecutor)`
*Line: 81*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = None)`
  - **Parameters:**
    - `self`
    - `max_workers = None`

#### 🔧 Public Functions (1)

- `def test_f(x)`
  - *Line: 88*


---

`````python
import multiprocessing
import concurrent.futures
import threading
from concurrent.futures.process import _ExceptionWithTraceback, _ResultItem  # noqa
from functools import wraps
import os

from funboost.core.loggers import get_funboost_file_logger

name = 'bounded_pool_executor'

logger = get_funboost_file_logger('BoundedProcessPoolExecutor')


def _process_worker(call_queue, result_queue):
    """Evaluates calls from call_queue and places the results in result_queue.

    This worker is run in a separate process.

    Args:
        call_queue: A multiprocessing.Queue of _CallItems that will be read and
            evaluated by the worker.
        result_queue: A multiprocessing.Queue of _ResultItems that will written
            to by the worker.
        shutdown: A multiprocessing.Event that will be set as a signal to the
            worker that it should exit when call_queue is empty.
    """
    while True:
        call_item = call_queue.get(block=True)
        if call_item is None:
            # Wake up queue management thread
            result_queue.put(os.getpid())
            return
        try:
            r = call_item.fn(*call_item.args, **call_item.kwargs)
        except BaseException as e:
            exc = _ExceptionWithTraceback(e, e.__traceback__)
            result_queue.put(_ResultItem(call_item.work_id, exception=exc))
            logger.exception(e)  # 主要是直接显示错误。
        else:
            result_queue.put(_ResultItem(call_item.work_id,
                                         result=r))


def _deco(f):
    @wraps(f)
    def __deco(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except BaseException as e:
            logger.exception(e)

    return __deco


class _BoundedPoolExecutor:
    semaphore = None

    def acquire(self):
        self.semaphore.acquire()

    def release(self, fn):
        self.semaphore.release()

    def submit(self, fn, *args, **kwargs):
        self.acquire()
        future = super().submit(fn, *args, **kwargs)  # noqa
        future.add_done_callback(self.release)

        return future


class BoundedProcessPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ProcessPoolExecutor):

    def __init__(self, max_workers=None):
        super().__init__(max_workers)
        self.semaphore = multiprocessing.BoundedSemaphore(max_workers)
        concurrent.futures.process._process_worker = _process_worker


class BoundedThreadPoolExecutor(_BoundedPoolExecutor, concurrent.futures.ThreadPoolExecutor):

    def __init__(self, max_workers=None):
        super().__init__(max_workers)
        self.semaphore = threading.BoundedSemaphore(max_workers)


def test_f(x):
    import time
    time.sleep(5)
    print(x * 10)
    1 / 0


if __name__ == '__main__':
    import nb_log

    # pool = BoundedProcessPoolExecutor(4)
    pool = BoundedThreadPoolExecutor(4)
    for i in range(10):
        print(i)
        pool.submit(test_f, i)
`````

--- **end of file: funboost/concurrent_pool/bounded_processpoolexcutor_py36.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/bounded_threadpoolexcutor.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/bounded_threadpoolexcutor.py`

#### 📝 Module Docstring

`````
一个有界任务队列的thradpoolexcutor
直接捕获错误日志
`````

#### 📦 Imports

- `from functools import wraps`
- `import queue`
- `from concurrent.futures import ThreadPoolExecutor`
- `from concurrent.futures import Future`
- `from concurrent.futures.thread import _WorkItem`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🏛️ Classes (1)

##### 📌 `class BoundedThreadPoolExecutor(ThreadPoolExecutor, FunboostBaseConcurrentPool)`
*Line: 29*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = None, thread_name_prefix = '')`
  - **Parameters:**
    - `self`
    - `max_workers = None`
    - `thread_name_prefix = ''`

**Public Methods (1):**
- `def submit(self, fn, *args, **kwargs)`

#### 🔧 Public Functions (1)

- `def fun()`
  - *Line: 47*


---

`````python
# coding=utf-8
"""
一个有界任务队列的thradpoolexcutor
直接捕获错误日志
"""
from functools import wraps
import queue
from concurrent.futures import ThreadPoolExecutor, Future
# noinspection PyProtectedMember
from concurrent.futures.thread import _WorkItem  # noqa

from funboost.concurrent_pool import FunboostBaseConcurrentPool
from funboost.core.loggers import get_funboost_file_logger

logger = get_funboost_file_logger('BoundedThreadPoolExecutor')


def _deco(f):
    @wraps(f)
    def __deco(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except BaseException as e:
            logger.exception(e)

    return __deco if f is not None else f


class BoundedThreadPoolExecutor(ThreadPoolExecutor,FunboostBaseConcurrentPool ):
    def __init__(self, max_workers=None, thread_name_prefix=''):
        ThreadPoolExecutor.__init__(self, max_workers, thread_name_prefix)
        self._work_queue = queue.Queue(max_workers * 2)

    def submit(self, fn, *args, **kwargs):
        with self._shutdown_lock:
            if self._shutdown:
                raise RuntimeError('cannot schedule new futures after shutdown')
            f = Future()
            fn_deco = _deco(fn)
            w = _WorkItem(f, fn_deco, args, kwargs)
            self._work_queue.put(w)
            self._adjust_thread_count()
            return f


if __name__ == '__main__':
    def fun():
        print(1 / 0.2)

    # 如果是官方线程池，这样不报错你还以为代码没毛病呢。
    with BoundedThreadPoolExecutor(10) as pool:
        for i in range(20):
            pool.submit(fun)

`````

--- **end of file: funboost/concurrent_pool/bounded_threadpoolexcutor.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/concurrent_pool_with_multi_process.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/concurrent_pool_with_multi_process.py`

#### 📦 Imports

- `import time`
- `import multiprocessing`
- `import threading`
- `import asyncio`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `import atexit`
- `import os`
- `import typing`
- `from funboost.concurrent_pool.custom_threadpool_executor import CustomThreadpoolExecutor`
- `from funboost.concurrent_pool.async_pool_executor import AsyncPoolExecutor`

#### 🏛️ Classes (1)

##### 📌 `class ConcurrentPoolWithProcess(FunboostFileLoggerMixin)`
*Line: 14*

**🔧 Constructor (`__init__`):**
- `def __init__(self, pool_class: typing.Type = CustomThreadpoolExecutor, max_works = 500, process_num = 1)`
  - **Parameters:**
    - `self`
    - `pool_class: typing.Type = CustomThreadpoolExecutor`
    - `max_works = 500`
    - `process_num = 1`

**Public Methods (2):**
- `def submit(self, func, *args, **kwargs)`
- `def shutdown(self, wait = True)`

#### 🔧 Public Functions (2)

- `def test_f(x)`
  - *Line: 38*

- `async def async_f(x)`
  - *Line: 43*


---

`````python
import time
import multiprocessing
import threading
import asyncio
from funboost.core.loggers import FunboostFileLoggerMixin
import atexit
import os
import typing
from funboost.concurrent_pool.custom_threadpool_executor import CustomThreadpoolExecutor

from funboost.concurrent_pool.async_pool_executor import AsyncPoolExecutor


class ConcurrentPoolWithProcess(FunboostFileLoggerMixin):
    def _start_a_pool(self, pool_class, max_works):
        pool = pool_class(max_works)
        while True:
            func, args, kwargs = self._multi_process_queue.get()  # 结束可以放None，然后这里判断，终止。或者joinable queue
            print(func, args, kwargs)
            pool.submit(func, *args, **kwargs)

    def __init__(self, pool_class: typing.Type = CustomThreadpoolExecutor, max_works=500, process_num=1):
        self._multi_process_queue = multiprocessing.Queue(100)
        for _ in range(process_num):
            multiprocessing.Process(target=self._start_a_pool, args=(pool_class, max_works), daemon=False).start()

    # noinspection PyUnusedLocal
    def _queue_call_back(self, result):
        self._multi_process_queue.task_done()

    def submit(self, func, *args, **kwargs):
        self._multi_process_queue.put((func, args, kwargs))

    def shutdown(self, wait=True):
        pass


def test_f(x):
    time.sleep(1)
    print(x * 10, os.getpid())


async def async_f(x):
    await asyncio.sleep(1)
    print(x * 10)


if __name__ == '__main__':
    pool = ConcurrentPoolWithProcess(AsyncPoolExecutor, 20, 2)
    # pool = GeventPoolExecutor(200,)

    # time.sleep(15)
    for i in range(1000):
        time.sleep(0.1)
        pool.submit(async_f, i)

`````

--- **end of file: funboost/concurrent_pool/concurrent_pool_with_multi_process.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/custom_evenlet_pool_executor.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/custom_evenlet_pool_executor.py`

#### 📦 Imports

- `import atexit`
- `import time`
- `import warnings`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.lazy_impoter import EventletImporter`

#### 🏛️ Classes (1)

##### 📌 `class CustomEventletPoolExecutor(EventletImporter().greenpool.GreenPool, FunboostBaseConcurrentPool)`
*Line: 55*

**🔧 Constructor (`__init__`):**
- `def __init__(self, *args, **kwargs)`
  - **Parameters:**
    - `self`
    - `*args`
    - `**kwargs`

**Public Methods (2):**
- `def submit(self, *args, **kwargs)`
- `def shutdown(self)`

#### 🔧 Public Functions (4)

- `def check_evenlet_monkey_patch(raise_exc = True)`
  - *Line: 15*

- `def evenlet_timeout_deco(timeout_t)`
  - *Line: 32*

- `def get_eventlet_pool_executor(*args2, **kwargs2)`
  - *Line: 54*

- `def f2(x)`
  - *Line: 77*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/7/3 10:35
import atexit
import time
import warnings
# from eventlet import greenpool, monkey_patch, patcher, Timeout

from funboost.concurrent_pool import FunboostBaseConcurrentPool
from funboost.core.loggers import get_funboost_file_logger
# print('eventlet 导入')
from funboost.core.lazy_impoter import EventletImporter


def check_evenlet_monkey_patch(raise_exc=True):
    try:
        if not EventletImporter().patcher.is_monkey_patched('socket'):  # 随便选一个检测标志
            if raise_exc:
                warnings.warn(f'检测到没有打 evenlet 包的猴子补丁 ,请在起始脚本文件首行加上     import eventlet;eventlet.monkey_patch(all=True) ')
                raise Exception('检测到没有打 evenlet 包的猴子补丁 ,请在起始脚本文件首行加上    import eventlet;eventlet.monkey_patch(all=True)')
        else:
            return 1
    except ModuleNotFoundError:
        if raise_exc:
            warnings.warn(f'检测到没有打 evenlet 包的猴子补丁 ,请在起始脚本文件首行加上     import eventlet;eventlet.monkey_patch(all=True) ')
            raise Exception('检测到没有打 evenlet 包的猴子补丁 ,请在起始脚本文件首行加上    import eventlet;eventlet.monkey_patch(all=True)')


logger_evenlet_timeout_deco = get_funboost_file_logger('evenlet_timeout_deco')


def evenlet_timeout_deco(timeout_t):
    def _evenlet_timeout_deco(f):
        def __evenlet_timeout_deco(*args, **kwargs):
            timeout = EventletImporter().Timeout(timeout_t, )
            # timeout.start()  # 与gevent不一样,直接start了。
            result = None
            try:
                result = f(*args, **kwargs)
            except EventletImporter().Timeout as t:
                logger_evenlet_timeout_deco.error(f'函数 {f} 运行超过了 {timeout_t} 秒')
                if t is not timeout:
                    print(t)
                    # raise  # not my timeout
            finally:
                timeout.cancel()
                return result

        return __evenlet_timeout_deco

    return _evenlet_timeout_deco


def get_eventlet_pool_executor(*args2, **kwargs2):
    class CustomEventletPoolExecutor(EventletImporter().greenpool.GreenPool, FunboostBaseConcurrentPool):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            check_evenlet_monkey_patch()  # basecomer.py中检查。
            atexit.register(self.shutdown)

        def submit(self, *args, **kwargs):  # 保持为一直的公有用法。
            # nb_print(args)
            self.spawn_n(*args, **kwargs)
            # self.spawn_n(*args, **kwargs)

        def shutdown(self):
            self.waitall()

    return CustomEventletPoolExecutor(*args2, **kwargs2)


if __name__ == '__main__':
    # greenpool.GreenPool.waitall()
    EventletImporter().monkey_patch(all=True)


    def f2(x):

        time.sleep(2)
        print(x)


    pool = get_eventlet_pool_executor(4)

    for i in range(15):
        print(f'放入{i}')
        pool.submit(evenlet_timeout_deco(8)(f2), i)

`````

--- **end of file: funboost/concurrent_pool/custom_evenlet_pool_executor.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/custom_gevent_pool_executor.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/custom_gevent_pool_executor.py`

#### 📦 Imports

- `import atexit`
- `import time`
- `import warnings`
- `from typing import Callable`
- `import threading`
- `from funboost.core.lazy_impoter import GeventImporter`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.loggers import FunboostFileLoggerMixin`

#### 🏛️ Classes (3)

##### 📌 `class GeventPoolExecutor2(FunboostFileLoggerMixin, FunboostBaseConcurrentPool)`
*Line: 74*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_works)`
  - **Parameters:**
    - `self`
    - `max_works`

**Public Methods (1):**
- `def submit(self, fn: Callable, *args, **kwargs)`

##### 📌 `class GeventPoolExecutor3(FunboostFileLoggerMixin, FunboostBaseConcurrentPool)`
*Line: 102*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_works)`
  - **Parameters:**
    - `self`
    - `max_works`

**Public Methods (3):**
- `def submit(self, fn: Callable, *args, **kwargs)`
- `def joinall(self)`
- `def joinall_in_new_thread(self)`

##### 📌 `class GeventPoolExecutor(GeventImporter().gevent_pool.Pool, FunboostBaseConcurrentPool)`
*Line: 59*

**🔧 Constructor (`__init__`):**
- `def __init__(self, size2 = None, greenlet_class2 = None)`
  - **Parameters:**
    - `self`
    - `size2 = None`
    - `greenlet_class2 = None`

**Public Methods (2):**
- `def submit(self, *args, **kwargs)`
- `def shutdown(self)`

#### 🔧 Public Functions (4)

- `def check_gevent_monkey_patch(raise_exc = True)`
  - *Line: 19*

- `def gevent_timeout_deco(timeout_t)`
  - *Line: 36*

- `def get_gevent_pool_executor(size = None, greenlet_class = None)`
  - *Line: 58*

- `def f2(x)`
  - *Line: 136*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/7/2 14:11
import atexit
import time
import warnings
# from collections import Callable
from typing import Callable
import threading
from funboost.core.lazy_impoter import GeventImporter

# from nb_log import LoggerMixin, nb_print, LogManager
from funboost.concurrent_pool import FunboostBaseConcurrentPool
from funboost.core.loggers import get_funboost_file_logger, FunboostFileLoggerMixin


# print('gevent 导入')

def check_gevent_monkey_patch(raise_exc=True):
    try:
        if not GeventImporter().monkey.is_module_patched('socket'):  # 随便选一个检测标志
            if raise_exc:
                warnings.warn(f'检测到 你还没有打gevent包的猴子补丁，请在所运行的起始脚本第一行写上  【import gevent.monkey;gevent.monkey.patch_all()】  这句话。')
                raise Exception(f'检测到 你还没有打gevent包的猴子补丁，请在所运行的起始脚本第一行写上  【import gevent.monkey;gevent.monkey.patch_all()】  这句话。')
        else:
            return 1
    except ModuleNotFoundError:
        if raise_exc:
            warnings.warn(f'检测到 你还没有打gevent包的猴子补丁，请在所运行的起始脚本第一行写上  【import gevent.monkey;gevent.monkey.patch_all()】  这句话。')
            raise Exception(f'检测到 你还没有打gevent包的猴子补丁，请在所运行的起始脚本第一行写上  【import gevent.monkey;gevent.monkey.patch_all()】  这句话。')


logger_gevent_timeout_deco = get_funboost_file_logger('gevent_timeout_deco')


def gevent_timeout_deco(timeout_t):
    def _gevent_timeout_deco(f):
        def __gevent_timeout_deceo(*args, **kwargs):
            timeout = GeventImporter().gevent.Timeout(timeout_t, )
            timeout.start()
            result = None
            try:
                result = f(*args, **kwargs)
            except GeventImporter().gevent.Timeout as t:
                logger_gevent_timeout_deco.error(f'函数 {f} 运行超过了 {timeout_t} 秒')
                if t is not timeout:
                    print(t)
                    # raise  # not my timeout
            finally:
                timeout.close()
                return result

        return __gevent_timeout_deceo

    return _gevent_timeout_deco


def get_gevent_pool_executor(size=None, greenlet_class=None):
    class GeventPoolExecutor(GeventImporter().gevent_pool.Pool, FunboostBaseConcurrentPool):
        def __init__(self, size2=None, greenlet_class2=None):
            check_gevent_monkey_patch()  # basecomer.py中检查。
            super().__init__(size2, greenlet_class2)
            atexit.register(self.shutdown)

        def submit(self, *args, **kwargs):
            self.spawn(*args, **kwargs)

        def shutdown(self):
            self.join()

    return GeventPoolExecutor(size, greenlet_class)


class GeventPoolExecutor2(FunboostFileLoggerMixin, FunboostBaseConcurrentPool):
    def __init__(self, max_works, ):
        self._q = GeventImporter().JoinableQueue(maxsize=max_works)
        # self._q = Queue(maxsize=max_works)
        for _ in range(max_works):
            GeventImporter().gevent.spawn(self.__worker)
        # atexit.register(self.__atexit)
        self._q.join(timeout=100)

    def __worker(self):
        while True:
            fn, args, kwargs = self._q.get()
            try:
                fn(*args, **kwargs)
            except BaseException as exc:
                self.logger.exception(f'函数 {fn.__name__} 中发生错误，错误原因是 {type(exc)} {exc} ')
            finally:
                pass
                self._q.task_done()

    def submit(self, fn: Callable, *args, **kwargs):
        self._q.put((fn, args, kwargs))

    def __atexit(self):
        self.logger.critical('想即将退出程序。')
        self._q.join()


class GeventPoolExecutor3(FunboostFileLoggerMixin, FunboostBaseConcurrentPool):
    def __init__(self, max_works, ):
        self._q = GeventImporter().gevent.queue.Queue(max_works)
        self.g_list = []
        for _ in range(max_works):
            self.g_list.append(GeventImporter().gevent.spawn(self.__worker))
        atexit.register(self.__atexit)

    def __worker(self):
        while True:
            fn, args, kwargs = self._q.get()
            try:
                fn(*args, **kwargs)
            except BaseException as exc:
                self.logger.exception(f'函数 {fn.__name__} 中发生错误，错误原因是 {type(exc)} {exc} ')

    def submit(self, fn: Callable, *args, **kwargs):
        self._q.put((fn, args, kwargs))

    def joinall(self):
        GeventImporter().gevent.joinall(self.g_list)

    def joinall_in_new_thread(self):
        threading.Thread(target=self.joinall)

    def __atexit(self):
        self.logger.critical('想即将退出程序。')
        self.joinall()


if __name__ == '__main__':
    GeventImporter().monkey.patch_all(thread=False)


    def f2(x):

        time.sleep(3)
        print(x * 10)


    pool = GeventPoolExecutor3(40)

    for i in range(20):
        time.sleep(0.1)
        print(f'放入{i}')
        pool.submit(gevent_timeout_deco(8)(f2), i)
    # pool.joinall_in_new_thread()
    print(66666666)

`````

--- **end of file: funboost/concurrent_pool/custom_gevent_pool_executor.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/custom_threadpool_executor.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/custom_threadpool_executor.py`

#### 📝 Module Docstring

`````
史上最强的python线程池。

最智能的可自动实时调节线程数量的线程池。此线程池和官方concurrent.futures的线程池 是鸭子类关系，所以可以一键替换类名 或者 import as来替换类名。
对比官方线程池，有4个创新功能或改进。

1、主要是不仅能扩大，还可自动缩小(官方内置的ThreadpoolExecutor不具备此功能，此概念是什么意思和目的，可以百度java ThreadpoolExecutor的KeepAliveTime参数的介绍)，
   例如实例化一个1000线程的线程池，上一分钟疯狂高频率的对线程池submit任务，线程池会扩张到最大线程数量火力全开运行，
   但之后的七八个小时平均每分钟只submit一两个任务，官方线程池会一直维持在1000线程，而此线程池会自动缩小，靠什么来识别预测啥时机可以自动缩小呢，就是KeepAliveTime。

2、非常节制的开启多线程，例如实例化一个最大100线程数目的pool，每隔2秒submit一个函数任务，而函数每次只需要1秒就能完成，实际上只需要调节增加到1个线程就可以，不需要慢慢增加到100个线程
官方的线程池不够智能，会一直增加到最大线程数目，此线程池则不会。

3、线程池任务的queue队列，修改为有界队列

4、此线程池运行函数出错时候，直接显示线程错误，官方的线程池则不会显示错误，例如函数中写1/0,任然不现实错误。

此实现了submit，还实现future相关的内容，真正的和内置的ThreadpoolExecutor 完全替代。

可以在各种地方加入 time.sleep 来验证 第1条和第2条的自动智能缩放功能。
`````

#### 📦 Imports

- `import logging`
- `import os`
- `import atexit`
- `import queue`
- `import sys`
- `import threading`
- `import time`
- `import weakref`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from nb_log import LoggerLevelSetterMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from concurrent.futures import Executor`
- `from concurrent.futures import Future`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch`

#### 🏛️ Classes (4)

##### 📌 `class _WorkItem(FunboostFileLoggerMixin)`
*Line: 65*

**🔧 Constructor (`__init__`):**
- `def __init__(self, future, fn, args, kwargs)`
  - **Parameters:**
    - `self`
    - `future`
    - `fn`
    - `args`
    - `kwargs`

**Public Methods (1):**
- `def run(self)`

##### 📌 `class ThreadPoolExecutorShrinkAble(Executor, FunboostFileLoggerMixin, LoggerLevelSetterMixin, FunboostBaseConcurrentPool)`
*Line: 95*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers: int = None, thread_name_prefix = '', work_queue_maxsize = 10)`
  - **Docstring:**
  `````
  最好需要兼容官方concurren.futures.ThreadPoolExecutor 和改版的BoundedThreadPoolExecutor，入参名字和个数保持了一致。
  :param max_workers:
  :param thread_name_prefix:
  `````
  - **Parameters:**
    - `self`
    - `max_workers: int = None`
    - `thread_name_prefix = ''`
    - `work_queue_maxsize = 10`

**Public Methods (2):**
- `def submit(self, func, *args, **kwargs)`
- `def shutdown(self, wait = True)`

**Class Variables (3):**
- `MIN_WORKERS = 1`
- `KEEP_ALIVE_TIME = 60`
- `THREAD_USE_DAEMON = True`

##### 📌 `class ThreadPoolExecutorShrinkAbleNonDaemon(ThreadPoolExecutorShrinkAble)`
*Line: 163*

**Docstring:**
`````
这个给 apscheduler 的 ThreadPoolExecutorForAps 使用很好，这个线程池里面的线程不是守护线程，

防止代码里面有子线程在运行但是主线程结束，导致这个报错 
raise RuntimeError('cannot schedule new futures after ' RuntimeError: cannot schedule new futures after interpreter shutdown

之前backgroud scheduler使用得是线程池里面是守护线程，为了避免cannot schedule new futures after ，
用户需要手动在主线程加个 ctrl_c_recv() 或者 while 1::time.sleep(10) 来阻止主线程结束，这样会麻烦用户。
`````

**Class Variables (2):**
- `MIN_WORKERS = 0`
- `THREAD_USE_DAEMON = False`

##### 📌 `class _CustomThread(threading.Thread, FunboostFileLoggerMixin, LoggerLevelSetterMixin)`
*Line: 178*

**🔧 Constructor (`__init__`):**
- `def __init__(self, executorx: ThreadPoolExecutorShrinkAble)`
  - **Parameters:**
    - `self`
    - `executorx: ThreadPoolExecutorShrinkAble`

**Public Methods (1):**
- `def run(self)`

**Class Variables (1):**
- `_lock_for_judge_threads_free_count = threading.Lock()`

#### 🔧 Public Functions (5)

- `def check_not_monkey()`
  - *Line: 43*

- `def set_threadpool_executor_shrinkable(min_works = 1, keep_alive_time = 5)`
  - *Line: 90*

- `def show_current_threads_num(sleep_time = 600, process_name = '', block = False, daemon = True)`
  - *Line: 230*
  - *另起一个线程每隔多少秒打印有多少线程，这个和可缩小线程池的实现没有关系*

- `def get_current_threads_num()`
  - *Line: 251*

- `def f1(a)`
  - *Line: 259*


---

`````python
"""
史上最强的python线程池。

最智能的可自动实时调节线程数量的线程池。此线程池和官方concurrent.futures的线程池 是鸭子类关系，所以可以一键替换类名 或者 import as来替换类名。
对比官方线程池，有4个创新功能或改进。

1、主要是不仅能扩大，还可自动缩小(官方内置的ThreadpoolExecutor不具备此功能，此概念是什么意思和目的，可以百度java ThreadpoolExecutor的KeepAliveTime参数的介绍)，
   例如实例化一个1000线程的线程池，上一分钟疯狂高频率的对线程池submit任务，线程池会扩张到最大线程数量火力全开运行，
   但之后的七八个小时平均每分钟只submit一两个任务，官方线程池会一直维持在1000线程，而此线程池会自动缩小，靠什么来识别预测啥时机可以自动缩小呢，就是KeepAliveTime。

2、非常节制的开启多线程，例如实例化一个最大100线程数目的pool，每隔2秒submit一个函数任务，而函数每次只需要1秒就能完成，实际上只需要调节增加到1个线程就可以，不需要慢慢增加到100个线程
官方的线程池不够智能，会一直增加到最大线程数目，此线程池则不会。

3、线程池任务的queue队列，修改为有界队列

4、此线程池运行函数出错时候，直接显示线程错误，官方的线程池则不会显示错误，例如函数中写1/0,任然不现实错误。

此实现了submit，还实现future相关的内容，真正的和内置的ThreadpoolExecutor 完全替代。

可以在各种地方加入 time.sleep 来验证 第1条和第2条的自动智能缩放功能。
"""
import logging

import os
import atexit
import queue
import sys
import threading
import time
import weakref

from funboost.concurrent_pool import FunboostBaseConcurrentPool
from nb_log import LoggerLevelSetterMixin
from funboost.core.loggers import FunboostFileLoggerMixin,get_funboost_file_logger
from concurrent.futures import Executor, Future



_shutdown = False
_threads_queues = weakref.WeakKeyDictionary()


def check_not_monkey():
    from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch
    from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch
    if check_gevent_monkey_patch(raise_exc=False):
        raise Exception('指定使用多线程模式时候，请不要打gevent包的补丁')
    if check_evenlet_monkey_patch(raise_exc=False):
        raise Exception('指定使用多线程模式时候，请不要打evenlet包的补丁')


def _python_exit():
    global _shutdown
    _shutdown = True
    items = list(_threads_queues.items())
    for t, q in items:
        q.put(None)
    for t, q in items:
        t.join()


atexit.register(_python_exit)


class _WorkItem(FunboostFileLoggerMixin):
    def __init__(self, future, fn, args, kwargs):
        self.future = future
        self.fn = fn
        self.args = args
        self.kwargs = kwargs

    def run(self):
        # noinspection PyBroadException
        if not self.future.set_running_or_notify_cancel():
            return
        try:
            result = self.fn(*self.args, **self.kwargs)
        except BaseException as exc:
            self.logger.exception(f'函数 {self.fn} 中发生错误，错误原因是 {type(exc)} {exc} ')
            self.future.set_exception(exc)
            # Break a reference cycle with the exception 'exc'
            self = None  # noqa
        else:
            self.future.set_result(result)

    def __str__(self):
        return f'{(self.fn.__name__, self.args, self.kwargs)}'


def set_threadpool_executor_shrinkable(min_works=1, keep_alive_time=5):
    ThreadPoolExecutorShrinkAble.MIN_WORKERS = min_works
    ThreadPoolExecutorShrinkAble.KEEP_ALIVE_TIME = keep_alive_time


class ThreadPoolExecutorShrinkAble(Executor, FunboostFileLoggerMixin, LoggerLevelSetterMixin,FunboostBaseConcurrentPool):
    # 为了和官方自带的THredpoolexecutor保持完全一致的鸭子类，参数设置成死的，不让用户传参了。
    # 建议用猴子补丁修改这两个参数，为了保持入参api和内置的concurrent.futures 相同。
    # MIN_WORKERS = 5   # 最小值可以设置为0，代表线程池无论多久没有任务最少要保持多少个线程待命。
    # KEEP_ALIVE_TIME = 60  # 这个参数表名，当前线程从queue.get(block=True, timeout=KEEP_ALIVE_TIME)多久没任务，就线程结束。

    MIN_WORKERS = 1
    KEEP_ALIVE_TIME = 60
    THREAD_USE_DAEMON = True

    def __init__(self, max_workers: int = None, thread_name_prefix='',work_queue_maxsize=10):
        """
        最好需要兼容官方concurren.futures.ThreadPoolExecutor 和改版的BoundedThreadPoolExecutor，入参名字和个数保持了一致。
        :param max_workers:
        :param thread_name_prefix:
        """
        # print(max_workers)
        self._max_workers = max_workers or (os.cpu_count() or 1) * 5
        self._thread_name_prefix = thread_name_prefix
        # print(self._max_workers)
        # self.work_queue = self._work_queue = queue.Queue(self._max_workers or 10)
        self.work_queue = self._work_queue = queue.Queue(work_queue_maxsize)
        # self._threads = set()
        self._threads = weakref.WeakSet()
        self._lock_compute_threads_free_count = threading.Lock()
        self.threads_free_count = 0
        self._shutdown = False
        self._shutdown_lock = threading.Lock()
        self.pool_ident = id(self)

    def _change_threads_free_count(self, change_num):
        with self._lock_compute_threads_free_count:
            self.threads_free_count += change_num

    def submit(self, func, *args, **kwargs):
        with self._shutdown_lock:
            if self._shutdown:
                raise RuntimeError('不能添加新的任务到线程池')
            f = Future()
            w = _WorkItem(f, func, args, kwargs)
            self.work_queue.put(w)
            self._adjust_thread_count()
            return f

    def _adjust_thread_count(self):
        # print(self.threads_free_count, self.MIN_WORKERS, len(self._threads), self._max_workers)
        if self.threads_free_count <= self.MIN_WORKERS and len(self._threads) < self._max_workers:
            t = _CustomThread(self).set_log_level(self.logger.level)
            t.daemon = self.THREAD_USE_DAEMON
            t.start()
            self._threads.add(t)
            _threads_queues[t] = self._work_queue

    def shutdown(self, wait=True):  # noqa
        with self._shutdown_lock:
            self._shutdown = True
            self.work_queue.put(None)
        if wait:
            for t in self._threads:
                t.join()




# 两个名字都可以，兼容以前的老名字（中文意思是 自定义线程池），但新名字更能表达意思（可缩小线程池）。
CustomThreadpoolExecutor = CustomThreadPoolExecutor = ThreadPoolExecutorShrinkAble


class ThreadPoolExecutorShrinkAbleNonDaemon(ThreadPoolExecutorShrinkAble):
    """这个给 apscheduler 的 ThreadPoolExecutorForAps 使用很好，这个线程池里面的线程不是守护线程，

    防止代码里面有子线程在运行但是主线程结束，导致这个报错 
    raise RuntimeError('cannot schedule new futures after ' RuntimeError: cannot schedule new futures after interpreter shutdown

    之前backgroud scheduler使用得是线程池里面是守护线程，为了避免cannot schedule new futures after ，
    用户需要手动在主线程加个 ctrl_c_recv() 或者 while 1::time.sleep(10) 来阻止主线程结束，这样会麻烦用户。
    """
    MIN_WORKERS = 0
    THREAD_USE_DAEMON = False



# noinspection PyProtectedMember
class _CustomThread(threading.Thread, FunboostFileLoggerMixin, LoggerLevelSetterMixin):
    _lock_for_judge_threads_free_count = threading.Lock()

    def __init__(self, executorx: ThreadPoolExecutorShrinkAble):
        super().__init__()
        self._executorx = executorx

    def _remove_thread(self, stop_resson=''):
        # noinspection PyUnresolvedReferences
        self.logger.debug(f'停止线程 {self._ident}, 触发条件是 {stop_resson} ')
        self._executorx._change_threads_free_count(-1)
        self._executorx._threads.remove(self)
        _threads_queues.pop(self)

    # noinspection PyProtectedMember
    def run(self):
        # noinspection PyUnresolvedReferences
        # print(logging.getLogger(None).level,logging.getLogger(None).handlers)
        # print(self.logger.level)
        # print(self.logger.handlers)
        self.logger.debug(f'新启动线程 {self._ident} ')
        self._executorx._change_threads_free_count(1)
        while True:
            try:
                work_item = self._executorx.work_queue.get(block=True, timeout=self._executorx.KEEP_ALIVE_TIME)
            except queue.Empty:
                # continue
                # self._remove_thread()
                with self._lock_for_judge_threads_free_count:
                    if self._executorx.threads_free_count > self._executorx.MIN_WORKERS:
                        self._remove_thread(
                            f'{self._executorx.pool_ident} 线程池中的 {self.ident} 线程 超过 {self._executorx.KEEP_ALIVE_TIME} 秒没有任务，线程池中不在工作状态中的线程数量是 '
                            f'{self._executorx.threads_free_count}，超过了指定的最小核心数量 {self._executorx.MIN_WORKERS}')
                        break  # 退出while 1，即是结束。这里才是决定线程结束销毁，_remove_thread只是个名字而已，不是由那个来销毁线程。
                    else:
                        continue

            if work_item is not None:
                self._executorx._change_threads_free_count(-1)
                work_item.run()
                del work_item
                self._executorx._change_threads_free_count(1)
                continue
            if _shutdown or self._executorx._shutdown:
                self._executorx.work_queue.put(None)
                break


process_name_set = set()
logger_show_current_threads_num = get_funboost_file_logger('show_current_threads_num',formatter_template=5, do_not_use_color_handler=False)


def show_current_threads_num(sleep_time=600, process_name='', block=False, daemon=True):
    """另起一个线程每隔多少秒打印有多少线程，这个和可缩小线程池的实现没有关系"""
    process_name = sys.argv[0] if process_name == '' else process_name

    def _show_current_threads_num():
        while True:
            # logger_show_current_threads_num.info(f'{process_name} 进程 的 并发数量是 -->  {threading.active_count()}')
            # nb_print(f'  {process_name} {os.getpid()} 进程 的 线程数量是 -->  {threading.active_count()}')
            logger_show_current_threads_num.info(
                f'  {process_name} {os.getpid()} 进程 的 总线程数量是 -->  {threading.active_count()}')
            time.sleep(sleep_time)

    if process_name not in process_name_set:
        if block:
            _show_current_threads_num()
        else:
            t = threading.Thread(target=_show_current_threads_num, daemon=daemon)
            t.start()
        process_name_set.add(process_name)


def get_current_threads_num():
    return threading.active_count()


if __name__ == '__main__':
    show_current_threads_num(sleep_time=5)


    def f1(a):
        time.sleep(0.2)  # 可修改这个数字测试多线程数量调节功能。
        print(f'{a} 。。。。。。。')
        return a * 10
        # raise Exception('抛个错误测试')  # 官方的不会显示函数出错你，你还以为你写的代码没毛病呢。


    pool = ThreadPoolExecutorShrinkAble(1)
    # pool = ThreadPoolExecutor(200)  # 测试对比官方自带

    for i in range(30):
        time.sleep(0.1)  # 这里的间隔时间模拟，当任务来临不密集，只需要少量线程就能搞定f1了，因为f1的消耗时间短，
        # 不需要开那么多线程，CustomThreadPoolExecutor比ThreadPoolExecutor 优势之一。
        futurex = pool.submit(f1, i)
        # print(futurex.result())

    # 1/下面测试阻塞主线程退出的情况。注释掉可以测主线程退出的情况。
    # 2/此代码可以证明，在一段时间后，连续长时间没任务，官方线程池的线程数目还是保持在最大数量了。而此线程池会自动缩小，实现了java线程池的keppalivetime功能。
    time.sleep(1000000)

`````

--- **end of file: funboost/concurrent_pool/custom_threadpool_executor.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/custom_threadpool_executor000.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/custom_threadpool_executor000.py`

#### 📝 Module Docstring

`````
可自动实时调节线程数量的线程池。
比官方ThreadpoolExecutor的改进是
1.有界队列
2.实时调节线程数量，指的是当任务很少时候会去关闭很多线程。官方ThreadpoolExecurot只能做到忙时候开启很多线程，但不忙时候线程没有关闭线程，
此线程池实现了java ThreadpoolExecutor线程池的keppaliveTime参数的功能，linux系统能承受的线程总数有限，一般不到2万。
3.能非常智能节制的开启多线程。比如设置线程池大小为500，线程池的运行函数消耗时间是只需要0.1秒，如果每隔2秒钟来一个任务。1个线程足够了，官方线程池是一直增长到500，然后不增长，官方的太不智能了。

这个线程池是框架的默认线程方式的线程池，如果不设置并发方式就用的这里。

此实现了submit，但没实现future相关的内容。
`````

#### 📦 Imports

- `import atexit`
- `import queue`
- `import sys`
- `import threading`
- `import time`
- `import weakref`
- `from nb_log import LoggerMixin`
- `from nb_log import nb_print`
- `from nb_log import LoggerLevelSetterMixin`
- `from nb_log import LogManager`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch`
- `from funboost.utils import decorators`
- `from funboost.concurrent_pool.bounded_threadpoolexcutor import BoundedThreadPoolExecutor`

#### 🏛️ Classes (3)

##### 📌 `class _WorkItem(LoggerMixin)`
*Line: 42*

**🔧 Constructor (`__init__`):**
- `def __init__(self, fn, args, kwargs)`
  - **Parameters:**
    - `self`
    - `fn`
    - `args`
    - `kwargs`

**Public Methods (1):**
- `def run(self)`

##### 📌 `class CustomThreadPoolExecutor(LoggerMixin, LoggerLevelSetterMixin)`
*Line: 66*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = None, thread_name_prefix = '')`
  - **Docstring:**
  `````
  最好需要兼容官方concurren.futures.ThreadPoolExecutor 和改版的BoundedThreadPoolExecutor，入参名字和个数保持了一致。
  :param max_workers:
  :param thread_name_prefix:
  `````
  - **Parameters:**
    - `self`
    - `max_workers = None`
    - `thread_name_prefix = ''`

**Public Methods (4):**
- `def set_min_workers(self, min_workers = 10)`
- `def change_threads_free_count(self, change_num)`
- `def submit(self, func, *args, **kwargs)`
- `def shutdown(self, wait = True)`

##### 📌 `class _CustomThread(threading.Thread, LoggerMixin, LoggerLevelSetterMixin)`
*Line: 128*

**🔧 Constructor (`__init__`):**
- `def __init__(self, executorx: CustomThreadPoolExecutor)`
  - **Parameters:**
    - `self`
    - `executorx: CustomThreadPoolExecutor`

**Public Methods (1):**
- `def run(self)`

**Class Variables (1):**
- `_lock_for_judge_threads_free_count = threading.Lock()`

#### 🔧 Public Functions (4)

- `def check_not_monkey()`
  - *Line: 59*

- `def show_current_threads_num(sleep_time = 60, process_name = '', block = False)`
  - *Line: 177*

- `def get_current_threads_num()`
  - *Line: 195*

- `def f1(a)`
  - *Line: 205*


---

`````python
"""
可自动实时调节线程数量的线程池。
比官方ThreadpoolExecutor的改进是
1.有界队列
2.实时调节线程数量，指的是当任务很少时候会去关闭很多线程。官方ThreadpoolExecurot只能做到忙时候开启很多线程，但不忙时候线程没有关闭线程，
此线程池实现了java ThreadpoolExecutor线程池的keppaliveTime参数的功能，linux系统能承受的线程总数有限，一般不到2万。
3.能非常智能节制的开启多线程。比如设置线程池大小为500，线程池的运行函数消耗时间是只需要0.1秒，如果每隔2秒钟来一个任务。1个线程足够了，官方线程池是一直增长到500，然后不增长，官方的太不智能了。

这个线程池是框架的默认线程方式的线程池，如果不设置并发方式就用的这里。

此实现了submit，但没实现future相关的内容。
"""

import atexit
import queue
import sys
import threading
import time
import weakref

from nb_log import LoggerMixin, nb_print, LoggerLevelSetterMixin, LogManager
from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch
from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch

_shutdown = False
_threads_queues = weakref.WeakKeyDictionary()


def _python_exit():
    global _shutdown
    _shutdown = True
    items = list(_threads_queues.items())
    for t, q in items:
        q.put(None)
    for t, q in items:
        t.join()


atexit.register(_python_exit)


class _WorkItem(LoggerMixin):
    def __init__(self, fn, args, kwargs):
        self.fn = fn
        self.args = args
        self.kwargs = kwargs

    def run(self):
        # noinspection PyBroadException
        try:
            self.fn(*self.args, **self.kwargs)
        except BaseException as exc:
            self.logger.exception(f'函数 {self.fn.__name__} 中发生错误，错误原因是 {type(exc)} {exc} ')

    def __str__(self):
        return f'{(self.fn.__name__, self.args, self.kwargs)}'


def check_not_monkey():
    if check_gevent_monkey_patch(raise_exc=False):
        raise Exception('请不要打gevent包的补丁')
    if check_evenlet_monkey_patch(raise_exc=False):
        raise Exception('请不要打evenlet包的补丁')


class CustomThreadPoolExecutor(LoggerMixin, LoggerLevelSetterMixin):
    def __init__(self, max_workers=None, thread_name_prefix=''):
        """
        最好需要兼容官方concurren.futures.ThreadPoolExecutor 和改版的BoundedThreadPoolExecutor，入参名字和个数保持了一致。
        :param max_workers:
        :param thread_name_prefix:
        """
        self._max_workers = max_workers or 4
        self._min_workers = 5  # 这是对应的 java Threadpoolexecutor的corePoolSize，为了保持线程池公有方法和与py官方内置的concurren.futures.ThreadPoolExecutor一致，不增加更多的实例化时候入参，这里写死为5.
        self._thread_name_prefix = thread_name_prefix
        self.work_queue = queue.Queue(max_workers)
        # self._threads = set()
        self._threads = weakref.WeakSet()
        self._lock_compute_threads_free_count = threading.Lock()
        self.threads_free_count = 0
        self._shutdown = False
        self._shutdown_lock = threading.Lock()
        # self.logger.setLevel(20)

    def set_min_workers(self, min_workers=10):
        self._min_workers = min_workers
        return self

    def change_threads_free_count(self, change_num):
        with self._lock_compute_threads_free_count:
            self.threads_free_count += change_num

    def submit(self, func, *args, **kwargs):
        with self._shutdown_lock:
            if self._shutdown:
                raise RuntimeError('不能添加新的任务到线程池')
        self.work_queue.put(_WorkItem(func, args, kwargs))
        self._adjust_thread_count()

    def _adjust_thread_count(self):
        # if len(self._threads) < self._threads_num:
        # self.logger.debug((self.threads_free_count, len(self._threads), len(_threads_queues), get_current_threads_num()))
        if self.threads_free_count < self._min_workers and len(self._threads) < self._max_workers:
            # t = threading.Thread(target=_work,
            #                      args=(self._work_queue,self))
            t = _CustomThread(self).set_log_level(self.logger.level)
            t.setDaemon(True)
            t.start()
            self._threads.add(t)
            _threads_queues[t] = self.work_queue

    def shutdown(self, wait=True):
        with self._shutdown_lock:
            self._shutdown = True
            self.work_queue.put(None)
        if wait:
            for t in self._threads:
                t.join()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.shutdown(wait=True)
        return False


class _CustomThread(threading.Thread, LoggerMixin, LoggerLevelSetterMixin):
    _lock_for_judge_threads_free_count = threading.Lock()

    def __init__(self, executorx: CustomThreadPoolExecutor):
        super().__init__()
        self._executorx = executorx
        self._run_times = 0

    # noinspection PyProtectedMember
    def _remove_thread(self, stop_resson=''):
        # noinspection PyUnresolvedReferences
        self.logger.debug(f'停止线程 {self._ident}, 触发条件是 {stop_resson} ')
        self._executorx.change_threads_free_count(-1)
        self._executorx._threads.remove(self)
        _threads_queues.pop(self)

    # noinspection PyProtectedMember
    def run(self):
        # noinspection PyUnresolvedReferences
        self.logger.debug(f'新启动线程 {self._ident} ')
        self._executorx.change_threads_free_count(1)
        while True:
            try:
                work_item = self._executorx.work_queue.get(block=True, timeout=60)
            except queue.Empty:
                with self._lock_for_judge_threads_free_count:
                    if self._executorx.threads_free_count > self._executorx._min_workers:
                        self._remove_thread(f'当前线程超过60秒没有任务，线程池中不在工作状态中的线程数量是 {self._executorx.threads_free_count}，超过了指定的数量 {self._executorx._min_workers}')
                        break  # 退出while 1，即是结束。这里才是决定线程结束销毁，_remove_thread只是个名字而已，不是由那个来销毁线程。
                    else:
                        continue

            # nb_print(work_item)
            if work_item is not None:
                self._executorx.change_threads_free_count(-1)
                work_item.run()
                del work_item
                self._executorx.change_threads_free_count(1)
                continue
            if _shutdown or self._executorx._shutdown:
                self._executorx.work_queue.put(None)
                break


process_name_set = set()
logger_show_current_threads_num = LogManager('show_current_threads_num').get_logger_and_add_handlers(
    formatter_template=5, log_filename='show_current_threads_num.log', do_not_use_color_handler=True)


def show_current_threads_num(sleep_time=60, process_name='', block=False):
    process_name = sys.argv[0] if process_name == '' else process_name

    def _show_current_threads_num():
        while True:
            # logger_show_current_threads_num.info(f'{process_name} 进程 的 并发数量是 -->  {threading.active_count()}')
            nb_print(f'{process_name} 进程 的 线程数量是 -->  {threading.active_count()}')
            time.sleep(sleep_time)

    if process_name not in process_name_set:
        if block:
            _show_current_threads_num()
        else:
            t = threading.Thread(target=_show_current_threads_num, daemon=True)
            t.start()
        process_name_set.add(process_name)


def get_current_threads_num():
    return threading.active_count()


if __name__ == '__main__':
    from funboost.utils import decorators
    from funboost.concurrent_pool.bounded_threadpoolexcutor import BoundedThreadPoolExecutor


    # @decorators.keep_circulating(1)
    def f1(a):
        time.sleep(0.2)
        nb_print(f'{a} 。。。。。。。')
        # raise Exception('抛个错误测试')


    # show_current_threads_num()
    pool = CustomThreadPoolExecutor(200).set_log_level(10).set_min_workers()
    # pool = BoundedThreadPoolExecutor(200)   # 测试对比原来写的BoundedThreadPoolExecutor
    show_current_threads_num(sleep_time=5)
    for i in range(300):
        time.sleep(0.3)  # 这里的间隔时间模拟，当任务来临不密集，只需要少量线程就能搞定f1了，因为f1的消耗时间短，不需要开那么多线程，CustomThreadPoolExecutor比BoundedThreadPoolExecutor 优势之一。
        pool.submit(f1, str(i))

    nb_print(6666)
    # pool.shutdown(wait=True)
    pool.submit(f1, 'yyyy')

    # 下面测试阻塞主线程退出的情况。注释掉可以测主线程退出的情况。
    while True:
        time.sleep(10)

`````

--- **end of file: funboost/concurrent_pool/custom_threadpool_executor000.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/fixed_thread_pool.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/fixed_thread_pool.py`

#### 📝 Module Docstring

`````
flxed_thread_pool.py 固定大小的非智能线程池, 最简单的粗暴实现线程池方式,任何人都可以写得出来.
弊端是代码不会自动结束,因为线程池的每个线程 while 1是非守护线程,不能自动判断代码是否需要结束.
如果有的人的代码是长期运行不需要结束的,可以用这种线程池。
`````

#### 📦 Imports

- `import threading`
- `import traceback`
- `from queue import Queue`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.core.loggers import FunboostFileLoggerMixin`

#### 🏛️ Classes (1)

##### 📌 `class FixedThreadPool(FunboostFileLoggerMixin, FunboostBaseConcurrentPool)`
*Line: 15*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers: int = 8)`
  - **Parameters:**
    - `self`
    - `max_workers: int = 8`

**Public Methods (1):**
- `def submit(self, func, *args, **kwargs)`

#### 🔧 Public Functions (1)

- `def f3(x)`
  - *Line: 38*


---

`````python
"""
flxed_thread_pool.py 固定大小的非智能线程池, 最简单的粗暴实现线程池方式,任何人都可以写得出来.
弊端是代码不会自动结束,因为线程池的每个线程 while 1是非守护线程,不能自动判断代码是否需要结束.
如果有的人的代码是长期运行不需要结束的,可以用这种线程池。
"""

import threading
import traceback
from queue import Queue
# import nb_log
from funboost.concurrent_pool import FunboostBaseConcurrentPool
from funboost.core.loggers import FunboostFileLoggerMixin


class FixedThreadPool(FunboostFileLoggerMixin,FunboostBaseConcurrentPool):
    def __init__(self, max_workers: int = 8):
        self._max_workers = max_workers
        self._work_queue = Queue(maxsize=10)
        self._start_thrads()

    def submit(self, func, *args, **kwargs):
        self._work_queue.put([func, args, kwargs])

    def _forever_fun(self):
        while True:
            func, args, kwargs = self._work_queue.get()
            try:
                func(*args, **kwargs)
            except BaseException as e:
                self.logger.error(f'func:{func}, args:{args}, kwargs:{kwargs} exc_type:{type(e)}  traceback_exc:{traceback.format_exc()}')

    def _start_thrads(self):
        for i in range(self._max_workers):
            threading.Thread(target=self._forever_fun).start()


if __name__ == '__main__':
    def f3(x):
        # time.sleep(1)
        # 1 / 0
        if x % 10000 == 0:
            print(x)


    pool = FixedThreadPool(100)
    for j in range(10):
        pool.submit(f3, j)

`````

--- **end of file: funboost/concurrent_pool/fixed_thread_pool.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/flexible_thread_pool.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/flexible_thread_pool.py`

#### 📝 Module Docstring

`````
比 ThreadPoolExecutorShrinkAble 更简单的的弹性线程池。完全彻底从头手工开发

这个线程池 submit没有返回值，不返回future对象，不支持map方法。

此线程池性能比concurrent.futures.ThreadPoolExecutor高200%

顺便兼容asyns def的函数并发运行
`````

#### 📦 Imports

- `import asyncio`
- `import inspect`
- `import os`
- `import queue`
- `import threading`
- `from functools import wraps`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import LoggerLevelSetterMixin`
- `from funboost.core.loggers import FunboostMetaTypeFileLogger`
- `import time`
- `from concurrent.futures import ThreadPoolExecutor`
- `from custom_threadpool_executor import ThreadPoolExecutorShrinkAble`

#### 🏛️ Classes (3)

##### 📌 `class FlexibleThreadPool(FunboostFileLoggerMixin, LoggerLevelSetterMixin, FunboostBaseConcurrentPool)`
*Line: 22*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers: int = None, work_queue_maxsize = 10)`
  - **Parameters:**
    - `self`
    - `max_workers: int = None`
    - `work_queue_maxsize = 10`

**Public Methods (1):**
- `def submit(self, func, *args, **kwargs)`

**Class Variables (2):**
- `KEEP_ALIVE_TIME = 10`
- `MIN_WORKERS = 1`

##### 📌 `class FlexibleThreadPoolMinWorkers0(FlexibleThreadPool)`
*Line: 53*

**Class Variables (1):**
- `MIN_WORKERS = 0`

##### 📌 `class _KeepAliveTimeThread(threading.Thread)`
*Line: 102*

**🔧 Constructor (`__init__`):**
- `def __init__(self, thread_pool: FlexibleThreadPool)`
  - **Parameters:**
    - `self`
    - `thread_pool: FlexibleThreadPool`

**Public Methods (1):**
- `def run(self) -> None`

#### 🔧 Public Functions (5)

- `def run_sync_or_async_fun000(func, *args, **kwargs)`
  - *Line: 57*
  - *这种方式造成电脑很卡,不行*

- `def run_sync_or_async_fun(func, *args, **kwargs)`
  - *Line: 80*

- `def sync_or_async_fun_deco(func)`
  - *Line: 93*

- `def testf(x)`
  - *Line: 144*

- `async def aiotestf(x)`
  - *Line: 150*


---

`````python
"""
比 ThreadPoolExecutorShrinkAble 更简单的的弹性线程池。完全彻底从头手工开发

这个线程池 submit没有返回值，不返回future对象，不支持map方法。

此线程池性能比concurrent.futures.ThreadPoolExecutor高200%

顺便兼容asyns def的函数并发运行
"""

import asyncio
import inspect
import os
import queue
import threading
from functools import wraps

from funboost.concurrent_pool import FunboostBaseConcurrentPool
from funboost.core.loggers import FunboostFileLoggerMixin, LoggerLevelSetterMixin, FunboostMetaTypeFileLogger


class FlexibleThreadPool(FunboostFileLoggerMixin, LoggerLevelSetterMixin, FunboostBaseConcurrentPool):
    KEEP_ALIVE_TIME = 10
    MIN_WORKERS = 1

    def __init__(self, max_workers: int = None,work_queue_maxsize=10):
        self.work_queue = queue.Queue(work_queue_maxsize)
        self.max_workers = max_workers
        self._threads_num = 0
        self.threads_free_count = 0
        self._lock_compute_start_thread = threading.Lock()
        self._lock_compute_threads_free_count = threading.Lock()
        self._lock_for_adjust_thread = threading.Lock()
        self._lock_for_judge_threads_free_count = threading.Lock()
        self.pool_ident = id(self)
        # self.asyncio_loop = asyncio.new_event_loop()

    def _change_threads_free_count(self, change_num):
        with self._lock_compute_threads_free_count:
            self.threads_free_count += change_num

    def _change_threads_start_count(self, change_num):
        with self._lock_compute_start_thread:
            self._threads_num += change_num

    def submit(self, func, *args, **kwargs):
        self.work_queue.put([func, args, kwargs])
        with self._lock_for_adjust_thread:
            if self.threads_free_count <= self.MIN_WORKERS and self._threads_num < self.max_workers:
                _KeepAliveTimeThread(self).start()


class FlexibleThreadPoolMinWorkers0(FlexibleThreadPool):
    MIN_WORKERS = 0


def run_sync_or_async_fun000(func, *args, **kwargs):
    """这种方式造成电脑很卡,不行"""
    fun_is_asyncio = inspect.iscoroutinefunction(func)
    if fun_is_asyncio:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(func(*args, **kwargs))
        finally:
            loop.close()
    else:
        return func(*args, **kwargs)


tl = threading.local()


def _get_thread_local_loop() -> asyncio.AbstractEventLoop:
    if not hasattr(tl, 'asyncio_loop'):
        tl.asyncio_loop = asyncio.new_event_loop()
    return tl.asyncio_loop


def run_sync_or_async_fun(func, *args, **kwargs):
    fun_is_asyncio = inspect.iscoroutinefunction(func)
    if fun_is_asyncio:
        loop = _get_thread_local_loop()
        try:
            return loop.run_until_complete(func(*args, **kwargs))
        finally:
            pass
            # loop.close()
    else:
        return func(*args, **kwargs)


def sync_or_async_fun_deco(func):
    @wraps(func)
    def _inner(*args, **kwargs):
        return run_sync_or_async_fun(func, *args, **kwargs)

    return _inner


# noinspection PyProtectedMember
class _KeepAliveTimeThread(threading.Thread, metaclass=FunboostMetaTypeFileLogger):
    def __init__(self, thread_pool: FlexibleThreadPool):
        super().__init__()
        self.pool = thread_pool

    def run(self) -> None:
        # 可以设置 LogManager('_KeepAliveTimeThread').preset_log_level(logging.INFO) 来屏蔽下面的话,见文档6.17.b
        self.logger.debug(f'新启动线程 {self.ident} ')
        self.pool._change_threads_free_count(1)
        self.pool._change_threads_start_count(1)
        while 1:
            try:
                func, args, kwargs = self.pool.work_queue.get(block=True, timeout=self.pool.KEEP_ALIVE_TIME)
            except queue.Empty:
                with self.pool._lock_for_judge_threads_free_count:
                    # print(self.pool.threads_free_count)
                    if self.pool.threads_free_count > self.pool.MIN_WORKERS:
                        # 可以设置 LogManager('_KeepAliveTimeThread').preset_log_level(logging.INFO) 来屏蔽下面的话,见文档6.17.b
                        self.logger.debug(f'停止线程 {self._ident}, 触发条件是 {self.pool.pool_ident} 线程池中的 {self.ident} 线程 超过 {self.pool.KEEP_ALIVE_TIME} 秒没有任务，线程池中不在工作状态中的线程数量是 {self.pool.threads_free_count}，超过了指定的最小核心数量 {self.pool.MIN_WORKERS}')  # noqa
                        self.pool._change_threads_free_count(-1)
                        self.pool._change_threads_start_count(-1)
                        break  # 退出while 1，即是结束。
                    else:
                        continue
            self.pool._change_threads_free_count(-1)
            try:
                fun = sync_or_async_fun_deco(func)
                fun(*args, **kwargs)
            except BaseException as exc:
                self.logger.exception(f'函数 {func} 中发生错误，错误原因是 {type(exc)} {exc} ')
            self.pool._change_threads_free_count(1)





if __name__ == '__main__':
    import time
    from concurrent.futures import ThreadPoolExecutor
    from custom_threadpool_executor import ThreadPoolExecutorShrinkAble


    def testf(x):
        # time.sleep(10)
        if x % 10000 == 0:
            print(x)


    async def aiotestf(x):
        # await asyncio.sleep(1)
        if x % 10 == 0 or 1:
            print(x)
        return x * 2


    pool = FlexibleThreadPool(100)
    # pool = ThreadPoolExecutor(100)
    # pool = ThreadPoolExecutorShrinkAble(100)

    for i in range(20000):
        # time.sleep(2)
        pool.submit(aiotestf, i)

    # for i in range(100000):
    #     pool.submit(testf, i)

    # while 1:
    #     time.sleep(1000)
    # loop.run_forever()

`````

--- **end of file: funboost/concurrent_pool/flexible_thread_pool.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/pool_commons.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/pool_commons.py`

#### 📦 Imports

- `import functools`
- `import threading`
- `import typing`
- `import os`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.base_pool_type import FunboostBaseConcurrentPool`

#### 🏛️ Classes (1)

##### 📌 `class ConcurrentPoolBuilder`
*Line: 10*

**Public Methods (1):**
- `def get_pool(cls, pool_type: typing.Type[FunboostBaseConcurrentPool], max_workers: int = None)` `classmethod`

**Class Variables (2):**
- `_pid__pool_map = {}`
- `_lock = threading.Lock()`


---

`````python
import functools
import threading
import typing
import os

from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool
from funboost.concurrent_pool.base_pool_type import FunboostBaseConcurrentPool


class ConcurrentPoolBuilder:
    _pid__pool_map = {}
    _lock = threading.Lock()

    @classmethod
    def get_pool(cls, pool_type: typing.Type[FunboostBaseConcurrentPool], max_workers: int = None):
        key = (os.getpid(), pool_type)
        with cls._lock:
            if key not in cls._pid__pool_map:
                pool = pool_type(max_workers)  # noqa
                cls._pid__pool_map[key] = pool
            return cls._pid__pool_map[key]


if __name__ == '__main__':
    for i in range(10):
        pool = functools.partial(ConcurrentPoolBuilder.get_pool, FlexibleThreadPool, 200)()
        print(id(pool))

`````

--- **end of file: funboost/concurrent_pool/pool_commons.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/readme.md** (project: funboost) --- 

`````markdown
####  这个里面是实现各种并发池，框架使用不同种类的并发池从而使用不同的并发模式来执行函数任务。


```python

'''
各种并发池的api都实现了submit，然后就自动执行函数。类似concurrent.futures包的api
'''


def fun(x):
    print(x)

pool = Pool(50)
pool.submit(fun,1)


```

```text
实现的池包括


gevent

eventlet

asyncio

custom_threadpool_executor.py 的 ThreadPoolExecutorShrinkAble 可变有界线程池,可变是指线程池嫩自动扩大，最厉害的是能自动缩小线程数量，官方不具备此功能。
如果线程池submit任务稀疏，即使设置500并发，但不会开到500线程，官方不具备此功能。 


flexible_thread_pool.py  从新开始写的，完全没有任何官方半点代码的智能可伸缩线程池，和 custom_threadpool_executor.py 功能一样，
可变有界线程池，可以自动扩大也能自动缩小，增加了支持运行 async def 的函数。


flxed_thread_pool.py 固定大小的线程池, 最简单的实现线程池方式,任何人都可以写得出来.弊端是代码不会自动结束,因为线程池的每个线程 while 1是非守护线程,不能自动判断代码是否需要结束.
如果有的人的代码是长期运行不需要结束的,可以用这种线程池
```


#### 框架的默认的多线程并发池是 flexible_thread_pool.py ，这个池能同时支持并发运行def 函数和async def函数。

#### 框架的默认的asyncio并发池是 AsyncPoolExecutor


`````

--- **end of file: funboost/concurrent_pool/readme.md** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/single_thread_executor.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/single_thread_executor.py`

#### 📦 Imports

- `from typing import Callable`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`

#### 🏛️ Classes (1)

##### 📌 `class SoloExecutor(FunboostBaseConcurrentPool)`
*Line: 6*

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers: int = 1)`
  - **Parameters:**
    - `self`
    - `max_workers: int = 1`

**Public Methods (2):**
- `def submit(self, fn: Callable, *args, **kwargs)`
- `def shutdown(self, wait = True)`


---

`````python
from typing import Callable

from funboost.concurrent_pool import FunboostBaseConcurrentPool


class SoloExecutor(FunboostBaseConcurrentPool):
    # noinspection PyUnusedLocal
    def __init__(self, max_workers: int = 1):
        pass

    # noinspection PyMethodMayBeStatic
    def submit(self, fn: Callable, *args, **kwargs):
        return fn(*args, **kwargs)

    # noinspection PyMethodMayBeStatic
    def shutdown(self, wait=True):
        pass

`````

--- **end of file: funboost/concurrent_pool/single_thread_executor.py** (project: funboost) --- 

---


--- **start of file: funboost/concurrent_pool/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/concurrent_pool/__init__.py`

#### 📝 Module Docstring

`````
并发池 包括
有界队列线程池 加 错误提示
eventlet协程
gevent协程
自定义的有界队列线程池 加 错误提示，同时线程数量在任务数量少的时候可自动减少。项目中默认使用的并发方式是基于这个。

此文件夹包括5种并发池，可以单独用于任何项目，即使没有使用这个函数调度框架。
`````

#### 📦 Imports

- `from base_pool_type import FunboostBaseConcurrentPool`
- `from async_pool_executor import AsyncPoolExecutor`
- `from bounded_threadpoolexcutor import BoundedThreadPoolExecutor`
- `from custom_threadpool_executor import CustomThreadPoolExecutor`
- `from flexible_thread_pool import FlexibleThreadPool`
- `from pool_commons import ConcurrentPoolBuilder`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 9:46
"""
并发池 包括
有界队列线程池 加 错误提示
eventlet协程
gevent协程
自定义的有界队列线程池 加 错误提示，同时线程数量在任务数量少的时候可自动减少。项目中默认使用的并发方式是基于这个。

此文件夹包括5种并发池，可以单独用于任何项目，即使没有使用这个函数调度框架。
"""
from .base_pool_type import FunboostBaseConcurrentPool
from .async_pool_executor import AsyncPoolExecutor
from .bounded_threadpoolexcutor import BoundedThreadPoolExecutor
from .custom_threadpool_executor import CustomThreadPoolExecutor
from .flexible_thread_pool import FlexibleThreadPool
from .pool_commons import ConcurrentPoolBuilder
`````

--- **end of file: funboost/concurrent_pool/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/base_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/base_consumer.py`

#### 📝 Module Docstring

`````
所有中间件类型消费者的抽象基类。使实现不同中间件的消费者尽可能代码少。
整个流程最难的都在这里面。因为要实现多种并发模型，和对函数施加20多种运行控制方式，所以代码非常长。

框架做主要的功能都是在这个文件里面实现的.
`````

#### 📦 Imports

- `import functools`
- `import sys`
- `import typing`
- `import abc`
- `import copy`
- `from apscheduler.jobstores.memory import MemoryJobStore`
- `from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config`
- `from funboost.core.funboost_time import FunboostTime`
- `from pathlib import Path`
- `import datetime`
- `import pytz`
- `import json`
- `import logging`
- `import atexit`
- `import os`
- `import uuid`
- `import time`
- `import traceback`
- `import inspect`
- `from functools import wraps`
- `import threading`
- `from threading import Lock`
- `import asyncio`
- `import nb_log`
- `from funboost.core.current_task import FctContext`
- `from funboost.core.current_task import set_fct_context`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BaseJsonAbleModel`
- `from funboost.core.serialization import PickleHelper`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.task_id_logger import TaskIdLogger`
- `from funboost.constant import FunctionKind`
- `from nb_libs.path_helper import PathHelper`
- `from nb_log import get_logger`
- `from nb_log import LoggerLevelSetterMixin`
- `from nb_log import LogManager`
- `from nb_log import is_main_process`
- `from nb_log import nb_log_config_default`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import logger_prompt`
- `from apscheduler.jobstores.redis import RedisJobStore`
- `from apscheduler.executors.pool import ThreadPoolExecutor as ApschedulerThreadPoolExecutor`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.concurrent_pool.single_thread_executor import SoloExecutor`
- `from funboost.core.function_result_status_saver import ResultPersistenceHelper`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.function_result_status_saver import RunStatus`
- `from funboost.core.helper_funs import delete_keys_and_return_new_dict`
- `from funboost.core.helper_funs import get_publish_time`
- `from funboost.core.helper_funs import MsgGenerater`
- `from funboost.concurrent_pool.async_helper import get_or_create_event_loop`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.concurrent_pool.async_pool_executor import AsyncPoolExecutor`
- `from funboost.concurrent_pool.bounded_threadpoolexcutor import BoundedThreadPoolExecutor`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.func_timeout import dafunc`
- `from funboost.concurrent_pool.custom_threadpool_executor import check_not_monkey`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.flexible_thread_pool import sync_or_async_fun_deco`
- `from funboost.consumers.redis_filter import RedisFilter`
- `from funboost.consumers.redis_filter import RedisImpermanencyFilter`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.utils import decorators`
- `from funboost.utils import time_util`
- `from funboost.utils import redis_manager`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConstStrForClassMethod`
- `from funboost.constant import RedisKeys`
- `from funboost.core import kill_remote_task`
- `from funboost.core.exceptions import ExceptionForRequeue`
- `from funboost.core.exceptions import ExceptionForPushToDlxqueue`
- `from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker`
- `from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`
- `from funboost.timing_job import FsdfBackgroundScheduler`
- `from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import gevent_timeout_deco`
- `from funboost.concurrent_pool.custom_gevent_pool_executor import get_gevent_pool_executor`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import evenlet_timeout_deco`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import get_eventlet_pool_executor`

#### 🏛️ Classes (5)

##### 📌 `class GlobalVars`
*Line: 88*

**Class Variables (2):**
- `global_concurrent_mode = None`
- `has_start_a_consumer_flag = False`

##### 📌 `class AbstractConsumer(LoggerLevelSetterMixin)`
*Line: 94*

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumer_params: BoosterParams)`
  - **Docstring:**
  `````
          
  `````
  - **Parameters:**
    - `self`
    - `consumer_params: BoosterParams`

**Public Methods (12):**
- `def bulid_a_new_publisher_of_same_queue(self)`
- `def join_dispatch_task_thread(cls)` `classmethod`
  - *:return:*
- `def custom_init(self)`
- `def keep_circulating(self, time_sleep = 0.001, exit_if_function_run_sucsess = False, is_display_detail_exception = True, block = True, daemon = False)`
  - **Docstring:**
  `````
  间隔一段时间，一直循环运行某个方法的装饰器
  :param time_sleep :循环的间隔时间
  :param is_display_detail_exception
  :param exit_if_function_run_sucsess :如果成功了就退出循环
  :param block:是否阻塞在当前主线程运行。
  :param daemon:是否守护线程
  `````
- `def start_consuming_message(self)`
- `def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`
- `async def aio_user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`
- `def check_heartbeat_and_message_count(self)`
- `def pause_consume(self)`
  - *从远程机器可以设置队列为暂停消费状态，funboost框架会自动停止消费，此功能需要配置好redis*
- `def continue_consume(self)`
  - *从远程机器可以设置队列为暂停消费状态，funboost框架会自动继续消费，此功能需要配置好redis*
- `def wait_for_possible_has_finish_all_tasks(self, minutes: int = 3)`
  - **Docstring:**
  `````
  判断队列所有任务是否消费完成了。
  由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
  一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
  :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成，为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
  :return:
  `````
- `def clear_filter_tasks(self)`

**Properties (3):**
- `@property publisher_of_same_queue`
- `@property publisher_of_dlx_queue`
- `@property concurrent_pool`

**Class Variables (3):**
- `time_interval_for_check_do_not_run_time = 60`
- `BROKER_KIND = None`
- `logger_apscheduler = get_logger('push_for_apscheduler_use_database_store', log_filename='push_for_apscheduler_use_database_store.log')`

##### 📌 `class ConcurrentModeDispatcher(FunboostFileLoggerMixin)`
*Line: 1104*

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumerx: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `consumerx: AbstractConsumer`

**Public Methods (3):**
- `def check_all_concurrent_mode(self)`
- `def build_pool(self)`
- `def schedulal_task_with_no_block(self)`

##### 📌 `class MetricCalculation`
*Line: 1210*

**🔧 Constructor (`__init__`):**
- `def __init__(self, conusmer: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `conusmer: AbstractConsumer`

**Public Methods (2):**
- `def cal(self, t_start_run_fun: float, current_function_result_status: FunctionResultStatus)`
- `def get_report_hearbeat_info(self) -> dict`

**Class Variables (1):**
- `UNIT_TIME_FOR_COUNT = 10`

##### 📌 `class DistributedConsumerStatistics(RedisMixin, FunboostFileLoggerMixin)`
*Line: 1293*

**Docstring:**
`````
为了兼容模拟mq的中间件（例如redis，他没有实现amqp协议，redis的list结构和真mq差远了），获取一个队列有几个连接活跃消费者数量。
分布式环境中的消费者统计。主要目的有3点

1、统计活跃消费者数量用于分布式控频。
    获取分布式的消费者数量后，用于分布式qps控频。如果不获取全环境中的消费者数量，则只能用于当前进程中的消费控频。
    即使只有一台机器，例如把xx.py启动3次，xx.py的consumer设置qps为10，如果不使用分布式控频，会1秒钟最终运行30次函数而不是10次。

2、记录分布式环境中的活跃消费者的所有消费者 id，如果消费者id不在此里面说明已掉线或关闭，消息可以重新分发，用于不支持服务端天然消费确认的中间件。

3、从redis中获取停止和暂停状态，以便支持在别的地方发送命令停止或者暂停消费。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, consumer: AbstractConsumer)`
  - **Parameters:**
    - `self`
    - `consumer: AbstractConsumer`

**Public Methods (3):**
- `def run(self)`
- `def send_heartbeat(self)`
- `def get_queue_heartbeat_ids(self, without_time: bool)`

**Class Variables (3):**
- `SHOW_CONSUMER_NUM_INTERVAL = 600`
- `HEARBEAT_EXPIRE_SECOND = 25`
- `SEND_HEARTBEAT_INTERVAL = 10`

#### 🔧 Public Functions (1)

- `def wait_for_possible_has_finish_all_tasks_by_conusmer_list(consumer_list: typing.List[AbstractConsumer], minutes: int = 3)`
  - *Line: 1195*
  - **Docstring:**
  `````
  判断多个消费者是否消费完成了。
  由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
  一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
  :param consumer_list: 多个消费者列表
  :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成。为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
  :return:
  
   
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:11
"""
所有中间件类型消费者的抽象基类。使实现不同中间件的消费者尽可能代码少。
整个流程最难的都在这里面。因为要实现多种并发模型，和对函数施加20多种运行控制方式，所以代码非常长。

框架做主要的功能都是在这个文件里面实现的.
"""
import functools
import sys
import typing
import abc
import copy
from apscheduler.jobstores.memory import MemoryJobStore
from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config
from funboost.core.funboost_time import FunboostTime
from pathlib import Path
# from multiprocessing import Process
import datetime
# noinspection PyUnresolvedReferences,PyPackageRequirements
import pytz
import json
import logging
import atexit
import os
import uuid
import time
import traceback
import inspect
from functools import wraps
import threading
from threading import Lock
import asyncio

import nb_log
from funboost.core.current_task import FctContext,set_fct_context
from funboost.core.loggers import develop_logger

from funboost.core.func_params_model import BoosterParams, PublisherParams, BaseJsonAbleModel
from funboost.core.serialization import PickleHelper, Serialization
from funboost.core.task_id_logger import TaskIdLogger
from funboost.constant import FunctionKind

from nb_libs.path_helper import PathHelper
from nb_log import (get_logger, LoggerLevelSetterMixin, LogManager, is_main_process,
                    nb_log_config_default)
from funboost.core.loggers import FunboostFileLoggerMixin, logger_prompt

from apscheduler.jobstores.redis import RedisJobStore

from apscheduler.executors.pool import ThreadPoolExecutor as ApschedulerThreadPoolExecutor

from funboost.funboost_config_deafult import FunboostCommonConfig
from funboost.concurrent_pool.single_thread_executor import SoloExecutor

from funboost.core.function_result_status_saver import ResultPersistenceHelper, FunctionResultStatus, RunStatus

from funboost.core.helper_funs import delete_keys_and_return_new_dict, get_publish_time, MsgGenerater

from funboost.concurrent_pool.async_helper import get_or_create_event_loop, simple_run_in_executor
from funboost.concurrent_pool.async_pool_executor import AsyncPoolExecutor
# noinspection PyUnresolvedReferences
from funboost.concurrent_pool.bounded_threadpoolexcutor import \
    BoundedThreadPoolExecutor
from funboost.utils.redis_manager import RedisMixin
# from func_timeout import func_set_timeout  # noqa
from funboost.utils.func_timeout import dafunc

from funboost.concurrent_pool.custom_threadpool_executor import check_not_monkey
from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool, sync_or_async_fun_deco
# from funboost.concurrent_pool.concurrent_pool_with_multi_process import ConcurrentPoolWithProcess
from funboost.consumers.redis_filter import RedisFilter, RedisImpermanencyFilter
from funboost.factories.publisher_factotry import get_publisher

from funboost.utils import decorators, time_util, redis_manager
from funboost.constant import ConcurrentModeEnum, BrokerEnum, ConstStrForClassMethod, RedisKeys
from funboost.core import kill_remote_task
from funboost.core.exceptions import ExceptionForRequeue, ExceptionForPushToDlxqueue
from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker, FakeFunGenerator

# from funboost.core.booster import BoostersManager  互相导入
from funboost.core.lazy_impoter import funboost_lazy_impoter


# patch_apscheduler_run_job()

class GlobalVars:
    global_concurrent_mode = None
    has_start_a_consumer_flag = False


# noinspection DuplicatedCode
class AbstractConsumer(LoggerLevelSetterMixin, metaclass=abc.ABCMeta, ):
    time_interval_for_check_do_not_run_time = 60
    BROKER_KIND = None

    @property
    @decorators.synchronized
    def publisher_of_same_queue(self):
        if not self._publisher_of_same_queue:
            self._publisher_of_same_queue = get_publisher(publisher_params=self.publisher_params)
        return self._publisher_of_same_queue

    def bulid_a_new_publisher_of_same_queue(self):
        return get_publisher(publisher_params=self.publisher_params)

    @property
    @decorators.synchronized
    def publisher_of_dlx_queue(self):
        """ 死信队列发布者 """
        if not self._publisher_of_dlx_queue:
            publisher_params_dlx = copy.copy(self.publisher_params)
            publisher_params_dlx.queue_name = self._dlx_queue_name
            publisher_params_dlx.consuming_function = None
            self._publisher_of_dlx_queue = get_publisher(publisher_params=publisher_params_dlx)
        return self._publisher_of_dlx_queue

    @classmethod
    def join_dispatch_task_thread(cls):
        """

        :return:
        """
        # ConsumersManager.join_all_consumer_dispatch_task_thread()
        if GlobalVars.has_start_a_consumer_flag:
            # self.keep_circulating(10,block=True,)(time.sleep)()
            while 1:
                time.sleep(10)

    def __init__(self, consumer_params: BoosterParams):

        """
        """
        self.raw_consumer_params = copy.copy(consumer_params)
        self.consumer_params = copy.copy(consumer_params)
        # noinspection PyUnresolvedReferences
        file_name = self.consumer_params.consuming_function.__code__.co_filename
        # noinspection PyUnresolvedReferences
        line = self.consumer_params.consuming_function.__code__.co_firstlineno
        self.consumer_params.auto_generate_info['where_to_instantiate'] = f'{file_name}:{line}'

        self.queue_name = self._queue_name = consumer_params.queue_name
        self.consuming_function = consumer_params.consuming_function
        if consumer_params.consuming_function is None:
            raise ValueError('必须传 consuming_function 参数')

        self._msg_schedule_time_intercal = 0 if consumer_params.qps in (None, 0) else 1.0 / consumer_params.qps

        self._concurrent_mode_dispatcher = ConcurrentModeDispatcher(self)
        if consumer_params.concurrent_mode == ConcurrentModeEnum.ASYNC:
            self._any_run = self._async_run  # 这里做了自动转化，使用async_run代替run
        else:
            self._any_run = self._run
        self.logger: logging.Logger
        self._build_logger()
        # stdout_write(f'''{time.strftime("%H:%M:%S")} "{self.consumer_params.auto_generate_info['where_to_instantiate']}"  \033[0;37;44m此行 实例化队列名 {self.queue_name} 的消费者, 类型为 {self.__class__}\033[0m\n''')
        print(f'''\033[0m
         "{self.consumer_params.auto_generate_info['where_to_instantiate']}" \033[0m此行 实例化队列名 {self.queue_name} 的消费者, 类型为 {self.__class__} ''')

        # only_print_on_main_process(f'{current_queue__info_dict["queue_name"]} 的消费者配置:\n', un_strict_json_dumps.dict2json(current_queue__info_dict))

        # self._do_task_filtering = consumer_params.do_task_filtering
        # self.consumer_params.is_show_message_get_from_broker = consumer_params.is_show_message_get_from_broker
        self._redis_filter_key_name = f'filter_zset:{consumer_params.queue_name}' if consumer_params.task_filtering_expire_seconds else f'filter_set:{consumer_params.queue_name}'
        filter_class = RedisFilter if consumer_params.task_filtering_expire_seconds == 0 else RedisImpermanencyFilter
        self._redis_filter = filter_class(self._redis_filter_key_name, consumer_params.task_filtering_expire_seconds)
        self._redis_filter.delete_expire_filter_task_cycle()

        # if  self.consumer_params.concurrent_mode == ConcurrentModeEnum.ASYNC and self.consumer_params.specify_async_loop is None:
        #     self.consumer_params.specify_async_loop= get_or_create_event_loop()
        self._lock_for_count_execute_task_times_every_unit_time = Lock()

        # self._unit_time_for_count = 10  # 每隔多少秒计数，显示单位时间内执行多少次，暂时固定为10秒。
        # self._execute_task_times_every_unit_time = 0  # 每单位时间执行了多少次任务。
        # self._execute_task_times_every_unit_time_fail =0  # 每单位时间执行了多少次任务失败。
        # self._lock_for_count_execute_task_times_every_unit_time = Lock()
        # self._current_time_for_execute_task_times_every_unit_time = time.time()
        # self._consuming_function_cost_time_total_every_unit_time = 0
        # self._last_execute_task_time = time.time()  # 最近一次执行任务的时间。
        # self._last_10s_execute_count = 0
        # self._last_10s_execute_count_fail = 0
        #
        # self._last_show_remaining_execution_time = 0
        # self._show_remaining_execution_time_interval = 300
        #
        # self._msg_num_in_broker = 0
        # self._last_timestamp_when_has_task_in_queue = 0
        # self._last_timestamp_print_msg_num = 0

        self.metric_calculation = MetricCalculation(self)

        self._result_persistence_helper: ResultPersistenceHelper
        self.consumer_params.broker_exclusive_config = generate_broker_exclusive_config(self.consumer_params.broker_kind, self.consumer_params.broker_exclusive_config, self.logger)

        self._stop_flag = None
        self._pause_flag = threading.Event()  # 暂停消费标志，从reids读取
        self._last_show_pause_log_time = 0
        # self._redis_key_stop_flag = f'funboost_stop_flag'
        # self._redis_key_pause_flag = RedisKeys.REDIS_KEY_PAUSE_FLAG

        # 控频要用到的成员变量
        self._last_submit_task_timestamp = 0
        self._last_start_count_qps_timestamp = time.time()
        self._has_execute_times_in_recent_second = 0

        self._publisher_of_same_queue = None  #
        self._dlx_queue_name = f'{self.queue_name}_dlx'
        self._publisher_of_dlx_queue = None  # 死信队列发布者

        self._do_not_delete_extra_from_msg = False
        self._concurrent_pool = None

        self.consumer_identification = f'{nb_log_config_default.computer_name}_{nb_log_config_default.computer_ip}_' \
                                       f'{time_util.DatetimeConverter().datetime_str.replace(":", "-")}_{os.getpid()}_{id(self)}'
        # noinspection PyUnresolvedReferences
        self.consumer_identification_map = {'queue_name': self.queue_name,
                                            'computer_name': nb_log_config_default.computer_name,
                                            'computer_ip': nb_log_config_default.computer_ip,
                                            'process_id': os.getpid(),
                                            'consumer_id': id(self),
                                            'consumer_uuid': str(uuid.uuid4()),
                                            'start_datetime_str': time_util.DatetimeConverter().datetime_str,
                                            'start_timestamp': time.time(),
                                            'hearbeat_datetime_str': time_util.DatetimeConverter().datetime_str,
                                            'hearbeat_timestamp': time.time(),
                                            'consuming_function': self.consuming_function.__name__,
                                            'code_filename': Path(self.consuming_function.__code__.co_filename).as_posix()
                                            }

        self._has_start_delay_task_scheduler = False
        self._consuming_function_is_asyncio = inspect.iscoroutinefunction(self.consuming_function)

        ConsumingFuncInputParamsChecker.gen_final_func_input_params_info(self.consumer_params)
        # print(self.consumer_params)

        # develop_logger.warning(consumer_params._log_filename)
        # self.publisher_params = PublisherParams(queue_name=consumer_params.queue_name, consuming_function=consumer_params.consuming_function,
        #                                         broker_kind=self.BROKER_KIND, log_level=consumer_params.log_level,
        #                                         logger_prefix=consumer_params.logger_prefix,
        #                                         create_logger_file=consumer_params.create_logger_file,
        #                                         log_filename=consumer_params.log_filename,
        #                                         logger_name=consumer_params.logger_name,
        #                                         broker_exclusive_config=self.consumer_params.broker_exclusive_config)
        self.publisher_params = BaseJsonAbleModel.init_by_another_model(PublisherParams, self.consumer_params)
        # print(self.publisher_params)
        self.custom_init()
        if is_main_process:
            self.logger.info(f'{self.queue_name} consumer 的消费者配置:\n {self.consumer_params.json_str_value()}')

        atexit.register(self.join_dispatch_task_thread)

        self._save_consumer_params()

        if self.consumer_params.is_auto_start_consuming_message:
            _ = self.publisher_of_same_queue
            self.start_consuming_message()

    def _save_consumer_params(self):
        """
        保存队列的消费者参数，以便在web界面查看。
        :return:
        """
        # pass
        if self.consumer_params.is_fake_booster is True:
            return
        if self.consumer_params.is_send_consumer_heartbeat_to_redis:
            RedisMixin().redis_db_frame.hmset(RedisKeys.FUNBOOST_QUEUE__CONSUMER_PARAMS,{self.queue_name: self.consumer_params.json_str_value()})
            RedisMixin().redis_db_frame.sadd(RedisKeys.FUNBOOST_ALL_QUEUE_NAMES, self.queue_name)
            RedisMixin().redis_db_frame.sadd(RedisKeys.FUNBOOST_ALL_IPS, nb_log_config_default.computer_ip)
            if self.consumer_params.project_name:
                RedisMixin().redis_db_frame.sadd(RedisKeys.FUNBOOST_ALL_PROJECT_NAMES, self.consumer_params.project_name)
                RedisMixin().redis_db_frame.sadd(RedisKeys.gen_funboost_project_name_key(self.consumer_params.project_name), self.queue_name)

       

    def _build_logger(self):
        logger_prefix = self.consumer_params.logger_prefix
        if logger_prefix != '':
            logger_prefix += '--'
            # logger_name = f'{logger_prefix}{self.__class__.__name__}--{concurrent_name}--{queue_name}--{self.consuming_function.__name__}'
        logger_name = self.consumer_params.logger_name or f'funboost.{logger_prefix}{self.__class__.__name__}--{self.queue_name}'
        self.logger_name = logger_name
        log_filename = self.consumer_params.log_filename or f'funboost.{self.queue_name}.log'
        self.logger = LogManager(logger_name, logger_cls=TaskIdLogger).get_logger_and_add_handlers(
            log_level_int=self.consumer_params.log_level,
            log_filename=log_filename if self.consumer_params.create_logger_file else None,
            error_log_filename=nb_log.generate_error_file_name(log_filename),
            formatter_template=FunboostCommonConfig.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER, )
        self.logger.info(f'队列 {self.queue_name} 的日志写入到 {nb_log_config_default.LOG_PATH} 文件夹的 {log_filename} 和 {nb_log.generate_error_file_name(log_filename)} 文件中')

    def _check_monkey_patch(self):
        if self.consumer_params.concurrent_mode == ConcurrentModeEnum.GEVENT:
            from funboost.concurrent_pool.custom_gevent_pool_executor import check_gevent_monkey_patch
            check_gevent_monkey_patch()
        elif self.consumer_params.concurrent_mode == ConcurrentModeEnum.EVENTLET:
            from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch
            check_evenlet_monkey_patch()
        else:
            check_not_monkey()

    # def _log_error(self, msg, exc_info=None):
    #     self.logger.error(msg=f'{msg} \n', exc_info=exc_info, extra={'sys_getframe_n': 3})  # 这是改变日志栈层级
    #     self.error_file_logger.error(msg=f'{msg} \n', exc_info=exc_info, extra={'sys_getframe_n': 3})
    #
    # def _log_critical(self, msg, exc_info=None):
    #     self.logger.critical(msg=f'{msg} \n', exc_info=exc_info, extra={'sys_getframe_n': 3})
    #     self.error_file_logger.critical(msg=f'{msg} \n', exc_info=exc_info, extra={'sys_getframe_n': 3})

    @property
    @decorators.synchronized
    def concurrent_pool(self):
        return self._concurrent_mode_dispatcher.build_pool()

    def custom_init(self):
        pass

    def keep_circulating(self, time_sleep=0.001, exit_if_function_run_sucsess=False, is_display_detail_exception=True,
                         block=True, daemon=False):
        """间隔一段时间，一直循环运行某个方法的装饰器
        :param time_sleep :循环的间隔时间
        :param is_display_detail_exception
        :param exit_if_function_run_sucsess :如果成功了就退出循环
        :param block:是否阻塞在当前主线程运行。
        :param daemon:是否守护线程
        """

        def _keep_circulating(func):
            @wraps(func)
            def __keep_circulating(*args, **kwargs):

                # noinspection PyBroadException
                def ___keep_circulating():
                    while 1:
                        if self._stop_flag == 1:
                            break
                        try:
                            result = func(*args, **kwargs)
                            if exit_if_function_run_sucsess:
                                return result
                        except BaseException as e:
                            log_msg = func.__name__ + '   运行出错\n ' + traceback.format_exc(
                                limit=10) if is_display_detail_exception else str(e)
                            # self.logger.error(msg=f'{log_msg} \n', exc_info=True)
                            # self.error_file_logger.error(msg=f'{log_msg} \n', exc_info=True)
                            self.logger.error(msg=log_msg, exc_info=True)
                        finally:
                            time.sleep(time_sleep)
                            # print(func,time_sleep)

                if block:
                    return ___keep_circulating()
                else:
                    threading.Thread(target=___keep_circulating, daemon=daemon).start()

            return __keep_circulating

        return _keep_circulating

    # noinspection PyAttributeOutsideInit
    def start_consuming_message(self):
        # ConsumersManager.show_all_consumer_info()
        # noinspection PyBroadException
        pid_queue_name_tuple = (os.getpid(), self.queue_name)
        if pid_queue_name_tuple in funboost_lazy_impoter.BoostersManager.pid_queue_name__has_start_consume_set:
            self.logger.warning(f'{pid_queue_name_tuple} 已启动消费,不要一直去启动消费,funboost框架自动阻止.')  # 有的人乱写代码,无数次在函数内部或for循环里面执行 f.consume(),一个队列只需要启动一次消费,不然每启动一次性能消耗很大,直到程序崩溃
            return
        else:
            funboost_lazy_impoter.BoostersManager.pid_queue_name__has_start_consume_set.add(pid_queue_name_tuple)
        GlobalVars.has_start_a_consumer_flag = True
        try:
            self._concurrent_mode_dispatcher.check_all_concurrent_mode()
            self._check_monkey_patch()
        except BaseException:  # noqa
            traceback.print_exc()
            os._exit(4444)  # noqa
        self.logger.info(f'开始消费 {self._queue_name} 中的消息')
        self._result_persistence_helper = ResultPersistenceHelper(self.consumer_params.function_result_status_persistance_conf, self.queue_name)

        self._distributed_consumer_statistics = DistributedConsumerStatistics(self)
        if self.consumer_params.is_send_consumer_heartbeat_to_redis:
            self._distributed_consumer_statistics.run()
            self.logger.warning(f'启动了分布式环境 使用 redis 的键 hearbeat:{self._queue_name} 统计活跃消费者 ，当前消费者唯一标识为 {self.consumer_identification}')

        self.keep_circulating(60, block=False, daemon=False)(self.check_heartbeat_and_message_count)()
        if self.consumer_params.is_support_remote_kill_task:
            kill_remote_task.RemoteTaskKiller(self.queue_name, None).start_cycle_kill_task()
            self.consumer_params.is_show_message_get_from_broker = True  # 方便用户看到从消息队列取出来的消息的task_id,然后使用task_id杀死运行中的消息。
        if self.consumer_params.do_task_filtering:
            self._redis_filter.delete_expire_filter_task_cycle()  # 这个默认是RedisFilter类，是个pass不运行。所以用别的消息中间件模式，不需要安装和配置redis。
        if self.consumer_params.schedule_tasks_on_main_thread:
            self.keep_circulating(1, daemon=False)(self._dispatch_task)()
        else:
            self._concurrent_mode_dispatcher.schedulal_task_with_no_block()

    def _start_delay_task_scheduler(self):
        from funboost.timing_job import FsdfBackgroundScheduler
        from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock
        # print(self.consumer_params.delay_task_apsscheduler_jobstores_kind )
        if self.consumer_params.delay_task_apscheduler_jobstores_kind == 'redis':
            jobstores = {
                "default": RedisJobStore(**redis_manager.get_redis_conn_kwargs(),
                                         jobs_key=RedisKeys.gen_funboost_redis_apscheduler_jobs_key_by_queue_name(self.queue_name),
                                         run_times_key=RedisKeys.gen_funboost_redis_apscheduler_run_times_key_by_queue_name(self.queue_name),
                                         )
            }
            self._delay_task_scheduler = FunboostBackgroundSchedulerProcessJobsWithinRedisLock(timezone=FunboostCommonConfig.TIMEZONE, daemon=False,
                                                                                               jobstores=jobstores  # push 方法的序列化带thredignn.lock
                                                                                               )
            self._delay_task_scheduler.set_process_jobs_redis_lock_key(
                RedisKeys.gen_funboost_apscheduler_redis_lock_key_by_queue_name(self.queue_name))
        elif self.consumer_params.delay_task_apscheduler_jobstores_kind == 'memory':
            jobstores = {"default": MemoryJobStore()}
            self._delay_task_scheduler = FsdfBackgroundScheduler(timezone=FunboostCommonConfig.TIMEZONE, daemon=False,
                                                                 jobstores=jobstores  # push 方法的序列化带thredignn.lock
                                                                 )

        else:
            raise Exception(f'delay_task_apsscheduler_jobstores_kind is error: {self.consumer_params.delay_task_apscheduler_jobstores_kind}')

        # self._delay_task_scheduler.add_executor(ApschedulerThreadPoolExecutor(2))  # 只是运行submit任务到并发池，不需要很多线程。
        # self._delay_task_scheduler.add_listener(self._apscheduler_job_miss, EVENT_JOB_MISSED)
        self._delay_task_scheduler.start()

        self.logger.warning('启动延时任务sheduler')

    logger_apscheduler = get_logger('push_for_apscheduler_use_database_store', log_filename='push_for_apscheduler_use_database_store.log')

    @classmethod
    def _push_apscheduler_task_to_broker(cls, queue_name, msg):
        funboost_lazy_impoter.BoostersManager.get_or_create_booster_by_queue_name(queue_name).publish(msg)

    @abc.abstractmethod
    def _dispatch_task(self):
        """
        每个子类必须实现这个的方法，完成如何从中间件取出消息，并将函数和运行参数添加到工作池。

        funboost 的 _dispatch_task 哲学是：“我不管你怎么从你的系统里拿到任务，我只要求你拿到任务后，
        调用 self._submit_task(msg) 方法把它交给我处理就行。”

        所以无论获取消息是 拉模式 还是推模式 还是轮询模式，无论是是单条获取 还是多条批量多条获取，
        无论是传统mq,kafka,还是数据库,还是socket grpc tcp,还是kombu,还是python任务框架 celery rq dramtiq,
        还是文件系统 ,以及火热的 mysql cdc(数据变更捕获) ,都能轻松扩展任意东西作为funboost的中间件。

        _dispatch_task 是万物可作为broker的核心,没有任何东西作为不了broker,扩展性无敌.

        :return:
        """

        """
        反观celery,由于kombu强行模拟靠拢经典amqp协议,只有rabbitmq作为broker在celery最完美,
        redis在celery作为broker,消费确认ack 使用visibility_timeout,方案简直太糟糕了,
        强制断电重启程序,要么孤儿消息重回不及时,要么把长耗时消息错误的当做是孤儿消息无限懵逼死循环重新入队.

        celery实现kafka作为broker,这个issue 提了十几年一直无法完美实现,这就是celery+kombu 的局限性.
        更别说把 mysql cdc作为celery的broker 了,funboost的设计在这方面是吊打celery.
        """

        raise NotImplementedError

    def _convert_msg_before_run(self, msg: typing.Union[str, dict]) -> dict:
        """
        转换消息,消息没有使用funboost来发送,并且没有extra相关字段时候
        用户也可以按照4.21文档,继承任意Consumer类,并实现方法 _user_convert_msg_before_run,先转换不规范的消息.
        """
        """ 一般消息至少包含这样
        {
          "a": 42,
          "b": 84,
          "extra": {
            "task_id": "queue_2_result:9b79a372-f765-4a33-8639-9d15d7a95f61",
            "publish_time": 1701687443.3596,
            "publish_time_format": "2023-12-04 18:57:23"
          }
        }
        """

        """
        extra_params = {'task_id': task_id, 'publish_time': round(time.time(), 4),
                        'publish_time_format': time.strftime('%Y-%m-%d %H:%M:%S')}
        """
        msg = self._user_convert_msg_before_run(msg)
        msg = Serialization.to_dict(msg)
        # 以下是清洗补全字段.
        if 'extra' not in msg:
            msg['extra'] = {'is_auto_fill_extra': True}
        extra = msg['extra']
        if 'task_id' not in extra:
            extra['task_id'] = MsgGenerater.generate_task_id(self._queue_name)
        if 'publish_time' not in extra:
            extra['publish_time'] = MsgGenerater.generate_publish_time()
        if 'publish_time_format':
            extra['publish_time_format'] = MsgGenerater.generate_publish_time_format()
        return msg

    def _user_convert_msg_before_run(self, msg: typing.Union[str, dict]) -> dict:
        """
        用户也可以提前清洗数据
        """
        # print(msg)
        return msg

    def _submit_task(self, kw):
        kw['body'] = self._convert_msg_before_run(kw['body'])
        self._print_message_get_from_broker(kw['body'])
        if self._judge_is_daylight():
            self._requeue(kw)
            time.sleep(self.time_interval_for_check_do_not_run_time)
            return
        function_only_params = delete_keys_and_return_new_dict(kw['body'], )
        kw['function_only_params'] = function_only_params
        if self._get_priority_conf(kw, 'do_task_filtering') and self._redis_filter.check_value_exists(
                function_only_params, self._get_priority_conf(kw, 'filter_str')):  # 对函数的参数进行检查，过滤已经执行过并且成功的任务。
            self.logger.warning(f'redis的 [{self._redis_filter_key_name}] 键 中 过滤任务 {kw["body"]}')
            self._confirm_consume(kw)  # 不运行就必须确认消费，否则会发不能确认消费，导致消息队列中间件认为消息没有被消费。
            return
        publish_time = get_publish_time(kw['body'])
        msg_expire_seconds_priority = self._get_priority_conf(kw, 'msg_expire_seconds')
        if msg_expire_seconds_priority and time.time() - msg_expire_seconds_priority > publish_time:
            self.logger.warning(
                f'消息发布时戳是 {publish_time} {kw["body"].get("publish_time_format", "")},距离现在 {round(time.time() - publish_time, 4)} 秒 ,'
                f'超过了指定的 {msg_expire_seconds_priority} 秒，丢弃任务')
            self._confirm_consume(kw)
            return

        msg_eta = self._get_priority_conf(kw, 'eta')
        msg_countdown = self._get_priority_conf(kw, 'countdown')
        misfire_grace_time = self._get_priority_conf(kw, 'misfire_grace_time')
        run_date = None
        # print(kw)
        if msg_countdown:
            run_date = FunboostTime(kw['body']['extra']['publish_time']).datetime_obj + datetime.timedelta(seconds=msg_countdown)
        if msg_eta:
            run_date = FunboostTime(msg_eta).datetime_obj
        # print(run_date,time_util.DatetimeConverter().datetime_obj)
        # print(run_date.timestamp(),time_util.DatetimeConverter().datetime_obj.timestamp())
        # print(self.concurrent_pool)
        if run_date:  # 延时任务
            # print(repr(run_date),repr(datetime.datetime.now(tz=pytz.timezone(frame_config.TIMEZONE))))
            if self._has_start_delay_task_scheduler is False:
                self._has_start_delay_task_scheduler = True
                self._start_delay_task_scheduler()

            # 这种方式是扔到线程池
            # self._delay_task_scheduler.add_job(self.concurrent_pool.submit, 'date', run_date=run_date, args=(self._any_run,), kwargs={'kw': kw},
            #                                    misfire_grace_time=misfire_grace_time)

            # 这种方式是延时任务重新以普通任务方式发送到消息队列
            msg_no_delay = copy.deepcopy(kw['body'])
            self.__delete_eta_countdown(msg_no_delay)
            # print(msg_no_delay)
            # 数据库作为apscheduler的jobstores时候， 不能用 self.pbulisher_of_same_queue.publish，self不能序列化
            self._delay_task_scheduler.add_job(self._push_apscheduler_task_to_broker, 'date', run_date=run_date,
                                               kwargs={'queue_name': self.queue_name, 'msg': msg_no_delay, },
                                               misfire_grace_time=misfire_grace_time,
                                               )
            self._confirm_consume(kw)

        else:  # 普通任务
            self.concurrent_pool.submit(self._any_run, kw)

        if self.consumer_params.is_using_distributed_frequency_control:  # 如果是需要分布式控频。
            active_num = self._distributed_consumer_statistics.active_consumer_num
            self._frequency_control(self.consumer_params.qps / active_num, self._msg_schedule_time_intercal * active_num)
        else:
            self._frequency_control(self.consumer_params.qps, self._msg_schedule_time_intercal)

        while 1:  # 这一块的代码为支持暂停消费。
            # print(self._pause_flag)
            if self._pause_flag.is_set():
                if time.time() - self._last_show_pause_log_time > 60:
                    self.logger.warning(f'已设置 {self.queue_name} 队列中的任务为暂停消费')
                    self._last_show_pause_log_time = time.time()
                time.sleep(5)
            else:
                break

    def __delete_eta_countdown(self, msg_body: dict):
        self.__dict_pop(msg_body.get('extra', {}), 'eta')
        self.__dict_pop(msg_body.get('extra', {}), 'countdown')
        self.__dict_pop(msg_body.get('extra', {}), 'misfire_grace_time')

    @staticmethod
    def __dict_pop(dictx, key):
        try:
            dictx.pop(key)
        except KeyError:
            pass

    def _frequency_control(self, qpsx: float, msg_schedule_time_intercalx: float):
        # 以下是消费函数qps控制代码。无论是单个消费者空频还是分布式消费控频，都是基于直接计算的，没有依赖redis inrc计数，使得控频性能好。
        if qpsx is None:  # 不需要控频的时候，就不需要休眠。
            return
        if qpsx <= 5:
            """ 原来的简单版 """
            time.sleep(msg_schedule_time_intercalx)
        elif 5 < qpsx <= 20:
            """ 改进的控频版,防止消息队列中间件网络波动，例如1000qps使用redis,不能每次间隔1毫秒取下一条消息，
            如果取某条消息有消息超过了1毫秒，后面不能匀速间隔1毫秒获取，time.sleep不能休眠一个负数来让时光倒流"""
            time_sleep_for_qps_control = max((msg_schedule_time_intercalx - (time.time() - self._last_submit_task_timestamp)) * 0.99, 10 ** -3)
            # print(time.time() - self._last_submit_task_timestamp)
            # print(time_sleep_for_qps_control)
            time.sleep(time_sleep_for_qps_control)
            self._last_submit_task_timestamp = time.time()
        else:
            """基于当前消费者计数的控频，qps很大时候需要使用这种"""
            if time.time() - self._last_start_count_qps_timestamp > 1:
                self._has_execute_times_in_recent_second = 1
                self._last_start_count_qps_timestamp = time.time()
            else:
                self._has_execute_times_in_recent_second += 1
            # print(self._has_execute_times_in_recent_second)
            if self._has_execute_times_in_recent_second >= qpsx:
                time.sleep((1 - (time.time() - self._last_start_count_qps_timestamp)) * 1)

    def _print_message_get_from_broker(self, msg, broker_name=None):
        # print(999)
        if self.consumer_params.is_show_message_get_from_broker:
            # self.logger.debug(f'从 {broker_name} 中间件 的 {self._queue_name} 中取出的消息是 {msg}')
            self.logger.debug(f'从 {broker_name or self.consumer_params.broker_kind} 中间件 的 {self._queue_name} 中取出的消息是 {Serialization.to_json_str(msg)}')

    def _get_priority_conf(self, kw: dict, broker_task_config_key: str):
        broker_task_config = kw['body'].get('extra', {}).get(broker_task_config_key, None)
        if not broker_task_config:
            return getattr(self.consumer_params, f'{broker_task_config_key}', None)
        else:
            return broker_task_config

    # noinspection PyMethodMayBeStatic
    def _get_concurrent_info(self):
        concurrent_info = ''
        '''  影响了日志长度和一丝丝性能。
        if self._concurrent_mode == 1:
            concurrent_info = f'[{threading.current_thread()}  {threading.active_count()}]'
        elif self._concurrent_mode == 2:
            concurrent_info = f'[{gevent.getcurrent()}  {threading.active_count()}]'
        elif self._concurrent_mode == 3:
            # noinspection PyArgumentList
            concurrent_info = f'[{eventlet.getcurrent()}  {threading.active_count()}]'
        '''
        return concurrent_info

    def _set_do_not_delete_extra_from_msg(self):
        """例如从死信队列，把完整的包括extra的消息移到另一个正常队列，不要把extra中的参数去掉
        queue2queue.py 的 consume_and_push_to_another_queue 中操作了这个，普通用户无需调用这个方法。
        """
        self._do_not_delete_extra_from_msg = True

    def _frame_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus, kw: dict):
        pass

    async def _aio_frame_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus, kw: dict):
        pass

    def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus, ):  # 这个可以继承
        pass

    async def aio_user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus, ):  # 这个可以继承
        pass

    def _convert_real_function_only_params_by_conusuming_function_kind(self, function_only_params: dict, extra_params: dict):
        """对于实例方法和classmethod 方法， 从消息队列的消息恢复第一个入参， self 和 cls"""
        can_not_json_serializable_keys = extra_params.get('can_not_json_serializable_keys', [])
        if self.consumer_params.consuming_function_kind in [FunctionKind.CLASS_METHOD, FunctionKind.INSTANCE_METHOD]:
            real_function_only_params = copy.copy(function_only_params)
            method_first_param_name = None
            method_first_param_value = None
            for k, v in function_only_params.items():
                if isinstance(v, dict) and ConstStrForClassMethod.FIRST_PARAM_NAME in v:
                    method_first_param_name = k
                    method_first_param_value = v
                    break
            # method_cls = getattr(sys.modules[self.consumer_params.consuming_function_class_module],
            #                      self.consumer_params.consuming_function_class_name)
            if self.publisher_params.consuming_function_kind == FunctionKind.CLASS_METHOD:
                method_cls = getattr(PathHelper.import_module(method_first_param_value[ConstStrForClassMethod.CLS_MODULE]),
                                     method_first_param_value[ConstStrForClassMethod.CLS_NAME])
                real_function_only_params[method_first_param_name] = method_cls
            elif self.publisher_params.consuming_function_kind == FunctionKind.INSTANCE_METHOD:
                method_cls = getattr(PathHelper.import_module(method_first_param_value[ConstStrForClassMethod.CLS_MODULE]),
                                     method_first_param_value[ConstStrForClassMethod.CLS_NAME])
                obj = method_cls(**method_first_param_value[ConstStrForClassMethod.OBJ_INIT_PARAMS])
                real_function_only_params[method_first_param_name] = obj
            # print(real_function_only_params)
            if can_not_json_serializable_keys:
                for key in can_not_json_serializable_keys:
                    real_function_only_params[key] = PickleHelper.to_obj(real_function_only_params[key])
            return real_function_only_params
        else:
            if can_not_json_serializable_keys:
                for key in can_not_json_serializable_keys:
                    function_only_params[key] = PickleHelper.to_obj(function_only_params[key])
            return function_only_params

    # noinspection PyProtectedMember
    def _run(self, kw: dict, ):
        # print(kw)
        try:
            t_start_run_fun = time.time()
            max_retry_times = self._get_priority_conf(kw, 'max_retry_times')
            current_function_result_status = FunctionResultStatus(self.queue_name, self.consuming_function.__name__, kw['body'], )
            current_retry_times = 0
            function_only_params = kw['function_only_params']
            for current_retry_times in range(max_retry_times + 1):
                current_function_result_status.run_times = current_retry_times + 1
                current_function_result_status.run_status = RunStatus.running
                self._result_persistence_helper.save_function_result_to_mongo(current_function_result_status)
                current_function_result_status = self._run_consuming_function_with_confirm_and_retry(kw, current_retry_times=current_retry_times,
                                                                                                     function_result_status=current_function_result_status)
                if (current_function_result_status.success is True or current_retry_times == max_retry_times
                        or current_function_result_status._has_requeue
                        or current_function_result_status._has_to_dlx_queue
                        or current_function_result_status._has_kill_task):
                    break
                else:
                    if self.consumer_params.retry_interval:
                        time.sleep(self.consumer_params.retry_interval)
            if not (current_function_result_status._has_requeue and self.BROKER_KIND in [BrokerEnum.RABBITMQ_AMQPSTORM, BrokerEnum.RABBITMQ_PIKA, BrokerEnum.RABBITMQ_RABBITPY]):  # 已经nack了，不能ack，否则rabbitmq delevar tag 报错
                self._confirm_consume(kw)
            current_function_result_status.run_status = RunStatus.finish
            self._result_persistence_helper.save_function_result_to_mongo(current_function_result_status)
            if self._get_priority_conf(kw, 'do_task_filtering'):
                self._redis_filter.add_a_value(function_only_params, self._get_priority_conf(kw, 'filter_str'))  # 函数执行成功后，添加函数的参数排序后的键值对字符串到set中。
            if current_function_result_status.success is False and current_retry_times == max_retry_times:
                log_msg = f'函数 {self.consuming_function.__name__} 达到最大重试次数 {self._get_priority_conf(kw, "max_retry_times")} 后,仍然失败， 入参是  {function_only_params} '
                if self.consumer_params.is_push_to_dlx_queue_when_retry_max_times:
                    log_msg += f'  。发送到死信队列 {self._dlx_queue_name} 中'
                    self.publisher_of_dlx_queue.publish(kw['body'])
                # self.logger.critical(msg=f'{log_msg} \n', )
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)

            if self._get_priority_conf(kw, 'is_using_rpc_mode'):
                # print(function_result_status.get_status_dict(without_datetime_obj=
                if (current_function_result_status.success is False and current_retry_times == max_retry_times) or current_function_result_status.success is True:
                    with RedisMixin().redis_db_filter_and_rpc_result.pipeline() as p:
                        # RedisMixin().redis_db_frame.lpush(kw['body']['extra']['task_id'], json.dumps(function_result_status.get_status_dict(without_datetime_obj=True)))
                        # RedisMixin().redis_db_frame.expire(kw['body']['extra']['task_id'], 600)
                        current_function_result_status.rpc_result_expire_seconds = self.consumer_params.rpc_result_expire_seconds
                        p.lpush(kw['body']['extra']['task_id'],
                                Serialization.to_json_str(current_function_result_status.get_status_dict(without_datetime_obj=True)))
                        p.expire(kw['body']['extra']['task_id'], self.consumer_params.rpc_result_expire_seconds)
                        p.execute()

            with self._lock_for_count_execute_task_times_every_unit_time:
                self.metric_calculation.cal(t_start_run_fun, current_function_result_status)
            self._frame_custom_record_process_info_func(current_function_result_status, kw)
            self.user_custom_record_process_info_func(current_function_result_status, )  # 两种方式都可以自定义,记录结果,建议继承方式,不使用boost中指定 user_custom_record_process_info_func
            if self.consumer_params.user_custom_record_process_info_func:
                self.consumer_params.user_custom_record_process_info_func(current_function_result_status, )
        except BaseException as e:
            log_msg = f' error 严重错误 {type(e)} {e} '
            # self.logger.critical(msg=f'{log_msg} \n', exc_info=True)
            # self.error_file_logger.critical(msg=f'{log_msg} \n', exc_info=True)
            self.logger.critical(msg=log_msg, exc_info=True)
        set_fct_context(None)

    # noinspection PyProtectedMember
    def _run_consuming_function_with_confirm_and_retry(self, kw: dict, current_retry_times,
                                                       function_result_status: FunctionResultStatus, ):
        function_only_params = kw['function_only_params'] if self._do_not_delete_extra_from_msg is False else kw['body']
        task_id = kw['body']['extra']['task_id']
        t_start = time.time()
        fct_context = FctContext(function_result_status=function_result_status,
                                 logger=self.logger, )
        set_fct_context(fct_context)
        try:
            function_run = self.consuming_function
            
            if self._consuming_function_is_asyncio:
                function_run = sync_or_async_fun_deco(function_run)
            function_timeout = self._get_priority_conf(kw, 'function_timeout')
            function_run = function_run if self.consumer_params.consuming_function_decorator is None else self.consumer_params.consuming_function_decorator(function_run)
            function_run = function_run if not function_timeout else self._concurrent_mode_dispatcher.timeout_deco(
                function_timeout)(function_run)

            if self.consumer_params.is_support_remote_kill_task:
                if kill_remote_task.RemoteTaskKiller(self.queue_name, task_id).judge_need_revoke_run():  # 如果远程指令杀死任务，如果还没开始运行函数，就取消运行
                    function_result_status._has_kill_task = True
                    self.logger.warning(f'取消运行 {task_id} {function_only_params}')
                    return function_result_status
                function_run = kill_remote_task.kill_fun_deco(task_id)(function_run)  # 用杀死装饰器包装起来在另一个线程运行函数,以便等待远程杀死。
            function_result_status.result = function_run(**self._convert_real_function_only_params_by_conusuming_function_kind(function_only_params, kw['body']['extra']))
            # if asyncio.iscoroutine(function_result_status.result):
            #     log_msg = f'''异步的协程消费函数必须使用 async 并发模式并发,请设置消费函数 {self.consuming_function.__name__} 的concurrent_mode 为 ConcurrentModeEnum.ASYNC 或 4'''
            #     # self.logger.critical(msg=f'{log_msg} \n')
            #     # self.error_file_logger.critical(msg=f'{log_msg} \n')
            #     self._log_critical(msg=log_msg)
            #     # noinspection PyProtectedMember,PyUnresolvedReferences
            #
            #     os._exit(4)
            function_result_status.success = True
            if self.consumer_params.log_level <= logging.DEBUG:
                result_str_to_be_print = str(function_result_status.result)[:100] if len(str(function_result_status.result)) < 100 else str(function_result_status.result)[:100] + '  。。。。。  '
               
                self.logger.debug(f' 函数 {self.consuming_function.__name__}  '
                                  f'第{current_retry_times + 1}次 运行, 正确了，函数运行时间是 {round(time.time() - t_start, 4)} 秒,入参是 {function_only_params} , '
                                  f'结果是  {result_str_to_be_print}   {self._get_concurrent_info()}  ')
        except BaseException as e:
            if isinstance(e, (ExceptionForRequeue,)):  # mongo经常维护备份时候插入不了或挂了，或者自己主动抛出一个ExceptionForRequeue类型的错误会重新入队，不受指定重试次数逇约束。
                log_msg = f'函数 [{self.consuming_function.__name__}] 中发生错误 {type(e)}  {e} 。消息重新放入当前队列 {self._queue_name}'
                # self.logger.critical(msg=f'{log_msg} \n')
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)
                time.sleep(0.1)  # 防止快速无限出错入队出队，导致cpu和中间件忙
                # 重回队列如果不修改task_id,insert插入函数消费状态结果到mongo会主键重复。要么保存函数消费状态使用replace，要么需要修改taskikd
                # kw_new = copy.deepcopy(kw)
                # new_task_id =f'{self._queue_name}_result:{uuid.uuid4()}'
                # kw_new['body']['extra']['task_id'] = new_task_id
                # self._requeue(kw_new)
                self._requeue(kw)
                function_result_status._has_requeue = True
            if isinstance(e, ExceptionForPushToDlxqueue):
                log_msg = f'函数 [{self.consuming_function.__name__}] 中发生错误 {type(e)}  {e}，消息放入死信队列 {self._dlx_queue_name}'
                # self.logger.critical(msg=f'{log_msg} \n')
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)
                self.publisher_of_dlx_queue.publish(kw['body'])  # 发布到死信队列，不重回当前队列
                function_result_status._has_to_dlx_queue = True
            if isinstance(e, kill_remote_task.TaskHasKilledError):
                log_msg = f'task_id 为 {task_id} , 函数 [{self.consuming_function.__name__}] 运行入参 {function_only_params}   ，已被远程指令杀死 {type(e)}  {e}'
                # self.logger.critical(msg=f'{log_msg} ')
                # self.error_file_logger.critical(msg=f'{log_msg} ')
                self.logger.critical(msg=log_msg)
                function_result_status._has_kill_task = True
            if isinstance(e, (ExceptionForRequeue, ExceptionForPushToDlxqueue, kill_remote_task.TaskHasKilledError)):
                return function_result_status
            log_msg = f'''函数 {self.consuming_function.__name__}  第{current_retry_times + 1}次运行发生错误，
                          函数运行时间是 {round(time.time() - t_start, 4)} 秒,  入参是  {function_only_params}    
                          {type(e)} {e} '''
            # self.logger.error(msg=f'{log_msg} \n', exc_info=self._get_priority_conf(kw, 'is_print_detail_exception'))
            # self.error_file_logger.error(msg=f'{log_msg} \n', exc_info=self._get_priority_conf(kw, 'is_print_detail_exception'))
            self.logger.error(msg=log_msg, exc_info=self._get_priority_conf(kw, 'is_print_detail_exception'))
            # traceback.print_exc()
            function_result_status.exception = f'{e.__class__.__name__}    {str(e)}'
            function_result_status.exception_msg = str(e)
            function_result_status.exception_type = e.__class__.__name__

            function_result_status.result = FunctionResultStatus.FUNC_RUN_ERROR
        return function_result_status

    def _gen_asyncio_objects(self):
        if getattr(self, '_async_lock_for_count_execute_task_times_every_unit_time', None) is None:
            self._async_lock_for_count_execute_task_times_every_unit_time = asyncio.Lock()

    # noinspection PyProtectedMember
    async def _async_run(self, kw: dict, ):
        """
        虽然 async def _async_run 和上面的 def _run 有点大面积结构重复相似，这个是为了asyncio模式的，
        asyncio模式真的和普通同步模式的代码思维和形式区别太大，
        框架实现兼容async的消费函数很麻烦复杂，连并发池都要单独写

        _run 和 _async_run 无法合并成一个方法：
        因为在一个函数体内部，您无法根据条件来决定是否使用 await。

        Python 语法不允许这样做：
        # 伪代码，这是无效的
        def _unified_run(self, kw, is_async):
            # ...
            if is_async:
                await asyncio.sleep(1) # 'await' outside async function 经典报错
            else:
                time.sleep(1)

        不能在同步函数里面去写 await,只要一个函数里出现了 await，这个函数就必须被声明为 async def



        funboost 这个代价算小了,为了支持异步的全流程生态包括发布/消费/获取rpc结果,对asyncio的累计专门投入代码不到500行.
        如果是celery 改造适配asyncio,起码要增加10倍以上的代码量,改5000行代码都搞不定支持真asyncio并发.
        我说的是支持兼容真asyncio并发,而不是每个线程内部搞个临时loop,然后临时loop.run_until_complete(用户async函数) 这种伪asyncio并发,
        真asyncio并发,是单个loop里面运行无数协程,
        伪asyncio并发是在每个线程启动一个临时的loop,每个loop仅仅运行一个协程,然后等待这个协程结束,这完全违背了 asyncio 的核心初心理念,这种比多线程性能本身还差.
        """
        try:
            self._gen_asyncio_objects()
            t_start_run_fun = time.time()
            max_retry_times = self._get_priority_conf(kw, 'max_retry_times')
            current_function_result_status = FunctionResultStatus(self.queue_name, self.consuming_function.__name__, kw['body'], )
            current_retry_times = 0
            function_only_params = kw['function_only_params']
            for current_retry_times in range(max_retry_times + 1):
                current_function_result_status.run_times = current_retry_times + 1
                current_function_result_status.run_status = RunStatus.running
                self._result_persistence_helper.save_function_result_to_mongo(current_function_result_status)
                current_function_result_status = await self._async_run_consuming_function_with_confirm_and_retry(kw, current_retry_times=current_retry_times,
                                                                                                                 function_result_status=current_function_result_status)
                if current_function_result_status.success is True or current_retry_times == max_retry_times or current_function_result_status._has_requeue:
                    break
                else:
                    if self.consumer_params.retry_interval:
                        await asyncio.sleep(self.consumer_params.retry_interval)

            if not (current_function_result_status._has_requeue and self.BROKER_KIND in [BrokerEnum.RABBITMQ_AMQPSTORM, BrokerEnum.RABBITMQ_PIKA, BrokerEnum.RABBITMQ_RABBITPY]):
                await simple_run_in_executor(self._confirm_consume, kw)
            current_function_result_status.run_status = RunStatus.finish
            await simple_run_in_executor(self._result_persistence_helper.save_function_result_to_mongo, current_function_result_status)
            if self._get_priority_conf(kw, 'do_task_filtering'):
                # self._redis_filter.add_a_value(function_only_params)  # 函数执行成功后，添加函数的参数排序后的键值对字符串到set中。
                await simple_run_in_executor(self._redis_filter.add_a_value, function_only_params, self._get_priority_conf(kw, 'filter_str'))
            if current_function_result_status.success is False and current_retry_times == max_retry_times:
                log_msg = f'函数 {self.consuming_function.__name__} 达到最大重试次数 {self._get_priority_conf(kw, "max_retry_times")} 后,仍然失败， 入参是  {function_only_params} '
                if self.consumer_params.is_push_to_dlx_queue_when_retry_max_times:
                    log_msg += f'  。发送到死信队列 {self._dlx_queue_name} 中'
                    await simple_run_in_executor(self.publisher_of_dlx_queue.publish, kw['body'])
                # self.logger.critical(msg=f'{log_msg} \n', )
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)

                # self._confirm_consume(kw)  # 错得超过指定的次数了，就确认消费了。
            if self._get_priority_conf(kw, 'is_using_rpc_mode'):
                def push_result():
                    with RedisMixin().redis_db_filter_and_rpc_result.pipeline() as p:
                        current_function_result_status.rpc_result_expire_seconds = self.consumer_params.rpc_result_expire_seconds
                        p.lpush(kw['body']['extra']['task_id'],
                                Serialization.to_json_str(current_function_result_status.get_status_dict(without_datetime_obj=True)))
                        p.expire(kw['body']['extra']['task_id'], self.consumer_params.rpc_result_expire_seconds)
                        p.execute()

                if (current_function_result_status.success is False and current_retry_times == max_retry_times) or current_function_result_status.success is True:
                    await simple_run_in_executor(push_result)
            async with self._async_lock_for_count_execute_task_times_every_unit_time:
                self.metric_calculation.cal(t_start_run_fun, current_function_result_status)

            self._frame_custom_record_process_info_func(current_function_result_status, kw)
            await self._aio_frame_custom_record_process_info_func(current_function_result_status, kw)
            self.user_custom_record_process_info_func(current_function_result_status, )  # 两种方式都可以自定义,记录结果.建议使用文档4.21.b的方式继承来重写
            await self.aio_user_custom_record_process_info_func(current_function_result_status, )
            if self.consumer_params.user_custom_record_process_info_func:
                self.consumer_params.user_custom_record_process_info_func(current_function_result_status, )

        except BaseException as e:
            log_msg = f' error 严重错误 {type(e)} {e} '
            # self.logger.critical(msg=f'{log_msg} \n', exc_info=True)
            # self.error_file_logger.critical(msg=f'{log_msg} \n', exc_info=True)
            self.logger.critical(msg=log_msg, exc_info=True)
        set_fct_context(None)

    # noinspection PyProtectedMember
    async def _async_run_consuming_function_with_confirm_and_retry(self, kw: dict, current_retry_times,
                                                                   function_result_status: FunctionResultStatus, ):
        """虽然和上面有点大面积重复相似，这个是为了asyncio模式的，asyncio模式真的和普通同步模式的代码思维和形式区别太大，
        框架实现兼容async的消费函数很麻烦复杂，连并发池都要单独写"""
        function_only_params = kw['function_only_params'] if self._do_not_delete_extra_from_msg is False else kw['body']

        # noinspection PyBroadException
        t_start = time.time()

        fct_context = FctContext(function_result_status=function_result_status,
                                 logger=self.logger,  )
        set_fct_context(fct_context)
        try:
            corotinue_obj = self.consuming_function(**self._convert_real_function_only_params_by_conusuming_function_kind(function_only_params, kw['body']['extra']))
            if not asyncio.iscoroutine(corotinue_obj):
                log_msg = f'''当前设置的并发模式为 async 并发模式，但消费函数不是异步协程函数，请不要把消费函数 {self.consuming_function.__name__} 的 concurrent_mode 设置错误'''
                # self.logger.critical(msg=f'{log_msg} \n')
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)
                # noinspection PyProtectedMember,PyUnresolvedReferences
                os._exit(444)
            if not self.consumer_params.function_timeout:
                rs = await corotinue_obj
                # rs = await asyncio.wait_for(corotinue_obj, timeout=4)
            else:
                rs = await asyncio.wait_for(corotinue_obj, timeout=self.consumer_params.function_timeout)
            function_result_status.result = rs
            function_result_status.success = True
            if self.consumer_params.log_level <= logging.DEBUG:
                result_str_to_be_print = str(rs)[:100] if len(str(rs)) < 100 else str(rs)[:100] + '  。。。。。  '
                self.logger.debug(f' 函数 {self.consuming_function.__name__}  '
                                  f'第{current_retry_times + 1}次 运行, 正确了，函数运行时间是 {round(time.time() - t_start, 4)} 秒,'
                                  f'入参是 【 {function_only_params} 】 ,结果是 {result_str_to_be_print}  。 {corotinue_obj} ')
        except BaseException as e:
            if isinstance(e, (ExceptionForRequeue,)):  # mongo经常维护备份时候插入不了或挂了，或者自己主动抛出一个ExceptionForRequeue类型的错误会重新入队，不受指定重试次数逇约束。
                log_msg = f'函数 [{self.consuming_function.__name__}] 中发生错误 {type(e)}  {e} 。 消息重新放入当前队列 {self._queue_name}'
                # self.logger.critical(msg=f'{log_msg} \n')
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)
                # time.sleep(1)  # 防止快速无限出错入队出队，导致cpu和中间件忙
                await asyncio.sleep(0.1)
                # return self._requeue(kw)
                await simple_run_in_executor(self._requeue, kw)
                function_result_status._has_requeue = True
            if isinstance(e, ExceptionForPushToDlxqueue):
                log_msg = f'函数 [{self.consuming_function.__name__}] 中发生错误 {type(e)}  {e}，消息放入死信队列 {self._dlx_queue_name}'
                # self.logger.critical(msg=f'{log_msg} \n')
                # self.error_file_logger.critical(msg=f'{log_msg} \n')
                self.logger.critical(msg=log_msg)
                await simple_run_in_executor(self.publisher_of_dlx_queue.publish, kw['body'])  # 发布到死信队列，不重回当前队列
                function_result_status._has_to_dlx_queue = True
            if isinstance(e, (ExceptionForRequeue, ExceptionForPushToDlxqueue)):
                return function_result_status
            log_msg = f'''函数 {self.consuming_function.__name__}  第{current_retry_times + 1}次运行发生错误，
                          函数运行时间是 {round(time.time() - t_start, 4)} 秒,  入参是  {function_only_params}     
                          原因是 {type(e)} {e} '''
            # self.logger.error(msg=f'{log_msg} \n', exc_info=self._get_priority_conf(kw, 'is_print_detail_exception'))
            # self.error_file_logger.error(msg=f'{log_msg} \n', exc_info=self._get_priority_conf(kw, 'is_print_detail_exception'))
            self.logger.error(msg=log_msg, exc_info=self._get_priority_conf(kw, 'is_print_detail_exception'))
            function_result_status.exception = f'{e.__class__.__name__}    {str(e)}'
            function_result_status.exception_msg = str(e)
            function_result_status.exception_type = e.__class__.__name__
            function_result_status.result = FunctionResultStatus.FUNC_RUN_ERROR
        return function_result_status

    @abc.abstractmethod
    def _confirm_consume(self, kw):
        """确认消费"""
        raise NotImplementedError

    def check_heartbeat_and_message_count(self):
        self.metric_calculation.msg_num_in_broker = self.publisher_of_same_queue.get_message_count()
        self.metric_calculation.last_get_msg_num_ts = time.time()
        if time.time() - self.metric_calculation.last_timestamp_print_msg_num > 600:
            if self.metric_calculation.msg_num_in_broker != -1:
                self.logger.info(f'队列 [{self._queue_name}] 中还有 [{self.metric_calculation.msg_num_in_broker}] 个任务')
            self.metric_calculation.last_timestamp_print_msg_num = time.time()
        if self.metric_calculation.msg_num_in_broker != 0:
            self.metric_calculation.last_timestamp_when_has_task_in_queue = time.time()
        return self.metric_calculation.msg_num_in_broker

    @abc.abstractmethod
    def _requeue(self, kw):
        """重新入队"""
        raise NotImplementedError

    def _apscheduler_job_miss(self, event):
        """
        这是 apscheduler 包的事件钩子。
        ev.function_args = job.args
        ev.function_kwargs = job.kwargs
        ev.function = job.func
        :return:
        """
        # print(event.scheduled_run_time)
        misfire_grace_time = self._get_priority_conf(event.function_kwargs["kw"], 'misfire_grace_time')
        log_msg = f''' 现在时间是 {time_util.DatetimeConverter().datetime_str} ,比此任务规定的本应该的运行时间 {event.scheduled_run_time} 相比 超过了指定的 {misfire_grace_time} 秒,放弃执行此任务 
                             {event.function_kwargs["kw"]["body"]} '''
        # self.logger.critical(msg=f'{log_msg} \n')
        # self.error_file_logger.critical(msg=f'{log_msg} \n')
        self.logger.critical(msg=log_msg)
        self._confirm_consume(event.function_kwargs["kw"])

        '''
        if self._get_priority_conf(event.function_kwargs["kw"], 'execute_delay_task_even_if_when_task_is_expired') is False:
            self.logger.critical(f'现在时间是 {time_util.DatetimeConverter().datetime_str} ,此任务设置的延时运行已过期 \n'
                                 f'{event.function_kwargs["kw"]["body"]} ， 此任务放弃执行')
            self._confirm_consume(event.function_kwargs["kw"])
        else:
            self.logger.warning(f'现在时间是 {time_util.DatetimeConverter().datetime_str} ,此任务设置的延时运行已过期 \n'
                                f'{event.function_kwargs["kw"]["body"]} ，'
                                f'但框架为了防止是任务积压导致消费延后，所以仍然使其运行一次')
            event.function(*event.function_args, **event.function_kwargs)
        '''

    def pause_consume(self):
        """从远程机器可以设置队列为暂停消费状态，funboost框架会自动停止消费，此功能需要配置好redis"""
        RedisMixin().redis_db_frame.hset(RedisKeys.REDIS_KEY_PAUSE_FLAG, self.queue_name, '1')

    def continue_consume(self):
        """从远程机器可以设置队列为暂停消费状态，funboost框架会自动继续消费，此功能需要配置好redis"""
        RedisMixin().redis_db_frame.hset(RedisKeys.REDIS_KEY_PAUSE_FLAG, self.queue_name, '0')

    @decorators.FunctionResultCacher.cached_function_result_for_a_time(120)
    def _judge_is_daylight(self):
        if self.consumer_params.is_do_not_run_by_specify_time_effect and (
                self.consumer_params.do_not_run_by_specify_time[0] < time_util.DatetimeConverter().time_str < self.consumer_params.do_not_run_by_specify_time[1]):
            self.logger.warning(
                f'现在时间是 {time_util.DatetimeConverter()} ，现在时间是在 {self.consumer_params.do_not_run_by_specify_time} 之间，不运行')
            return True

    def wait_for_possible_has_finish_all_tasks(self, minutes: int = 3):
        """
        判断队列所有任务是否消费完成了。
        由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
        一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
        :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成，为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
        :return:

        """
        if minutes <= 1:
            raise ValueError('疑似完成任务，判断时间最少需要设置为3分钟内,最好是是10分钟')
        no_task_time = 0
        while 1:
            # noinspection PyBroadException
            message_count = self.metric_calculation.msg_num_in_broker
            # print(message_count,self._last_execute_task_time,time.time() - self._last_execute_task_time,no_task_time)
            if message_count == 0 and self.metric_calculation.last_execute_task_time != 0 and (time.time() - self.metric_calculation.last_execute_task_time) > minutes * 60:
                no_task_time += 30
            else:
                no_task_time = 0
            time.sleep(30)
            if no_task_time > minutes * 60:
                break

    def clear_filter_tasks(self):
        RedisMixin().redis_db_frame.delete(self._redis_filter_key_name)
        self.logger.warning(f'清空 {self._redis_filter_key_name} 键的任务过滤')

    def __str__(self):
        return f'队列为 {self.queue_name} 函数为 {self.consuming_function} 的消费者'


# noinspection PyProtectedMember
class ConcurrentModeDispatcher(FunboostFileLoggerMixin):

    def __init__(self, consumerx: AbstractConsumer):
        self.consumer = consumerx
        self._concurrent_mode = self.consumer.consumer_params.concurrent_mode
        self.timeout_deco = None
        if self._concurrent_mode in (ConcurrentModeEnum.THREADING, ConcurrentModeEnum.SINGLE_THREAD):
            # self.timeout_deco = decorators.timeout
            self.timeout_deco = dafunc.func_set_timeout  # 这个超时装饰器性能好很多。
        elif self._concurrent_mode == ConcurrentModeEnum.GEVENT:
            from funboost.concurrent_pool.custom_gevent_pool_executor import gevent_timeout_deco
            self.timeout_deco = gevent_timeout_deco
        elif self._concurrent_mode == ConcurrentModeEnum.EVENTLET:
            from funboost.concurrent_pool.custom_evenlet_pool_executor import evenlet_timeout_deco
            self.timeout_deco = evenlet_timeout_deco
        # self.logger.info(f'{self.consumer} 设置并发模式 {self.consumer.consumer_params.concurrent_mode}')

    def check_all_concurrent_mode(self):
        if GlobalVars.global_concurrent_mode is not None and \
                self.consumer.consumer_params.concurrent_mode != GlobalVars.global_concurrent_mode:
            # print({self.consumer._concurrent_mode, ConsumersManager.global_concurrent_mode})
            if not {self.consumer.consumer_params.concurrent_mode, GlobalVars.global_concurrent_mode}.issubset({ConcurrentModeEnum.THREADING,
                                                                                                                ConcurrentModeEnum.ASYNC,
                                                                                                                ConcurrentModeEnum.SINGLE_THREAD}):
                # threding、asyncio、solo 这几种模式可以共存。但同一个解释器不能同时选择 gevent + 其它并发模式，也不能 eventlet + 其它并发模式。
                raise ValueError('''由于猴子补丁的原因，同一解释器中不可以设置两种并发类型,请查看显示的所有消费者的信息，
                                 搜索 concurrent_mode 关键字，确保当前解释器内的所有消费者的并发模式只有一种(或可以共存),
                                 asyncio threading single_thread 并发模式可以共存，但gevent和threading不可以共存，
                                 gevent和eventlet不可以共存''')

        GlobalVars.global_concurrent_mode = self.consumer.consumer_params.concurrent_mode

    def build_pool(self):
        if self.consumer._concurrent_pool is not None:
            return self.consumer._concurrent_pool

        pool_type = None  # 是按照ThreadpoolExecutor写的三个鸭子类，公有方法名和功能写成完全一致，可以互相替换。
        if self._concurrent_mode == ConcurrentModeEnum.THREADING:
            # pool_type = CustomThreadPoolExecutor
            # pool_type = BoundedThreadPoolExecutor
            pool_type = FlexibleThreadPool
        elif self._concurrent_mode == ConcurrentModeEnum.GEVENT:
            from funboost.concurrent_pool.custom_gevent_pool_executor import get_gevent_pool_executor
            pool_type = get_gevent_pool_executor
        elif self._concurrent_mode == ConcurrentModeEnum.EVENTLET:
            from funboost.concurrent_pool.custom_evenlet_pool_executor import get_eventlet_pool_executor
            pool_type = get_eventlet_pool_executor
        elif self._concurrent_mode == ConcurrentModeEnum.ASYNC:
            pool_type = AsyncPoolExecutor
        elif self._concurrent_mode == ConcurrentModeEnum.SINGLE_THREAD:
            pool_type = SoloExecutor
        # elif self._concurrent_mode == ConcurrentModeEnum.LINUX_FORK:
        #     pool_type = SimpleProcessPool
        # pool_type = BoundedProcessPoolExecutor
        # from concurrent.futures import ProcessPoolExecutor
        # pool_type = ProcessPoolExecutor
        if self._concurrent_mode == ConcurrentModeEnum.ASYNC:
            self.consumer._concurrent_pool = self.consumer.consumer_params.specify_concurrent_pool or pool_type(
                self.consumer.consumer_params.concurrent_num,
                specify_async_loop=self.consumer.consumer_params.specify_async_loop,
                is_auto_start_specify_async_loop_in_child_thread=self.consumer.consumer_params.is_auto_start_specify_async_loop_in_child_thread)
        else:
            # print(pool_type)
            self.consumer._concurrent_pool = self.consumer.consumer_params.specify_concurrent_pool or pool_type(self.consumer.consumer_params.concurrent_num)
        # print(self._concurrent_mode,self.consumer._concurrent_pool)
        return self.consumer._concurrent_pool

    # def schedulal_task_with_no_block(self):
    #     if ConsumersManager.schedual_task_always_use_thread:
    #         t = Thread(target=self.consumer.keep_circulating(1)(self.consumer._dispatch_task))
    #         ConsumersManager.schedulal_thread_to_be_join.append(t)
    #         t.start()
    #     else:
    #         if self._concurrent_mode in [ConcurrentModeEnum.THREADING, ConcurrentModeEnum.ASYNC,
    #                                      ConcurrentModeEnum.SINGLE_THREAD, ]:
    #             t = Thread(target=self.consumer.keep_circulating(1)(self.consumer._dispatch_task))
    #             ConsumersManager.schedulal_thread_to_be_join.append(t)
    #             t.start()
    #         elif self._concurrent_mode == ConcurrentModeEnum.GEVENT:
    #             import gevent
    #             g = gevent.spawn(self.consumer.keep_circulating(1)(self.consumer._dispatch_task), )
    #             ConsumersManager.schedulal_thread_to_be_join.append(g)
    #         elif self._concurrent_mode == ConcurrentModeEnum.EVENTLET:
    #             import eventlet
    #             g = eventlet.spawn(self.consumer.keep_circulating(1)(self.consumer._dispatch_task), )
    #             ConsumersManager.schedulal_thread_to_be_join.append(g)

    def schedulal_task_with_no_block(self):
        self.consumer.keep_circulating(1, block=False, daemon=False)(self.consumer._dispatch_task)()


def wait_for_possible_has_finish_all_tasks_by_conusmer_list(consumer_list: typing.List[AbstractConsumer], minutes: int = 3):
    """
   判断多个消费者是否消费完成了。
   由于是异步消费，和存在队列一边被消费，一边在推送，或者还有结尾少量任务还在确认消费者实际还没彻底运行完成。  但有时候需要判断 所有任务，务是否完成，提供一个不精确的判断，要搞清楚原因和场景后再慎用。
   一般是和celery一样，是永久运行的后台任务，永远无限死循环去任务执行任务，但有的人有判断是否执行完成的需求。
   :param consumer_list: 多个消费者列表
   :param minutes: 消费者连续多少分钟没执行任务任务 并且 消息队列中间件中没有，就判断为消费完成。为了防止是长耗时任务，一般判断完成是真正提供的minutes的2个周期时间。
   :return:

    """
    with BoundedThreadPoolExecutor(len(consumer_list)) as pool:
        for consumer in consumer_list:
            pool.submit(consumer.wait_for_possible_has_finish_all_tasks(minutes))


class MetricCalculation:
    UNIT_TIME_FOR_COUNT = 10  # 这个不要随意改,需要其他地方配合,每隔多少秒计数，显示单位时间内执行多少次，暂时固定为10秒。

    def __init__(self, conusmer: AbstractConsumer) -> None:
        self.consumer = conusmer

        self.unit_time_for_count = self.UNIT_TIME_FOR_COUNT  #
        self.execute_task_times_every_unit_time_temp = 0  # 每单位时间执行了多少次任务。
        self.execute_task_times_every_unit_time_temp_fail = 0  # 每单位时间执行了多少次任务失败。
        self.current_time_for_execute_task_times_every_unit_time = time.time()
        self.consuming_function_cost_time_total_every_unit_time_tmp = 0
        self.last_execute_task_time = time.time()  # 最近一次执行任务的时间。
        self.last_x_s_execute_count = 0
        self.last_x_s_execute_count_fail = 0
        self.last_x_s_avarage_function_spend_time = None
        self.last_show_remaining_execution_time = 0
        self.show_remaining_execution_time_interval = 300
        self.msg_num_in_broker = 0
        self.last_get_msg_num_ts = 0
        self.last_timestamp_when_has_task_in_queue = 0
        self.last_timestamp_print_msg_num = 0

        self.total_consume_count_from_start = 0
        self.total_consume_count_from_start_fail = 0
        self.total_cost_time_from_start = 0  # 函数运行累计花费时间
        self.last_x_s_total_cost_time = None

    def cal(self, t_start_run_fun: float, current_function_result_status: FunctionResultStatus):
        self.last_execute_task_time = time.time()
        current_msg_cost_time = time.time() - t_start_run_fun
        self.execute_task_times_every_unit_time_temp += 1
        self.total_consume_count_from_start += 1
        self.total_cost_time_from_start += current_msg_cost_time
        if current_function_result_status.success is False:
            self.execute_task_times_every_unit_time_temp_fail += 1
            self.total_consume_count_from_start_fail += 1
        self.consuming_function_cost_time_total_every_unit_time_tmp += current_msg_cost_time

        if time.time() - self.current_time_for_execute_task_times_every_unit_time > self.unit_time_for_count:
            self.last_x_s_execute_count = self.execute_task_times_every_unit_time_temp
            self.last_x_s_execute_count_fail = self.execute_task_times_every_unit_time_temp_fail
            self.last_x_s_total_cost_time = self.consuming_function_cost_time_total_every_unit_time_tmp
            self.last_x_s_avarage_function_spend_time = round(self.last_x_s_total_cost_time / self.last_x_s_execute_count, 3)
            msg = f'{self.unit_time_for_count} 秒内执行了 {self.last_x_s_execute_count} 次函数 [ {self.consumer.consuming_function.__name__} ] ,' \
                  f'失败了{self.last_x_s_execute_count_fail} 次,函数平均运行耗时 {self.last_x_s_avarage_function_spend_time} 秒。 '
            self.consumer.logger.info(msg)
            if time.time() - self.last_show_remaining_execution_time > self.show_remaining_execution_time_interval:
                self.msg_num_in_broker = self.consumer.publisher_of_same_queue.get_message_count()
                self.last_get_msg_num_ts = time.time()
                if self.msg_num_in_broker != -1:  # 有的中间件无法统计或没实现统计队列剩余数量的，统一返回的是-1，不显示这句话。
                    need_time = time_util.seconds_to_hour_minute_second(self.msg_num_in_broker / (self.execute_task_times_every_unit_time_temp / self.unit_time_for_count) /
                                                                        self.consumer._distributed_consumer_statistics.active_consumer_num)
                    msg += f''' 预计还需要 {need_time} 时间 才能执行完成 队列 {self.consumer.queue_name} 中的 {self.msg_num_in_broker} 个剩余任务'''
                    self.consumer.logger.info(msg)
                self.last_show_remaining_execution_time = time.time()
            if self.consumer.consumer_params.is_send_consumer_heartbeat_to_redis is True:
                RedisMixin().redis_db_frame.hincrby(RedisKeys.FUNBOOST_QUEUE__RUN_COUNT_MAP, self.consumer.queue_name, self.execute_task_times_every_unit_time_temp)
                RedisMixin().redis_db_frame.hincrby(RedisKeys.FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP, self.consumer.queue_name, self.execute_task_times_every_unit_time_temp_fail)

            self.current_time_for_execute_task_times_every_unit_time = time.time()
            self.consuming_function_cost_time_total_every_unit_time_tmp = 0
            self.execute_task_times_every_unit_time_temp = 0
            self.execute_task_times_every_unit_time_temp_fail = 0

    def get_report_hearbeat_info(self) -> dict:
        return {
            'unit_time_for_count': self.unit_time_for_count,
            'last_x_s_execute_count': self.last_x_s_execute_count,
            'last_x_s_execute_count_fail': self.last_x_s_execute_count_fail,
            'last_execute_task_time': self.last_execute_task_time,
            'last_x_s_avarage_function_spend_time': self.last_x_s_avarage_function_spend_time,
            # 'last_show_remaining_execution_time':self.last_show_remaining_execution_time,
            'msg_num_in_broker': self.msg_num_in_broker,
            'current_time_for_execute_task_times_every_unit_time': self.current_time_for_execute_task_times_every_unit_time,
            'last_timestamp_when_has_task_in_queue': self.last_timestamp_when_has_task_in_queue,
            'total_consume_count_from_start': self.total_consume_count_from_start,
            'total_consume_count_from_start_fail': self.total_consume_count_from_start_fail,
            'total_cost_time_from_start': self.total_cost_time_from_start,
            'last_x_s_total_cost_time': self.last_x_s_total_cost_time,
            'avarage_function_spend_time_from_start': round(self.total_cost_time_from_start / self.total_consume_count_from_start, 3) if self.total_consume_count_from_start else None,
        }


class DistributedConsumerStatistics(RedisMixin, FunboostFileLoggerMixin):
    """
    为了兼容模拟mq的中间件（例如redis，他没有实现amqp协议，redis的list结构和真mq差远了），获取一个队列有几个连接活跃消费者数量。
    分布式环境中的消费者统计。主要目的有3点

    1、统计活跃消费者数量用于分布式控频。
        获取分布式的消费者数量后，用于分布式qps控频。如果不获取全环境中的消费者数量，则只能用于当前进程中的消费控频。
        即使只有一台机器，例如把xx.py启动3次，xx.py的consumer设置qps为10，如果不使用分布式控频，会1秒钟最终运行30次函数而不是10次。

    2、记录分布式环境中的活跃消费者的所有消费者 id，如果消费者id不在此里面说明已掉线或关闭，消息可以重新分发，用于不支持服务端天然消费确认的中间件。

    3、从redis中获取停止和暂停状态，以便支持在别的地方发送命令停止或者暂停消费。
    """
    SHOW_CONSUMER_NUM_INTERVAL = 600
    HEARBEAT_EXPIRE_SECOND = 25
    SEND_HEARTBEAT_INTERVAL = 10

    if HEARBEAT_EXPIRE_SECOND < SEND_HEARTBEAT_INTERVAL * 2:
        raise ValueError(f'HEARBEAT_EXPIRE_SECOND:{HEARBEAT_EXPIRE_SECOND} , SEND_HEARTBEAT_INTERVAL:{SEND_HEARTBEAT_INTERVAL} ')

    def __init__(self, consumer: AbstractConsumer):
        # self._consumer_identification = consumer_identification
        # self._consumer_identification_map = consumer_identification_map
        # self._queue_name = queue_name
        self._consumer_identification = consumer.consumer_identification
        self._consumer_identification_map = consumer.consumer_identification_map
        self._queue_name = consumer.queue_name
        self._consumer = consumer
        self._redis_key_name = f'funboost_hearbeat_queue__str:{self._queue_name}'
        self.active_consumer_num = 1
        self._last_show_consumer_num_timestamp = 0

        self._queue__consumer_identification_map_key_name = RedisKeys.gen_funboost_hearbeat_queue__dict_key_by_queue_name(self._queue_name)
        self._server__consumer_identification_map_key_name = RedisKeys.gen_funboost_hearbeat_server__dict_key_by_ip(nb_log_config_default.computer_ip)

    def run(self):
        self.send_heartbeat()
        self._consumer.keep_circulating(self.SEND_HEARTBEAT_INTERVAL, block=False, daemon=False)(self.send_heartbeat)()

    def _send_heartbeat_with_dict_value(self, redis_key, ):
        # 发送当前消费者进程心跳的，值是字典，按一个机器或者一个队列运行了哪些进程。

        results = self.redis_db_frame.smembers(redis_key)
        with self.redis_db_frame.pipeline() as p:
            for result in results:
                result_dict = Serialization.to_dict(result)
                if self.timestamp() - result_dict['hearbeat_timestamp'] > self.HEARBEAT_EXPIRE_SECOND \
                        or self._consumer_identification_map['consumer_uuid'] == result_dict['consumer_uuid']:
                    # 因为这个是10秒钟运行一次，15秒还没更新，那肯定是掉线了。如果消费者本身是自己也先删除。
                    p.srem(redis_key, result)
            self._consumer_identification_map['hearbeat_datetime_str'] = time_util.DatetimeConverter().datetime_str
            self._consumer_identification_map['hearbeat_timestamp'] = self.timestamp()
            self._consumer_identification_map.update(self._consumer.metric_calculation.get_report_hearbeat_info())
            value = Serialization.to_json_str(self._consumer_identification_map, )
            p.sadd(redis_key, value)
            p.execute()

    def _send_msg_num(self):
        dic = {'msg_num_in_broker': self._consumer.metric_calculation.msg_num_in_broker,
               'last_get_msg_num_ts': self._consumer.metric_calculation.last_get_msg_num_ts,
               'report_ts': time.time(),
               }
        self.redis_db_frame.hset(RedisKeys.QUEUE__MSG_COUNT_MAP, self._consumer.queue_name, json.dumps(dic))

    def send_heartbeat(self):
        # 根据队列名心跳的，值是字符串，方便值作为其他redis的键名

        results = self.redis_db_frame.smembers(self._redis_key_name)
        with self.redis_db_frame.pipeline() as p:
            for result in results:
                if self.timestamp() - float(result.split('&&')[-1]) > self.HEARBEAT_EXPIRE_SECOND or \
                        self._consumer_identification == result.split('&&')[0]:  # 因为这个是10秒钟运行一次，15秒还没更新，那肯定是掉线了。如果消费者本身是自己也先删除。
                    p.srem(self._redis_key_name, result)
            p.sadd(self._redis_key_name, f'{self._consumer_identification}&&{self.timestamp()}')
            p.execute()

        self._send_heartbeat_with_dict_value(self._queue__consumer_identification_map_key_name)
        self._send_heartbeat_with_dict_value(self._server__consumer_identification_map_key_name)
        self._show_active_consumer_num()
        self._get_stop_and_pause_flag_from_redis()
        self._send_msg_num()

    def _show_active_consumer_num(self):
        self.active_consumer_num = self.redis_db_frame.scard(self._redis_key_name) or 1
        if time.time() - self._last_show_consumer_num_timestamp > self.SHOW_CONSUMER_NUM_INTERVAL:
            self.logger.info(f'分布式所有环境中使用 {self._queue_name} 队列的，一共有 {self.active_consumer_num} 个消费者')
            self._last_show_consumer_num_timestamp = time.time()

    def get_queue_heartbeat_ids(self, without_time: bool):
        if without_time:
            return [idx.split('&&')[0] for idx in self.redis_db_frame.smembers(self._redis_key_name)]
        else:
            return [idx for idx in self.redis_db_frame.smembers(self._redis_key_name)]

    # noinspection PyProtectedMember
    def _get_stop_and_pause_flag_from_redis(self):
        stop_flag = self.redis_db_frame.hget(RedisKeys.REDIS_KEY_STOP_FLAG, self._consumer.queue_name)
        if stop_flag is not None and int(stop_flag) == 1:
            self._consumer._stop_flag = 1
        else:
            self._consumer._stop_flag = 0

        pause_flag = self.redis_db_frame.hget(RedisKeys.REDIS_KEY_PAUSE_FLAG, self._consumer.queue_name)
        if pause_flag is not None and int(pause_flag) == 1:
            self._consumer._pause_flag.set()
        else:
            self._consumer._pause_flag.clear()

`````

--- **end of file: funboost/consumers/base_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/celery_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/celery_consumer.py`

#### 📦 Imports

- `import time`
- `from funboost.assist.celery_helper import CeleryHelper`
- `from funboost.assist.celery_helper import celery_app`
- `from celery import Task as CeleryTask`
- `from funboost.consumers.base_consumer import AbstractConsumer`

#### 🏛️ Classes (1)

##### 📌 `class CeleryConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
celery作为中间件实现的。
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32

import time
from funboost.assist.celery_helper import CeleryHelper, celery_app
from celery import Task as CeleryTask
from funboost.consumers.base_consumer import AbstractConsumer


class CeleryConsumer(AbstractConsumer):
    """
    celery作为中间件实现的。
    """



    # celery的可以配置项大全  https://docs.celeryq.dev/en/stable/userguide/configuration.html#new-lowercase-settings
    # celery @app.task() 所有可以配置项可以看  D:\ProgramData\Miniconda3\Lib\site-packages\celery\app\task.py

    '''
        #: Execution strategy used, or the qualified name of one.
        Strategy = 'celery.worker.strategy:default'

        #: Request class used, or the qualified name of one.
        Request = 'celery.worker.request:Request'

        #: The application instance associated with this task class.
        _app = None

        #: Name of the task.
        name = None

        #: Enable argument checking.
        #: You can set this to false if you don't want the signature to be
        #: checked when calling the task.
        #: Defaults to :attr:`app.strict_typing <@Celery.strict_typing>`.
        typing = None

        #: Maximum number of retries before giving up.  If set to :const:`None`,
        #: it will **never** stop retrying.
        max_retries = 3

        #: Default time in seconds before a retry of the task should be
        #: executed.  3 minutes by default.
        default_retry_delay = 3 * 60

        #: Rate limit for this task type.  Examples: :const:`None` (no rate
        #: limit), `'100/s'` (hundred tasks a second), `'100/m'` (hundred tasks
        #: a minute),`'100/h'` (hundred tasks an hour)
        rate_limit = None

        #: If enabled the worker won't store task state and return values
        #: for this task.  Defaults to the :setting:`task_ignore_result`
        #: setting.
        ignore_result = None

        #: If enabled the request will keep track of subtasks started by
        #: this task, and this information will be sent with the result
        #: (``result.children``).
        trail = True

        #: If enabled the worker will send monitoring events related to
        #: this task (but only if the worker is configured to send
        #: task related events).
        #: Note that this has no effect on the task-failure event case
        #: where a task is not registered (as it will have no task class
        #: to check this flag).
        send_events = True

        #: When enabled errors will be stored even if the task is otherwise
        #: configured to ignore results.
        store_errors_even_if_ignored = None

        #: The name of a serializer that are registered with
        #: :mod:`kombu.serialization.registry`.  Default is `'json'`.
        serializer = None

        #: Hard time limit.
        #: Defaults to the :setting:`task_time_limit` setting.
        time_limit = None

        #: Soft time limit.
        #: Defaults to the :setting:`task_soft_time_limit` setting.
        soft_time_limit = None

        #: The result store backend used for this task.
        backend = None

        #: If enabled the task will report its status as 'started' when the task
        #: is executed by a worker.  Disabled by default as the normal behavior
        #: is to not report that level of granularity.  Tasks are either pending,
        #: finished, or waiting to be retried.
        #:
        #: Having a 'started' status can be useful for when there are long
        #: running tasks and there's a need to report what task is currently
        #: running.
        #:
        #: The application default can be overridden using the
        #: :setting:`task_track_started` setting.
        track_started = None

        #: When enabled messages for this task will be acknowledged **after**
        #: the task has been executed, and not *just before* (the
        #: default behavior).
        #:
        #: Please note that this means the task may be executed twice if the
        #: worker crashes mid execution.
        #:
        #: The application default can be overridden with the
        #: :setting:`task_acks_late` setting.
        acks_late = None

        #: When enabled messages for this task will be acknowledged even if it
        #: fails or times out.
        #:
        #: Configuring this setting only applies to tasks that are
        #: acknowledged **after** they have been executed and only if
        #: :setting:`task_acks_late` is enabled.
        #:
        #: The application default can be overridden with the
        #: :setting:`task_acks_on_failure_or_timeout` setting.
        acks_on_failure_or_timeout = None

        #: Even if :attr:`acks_late` is enabled, the worker will
        #: acknowledge tasks when the worker process executing them abruptly
        #: exits or is signaled (e.g., :sig:`KILL`/:sig:`INT`, etc).
        #:
        #: Setting this to true allows the message to be re-queued instead,
        #: so that the task will execute again by the same worker, or another
        #: worker.
        #:
        #: Warning: Enabling this can cause message loops; make sure you know
        #: what you're doing.
        reject_on_worker_lost = None

        #: Tuple of expected exceptions.
        #:
        #: These are errors that are expected in normal operation
        #: and that shouldn't be regarded as a real error by the worker.
        #: Currently this means that the state will be updated to an error
        #: state, but the worker won't log the event as an error.
        throws = ()

        #: Default task expiry time.
        expires = None

        #: Default task priority.
        priority = None

        #: Max length of result representation used in logs and events.
        resultrepr_maxsize = 1024

        #: Task request stack, the current request will be the topmost.
        request_stack = None
    '''

    def custom_init(self):
        # 这就是核心，@boost时候会 @ celery app.task装饰器
        celery_task_deco_options = dict(name=self. queue_name,
                                        max_retries=self.consumer_params.max_retry_times, bind=True)
        if self.consumer_params.qps:
            celery_task_deco_options['rate_limit'] = f'{self.consumer_params.qps}/s'
        if self.consumer_params.function_timeout:
            celery_task_deco_options['soft_time_limit'] = self.consumer_params.function_timeout
        celery_task_deco_options.update(self.consumer_params.broker_exclusive_config['celery_task_config'])

        @celery_app.task(**celery_task_deco_options)
        def f(this: CeleryTask, *args, **kwargs):
            self.logger.debug(f' 这条消息是 celery 从 {self.queue_name} 队列中取出 ,是由 celery 框架调度 {self.consuming_function.__name__} 函数处理: args:  {args} ,  kwargs: {kwargs}')
            # return self.consuming_function(*args, **kwargs) # 如果没有声明 autoretry_for ，那么消费函数出错了就不会自动重试了。
            try:
                return self.consuming_function(*args, **kwargs)
            except Exception as exc:  # 改成自动重试。
                # print(this.request.__dict__,dir(this))
                if this.request.retries != self.consumer_params.max_retry_times:
                    log_msg = f'fun: {self.consuming_function}  args: {args} , kwargs: {kwargs} 消息第{this.request.retries}次运行出错,  {exc} \n'
                    self.logger.error(log_msg, exc_info=self.consumer_params.is_print_detail_exception)
                else:
                    log_msg = f'fun: {self.consuming_function}  args: {args} , kwargs: {kwargs} 消息达到最大重试次数{this.request.retries}次仍然出错,  {exc} \n'
                    self.logger.critical(log_msg, exc_info=self.consumer_params.is_print_detail_exception)
                # 发生异常，尝试重试任务,countdown 是多少秒后重试
                raise this.retry(exc=exc, countdown=self.consumer_params.retry_interval)

        celery_app.conf.task_routes.update({self.queue_name: {"queue": self.queue_name}})  # 自动配置celery每个函数使用不同的队列名。
        self.celery_task = f
        CeleryHelper.concurrent_mode = self.consumer_params.concurrent_mode

    def start_consuming_message(self):
        # 不单独每个函数都启动一次celery的worker消费，是把要消费的 queue name放到列表中，CeleryHelper.realy_start_celery_worker 一次性启动多个函数消费。
        CeleryHelper.add_start_work_celery_queue_name(self.queue_name)
        super().start_consuming_message()

    def _dispatch_task(self):
        """ 完全由celery框架接管控制消费，不使用funboost的AbstractConsumer的_run"""
        while 1:
            time.sleep(100)

    def _confirm_consume(self, kw):
        """完全由celery框架接管控制消费和ack确认消费，不需要funboost自己的代码来执行"""
        pass

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/celery_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/confirm_mixin.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/confirm_mixin.py`

#### 📦 Imports

- `import json`
- `import time`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils import decorators`
- `from funboost.core.serialization import Serialization`

#### 🏛️ Classes (2)

##### 📌 `class ConsumerConfirmMixinWithTheHelpOfRedis(RedisMixin)`
*Line: 15*

**Docstring:**
`````
使用redis的zset结构，value为任务，score为时间戳，这样具有良好的按时间范围搜索特性和删除特性。
把这个抽离出来了。，是因为这个不仅可以给redis做消息确认，也可以给其他不支持消费确认的消息中间件增加消费确认。
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`

**Class Variables (1):**
- `UNCONFIRMED_TIMEOUT = 600`

##### 📌 `class ConsumerConfirmMixinWithTheHelpOfRedisByHearbeat(ConsumerConfirmMixinWithTheHelpOfRedis)`
*Line: 56*

**Docstring:**
`````
使用的是根据心跳，判断非活跃消费者，将非活跃消费者对应的unack zset的重新回到消费队列。
`````

**Public Methods (1):**
- `def custom_init(self)`

**Class Variables (1):**
- `SCAN_COUNT = 2000`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/23 0023 21:10
import json
import time
from funboost.utils.redis_manager import RedisMixin
from funboost.utils import decorators
from funboost.core.serialization import Serialization
"""
此模块是依赖redis的确认消费，所以比较复杂。
"""


# noinspection PyUnresolvedReferences
class ConsumerConfirmMixinWithTheHelpOfRedis(RedisMixin):
    """
    使用redis的zset结构，value为任务，score为时间戳，这样具有良好的按时间范围搜索特性和删除特性。
    把这个抽离出来了。，是因为这个不仅可以给redis做消息确认，也可以给其他不支持消费确认的消息中间件增加消费确认。

    """
    # 超时未确认的时间，例如取出来后600秒都没有确认消费，就重新消费。这在rabbitmq和nsq对应的相同功能参数是heartbeat_interval。
    # 这个弊端很多，例如一个函数本身就需要10分钟以上，重回队列会造成死循环消费。已近废弃了。基于消费者的心跳是确认消费好的方式。
    UNCONFIRMED_TIMEOUT = 600

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._unack_zset_name = f'{self._queue_name}__unack'

    def start_consuming_message(self):
        self.consumer_params.is_send_consumer_heartbeat_to_redis = True
        super().start_consuming_message()
        self.keep_circulating(60, block=False)(self._requeue_tasks_which_unconfirmed)()

    def _add_task_str_to_unack_zset(self, task_str, ):
        self.redis_db_frame.zadd(self._unack_zset_name, {task_str: time.time()})

    def _confirm_consume(self, kw):
        self.redis_db_frame.zrem(self._unack_zset_name, kw['task_str'])

    def _requeue_tasks_which_unconfirmed(self):
        """不使用这种方案，不适合本来来就需要长耗时的函数，很死板"""
        # 防止在多个进程或多个机器中同时做扫描和放入未确认消费的任务。使用个分布式锁。
        lock_key = f'fsdf_lock__requeue_tasks_which_unconfirmed_timeout:{self._queue_name}'
        with decorators.RedisDistributedLockContextManager(self.redis_db_frame, lock_key, ) as lock:
            if lock.has_aquire_lock:
                time_max = time.time() - self.UNCONFIRMED_TIMEOUT
                for value in self.redis_db_frame.zrangebyscore(self._unack_zset_name, 0, time_max):
                    self.logger.warning(f'向 {self._queue_name} 重新放入未消费确认的任务 {value}')
                    self._requeue({'body': Serialization.to_dict(value)})
                    self.redis_db_frame.zrem(self._unack_zset_name, value)
                self.logger.info(f'{self._unack_zset_name} 中有待确认消费任务的数量是'
                                 f' {self.redis_db_frame.zcard(self._unack_zset_name)}')


# noinspection PyUnresolvedReferences
class ConsumerConfirmMixinWithTheHelpOfRedisByHearbeat(ConsumerConfirmMixinWithTheHelpOfRedis):
    """
    使用的是根据心跳，判断非活跃消费者，将非活跃消费者对应的unack zset的重新回到消费队列。
    """
    SCAN_COUNT = 2000

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._unack_zset_name = f'{self._queue_name}__unack_id_{self.consumer_identification}'
        self.consumer_params.is_send_consumer_heartbeat_to_redis = True
        self._last_show_unacked_msg_num_log = 0

    def _requeue_tasks_which_unconfirmed(self):
        lock_key = f'fsdf_lock__requeue_tasks_which_unconfirmed:{self._queue_name}'
        with decorators.RedisDistributedLockContextManager(self.redis_db_frame, lock_key, ).set_log_level(30) as lock:
            if lock.has_aquire_lock:
                # self._distributed_consumer_statistics.send_heartbeat() # 已经周期运行了。
                current_queue_hearbeat_ids = self._distributed_consumer_statistics.get_queue_heartbeat_ids(without_time=True)
                current_queue_unacked_msg_queues = self.redis_db_frame.scan(0, f'{self._queue_name}__unack_id_*', count=self.SCAN_COUNT) # 不要在funboost的队列所在db放弃他缓存keys，要保持db的keys少于1000，否则要多次scan。
                # print(current_queue_unacked_msg_queues)
                for current_queue_unacked_msg_queue in current_queue_unacked_msg_queues[1]:
                    current_queue_unacked_msg_queue_name = current_queue_unacked_msg_queue
                    if time.time() - self._last_show_unacked_msg_num_log > 600:
                        self.logger.info(f'{current_queue_unacked_msg_queue_name} 中有待确认消费任务的数量是'
                                         f' {self.redis_db_frame.zcard(current_queue_unacked_msg_queue_name)}')
                        self._last_show_unacked_msg_num_log = time.time()
                    if current_queue_unacked_msg_queue_name.split(f'{self._queue_name}__unack_id_')[1] not in current_queue_hearbeat_ids:
                        self.logger.warning(f'{current_queue_unacked_msg_queue_name} 是掉线或关闭消费者的')
                        while 1:
                            if self.redis_db_frame.exists(current_queue_unacked_msg_queue_name):
                                for unacked_task_str in self.redis_db_frame.zrevrange(current_queue_unacked_msg_queue_name, 0, 1000):
                                    self.logger.warning(f'从 {current_queue_unacked_msg_queue_name} 向 {self._queue_name} 重新放入掉线消费者未消费确认的任务'
                                                        f' {unacked_task_str}')
                                    # self.redis_db_frame.lpush(self._queue_name, unacked_task_str)
                                    self.publisher_of_same_queue.publish(unacked_task_str) # redis优先级队列的入队不一样，不使用上面。
                                    self.redis_db_frame.zrem(current_queue_unacked_msg_queue_name, unacked_task_str)
                            else:
                                break
                    else:
                        pass
                        # print('是活跃消费者')

`````

--- **end of file: funboost/consumers/confirm_mixin.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/dramatiq_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/dramatiq_consumer.py`

#### 📦 Imports

- `import time`
- `import dramatiq`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.assist.dramatiq_helper import DramatiqHelper`

#### 🏛️ Classes (1)

##### 📌 `class DramatiqConsumer(AbstractConsumer)`
*Line: 9*

**Docstring:**
`````
dramatiq作为中间件实现的。
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
import time

import dramatiq

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.assist.dramatiq_helper import DramatiqHelper


class DramatiqConsumer(AbstractConsumer):
    """
    dramatiq作为中间件实现的。
    """


    def custom_init(self):
        # 这就是核心，
        dramatiq_actor_options = self.consumer_params.broker_exclusive_config['dramatiq_actor_options']
        if self.consumer_params.function_timeout:
            dramatiq_actor_options['time_limit'] = self.consumer_params.function_timeout * 1000  # dramatiq的超时单位是毫秒，funboost是秒。
        dramatiq_actor_options['max_retries'] = self.consumer_params.max_retry_times

        @dramatiq.actor(actor_name=self.queue_name, queue_name=self.queue_name,
                        **dramatiq_actor_options)
        def f(*args, **kwargs):
            self.logger.debug(f' 这条消息是 dramatiq 从 {self.queue_name} 队列中取出 ,是由 dramatiq 框架调度 {self.consuming_function.__name__} 函数处理: args:  {args} ,  kwargs: {kwargs}')
            return self.consuming_function(*args, **kwargs)

        DramatiqHelper.queue_name__actor_map[self.queue_name] = f

    def start_consuming_message(self):
        # 不单独每个函数都启动一次celery的worker消费，是把要消费的 queue name放到列表中，realy_start_dramatiq_worker 一次性启动多个函数消费。
        DramatiqHelper.to_be_start_work_celery_queue_name_set.add(self.queue_name)
        super().start_consuming_message()

    def _dispatch_task(self):
        """ 完全由dramatiq框架接管控制消费，不使用funboost的AbstractConsumer的_run"""
        while 1:
            time.sleep(100)

    def _confirm_consume(self, kw):
        """dramatiq框架默认自带，不需要funboost实现"""

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/dramatiq_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/empty_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/empty_consumer.py`

#### 📦 Imports

- `import abc`
- `from funboost.consumers.base_consumer import AbstractConsumer`

#### 🏛️ Classes (1)

##### 📌 `class EmptyConsumer(AbstractConsumer)`
*Line: 9*

**Docstring:**
`````
一个空的消费者基类，作为自定义 Broker 的模板。

这个类其实是多余的，因为用户完全可以继承AbstractConsumer，然后实现custom_init方法，然后实现_dispatch_task, _confirm_consume, _requeue方法来新增自定义broker。
这个类是为了清晰明确的告诉你，仅仅需要下面三个方法，就可以实现一个自定义broker，因为AbstractConsumer基类功能太丰富了，基类方法是在太多了，用户不知道需要继承重写哪方法
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
﻿# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 13:32

import abc
from funboost.consumers.base_consumer import AbstractConsumer


class EmptyConsumer(AbstractConsumer, metaclass=abc.ABCMeta):
    """
    一个空的消费者基类，作为自定义 Broker 的模板。

    这个类其实是多余的，因为用户完全可以继承AbstractConsumer，然后实现custom_init方法，然后实现_dispatch_task, _confirm_consume, _requeue方法来新增自定义broker。
    这个类是为了清晰明确的告诉你，仅仅需要下面三个方法，就可以实现一个自定义broker，因为AbstractConsumer基类功能太丰富了，基类方法是在太多了，用户不知道需要继承重写哪方法
    
    
    """
    def custom_init(self):
        pass

    @abc.abstractmethod
    def _dispatch_task(self):
        """
        核心调度任务。此方法需要实现一个循环，负责从你的中间件中获取消息，
        然后调用 `self._submit_task(msg)` 将任务提交到框架的并发池中执行。 可以参考funboos源码中的各种消费者实现。
        """
        raise NotImplemented('not realization')

    @abc.abstractmethod
    def _confirm_consume(self, kw):
        """确认消费，就是ack概念"""
        raise NotImplemented('not realization')

    @abc.abstractmethod
    def _requeue(self, kw):
        """重新入队"""
        raise NotImplemented('not realization')

`````

--- **end of file: funboost/consumers/empty_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/faststream_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/faststream_consumer.py`

#### 📦 Imports

- `import asyncio`
- `import json`
- `import threading`
- `import time`
- `from funboost import EmptyConsumer`
- `from funboost.assist.faststream_helper import broker`
- `from funboost.assist.faststream_helper import app`
- `from funboost.assist.faststream_helper import get_broker`
- `from faststream import FastStream`
- `from faststream import Context`
- `from faststream.annotations import Logger`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.helper_funs import delete_keys_and_return_new_dict`

#### 🏛️ Classes (1)

##### 📌 `class FastStreamConsumer(EmptyConsumer)`
*Line: 16*

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
import asyncio
import json
import threading
import time

from funboost import EmptyConsumer
from funboost.assist.faststream_helper import broker,app,get_broker
from faststream import FastStream,Context
from faststream.annotations import Logger

from funboost.concurrent_pool.async_helper import simple_run_in_executor
from funboost.core.serialization import Serialization
from funboost.core.helper_funs import delete_keys_and_return_new_dict


class FastStreamConsumer(EmptyConsumer):
    def custom_init(self):
        self.broker = get_broker(max_consumers=self.consumer_params.concurrent_num)
        subc = self.broker.subscriber(self.queue_name)
        # @broker.subscriber(self.queue_name)
        async def f(msg:str, logger: Logger,message=Context(),broker=Context(),context=Context(),):
            self.logger.debug(f' 这条消息是 faststream 从 {self.queue_name} 队列中取出 ,是由 faststream 框架调度 {self.consuming_function.__name__} 函数处理,msg:{message} {context}')
            # print(logger.name)
            # return self.consuming_function(*args, **kwargs) # 如果没有声明 autoretry_for ，那么消费函数出错了就不会自动重试了。
            # print(msg)
            function_only_params = delete_keys_and_return_new_dict(Serialization.to_dict(msg))
            if self._consuming_function_is_asyncio:
                result = await self.consuming_function(**function_only_params)
            else:
                result = await simple_run_in_executor(self.consuming_function,**function_only_params)
            # print(result)
            return result
        subc(f)
        self.faststream_subscriber = subc

    def _dispatch_task(self):
        """ 完全由faststream框架接管控制消费，不使用funboost的AbstractConsumer的_run"""
        while 1:
            time.sleep(100)


    def _confirm_consume(self, kw):
        pass

    def start_consuming_message(self):
        def _f():
            loop = asyncio.new_event_loop()
            loop.run_until_complete(self.broker.connect())
            loop.run_until_complete(self.faststream_subscriber.start())
            loop.run_forever()
        self.keep_circulating(10, block=False)(_f)()
        # threading.Thread(target=_f).start()

    def _requeue(self, kw):
        pass
`````

--- **end of file: funboost/consumers/faststream_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/grpc_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/grpc_consumer.py`

#### 📦 Imports

- `import abc`
- `import threading`
- `import grpc`
- `import time`
- `from funboost import FunctionResultStatus`
- `from funboost.assist.grpc_helper import funboost_grpc_pb2_grpc`
- `from funboost.assist.grpc_helper import funboost_grpc_pb2`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.msg_result_getter import FutureStatusResult`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.exceptions import FunboostWaitRpcResultTimeout`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`

#### 🏛️ Classes (1)

##### 📌 `class GrpcConsumer(AbstractConsumer)`
*Line: 22*

**Docstring:**
`````
grpc as  broker
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 13:32

import abc
import threading
import grpc
import time

from funboost import FunctionResultStatus
from funboost.assist.grpc_helper import funboost_grpc_pb2_grpc, funboost_grpc_pb2
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.msg_result_getter import FutureStatusResult
from funboost.core.serialization import Serialization
from funboost.core.exceptions import FunboostWaitRpcResultTimeout
from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool





class GrpcConsumer(AbstractConsumer, ):
    """
     grpc as  broker
    """


    def custom_init(self):
        class FunboostGrpcServicer(funboost_grpc_pb2_grpc.FunboostBrokerServiceServicer):
            """
            HelloService 的实现类
            """

            def Call(this, request, context):
                """
                实现 SayHello 方法
                """
                future_status_result = FutureStatusResult(call_type=request.call_type)
                kw = {'body': request.json_req, 'future_status_result': future_status_result,}
                self._submit_task(kw)
                if request.call_type =="sync_call":
                    if future_status_result.wait_finish(self.consumer_params.rpc_timeout):  # 等待并发出的消费结果
                        return funboost_grpc_pb2.FunboostGrpcResponse(json_resp=Serialization.to_json_str(
                            future_status_result.get_staus_result_obj().get_status_dict(without_datetime_obj=True)))
                    else:
                        self.logger.error(f'wait rpc data timeout')
                        context.set_code(grpc.StatusCode.DEADLINE_EXCEEDED)
                        context.set_details(f'wait rpc data timeout')
                        # raise FunboostWaitRpcResultTimeout(f'wait rpc data timeout')
                else:
                    return funboost_grpc_pb2.FunboostGrpcResponse(json_resp='{"publish_status":"ok"}')

        self.GRPC_SERVICER_CLS = FunboostGrpcServicer

    def _dispatch_task(self):
        server = grpc.server(self.concurrent_pool)

        # 添加服务
        funboost_grpc_pb2_grpc.add_FunboostBrokerServiceServicer_to_server(self.GRPC_SERVICER_CLS(), server)

        # 绑定端口
        port = self.consumer_params.broker_exclusive_config['port']
        if port is None:
            raise ValueError('please specify port')
        listen_addr = f'[::]:{port}'
        server.add_insecure_port(listen_addr)

        # 启动服务器
        server.start()
        print(f"GRPC Has started. listening on: {listen_addr}")

        while True:
            time.sleep(100)  # 保持服务器运行

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        pass

    def _frame_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus, kw):
        future_status_result: FutureStatusResult = kw['future_status_result']
        if future_status_result.call_type == "sync_call":
            future_status_result.set_staus_result_obj(current_function_result_status)
            future_status_result.set_finish()  # 这是最重要最核心的, 并发池里面处理函数完成,马上告诉grpc服务端，已经处理完成.

`````

--- **end of file: funboost/consumers/grpc_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/httpsqs_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/httpsqs_consumer.py`

#### 📦 Imports

- `import json`
- `import time`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.httpsqs_publisher import HttpsqsPublisher`
- `from funboost.core.func_params_model import PublisherParams`

#### 🏛️ Classes (1)

##### 📌 `class HttpsqsConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
httpsqs作为中间件
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
import time
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.publishers.httpsqs_publisher import HttpsqsPublisher
from funboost.core.func_params_model import PublisherParams

class HttpsqsConsumer(AbstractConsumer):
    """
    httpsqs作为中间件
    """


    def custom_init(self):
        # noinspection PyAttributeOutsideInit
        self.httpsqs_publisher = HttpsqsPublisher(publisher_params=PublisherParams(queue_name=self.queue_name))

    # noinspection DuplicatedCode
    def _dispatch_task(self):
        while True:
            text = self.httpsqs_publisher.opt_httpsqs('get')
            if text == 'HTTPSQS_GET_END':
                time.sleep(0.5)
            else:
                kw = {'body': text}
                self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        try:
            kw['body'].pop('extra')
        except KeyError:
            pass
        self.httpsqs_publisher.publish(kw['body'])

`````

--- **end of file: funboost/consumers/httpsqs_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/http_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/http_consumer.py`

#### 📦 Imports

- `import logging`
- `import threading`
- `from flask import Flask`
- `from flask import request`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.msg_result_getter import FutureStatusResult`
- `from funboost.core.serialization import Serialization`
- `import waitress`

#### 🏛️ Classes (1)

##### 📌 `class HTTPConsumer(AbstractConsumer)`
*Line: 18*

**Docstring:**
`````
flask 作为消息队列实现 consumer
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import logging
import threading


from flask import Flask, request

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.function_result_status_saver import FunctionResultStatus
from funboost.core.msg_result_getter import FutureStatusResult
from funboost.core.serialization import Serialization




class HTTPConsumer(AbstractConsumer, ):
    """
    flask 作为消息队列实现 consumer
    """


    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        # try:
        #     self._ip, self._port = self.queue_name.split(':')
        #     self._port = int(self._port)
        # except BaseException as e:
        #     self.logger.critical(f'http作为消息队列时候,队列名字必须设置为 例如 192.168.1.101:8200  这种,  ip:port')
        #     raise e
        self._ip = self.consumer_params.broker_exclusive_config['host']
        self._port = self.consumer_params.broker_exclusive_config['port']
        if self._port is None:
            raise ValueError('please specify port')

    def _dispatch_task(self):
        """
        使用Flask实现HTTP服务器
        相比aiohttp，Flask是同步框架，避免了异步阻塞问题
        """
     

        # 创建Flask应用
        flask_app = Flask(__name__)
        # 关闭Flask的日志，避免干扰funboost的日志
        flask_app.logger.disabled = True
        logging.getLogger('werkzeug').disabled = True
        
        @flask_app.route('/', methods=['GET'])
        def hello():
            """健康检查接口"""
            return "Hello, from funboost (Flask version)"
        
        @flask_app.route('/queue', methods=['POST'])
        def recv_msg():
            """
            接收消息的核心接口
            支持两种调用类型：
            1. publish: 异步发布，立即返回
            2. sync_call: 同步调用，等待结果返回
            """
            try:
                # 获取请求数据
                msg = request.form.get('msg')
                call_type = request.form.get('call_type', 'publish')
                
                if not msg:
                    return {"error": "msg parameter is required"}, 400
                
                # 构造消息数据
                kw = {
                    'body': msg,
                    'call_type': call_type,
                }
                
                if call_type == 'sync_call':
                    # 同步调用：需要等待执行结果
                    future_status_result = FutureStatusResult(call_type=call_type)
                    kw['future_status_result'] = future_status_result
                    
                    # 提交任务到线程池执行
                    self._submit_task(kw)
                    
                    # 等待任务完成（带超时）
                    if future_status_result.wait_finish(self.consumer_params.rpc_timeout):
                        # 返回执行结果
                        result = future_status_result.get_staus_result_obj()
                        return Serialization.to_json_str(
                            result.get_status_dict(without_datetime_obj=True)
                        )
                    else:
                        # 超时处理
                        self.logger.error(f'sync_call wait timeout after {self.consumer_params.rpc_timeout}s')
                        return {"error": "execution timeout"}, 408
                        
                else:
                    # 异步发布：直接提交任务，立即返回
                    self._submit_task(kw)
                    return "finish"
                    
            except Exception as e:
                self.logger.error(f'处理HTTP请求时出错: {e}', exc_info=True)
                return {"error": str(e)}, 500
        
        # 启动Flask服务器
        # 注意：Flask默认是单线程的，但funboost使用线程池处理任务，所以这里threaded=True
        self.logger.info(f'启动Flask HTTP服务器，监听 {self._ip}:{self._port}')

        # flask_app.run(
        #     host='0.0.0.0',  # 监听所有接口
        #     port=self._port,
        #     debug=False,     # 生产环境关闭debug
        #     threaded=True,   # 开启多线程支持
        #     use_reloader=False,  # 关闭自动重载
        # )

        import waitress
        waitress.serve(flask_app, host='0.0.0.0', port=self._port,threads=self.consumer_params.concurrent_num)

    def _frame_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus, kw: dict):
        """
        任务执行完成后的回调函数
        对于sync_call模式，需要通知等待的HTTP请求
        """
        if kw['call_type'] == "sync_call":
            future_status_result: FutureStatusResult = kw['future_status_result']
            future_status_result.set_staus_result_obj(current_function_result_status)
            future_status_result.set_finish()
            # self.logger.info('sync_call任务执行完成，通知HTTP请求返回结果')

    def _confirm_consume(self, kw):
        """HTTP模式没有确认消费的功能"""
        pass

    def _requeue(self, kw):
        """HTTP模式没有重新入队的功能"""
        pass

`````

--- **end of file: funboost/consumers/http_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/http_consumer_aiohttp_old.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/http_consumer_aiohttp_old.py`

#### 📦 Imports

- `import asyncio`
- `import json`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.lazy_impoter import AioHttpImporter`
- `from funboost.core.serialization import Serialization`

#### 🏛️ Classes (2)

##### 📌 `class AioFutureStatusResult`
*Line: 16*

**🔧 Constructor (`__init__`):**
- `def __init__(self, call_type: str)`
  - **Parameters:**
    - `self`
    - `call_type: str`

**Public Methods (4):**
- `def set_finish(self)`
- `async def wait_finish(self, rpc_timeout)`
- `def set_staus_result_obj(self, staus_result_obj: FunctionResultStatus)`
- `def get_staus_result_obj(self)`

##### 📌 `class HTTPConsumer(AbstractConsumer)`
*Line: 34*

**Docstring:**
`````
aiohttp 实现消息队列，不支持持久化，但不需要安装软件。
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import asyncio
import json

# from aiohttp import web
# from aiohttp.web_request import Request

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.function_result_status_saver import FunctionResultStatus
from funboost.core.lazy_impoter import AioHttpImporter
from funboost.core.serialization import Serialization


class AioFutureStatusResult:
    def __init__(self,call_type:str):
        self.execute_finish_event = asyncio.Event()
        self.staus_result_obj: FunctionResultStatus = None
        self.call_type  = call_type  # sync_call   or  publish

    def set_finish(self):
        self.execute_finish_event.set()

    async def wait_finish(self,rpc_timeout):
        return await self.execute_finish_event.wait()

    def set_staus_result_obj(self, staus_result_obj:FunctionResultStatus):
        self.staus_result_obj = staus_result_obj

    def get_staus_result_obj(self):
        return self.staus_result_obj

class HTTPConsumer(AbstractConsumer, ):
    """
    aiohttp 实现消息队列，不支持持久化，但不需要安装软件。
    """


    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        # try:
        #     self._ip, self._port = self.queue_name.split(':')
        #     self._port = int(self._port)
        # except BaseException as e:
        #     self.logger.critical(f'http作为消息队列时候,队列名字必须设置为 例如 192.168.1.101:8200  这种,  ip:port')
        #     raise e
        self._ip = self.consumer_params.broker_exclusive_config['host']
        self._port = self.consumer_params.broker_exclusive_config['port']
        if self._port is None:
            raise ValueError('please specify port')

    # noinspection DuplicatedCode
    def _dispatch_task(self):
        # flask_app = Flask(__name__)
        #
        # @flask_app.route('/queue', methods=['post'])
        # def recv_msg():
        #     msg = request.form['msg']
        #     kw = {'body': json.loads(msg)}
        #     self._submit_task(kw)
        #     return 'finish'
        #
        # flask_app.run('0.0.0.0', port=self._port,debug=False)

        routes = AioHttpImporter().web.RouteTableDef()

        # noinspection PyUnusedLocal
        @routes.get('/')
        async def hello(request):
            return AioHttpImporter().web.Response(text="Hello, from funboost")

        @routes.post('/queue')
        async def recv_msg(request: AioHttpImporter().Request):
            data = await request.post()
            msg = data['msg']
            call_type = data['call_type']
            kw = {'body': msg,'call_type': call_type,}
            if call_type == 'sync_call':
                aio_future_status_result = AioFutureStatusResult(call_type=call_type)
                kw['aio_future_status_result'] = aio_future_status_result
            self._submit_task(kw)
            if data['call_type'] == 'sync_call':
                await aio_future_status_result.wait_finish(self.consumer_params.rpc_timeout)
                return AioHttpImporter().web.Response(text=Serialization.to_json_str(
                    aio_future_status_result.get_staus_result_obj().get_status_dict(without_datetime_obj=True)))
            return AioHttpImporter().web.Response(text="finish")

        app = AioHttpImporter().web.Application()
        app.add_routes(routes)
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        AioHttpImporter().web.run_app(app, host='0.0.0.0', port=self._port, )

    def _frame_custom_record_process_info_func(self,current_function_result_status: FunctionResultStatus,kw:dict):
        if  kw['call_type'] == "sync_call":
            aio_future_status_result: AioFutureStatusResult = kw['aio_future_status_result']
            aio_future_status_result.set_staus_result_obj(current_function_result_status)
            aio_future_status_result.set_finish()
            self.logger.info(f'aio_future_status_result.set_finish()')

    # async def _aio_frame_custom_record_process_info_func(self,current_function_result_status: FunctionResultStatus,kw:dict):
    #     self.logger.info(666666)
    #     if kw['call_type'] == "sync_call":
    #         aio_future_status_result: AioFutureStatusResult = kw['aio_future_status_result']
    #         aio_future_status_result.set_staus_result_obj(current_function_result_status)
    #         aio_future_status_result.set_finish()
    #         self.logger.info(f'aio_future_status_result.set_finish()')
    def _confirm_consume(self, kw):
        pass  # 没有确认消费的功能。

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/http_consumer_aiohttp_old.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/huey_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/huey_consumer.py`

#### 📦 Imports

- `import time`
- `from huey import RedisHuey`
- `from huey.consumer import Consumer`
- `from funboost import AbstractConsumer`
- `from funboost.assist.huey_helper import HueyHelper`

#### 🏛️ Classes (1)

##### 📌 `class HueyConsumer(AbstractConsumer)`
*Line: 10*

**Docstring:**
`````
huey作为中间件实现的。
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
import time

from huey import RedisHuey
from huey.consumer import Consumer

from funboost import AbstractConsumer
from funboost.assist.huey_helper import HueyHelper


class HueyConsumer(AbstractConsumer):
    """
    huey作为中间件实现的。
    """




    def custom_init(self):
        # 这就是核心，
        huey_task_kwargs = self.consumer_params.broker_exclusive_config['huey_task_kwargs']
        huey_task_kwargs['retries'] = self.consumer_params.max_retry_times

        @HueyHelper.huey_obj.task(name=self.queue_name,
                        **huey_task_kwargs)
        def f(*args, **kwargs):
            self.logger.debug(f' 这条消息是 huey 从 {self.queue_name} 队列中取出 ,是由 huey 框架调度 {self.consuming_function.__name__} 函数处理: args:  {args} ,  kwargs: {kwargs}')
            return self.consuming_function(*args, **kwargs)

        HueyHelper.queue_name__huey_task_fun_map[self.queue_name] = f

    def start_consuming_message(self):
        # 不单独每个函数都启动一次celery的worker消费，是把要消费的 queue name放到列表中，realy_start_dramatiq_worker 一次性启动多个函数消费。
        HueyHelper.to_be_start_huey_queue_name_set.add(self.queue_name)
        super().start_consuming_message()

    def _dispatch_task(self):
        """ 完全由dramatiq框架接管控制消费，不使用funboost的AbstractConsumer的_run"""
        while 1:
            time.sleep(100)

    def _confirm_consume(self, kw):
        """dramatiq框架默认自带，不需要funboost实现"""

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/huey_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/kafka_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/kafka_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.lazy_impoter import KafkaPythonImporter`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🏛️ Classes (1)

##### 📌 `class KafkaConsumer(AbstractConsumer)`
*Line: 18*

**Docstring:**
`````
kafka作为中间件实现的。自动确认消费，最多消费一次，随意重启会丢失正在大批正在运行的任务。推荐使用 confluent_kafka 中间件，kafka_consumer_manually_commit.py。

可以让消费函数内部 sleep60秒，突然停止消费代码，使用 kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group funboost 来证实自动确认消费和手动确认消费的区别。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
# noinspection PyPackageRequirements

from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.lazy_impoter import KafkaPythonImporter
from funboost.funboost_config_deafult import BrokerConnConfig
# from nb_log import get_logger
from funboost.core.loggers import get_funboost_file_logger

# LogManager('kafka').get_logger_and_add_handlers(30)
get_funboost_file_logger('kafka', log_level_int=30)


class KafkaConsumer(AbstractConsumer):
    """
    kafka作为中间件实现的。自动确认消费，最多消费一次，随意重启会丢失正在大批正在运行的任务。推荐使用 confluent_kafka 中间件，kafka_consumer_manually_commit.py。

    可以让消费函数内部 sleep60秒，突然停止消费代码，使用 kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group funboost 来证实自动确认消费和手动确认消费的区别。
    """

    """
    auto_offset_reset 介绍
      auto_offset_reset (str): A policy for resetting offsets on
            OffsetOutOfRange errors: 'earliest' will move to the oldest
            available message, 'latest' will move to the most recent. Any
            other value will raise the exception. Default: 'latest'.
    """

    def _dispatch_task(self):
        try:
            admin_client = KafkaPythonImporter().KafkaAdminClient(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
            admin_client.create_topics([KafkaPythonImporter().NewTopic(self._queue_name,
                                                                       self.consumer_params.broker_exclusive_config['num_partitions'],
                                                                       self.consumer_params.broker_exclusive_config['replication_factor'])])
            # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
        except KafkaPythonImporter().TopicAlreadyExistsError:
            pass

        self._producer = KafkaPythonImporter().KafkaProducer(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
        consumer = KafkaPythonImporter().OfficialKafkaConsumer(self._queue_name, bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS,
                                                               group_id=self.consumer_params.broker_exclusive_config["group_id"],
                                                               enable_auto_commit=True,
                                                               auto_offset_reset=self.consumer_params.broker_exclusive_config["auto_offset_reset"],
                                                               )
        #  auto_offset_reset (str): A policy for resetting offsets on
        #             OffsetOutOfRange errors: 'earliest' will move to the oldest
        #             available message, 'latest' will move to the most recent. Any
        #             other value will raise the exception. Default: 'latest'.       默认是latest

        # kafka 的 group_id

        # REMIND 由于是很高数量的并发消费，线程很多，分区很少，这里设置成自动确认消费了，否则多线程提交同一个分区的偏移量导致超前错乱，就没有意义了。
        # REMIND 要保证很高的可靠性和一致性，请用rabbitmq。
        # REMIND 好处是并发高。topic像翻书一样，随时可以设置偏移量重新消费。多个分组消费同一个主题，每个分组对相同主题的偏移量互不干扰 。
        for message in consumer:
            # 注意: message ,value都是原始的字节数据，需要decode
            kw = {'consumer': consumer, 'message': message, 'body': message.value.decode('utf-8')}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass  # 使用kafka的自动commit模式。

    def _requeue(self, kw):
        self._producer.send(self._queue_name, json.dumps(kw['body']).encode())

`````

--- **end of file: funboost/consumers/kafka_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/kafka_consumer_manually_commit.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/kafka_consumer_manually_commit.py`

#### 📝 Module Docstring

`````
这个可以实现kafka topic单分区,但funboost 200线程消费消息,并且随意强制重启消费进程,不丢失消息
`````

#### 📦 Imports

- `import json`
- `import threading`
- `from collections import defaultdict`
- `from collections import OrderedDict`
- `import time`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.lazy_impoter import KafkaPythonImporter`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from confluent_kafka.cimpl import TopicPartition`
- `from confluent_kafka import Consumer as ConfluentConsumer`

#### 🏛️ Classes (2)

##### 📌 `class KafkaConsumerManuallyCommit(AbstractConsumer)`
*Line: 25*

**Docstring:**
`````
confluent_kafla作为中间件实现的。操作kafka中间件的速度比kafka-python快10倍。
这个是自动间隔2秒的手动确认，由于是异步在并发池中并发消费，可以防止强制关闭程序造成正在运行的任务丢失，比自动commit好。
如果使用kafka，推荐这个。

可以让消费函数内部 sleep 60秒，突然停止消费代码，使用 kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group frame_group 来证实自动确认消费和手动确认消费的区别。
`````

**Public Methods (1):**
- `def custom_init(self)`

##### 📌 `class SaslPlainKafkaConsumer(KafkaConsumerManuallyCommit)`
*Line: 127*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2021/4/18 0008 13:32

"""
    这个可以实现kafka topic单分区,但funboost 200线程消费消息,并且随意强制重启消费进程,不丢失消息
"""

import json
import threading
from collections import defaultdict, OrderedDict
# noinspection PyPackageRequirements
import time

# noinspection PyPackageRequirements
# pip install kafka-python==2.0.2

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.lazy_impoter import KafkaPythonImporter
from funboost.funboost_config_deafult import BrokerConnConfig
from confluent_kafka.cimpl import TopicPartition
from confluent_kafka import Consumer as ConfluentConsumer  # 这个包在win下不好安装，用户用这个中间件的时候自己再想办法安装。win用户需要安装c++ 14.0以上环境。


class KafkaConsumerManuallyCommit(AbstractConsumer):
    """
    confluent_kafla作为中间件实现的。操作kafka中间件的速度比kafka-python快10倍。
    这个是自动间隔2秒的手动确认，由于是异步在并发池中并发消费，可以防止强制关闭程序造成正在运行的任务丢失，比自动commit好。
    如果使用kafka，推荐这个。

    可以让消费函数内部 sleep 60秒，突然停止消费代码，使用 kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group frame_group 来证实自动确认消费和手动确认消费的区别。
    """


    def custom_init(self):
        self._lock_for_operate_offset_dict = threading.Lock()

    def _dispatch_task(self):

        try:
            admin_client = KafkaPythonImporter().KafkaAdminClient(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
            admin_client.create_topics([KafkaPythonImporter().NewTopic(self._queue_name,
                                                                       self.consumer_params.broker_exclusive_config['num_partitions'],
                                                                       self.consumer_params.broker_exclusive_config['replication_factor'])])
            # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
        except KafkaPythonImporter().TopicAlreadyExistsError:
            pass

        self._producer = KafkaPythonImporter().KafkaProducer(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
        # consumer 配置 https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md
        self._confluent_consumer = ConfluentConsumer({
            'bootstrap.servers': ','.join(BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS),
            'group.id': self.consumer_params.broker_exclusive_config["group_id"],
            'auto.offset.reset': self.consumer_params.broker_exclusive_config["auto_offset_reset"],
            'enable.auto.commit': False
        })
        self._confluent_consumer.subscribe([self._queue_name])

        self._recent_commit_time = time.time()
        self._partion__offset_consume_status_map = defaultdict(OrderedDict)
        while 1:
            msg = self._confluent_consumer.poll(timeout=10)
            self._manually_commit()
            if msg is None:
                continue
            if msg.error():
                print("Consumer error: {}".format(msg.error()))
                continue
            # msg的类型  https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#message
            # value()  offset() partition()
            # print('Received message: {}'.format(msg.value().decode('utf-8'))) # noqa
            self._partion__offset_consume_status_map[msg.partition()][msg.offset()] = 0
            kw = {'partition': msg.partition(), 'offset': msg.offset(), 'body': msg.value()}  # noqa
            if self.consumer_params.is_show_message_get_from_broker:
                self.logger.debug(
                    f'从kafka的 [{self._queue_name}] 主题,分区 {msg.partition()} 中 的 offset {msg.offset()} 取出的消息是：  {msg.value()}')  # noqa
            self._submit_task(kw)


    def _manually_commit(self):
        """
        kafka要求消费线程数量和分区数量是一对一或一对多，不能多对一，消息并发处理收到分区数量的限制，这种是支持超高线程数量消费，所以commit非常复杂。
        因为这种是可以支持单分区200线程消费，消费本身和拉取kafka任务不在同一个线程，而且可能offset较大的比offset较小的任务先完成，
        每隔2秒对1组offset，对连续消费状态是1的最大offset进行commit
        :return:
        """
        with self._lock_for_operate_offset_dict:
            if time.time() - self._recent_commit_time > 2:
                partion_max_consumed_offset_map = dict()
                to_be_remove_from_partion_max_consumed_offset_map = defaultdict(list)
                for partion, offset_consume_status in self._partion__offset_consume_status_map.items():
                    sorted_keys = sorted(offset_consume_status.keys())
                    offset_consume_status_ordered = {key: offset_consume_status[key] for key in sorted_keys}
                    max_consumed_offset = None

                    for offset, consume_status in offset_consume_status_ordered.items():
                        # print(offset,consume_status)
                        if consume_status == 1:
                            max_consumed_offset = offset
                            to_be_remove_from_partion_max_consumed_offset_map[partion].append(offset)
                        else:
                            break
                    if max_consumed_offset is not None:
                        partion_max_consumed_offset_map[partion] = max_consumed_offset
                # self.logger.info(partion_max_consumed_offset_map)
                # TopicPartition
                offsets = list()
                for partion, max_consumed_offset in partion_max_consumed_offset_map.items():
                    # print(partion,max_consumed_offset)
                    offsets.append(TopicPartition(topic=self._queue_name, partition=partion, offset=max_consumed_offset + 1))
                if len(offsets):
                    self._confluent_consumer.commit(offsets=offsets, asynchronous=False)
                self._recent_commit_time = time.time()
                for partion, offset_list in to_be_remove_from_partion_max_consumed_offset_map.items():
                    for offset in offset_list:
                        del self._partion__offset_consume_status_map[partion][offset]

    def _confirm_consume(self, kw):
        with self._lock_for_operate_offset_dict:
            self._partion__offset_consume_status_map[kw['partition']][kw['offset']] = 1
            # print(self._partion__offset_consume_status_map)

    def _requeue(self, kw):
        self._producer.send(self._queue_name, json.dumps(kw['body']).encode())


class SaslPlainKafkaConsumer(KafkaConsumerManuallyCommit):

    def _dispatch_task(self):

        try:
            admin_client = KafkaPythonImporter().KafkaAdminClient(
                **BrokerConnConfig.KFFKA_SASL_CONFIG)
            admin_client.create_topics([KafkaPythonImporter().NewTopic(self._queue_name, 10, 1)])
            # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
        except KafkaPythonImporter().TopicAlreadyExistsError:
            pass

        self._producer = KafkaPythonImporter().KafkaProducer(
            **BrokerConnConfig.KFFKA_SASL_CONFIG)
        # consumer 配置 https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md
        self._confluent_consumer = ConfluentConsumer({
            'bootstrap.servers': ','.join(BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS),
            'security.protocol': BrokerConnConfig.KFFKA_SASL_CONFIG['security_protocol'],
            'sasl.mechanisms': BrokerConnConfig.KFFKA_SASL_CONFIG['sasl_mechanism'],
            'sasl.username': BrokerConnConfig.KFFKA_SASL_CONFIG['sasl_plain_username'],
            'sasl.password': BrokerConnConfig.KFFKA_SASL_CONFIG['sasl_plain_password'],
            'group.id': self.consumer_params.broker_exclusive_config["group_id"],
            'auto.offset.reset': self.consumer_params.broker_exclusive_config["auto_offset_reset"],
            'enable.auto.commit': False
        })
        self._confluent_consumer.subscribe([self._queue_name])

        self._recent_commit_time = time.time()
        self._partion__offset_consume_status_map = defaultdict(OrderedDict)

        while 1:
            msg = self._confluent_consumer.poll(timeout=10)
            self._manually_commit()
            if msg is None:
                continue
            if msg.error():
                print("Consumer error: {}".format(msg.error()))
                continue
            # msg的类型  https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html#message
            # value()  offset() partition()
            # print('Received message: {}'.format(msg.value().decode('utf-8'))) # noqa
            self._partion__offset_consume_status_map[msg.partition(
            )][msg.offset()] = 0
            kw = {'partition': msg.partition(), 'offset': msg.offset(), 'body': msg.value()}  # noqa
            if self.consumer_params.is_show_message_get_from_broker:
                self.logger.debug(
                    f'从kafka的 [{self._queue_name}] 主题,分区 {msg.partition()} 中 的 offset {msg.offset()} 取出的消息是：  {msg.value()}')  # noqa
            self._submit_task(kw)

`````

--- **end of file: funboost/consumers/kafka_consumer_manually_commit.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/kombu_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/kombu_consumer.py`

#### 📦 Imports

- `import os`
- `import traceback`
- `from pathlib import Path`
- `from kombu.entity import Exchange`
- `from kombu.entity import Queue`
- `from kombu.connection import Connection`
- `from kombu.transport.virtual.base import Channel`
- `from kombu.transport.virtual.base import Message`
- `from kombu.transport import redis`
- `from kombu.transport.redis import Empty`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class KombuConsumer(AbstractConsumer)`
*Line: 79*

**Docstring:**
`````
使用kombu作为中间件,这个能直接一次性支持很多种小众中间件，但性能很差，除非是分布式函数调度框架没实现的中间件种类用户才可以用这种，用户也可以自己对比性能。
`````

**Public Methods (1):**
- `def custom_init(self)`

#### 🔧 Public Functions (2)

- `def patch_kombu_redis()`
  - *Line: 25*
  - **Docstring:**
  `````
  给kombu的redis 模式打猴子补丁
  kombu有bug，redis中间件 unnacked 中的任务即使客户端掉线了或者突然关闭脚本中正在运行的任务，也永远不会被重新消费。
  这个很容易验证那个测试，把消费函数写成sleep 100秒，启动20秒后把脚本关掉，取出来的任务在 unacked 队列中那个永远不会被确认消费，也不会被重新消费。
  `````

- `def monkey_get(self, callback, timeout = None)`
  - *Line: 36*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2021/04/18 0008 13:32
# import time
import os

import traceback
from pathlib import Path
from kombu.entity import Exchange, Queue
from kombu.connection import Connection
from kombu.transport.virtual.base import Channel
from kombu.transport.virtual.base import Message
from kombu.transport import redis
from kombu.transport.redis import Empty


from funboost.consumers.base_consumer import AbstractConsumer
from funboost.funboost_config_deafult import BrokerConnConfig



has_patch_kombu_redis = False


def patch_kombu_redis():
    """
    给kombu的redis 模式打猴子补丁
    kombu有bug，redis中间件 unnacked 中的任务即使客户端掉线了或者突然关闭脚本中正在运行的任务，也永远不会被重新消费。
    这个很容易验证那个测试，把消费函数写成sleep 100秒，启动20秒后把脚本关掉，取出来的任务在 unacked 队列中那个永远不会被确认消费，也不会被重新消费。
    """
    global has_patch_kombu_redis
    if not has_patch_kombu_redis:
        redis_multichannelpoller_get_raw = redis.MultiChannelPoller.get

        # noinspection PyUnusedLocal
        def monkey_get(self, callback, timeout=None):
            try:
                redis_multichannelpoller_get_raw(self, callback, timeout)
            except Empty:
                self.maybe_restore_messages()
                raise Empty()

        redis.MultiChannelPoller.get = monkey_get
        has_patch_kombu_redis = True


''' kombu 能支持的消息队列中间件有如下，可以查看 D:\ProgramData\Miniconda3\Lib\site-packages\kombu\transport\__init__.py 文件。

TRANSPORT_ALIASES = {
    'amqp': 'kombu.transport.pyamqp:Transport',
    'amqps': 'kombu.transport.pyamqp:SSLTransport',
    'pyamqp': 'kombu.transport.pyamqp:Transport',
    'librabbitmq': 'kombu.transport.librabbitmq:Transport',
    'memory': 'kombu.transport.memory:Transport',
    'redis': 'kombu.transport.redis:Transport',
    'rediss': 'kombu.transport.redis:Transport',
    'SQS': 'kombu.transport.SQS:Transport',
    'sqs': 'kombu.transport.SQS:Transport',
    'mongodb': 'kombu.transport.mongodb:Transport',
    'zookeeper': 'kombu.transport.zookeeper:Transport',
    'sqlalchemy': 'kombu.transport.sqlalchemy:Transport',
    'sqla': 'kombu.transport.sqlalchemy:Transport',
    'SLMQ': 'kombu.transport.SLMQ.Transport',
    'slmq': 'kombu.transport.SLMQ.Transport',
    'filesystem': 'kombu.transport.filesystem:Transport',
    'qpid': 'kombu.transport.qpid:Transport',
    'sentinel': 'kombu.transport.redis:SentinelTransport',
    'consul': 'kombu.transport.consul:Transport',
    'etcd': 'kombu.transport.etcd:Transport',
    'azurestoragequeues': 'kombu.transport.azurestoragequeues:Transport',
    'azureservicebus': 'kombu.transport.azureservicebus:Transport',
    'pyro': 'kombu.transport.pyro:Transport'
}

'''


# noinspection PyAttributeOutsideInit
class KombuConsumer(AbstractConsumer, ):
    """
    使用kombu作为中间件,这个能直接一次性支持很多种小众中间件，但性能很差，除非是分布式函数调度框架没实现的中间件种类用户才可以用这种，用户也可以自己对比性能。
    """


    def custom_init(self):
        self.kombu_url = self.consumer_params.broker_exclusive_config['kombu_url'] or BrokerConnConfig.KOMBU_URL
        self._middware_name = self.kombu_url.split(":")[0]
        # logger_name = f'{self.consumer_params.logger_prefix}{self.__class__.__name__}--{self._middware_name}--{self._queue_name}'
        # self.logger = get_logger(logger_name, log_level_int=self.consumer_params.log_level,
        #                          _log_filename=f'{logger_name}.log' if self.consumer_params.create_logger_file else None,
        #                          formatter_template=FunboostCommonConfig.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
        #                          )  #
        if self.kombu_url.startswith('filesystem://'):
            self._create_msg_file_dir()

    def _create_msg_file_dir(self):
        os.makedirs(self.consumer_params.broker_exclusive_config['transport_options']['data_folder_in'], exist_ok=True)
        os.makedirs(self.consumer_params.broker_exclusive_config['transport_options']['data_folder_out'], exist_ok=True)
        processed_folder = self.consumer_params.broker_exclusive_config['transport_options'].get('processed_folder', None)
        if processed_folder:
            os.makedirs(processed_folder, exist_ok=True)

    # noinspection DuplicatedCode
    def _dispatch_task(self):  # 这个倍while 1 启动的，会自动重连。
        # patch_kombu_redis() # 不调用

        def callback(body: dict, message: Message):
            # print(type(body),body,type(message),message)
            # self.logger.debug(f""" 从 kombu {self._middware_name} 中取出的消息是 {body}""")
            kw = {'body': body, 'message': message, }
            self._submit_task(kw)

        self.exchange = Exchange('funboost_exchange', 'direct', durable=True)
        self.queue = Queue(self._queue_name, exchange=self.exchange, routing_key=self._queue_name, auto_delete=False, no_ack=False)
        # https://docs.celeryq.dev/projects/kombu/en/stable/reference/kombu.html?highlight=visibility_timeout#kombu.Connection 每种中间件的transport_options不一样。
        self.conn = Connection(self.kombu_url, transport_options=self.consumer_params.broker_exclusive_config['transport_options'])
        self.queue(self.conn).declare()
        with self.conn.Consumer(self.queue, callbacks=[callback], no_ack=False, prefetch_count=self.consumer_params.broker_exclusive_config['prefetch_count']) as consumer:
            # Process messages and handle events on all channels
            channel = consumer.channel  # type:Channel
            channel.body_encoding = 'no_encode'  # 这里改了编码，存到中间件的参数默认把消息base64了，我觉得没必要不方便查看消息明文。
            while True:
                self.conn.drain_events()

    def _confirm_consume(self, kw):
        kw['message'].ack()

    def _requeue(self, kw):
        kw['message'].requeue()

`````

--- **end of file: funboost/consumers/kombu_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/local_python_queue_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/local_python_queue_consumer.py`

#### 📦 Imports

- `import json`
- `from queue import Queue`
- `from queue import SimpleQueue`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.queues.memory_queues_map import PythonQueues`

#### 🏛️ Classes (1)

##### 📌 `class LocalPythonQueueConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
python 内置queue对象作为消息队列，这个要求发布和消费必须在同一python解释器内部运行，不支持分布式。
`````

**Properties (1):**
- `@property local_python_queue -> Queue`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:36
import json
from queue import Queue,SimpleQueue
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.queues.memory_queues_map import PythonQueues


class LocalPythonQueueConsumer(AbstractConsumer):
    """
    python 内置queue对象作为消息队列，这个要求发布和消费必须在同一python解释器内部运行，不支持分布式。
    """

    @property
    def local_python_queue(self) -> Queue:
        return PythonQueues.get_queue(self._queue_name)

    def _dispatch_task(self):
        while True:
            task = self.local_python_queue.get()
            if isinstance(task, dict):
                task = json.dumps(task)
            # self.logger.debug(f'从当前python解释器内部的 [{self._queue_name}] 队列中 取出的消息是：  {json.dumps(task)}  ')
            kw = {'body': task}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        self.local_python_queue.put(kw['body'])


`````

--- **end of file: funboost/consumers/local_python_queue_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/memory_deque_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/memory_deque_consumer.py`

#### 📦 Imports

- `import json`
- `from collections import deque`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers import meomory_deque_publisher`

#### 🏛️ Classes (1)

##### 📌 `class LocalPythonQueueConsumer(AbstractConsumer)`
*Line: 12*

**Docstring:**
`````
python 内置queue对象作为消息队列，这个要求发布和消费必须在同一python解释器内部运行，不支持分布式。
`````

**Properties (1):**
- `@property local_python_queue -> deque`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:36
import json
from collections import deque

from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.publishers import meomory_deque_publisher


class LocalPythonQueueConsumer(AbstractConsumer):
    """
    python 内置queue对象作为消息队列，这个要求发布和消费必须在同一python解释器内部运行，不支持分布式。
    """

    @property
    def local_python_queue(self) -> deque:
        return meomory_deque_publisher.deque_queue_name__deque_obj_map[self._queue_name]

    def _dispatch_task(self):
        while True:
            task = self.local_python_queue.popleft()
            # self.logger.debug(f'从当前python解释器内部的 [{self._queue_name}] 队列中 取出的消息是：  {json.dumps(task)}  ')
            kw = {'body': task}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        self.local_python_queue.append(kw['body'])

`````

--- **end of file: funboost/consumers/memory_deque_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/mongomq_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/mongomq_consumer.py`

#### 📦 Imports

- `import time`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.mongomq_publisher import MongoMixin`
- `from funboost.publishers.mongomq_publisher import MongoMqPublisher`
- `from funboost.core.func_params_model import PublisherParams`

#### 🏛️ Classes (1)

##### 📌 `class MongoMqConsumer(AbstractConsumer, MongoMixin)`
*Line: 10*

**Docstring:**
`````
Mongo queue包实现的基于mongo的消息队列，支持消费确认。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:33
import time
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.publishers.mongomq_publisher import MongoMixin, MongoMqPublisher
from funboost.core.func_params_model import PublisherParams

class MongoMqConsumer(AbstractConsumer, MongoMixin):
    """
    Mongo queue包实现的基于mongo的消息队列，支持消费确认。
    """


    def _dispatch_task(self):
        mp = MongoMqPublisher(publisher_params=PublisherParams(queue_name=self.queue_name))
        while True:
            job = mp.queue.next()
            if job is not None:
                # self.logger.debug(f'从mongo的 [{self._queue_name}] 队列中 取出的消息是：   消息是：  {job.payload}  ')
                kw = {'body': job.payload, 'job': job}
                self._submit_task(kw)
            else:
                time.sleep(0.1)

    def _confirm_consume(self, kw):
        kw['job'].complete()

    def _requeue(self, kw):
        kw['job'].release()

`````

--- **end of file: funboost/consumers/mongomq_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/mqtt_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/mqtt_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.lazy_impoter import PahoMqttImporter`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class MqttConsumer(AbstractConsumer)`
*Line: 13*

**Docstring:**
`````
emq 作为中间件 实现的消费者 ，使用共享订阅。
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
# import time
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.lazy_impoter import PahoMqttImporter
from funboost.funboost_config_deafult import BrokerConnConfig
# import paho.mqtt.client as mqtt


class MqttConsumer(AbstractConsumer):
    """
    emq 作为中间件 实现的消费者 ，使用共享订阅。
    """


    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        # fsdf 表示 funboost.相当于kafka的消费者组作用。
        # 这个是共享订阅，见  https://blog.csdn.net/emqx_broker/article/details/103027813
        self._topic_shared = f'$share/fsdf/{self._queue_name}'

    # noinspection DuplicatedCode
    def _dispatch_task(self):
        client = PahoMqttImporter().mqtt.Client()
        # client.username_pw_set('admin', password='public')
        client.on_connect = self._on_connect
        client.on_message = self._on_message
        client.on_disconnect = self._on_socket_close
        client.on_socket_close = self._on_socket_close
        client.connect(BrokerConnConfig.MQTT_HOST, BrokerConnConfig.MQTT_TCP_PORT, 600)  # 600为keepalive的时间间隔
        client.subscribe(self._topic_shared, qos=0)  # on message 是异把消息丢到线程池，本身不可能失败。
        client.loop_forever(retry_first_connection=True)  # 保持连接

    def _on_socket_close(self, client, userdata, socket):
        self.logger.critical(f'{client, userdata, socket}')
        self._dispatch_task()

    # noinspection PyPep8Naming
    def _on_disconnect(self, client, userdata, reasonCode, properties):
        self.logger.critical(f'{client, userdata, reasonCode, properties}')

    def _on_connect(self, client, userdata, flags, rc):
        self.logger.info(f'连接mqtt服务端成功, {client, userdata, flags, rc}')

    # noinspection PyUnusedLocal
    def _on_message(self, client, userdata, msg):
        # print(msg.topic + " " + str(msg.payload))
        kw = {'body': msg.payload}
        self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/mqtt_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/mysql_cdc_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/mysql_cdc_consumer.py`

#### 📦 Imports

- `import time`
- `import typing`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.loggers import develop_logger`
- `from pymysqlreplication import BinLogStreamReader`
- `from pymysqlreplication.row_event import DeleteRowsEvent`
- `from pymysqlreplication.row_event import UpdateRowsEvent`
- `from pymysqlreplication.row_event import WriteRowsEvent`

#### 🏛️ Classes (1)

##### 📌 `class MysqlCdcConsumer(AbstractConsumer)`
*Line: 18*

**Docstring:**
`````
A consumer that listens to MySQL binlog events (CDC) and treats them as tasks.
This broker is consumer-driven; it automatically generates tasks from database changes.
`````

**Public Methods (1):**
- `def custom_init(self)`
  - *Validates the essential configuration.*


---

`````python
# funboost/consumers/cdc_consumer.py

import time
import typing
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.loggers import develop_logger

# pip install mysql-replication==1.0.9
from pymysqlreplication import BinLogStreamReader
from pymysqlreplication.row_event import (
    DeleteRowsEvent,
    UpdateRowsEvent,
    WriteRowsEvent,
)



class MysqlCdcConsumer(AbstractConsumer):
    """
    A consumer that listens to MySQL binlog events (CDC) and treats them as tasks.
    This broker is consumer-driven; it automatically generates tasks from database changes.
    """



    def custom_init(self):
        """Validates the essential configuration."""
        config = self.consumer_params.broker_exclusive_config['BinLogStreamReaderConfig']
        if not config.get('connection_settings') or not config.get('server_id'):
            raise ValueError("For 'funboost_cdc' broker, 'connection_settings' and 'server_id' must be provided in 'broker_exclusive_config'.")
        self.logger.info("FunboostCdcConsumer initialized. Ready to listen for binlog events.")
        self._bin_log_stream_reader_config = config

    def _dispatch_task(self):
        """
        This is the main loop that connects to MySQL, reads binlog events,
        and submits them as tasks to the funboost engine.
        """
        # Prepare the arguments for BinLogStreamReader by filtering out None values


        stream = BinLogStreamReader(**self._bin_log_stream_reader_config)

        try:
            for binlogevent in stream:
                event_type = None
                if isinstance(binlogevent, WriteRowsEvent):
                    event_type = 'INSERT'
                elif isinstance(binlogevent, UpdateRowsEvent):
                    event_type = 'UPDATE'
                elif isinstance(binlogevent, DeleteRowsEvent):
                    event_type = 'DELETE'

                if event_type:
                    for row in binlogevent.rows:
                        # Construct a clear, flat dictionary to be used as function kwargs
                        task_body = {
                            'event_type': event_type,
                            'schema': binlogevent.schema,
                            'table': binlogevent.table,
                            'timestamp': binlogevent.timestamp,
                        }
                        # Unpack row data ('values' or 'before_values'/'after_values')
                        task_body.update(row)

                        # Submit the structured data as a task to the funboost engine
                        self._submit_task({'body': task_body})
        except Exception as e:
            self.logger.critical(f"An error occurred in the binlog stream: {e}", exc_info=True)
            # A small delay before potentially restarting or exiting, depending on supervisor.
            time.sleep(10)
        finally:
            self.logger.info("Closing binlog stream.")
            stream.close()

    def _confirm_consume(self, kw: dict):
        """
        Confirmation is implicitly handled by the BinLogStreamReader's position management.
        When resume_stream=True, the library automatically saves its position.
        Funboost's ACK here confirms that the *processing* of the event is complete.
        """
        pass

    def _requeue(self, kw: dict):
        """
        Requeuing a binlog event is not a standard operation.
        Funboost's built-in retry mechanism should be used for transient processing errors.
        If a task fails permanently, it will be ACK'd after exhausting retries,
        and the binlog position will eventually advance.
        """
        self.logger.warning(f"Requeuing a CDC event is not supported. "
                            f"Use funboost's retry mechanism for processing failures. Task: {kw.get('body')}")
        pass
`````

--- **end of file: funboost/consumers/mysql_cdc_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/nameko_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/nameko_consumer.py`

#### 📦 Imports

- `from multiprocessing import Process`
- `import threading`
- `import typing`
- `from funboost.constant import BrokerEnum`
- `from nameko.containers import ServiceContainer`
- `from nameko.rpc import rpc`
- `from nameko.runners import ServiceRunner`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.nameko_publisher import get_nameko_config`
- `from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch`

#### 🏛️ Classes (1)

##### 📌 `class NamekoConsumer(AbstractConsumer)`
*Line: 22*

**Docstring:**
`````
nameko作为中间件实现的。
`````

**Public Methods (1):**
- `def custom_init(self)`

#### 🔧 Public Functions (3)

- `def batch_start_nameko_consumers(boost_fun_list: typing.List)`
  - *Line: 58*

- `def batch_start_nameko_service_in_new_thread(boost_fun_list: typing.List)`
  - *Line: 66*

- `def batch_start_nameko_service_in_new_process(boost_fun_list: typing.List, process_num = 1)`
  - *Line: 70*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 13:32
from multiprocessing import Process

import threading

import typing
from funboost.constant import BrokerEnum


from nameko.containers import ServiceContainer
from nameko.rpc import rpc
from nameko.runners import ServiceRunner

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.publishers.nameko_publisher import get_nameko_config

all_queue_name__nameko_service_cls_map = {}


class NamekoConsumer(AbstractConsumer, ):
    """
    nameko作为中间件实现的。
    """


    def custom_init(self):
        try:
            from funboost.concurrent_pool.custom_evenlet_pool_executor import check_evenlet_monkey_patch
            check_evenlet_monkey_patch()
        except Exception as e:
            self.logger.critical('nameko 必须使用eventlet 并发，并且eventlet包打猴子补丁')
            raise e

        class MyService:
            name = self.queue_name

            @rpc
            def call(this, *args, **kwargs):
                return self.consuming_function(*args, **kwargs)

        all_queue_name__nameko_service_cls_map[self.queue_name] = MyService

    def _dispatch_task(self):
        container = ServiceContainer(all_queue_name__nameko_service_cls_map[self.queue_name], config=get_nameko_config())
        container.start()
        container.wait()

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        pass



def batch_start_nameko_consumers(boost_fun_list: typing.List):
    runner = ServiceRunner(config=get_nameko_config())
    for boost_fun in boost_fun_list:
        runner.add_service(all_queue_name__nameko_service_cls_map[boost_fun.queue_name])
    runner.start()
    runner.wait()


def batch_start_nameko_service_in_new_thread(boost_fun_list: typing.List):
    threading.Thread(target=batch_start_nameko_consumers, args=(boost_fun_list,)).start()


def batch_start_nameko_service_in_new_process(boost_fun_list: typing.List, process_num=1):
    for i in range(process_num):
        Process(target=batch_start_nameko_consumers, args=(boost_fun_list,)).start()

`````

--- **end of file: funboost/consumers/nameko_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/nats_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/nats_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.lazy_impoter import NatsImporter`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class NatsConsumer(AbstractConsumer)`
*Line: 9*

**Docstring:**
`````
nats作为中间件实现的。
`````


---

`````python
﻿import json
# from pynats import NATSClient, NATSMessage  # noqa

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.lazy_impoter import NatsImporter
from funboost.funboost_config_deafult import BrokerConnConfig


class NatsConsumer(AbstractConsumer):
    """
    nats作为中间件实现的。
    """


    def _dispatch_task(self):
        # print(88888888888888)
        nats_client = NatsImporter().NATSClient(BrokerConnConfig.NATS_URL, socket_timeout=600, socket_keepalive=True)
        nats_client.connect()

        def callback(msg: NatsImporter().NATSMessage):
            # print(type(msg))
            # print(msg.reply)
            # print(f"Received a message with subject {msg.subject}: {msg.payload}")
            kw = {'body': msg.payload}
            self._submit_task(kw)

        nats_client.subscribe(subject=self.queue_name, callback=callback)
        nats_client.wait()

    def _confirm_consume(self, kw):
        pass   # 没有确认消费

    def _requeue(self, kw):
        self.publisher_of_same_queue.publish(kw['body'])

`````

--- **end of file: funboost/consumers/nats_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/nsq_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/nsq_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.core.lazy_impoter import GnsqImporter`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🏛️ Classes (1)

##### 📌 `class NsqConsumer(AbstractConsumer)`
*Line: 17*

**Docstring:**
`````
nsq作为中间件实现的。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json

from funboost.core.lazy_impoter import GnsqImporter
# from gnsq import Consumer, Message

from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.consumers.base_consumer import AbstractConsumer
# from nb_log import LogManager
from funboost.core.loggers import get_funboost_file_logger

get_funboost_file_logger('gnsq',log_level_int=20)


class NsqConsumer(AbstractConsumer):
    """
    nsq作为中间件实现的。
    """


    def _dispatch_task(self):
        consumer = GnsqImporter().Consumer(self._queue_name, 'frame_channel', BrokerConnConfig.NSQD_TCP_ADDRESSES,
                            max_in_flight=self.consumer_params.concurrent_num, heartbeat_interval=60, timeout=600, )  # heartbeat_interval 不能设置为600

        @consumer.on_message.connect
        def handler(consumerx: GnsqImporter().Consumer, message: GnsqImporter().Message):
            # 第一条消息不能并发，第一条消息之后可以并发。
            # self.logger.debug(f'从nsq的 [{self._queue_name}] 主题中 取出的消息是：  {message.body.decode()}')
            message.enable_async()
            kw = {'consumer': consumerx, 'message': message, 'body': message.body}
            self._submit_task(kw)

        consumer.start()

    def _confirm_consume(self, kw):
        kw['message'].finish()

    def _requeue(self, kw):
        kw['message'].requeue()

`````

--- **end of file: funboost/consumers/nsq_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/peewee_conusmer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/peewee_conusmer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.queues.peewee_queue import PeeweeQueue`
- `from funboost.queues.peewee_queue import TaskStatus`

#### 🏛️ Classes (1)

##### 📌 `class PeeweeConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
peewee实现的操作5种数据库模拟消息队列，支持消费确认。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:33
import json
from funboost.constant import BrokerEnum
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.queues.peewee_queue import PeeweeQueue,TaskStatus


class PeeweeConsumer(AbstractConsumer):
    """
    peewee实现的操作5种数据库模拟消息队列，支持消费确认。
    """


    def _dispatch_task(self):
        self.queue = PeeweeQueue(self.queue_name)
        while True:
            task_dict = self.queue.get()
            # print(task_dict)
            # self.logger.debug(f'从数据库 {frame_config.SQLACHEMY_ENGINE_URL[:25]}。。 的 [{self._queue_name}] 队列中 取出的消息是：   消息是：  {sqla_task_dict}')
            kw = {'body':task_dict['body'], 'job_id': task_dict['job_id']}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        self.queue.set_success(kw['job_id'])

    def _requeue(self, kw):
        self.queue.requeue_task(kw['job_id'])




`````

--- **end of file: funboost/consumers/peewee_conusmer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/persist_queue_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/persist_queue_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.persist_queue_publisher import PersistQueuePublisher`
- `from funboost.core.func_params_model import PublisherParams`

#### 🏛️ Classes (1)

##### 📌 `class PersistQueueConsumer(AbstractConsumer)`
*Line: 10*

**Docstring:**
`````
persist queue包实现的本地持久化消息队列。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:35
import json
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.publishers.persist_queue_publisher import PersistQueuePublisher
from funboost.core.func_params_model import PublisherParams

class PersistQueueConsumer(AbstractConsumer):
    """
    persist queue包实现的本地持久化消息队列。
    """

    def _dispatch_task(self):
        pub = PersistQueuePublisher(publisher_params=PublisherParams(queue_name=self.queue_name))
        while True:
            item = pub.queue.get()
            # self.logger.debug(f'从本地持久化sqlite的 [{self._queue_name}] 队列中 取出的消息是：   {item}  ')
            kw = {'body': item, 'q': pub.queue, 'item': item}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        kw['q'].ack(kw['item'])

    def _requeue(self, kw):
        kw['q'].nack(kw['item'])

`````

--- **end of file: funboost/consumers/persist_queue_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/pulsar_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/pulsar_consumer.py`

#### 📝 Module Docstring

`````
import pulsar

client = pulsar.Client('pulsar://localhost:6650')
consumer = client.subscribe('my-topic',
                            subscription_name='my-sub')

while True:
    msg = consumer.receive()
    print("Received message: '%s'" % msg.data())
    consumer.acknowledge(msg)

client.close()
`````

#### 📦 Imports

- `import os`
- `import json`
- `from _pulsar import ConsumerType`
- `from pulsar.schema import schema`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `import pulsar`

#### 🏛️ Classes (1)

##### 📌 `class PulsarConsumer(AbstractConsumer)`
*Line: 30*

**Docstring:**
`````
pulsar作为中间件实现的。
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
'''

import pulsar

client = pulsar.Client('pulsar://localhost:6650')
consumer = client.subscribe('my-topic',
                            subscription_name='my-sub')

while True:
    msg = consumer.receive()
    print("Received message: '%s'" % msg.data())
    consumer.acknowledge(msg)

client.close()
'''

# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import os

import json
from _pulsar import ConsumerType
from pulsar.schema import schema
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.funboost_config_deafult import BrokerConnConfig


class PulsarConsumer(AbstractConsumer, ):
    """
    pulsar作为中间件实现的。
    """



    def custom_init(self):
        pass

    def _dispatch_task(self):
        try:
            import pulsar  # 需要用户自己 pip install pulsar-client ，目前20221206只支持linux安装此python包。
        except ImportError:
            raise ImportError('需要用户自己 pip install pulsar-client ，')
        self._client = pulsar.Client(BrokerConnConfig.PULSAR_URL, )

        consumer_type_map = {
            'Exclusive':ConsumerType.Exclusive,
            'Shared':ConsumerType.Shared,
            'Failover':ConsumerType.Failover,
            'KeyShared':ConsumerType.KeyShared,
        }
        consumer_type_obj = consumer_type_map[self.consumer_params.broker_exclusive_config['consumer_type']]
        self._consumer = self._client.subscribe(self._queue_name, schema=schema.StringSchema(), consumer_name=f'funboost_consumer_{os.getpid()}',
                                                subscription_name=self.consumer_params.broker_exclusive_config['subscription_name'],
                                                consumer_type=consumer_type_obj,
                                                replicate_subscription_state_enabled=self.consumer_params.broker_exclusive_config['replicate_subscription_state_enabled'])
        while True:
            msg = self._consumer.receive()
            if msg:
                kw = {'body': msg.data(), 'msg': msg}
                self._submit_task(kw)

    def _confirm_consume(self, kw):
        self._consumer.acknowledge(kw['msg'])

    def _requeue(self, kw):
        self._consumer.negative_acknowledge(kw['msg'])

`````

--- **end of file: funboost/consumers/pulsar_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/rabbitmq_amqpstorm_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/rabbitmq_amqpstorm_consumer.py`

#### 📦 Imports

- `import amqpstorm`
- `from funboost.consumers.base_consumer import AbstractConsumer`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqConsumerAmqpStorm(AbstractConsumer)`
*Line: 10*

**Docstring:**
`````
使用AmqpStorm实现的，多线程安全的，不用加锁。
funboost 强烈推荐使用这个做消息队列中间件。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:30

import amqpstorm
from funboost.consumers.base_consumer import AbstractConsumer



class RabbitmqConsumerAmqpStorm(AbstractConsumer):
    """
    使用AmqpStorm实现的，多线程安全的，不用加锁。
    funboost 强烈推荐使用这个做消息队列中间件。
    """

    # _rabbitmq_pb_cls = RabbitmqPublisherUsingAmqpStorm

    def _dispatch_task(self):
        # noinspection PyTypeChecker
        def callback(amqpstorm_message: amqpstorm.Message):
            body = amqpstorm_message.body
            # self.logger.debug(f'从rabbitmq的 [{self._queue_name}] 队列中 取出的消息是：  {body}')
            kw = {'amqpstorm_message': amqpstorm_message, 'body': body}
            self._submit_task(kw)

        # rp = self._rabbitmq_pb_cls(publisher_params=PublisherParams(queue_name=self.queue_name,broker_kind=self.consumer_params.broker_kind,
                                                                    # broker_exclusive_config=self.consumer_params.broker_exclusive_config))
        rp = self.bulid_a_new_publisher_of_same_queue()
        rp.init_broker()
        rp.channel_wrapper_by_ampqstormbaic.qos(self.consumer_params.concurrent_num)
        rp.channel_wrapper_by_ampqstormbaic.consume(callback=callback, queue=self.queue_name, no_ack=self.consumer_params.broker_exclusive_config['no_ack'],
                                                    )
        self._rp = rp
        rp.channel.start_consuming(auto_decode=True)

    def _confirm_consume(self, kw):
        # noinspection PyBroadException
        if self.consumer_params.broker_exclusive_config['no_ack'] is False:
            try:
                kw['amqpstorm_message'].ack()  # 确认消费
            except BaseException as e:
                self.logger.error(f'AmqpStorm确认消费失败  {type(e)} {e}')

    def _requeue(self, kw):
        # amqpstorm.Message.delivery_tag
        # print(kw['amqpstorm_message'].delivery_tag)
        kw['amqpstorm_message'].nack(requeue=True)
        # kw['amqpstorm_message'].reject(requeue=True)
        # kw['amqpstorm_message'].ack()
        # self.publisher_of_same_queue.publish(kw['body'])

`````

--- **end of file: funboost/consumers/rabbitmq_amqpstorm_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/rabbitmq_complex_routing_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/rabbitmq_complex_routing_consumer.py`

#### 📦 Imports

- `import amqpstorm`
- `from funboost.consumers.rabbitmq_amqpstorm_consumer import RabbitmqConsumerAmqpStorm`
- `from amqpstorm.queue import Queue as AmqpStormQueue`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqComplexRoutingConsumer(RabbitmqConsumerAmqpStorm)`
*Line: 9*

**Docstring:**
`````
    
    
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:30
import amqpstorm
from funboost.consumers.rabbitmq_amqpstorm_consumer import RabbitmqConsumerAmqpStorm
from amqpstorm.queue import Queue as AmqpStormQueue


class RabbitmqComplexRoutingConsumer(RabbitmqConsumerAmqpStorm):
    """
    
    """
    def custom_init(self):
        super().custom_init()
        rp = self.bulid_a_new_publisher_of_same_queue()
        rp.init_broker()  # 发布者那边只声明了交换机

        # 消费者负责声明队列和唯一的绑定逻辑
        AmqpStormQueue(rp.channel).declare(**rp.queue_declare_params)
        
        # 消费者负责唯一的绑定逻辑
        if rp._exchange_name:
            self.logger.info(f'消费者开始绑定: 队列 [{self._queue_name}] <--> 交换机 [{rp._exchange_name}] (类型: {rp._exchange_type})')
            
            routing_key_bind = self.consumer_params.broker_exclusive_config.get('routing_key_for_bind')
            arguments_for_bind = None

            if rp._exchange_type == 'fanout':
                routing_key_bind = ''  # fanout 必须使用空 routing_key
            elif rp._exchange_type == 'headers':
                routing_key_bind = ''  # headers 必须使用空 routing_key
                arguments_for_bind = self.consumer_params.broker_exclusive_config.get('headers_for_bind', {})
                arguments_for_bind['x-match'] = self.consumer_params.broker_exclusive_config.get('x_match_for_bind', 'all')
            elif routing_key_bind is None:  # 用户未指定绑定键时，根据交换机类型设置默认值
                if rp._exchange_type == 'topic':
                    routing_key_bind = '#'  # topic 默认订阅所有
                else:  # direct
                    routing_key_bind = self._queue_name

            AmqpStormQueue(rp.channel).bind(queue=self._queue_name, exchange=rp._exchange_name,
                                           routing_key=routing_key_bind, arguments=arguments_for_bind)
        self._rp = rp

    def _dispatch_task(self):
        # 重写父类的方法，以支持更复杂的绑定逻辑
        def callback(amqpstorm_message: amqpstorm.Message):
            body = amqpstorm_message.body
            kw = {'amqpstorm_message': amqpstorm_message, 'body': body}
            self._submit_task(kw)

        rp = self._rp
        rp.channel_wrapper_by_ampqstormbaic.qos(self.consumer_params.concurrent_num)
        rp.channel_wrapper_by_ampqstormbaic.consume(callback=callback, queue=self.queue_name, no_ack=self.consumer_params.broker_exclusive_config['no_ack'])
        rp.channel.start_consuming(auto_decode=True)

`````

--- **end of file: funboost/consumers/rabbitmq_complex_routing_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/rabbitmq_pika_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/rabbitmq_pika_consumer.py`

#### 📦 Imports

- `import os`
- `import functools`
- `import json`
- `from threading import Lock`
- `from deprecated import deprecated`
- `from funboost.core.loggers import get_funboost_file_logger`
- `import pikav1.exceptions`
- `from pikav1.exceptions import AMQPError`
- `import pikav1`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqConsumer(AbstractConsumer)`
*Line: 23*

**Docstring:**
`````
使用pika包实现的。
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:27
import os
import functools
import json
from threading import Lock

from deprecated import deprecated
# # from nb_log import LogManager, get_logger
# from funboost.constant import BrokerEnum
# from funboost.publishers.base_publisher import deco_mq_conn_error
from funboost.core.loggers import get_funboost_file_logger
import pikav1.exceptions
from pikav1.exceptions import AMQPError
import pikav1
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.funboost_config_deafult import BrokerConnConfig

get_funboost_file_logger('pikav1', log_level_int=20)

@deprecated('不建议使用这个中间件模式，建议使用 BrokerEnum.RABBITMQ_AMQPSTORM 操作rabbitmq')
class RabbitmqConsumer(AbstractConsumer):
    """
    使用pika包实现的。
    """


    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._lock_for_pika = Lock()
        self.logger.critical('pika 多线程中操作同一个 channel 有问题，如果使用 rabbitmq 建议设置中间件为 BrokerEnum.RABBITMQ_AMQPSTORM')
        os._exit(444) # noqa

    def _dispatch_task(self):
        # channel = RabbitMqFactory(is_use_rabbitpy=0).get_rabbit_cleint().creat_a_channel()
        # channel.queue_declare(queue=self._queue_name, durable=True)
        # channel.basic_qos(prefetch_count=self.consumer_params.concurrent_num)
        def callback(ch, method, properties, body):
            body = body.decode()
            # self.logger.debug(f'从rabbitmq的 [{self._queue_name}] 队列中 取出的消息是：  {body}')
            kw = {'ch': ch, 'method': method, 'properties': properties, 'body': body}
            self._submit_task(kw)

        while True:
            # 文档例子  https://github.com/pika/pika
            try:
                self.logger.warning(f'使用pika 链接mq')
                # self.rabbit_client = RabbitMqFactory(is_use_rabbitpy=0).get_rabbit_cleint()
                # self.channel = self.rabbit_client.creat_a_channel()

                credentials = pikav1.PlainCredentials(BrokerConnConfig.RABBITMQ_USER, BrokerConnConfig.RABBITMQ_PASS)
                self.connection = pikav1.BlockingConnection(pikav1.ConnectionParameters(
                    BrokerConnConfig.RABBITMQ_HOST, BrokerConnConfig.RABBITMQ_PORT, BrokerConnConfig.RABBITMQ_VIRTUAL_HOST, credentials, heartbeat=600))
                self.channel = self.connection.channel()
                self.rabbitmq_queue = self.channel.queue_declare(queue=self._queue_name, durable=True)
                self.channel.basic_consume(on_message_callback = callback,
                                           queue=self._queue_name,
                                           # no_ack=True
                                           )
                self.channel.start_consuming()
            # Don't recover if connection was closed by broker
            # except pikav0.exceptions.ConnectionClosedByBroker:
            #     break
            # Don't recover on channel errors
            except pikav1.exceptions.AMQPChannelError as e:
                # break
                self.logger.error(e)
                continue
                # Recover on all other connection errors
            except pikav1.exceptions.AMQPConnectionError as e:
                self.logger.error(e)
                continue

    def _confirm_consume000(self, kw):
        with self._lock_for_pika:
            try:
                kw['ch'].basic_ack(delivery_tag=kw['method'].delivery_tag)  # 确认消费
            except AMQPError as e:
                self.logger.error(f'pika确认消费失败  {e}')

    def _confirm_consume(self, kw):
        # with self._lock_for_pika:
        #     self.__ack_message_pika(kw['ch'], kw['method'].delivery_tag)
        kw['ch'].connection.add_callback_threadsafe(functools.partial(self.__ack_message_pika, kw['ch'], kw['method'].delivery_tag))

    def _requeue(self, kw):
        kw['ch'].connection.add_callback_threadsafe(functools.partial(self.__nack_message_pika, kw['ch'], kw['method'].delivery_tag))
        # with self._lock_for_pika:
        # return kw['ch'].basic_nack(delivery_tag=kw['method'].delivery_tag)  # 立即重新入队。
        # with self._lock_for_pika:
        #     self.__nack_message_pika(kw['ch'], kw['method'].delivery_tag)

    def __nack_message_pika(self, channelx, delivery_tagx):
        """Note that `channel` must be the same pika channel instance via which
        the message being ACKed was retrieved (AMQP protocol constraint).
        """
        if channelx.is_open:
            channelx.basic_nack(delivery_tagx)
        else:
            # Channel is already closed, so we can't ACK this message;
            # log and/or do something that makes sense for your app in this case.
            self.logger.error(channelx.is_open)
            pass

    def __ack_message_pika(self, channelx, delivery_tagx):
        """Note that `channel` must be the same pika channel instance via which
        the message being ACKed was retrieved (AMQP protocol constraint).
        """
        if channelx.is_open:
            channelx.basic_ack(delivery_tagx)
        else:
            # Channel is already closed, so we can't ACK this message;
            # log and/or do something that makes sense for your app in this case.
            self.logger.error(channelx.is_open)
            pass

`````

--- **end of file: funboost/consumers/rabbitmq_pika_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/rabbitmq_rabbitpy_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/rabbitmq_rabbitpy_consumer.py`

#### 📦 Imports

- `import json`
- `from deprecated import deprecated`
- `import rabbitpy`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.utils.rabbitmq_factory import RabbitMqFactory`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqConsumerRabbitpy(AbstractConsumer)`
*Line: 12*

**Docstring:**
`````
使用rabbitpy实现的
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:31
import json
from deprecated import deprecated
import rabbitpy
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.utils.rabbitmq_factory import RabbitMqFactory

@deprecated('不建议使用这个中间件模式，建议使用 BrokerEnum.RABBITMQ_AMQPSTORM 操作rabbitmq')
class RabbitmqConsumerRabbitpy(AbstractConsumer):
    """
    使用rabbitpy实现的
    """
    def custom_init(self):
        raise Exception('不建议使用这个中间件模式，建议使用 BrokerEnum.RABBITMQ_AMQPSTORM 操作rabbitmq')

    def _dispatch_task(self):
        # noinspection PyTypeChecker
        channel = RabbitMqFactory(is_use_rabbitpy=1).get_rabbit_cleint().creat_a_channel()  # type:  rabbitpy.AMQP         #
        channel.queue_declare(queue=self._queue_name, durable=True)
        channel.basic_qos(prefetch_count=self.consumer_params.concurrent_num)
        for message in channel.basic_consume(self._queue_name, no_ack=False):
            body = message.body.decode()
            # self.logger.debug(f'从rabbitmq {self._queue_name} 队列中 取出的消息是：  {body}')
            kw = {'message': message, 'body': body}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        kw['message'].ack()

    def _requeue(self, kw):
        kw['message'].nack(requeue=True)

`````

--- **end of file: funboost/consumers/rabbitmq_rabbitpy_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_brpoplpush_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_brpoplpush_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.utils import decorators`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisBrpopLpushConsumer(AbstractConsumer, RedisMixin)`
*Line: 12*

**Docstring:**
`````
redis作为中间件实现的，使用redis brpoplpush 实现的，并且使用心跳来解决 关闭/掉线 重新分发问题。
`````

**Public Methods (1):**
- `def start_consuming_message(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
# import time
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.utils import  decorators
from funboost.utils.redis_manager import RedisMixin


class RedisBrpopLpushConsumer(AbstractConsumer, RedisMixin):
    """
    redis作为中间件实现的，使用redis brpoplpush 实现的，并且使用心跳来解决 关闭/掉线 重新分发问题。

    """


    def start_consuming_message(self):
        self.consumer_params.is_send_consumer_heartbeat_to_redis = True
        super().start_consuming_message()
        self.keep_circulating(60, block=False)(self._requeue_tasks_which_unconfirmed)()

    # noinspection DuplicatedCode
    def _dispatch_task(self):
        unack_list_name = f'unack_{self._queue_name}_{self.consumer_identification}'
        while True:
            msg = self.redis_db_frame.brpoplpush(self._queue_name, unack_list_name, timeout=60)
            if msg:
                kw = {'body': msg, 'raw_msg': msg}
                self._submit_task(kw)

    def _confirm_consume(self, kw):
        self.redis_db_frame.lrem(f'unack_{self._queue_name}_{self.consumer_identification}',count=1,value= kw['raw_msg'], )

    def _requeue(self, kw):
        self.redis_db_frame.lpush(self._queue_name, json.dumps(kw['body']))

    def _requeue_tasks_which_unconfirmed(self):
        lock_key = f'fsdf_lock__requeue_tasks_which_unconfirmed:{self._queue_name}'
        with decorators.RedisDistributedLockContextManager(self.redis_db_frame, lock_key, ) as lock:
            if lock.has_aquire_lock:
                self._distributed_consumer_statistics.send_heartbeat()
                current_queue_hearbeat_ids = self._distributed_consumer_statistics.get_queue_heartbeat_ids(without_time=True)
                current_queue_unacked_msg_queues = self.redis_db_frame.scan(0, f'unack_{self._queue_name}_*', count=100)
                for current_queue_unacked_msg_queue in current_queue_unacked_msg_queues[1]:
                    current_queue_unacked_msg_queue_str = current_queue_unacked_msg_queue
                    if current_queue_unacked_msg_queue_str.split(f'unack_{self._queue_name}_')[1] not in current_queue_hearbeat_ids:
                        msg_list = self.redis_db_frame.lrange(current_queue_unacked_msg_queue_str, 0, -1)
                        self.logger.warning(f"""{current_queue_unacked_msg_queue_str} 是掉线或关闭消费者的待确认任务, 将 一共 {len(msg_list)} 个消息,
                                            详情是 {msg_list} 推送到正常消费队列 {self._queue_name} 队列中。
                                            """)
                        self.redis_db_frame.lpush(self._queue_name, *msg_list)
                        self.redis_db_frame.delete(current_queue_unacked_msg_queue_str)

`````

--- **end of file: funboost/consumers/redis_brpoplpush_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_consumer.py`

#### 📦 Imports

- `import json`
- `import time`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.core.serialization import Serialization`

#### 🏛️ Classes (1)

##### 📌 `class RedisConsumer(AbstractConsumer, RedisMixin)`
*Line: 15*

**Docstring:**
`````
redis作为中间件实现的，使用redis list 结构实现的。
这个如果消费脚本在运行时候随意反复重启或者非正常关闭或者消费宕机，会丢失大批任务。高可靠需要用rabbitmq或者redis_ack_able或者redis_stream的中间件方式。

这个是复杂版，一次性拉取100个,减少和redis的交互，简单版在 funboost/consumers/redis_consumer_simple.py
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
# import time
import time



from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.utils.redis_manager import RedisMixin
from funboost.core.serialization import Serialization

class RedisConsumer(AbstractConsumer, RedisMixin):
    """
    redis作为中间件实现的，使用redis list 结构实现的。
    这个如果消费脚本在运行时候随意反复重启或者非正常关闭或者消费宕机，会丢失大批任务。高可靠需要用rabbitmq或者redis_ack_able或者redis_stream的中间件方式。

    这个是复杂版，一次性拉取100个,减少和redis的交互，简单版在 funboost/consumers/redis_consumer_simple.py
    """



    # noinspection DuplicatedCode
    def _dispatch_task(self):
        pull_msg_batch_size =  self.consumer_params.broker_exclusive_config['pull_msg_batch_size']
        while True:
            # if False:
            #     pass
            with self.redis_db_frame.pipeline() as p:
                p.lrange(self._queue_name, 0, pull_msg_batch_size- 1)
                p.ltrim(self._queue_name, pull_msg_batch_size, -1)
                task_str_list = p.execute()[0]
            if task_str_list:
                # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {task_str_list}  ')
                self._print_message_get_from_broker( task_str_list)
                for task_str in task_str_list:
                    kw = {'body': task_str}
                    self._submit_task(kw)
            else:
                result = self.redis_db_frame.brpop(self._queue_name, timeout=60)
                if result:
                    # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {result[1].decode()}  ')
                    kw = {'body': result[1]}
                    self._submit_task(kw)

    def _dispatch_task00(self):
        while True:
            result = self.redis_db_frame.blpop(self._queue_name, timeout=60)
            if result:
                # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {result[1].decode()}  ')
                kw = {'body': result[1]}
                self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass  # redis没有确认消费的功能。

    def _requeue(self, kw):
        self.redis_db_frame.rpush(self._queue_name,Serialization.to_json_str(kw['body']))

`````

--- **end of file: funboost/consumers/redis_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_consumer_ack_able.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_consumer_ack_able.py`

#### 📝 Module Docstring

`````
这个是加强版的可确认消费的redis消费实现，所以比redis_conusmer实现复杂很多。
这个可以确保随意反复多次停止重启脚本，任务永不丢失
`````

#### 📦 Imports

- `import json`
- `import time`
- `from deprecated.sphinx import deprecated`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.consumers.confirm_mixin import ConsumerConfirmMixinWithTheHelpOfRedis`
- `from funboost.consumers.confirm_mixin import ConsumerConfirmMixinWithTheHelpOfRedisByHearbeat`

#### 🏛️ Classes (3)

##### 📌 `class RedisConsumerAckAble000(ConsumerConfirmMixinWithTheHelpOfRedis, AbstractConsumer)`
*Line: 18*

**Docstring:**
`````
随意重启代码会极小概率丢失1个任务。
redis作为中间件实现的。将取出来的消息同时放入一个set中，代表unack消费状态。以支持对机器和python进程的随意关闭和断电。
和celery的配置  task_reject_on_worker_lost = True task_acks_late = True后，处理逻辑几乎不约而同相似。
`````

##### 📌 `class RedisConsumerAckAble111(ConsumerConfirmMixinWithTheHelpOfRedis, AbstractConsumer)`
*Line: 43*

**Docstring:**
`````
 随意重启代码不会丢失任务，使用的是超时10分钟没有确认消费就认为是已经断开了，重新回到代消费队列。
 redis作为中间件实现的。将取出来的消息同时放入一个set中，代表unack消费状态。以支持对机器和python进程的随意关闭和断电。
 和celery的配置  task_reject_on_worker_lost = True task_acks_late = True后，处理逻辑几乎不约而同相似。

 lua_4 = '''
local v = redis.call("lpop", KEYS[1])
if v then
redis.call('rpush',KEYS[2],v)
 end
return v'''
 # script_4 = r.register_script(lua_4)
 #
 # print(script_4(keys=["text_pipelien1","text_pipelien1b"]))
 
`````

##### 📌 `class RedisConsumerAckAble(ConsumerConfirmMixinWithTheHelpOfRedisByHearbeat, AbstractConsumer)`
*Line: 85*

**Docstring:**
`````
 随意重启代码不会丢失任务，采用的是配合redis心跳，将心跳过期的未确认的队列，全部重回消费队列。这种不需要等待10分钟，判断更精确。
 redis作为中间件实现的。将取出来的消息同时放入一个set中，代表unack消费状态。以支持对机器和python进程的随意关闭和断电。
 和celery的配置  task_reject_on_worker_lost = True task_acks_late = True后，处理逻辑几乎不约而同相似。

 lua_4 = '''
local v = redis.call("lpop", KEYS[1])
if v then
redis.call('rpush',KEYS[2],v)
 end
return v'''
 # script_4 = r.register_script(lua_4)
 #
 # print(script_4(keys=["text_pipelien1","text_pipelien1b"]))
 
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
"""

这个是加强版的可确认消费的redis消费实现，所以比redis_conusmer实现复杂很多。
这个可以确保随意反复多次停止重启脚本，任务永不丢失
"""
import json
import time
from deprecated.sphinx import deprecated
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.consumers.confirm_mixin import ConsumerConfirmMixinWithTheHelpOfRedis, ConsumerConfirmMixinWithTheHelpOfRedisByHearbeat


@deprecated(version='1.0', reason="This class not used")
class RedisConsumerAckAble000(ConsumerConfirmMixinWithTheHelpOfRedis, AbstractConsumer, ):
    """
    随意重启代码会极小概率丢失1个任务。
    redis作为中间件实现的。将取出来的消息同时放入一个set中，代表unack消费状态。以支持对机器和python进程的随意关闭和断电。
    和celery的配置  task_reject_on_worker_lost = True task_acks_late = True后，处理逻辑几乎不约而同相似。
    """


    def _dispatch_task(self):
        while True:
            result = self.redis_db_frame.blpop(self._queue_name, timeout=60)
            # task_bytes = self.redis_db_frame.lpop(self._queue_name)
            if result:
                task_str = result[1]
                # 如果运行了第20行，但没运行下面这一行，仍然有极小概率会丢失1个任务。但比不做控制随意关停，丢失几百个线程你的redis任务强多了。
                self._add_task_str_to_unack_zset(task_str, )
                # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：     {task_str}  ')
                kw = {'body': task_str, 'task_str': task_str}
                self._submit_task(kw)

    def _requeue(self, kw):
        self.redis_db_frame.rpush(self._queue_name, json.dumps(kw['body']))


@deprecated(version='1.0', reason="This class not used")
class RedisConsumerAckAble111(ConsumerConfirmMixinWithTheHelpOfRedis, AbstractConsumer, ):
    """
    随意重启代码不会丢失任务，使用的是超时10分钟没有确认消费就认为是已经断开了，重新回到代消费队列。
    redis作为中间件实现的。将取出来的消息同时放入一个set中，代表unack消费状态。以支持对机器和python进程的随意关闭和断电。
    和celery的配置  task_reject_on_worker_lost = True task_acks_late = True后，处理逻辑几乎不约而同相似。

    lua_4 = '''
   local v = redis.call("lpop", KEYS[1])
   if v then
   redis.call('rpush',KEYS[2],v)
    end
   return v'''
    # script_4 = r.register_script(lua_4)
    #
    # print(script_4(keys=["text_pipelien1","text_pipelien1b"]))
    """


    def _dispatch_task(self):
        lua = '''
                     local v = redis.call("lpop", KEYS[1])
                     if v then
                     redis.call('zadd',KEYS[2],ARGV[1],v)
                      end
                     return v
                '''
        script = self.redis_db_frame.register_script(lua)
        while True:
            return_v = script(keys=[self._queue_name, self._unack_zset_name], args=[time.time()])
            if return_v:
                task_str = return_v
                self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：     {task_str}  ')
                kw = {'body': task_str, 'task_str': task_str}
                self._submit_task(kw)
            else:
                # print('xiuxi')
                time.sleep(0.1)

    def _requeue(self, kw):
        self.redis_db_frame.rpush(self._queue_name, json.dumps(kw['body']))


class RedisConsumerAckAble(ConsumerConfirmMixinWithTheHelpOfRedisByHearbeat, AbstractConsumer, ):
    """
    随意重启代码不会丢失任务，采用的是配合redis心跳，将心跳过期的未确认的队列，全部重回消费队列。这种不需要等待10分钟，判断更精确。
    redis作为中间件实现的。将取出来的消息同时放入一个set中，代表unack消费状态。以支持对机器和python进程的随意关闭和断电。
    和celery的配置  task_reject_on_worker_lost = True task_acks_late = True后，处理逻辑几乎不约而同相似。

    lua_4 = '''
   local v = redis.call("lpop", KEYS[1])
   if v then
   redis.call('rpush',KEYS[2],v)
    end
   return v'''
    # script_4 = r.register_script(lua_4)
    #
    # print(script_4(keys=["text_pipelien1","text_pipelien1b"]))
    """



    def _dispatch_task000(self):
        # 可以采用lua脚本，也可以采用redis的watch配合pipeline使用。比代码分两行pop和zadd比还能减少一次io交互，还能防止丢失小概率一个任务。
        lua = '''
                     local v = redis.call("lpop", KEYS[1])
                     if v then
                     redis.call('zadd',KEYS[2],ARGV[1],v)
                      end
                     return v 
                '''
        script = self.redis_db_frame.register_script(lua)
        while True:
            return_v = script(keys=[self._queue_name, self._unack_zset_name], args=[time.time()])
            if return_v:
                task_str = return_v
                self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：     {task_str}  ')
                kw = {'body': task_str, 'task_str': task_str}
                self._submit_task(kw)
            else:
                # print('xiuxi')
                time.sleep(0.5)

    def _dispatch_task(self):
        pull_msg_batch_size = self.consumer_params.broker_exclusive_config['pull_msg_batch_size']
        lua = f'''
                     local task_list = redis.call("lrange", KEYS[1],0,{pull_msg_batch_size-1})
                     redis.call("ltrim", KEYS[1],{pull_msg_batch_size},-1)
                     if (#task_list > 0) then
                        for task_index,task_value in ipairs(task_list)
                        do
                            redis.call('zadd',KEYS[2],ARGV[1],task_value)
                        end
                        return task_list
                    else
                        --local v = redis.call("blpop",KEYS[1],4)      
                        --return v
                      end

                '''
        """
        local v = redis.call("blpop",KEYS[1],60)  # redis 的lua 脚本禁止使用blpop
        local v = redis.call("lpop",KEYS[1])
        """
        script = self.redis_db_frame.register_script(lua)
        while True:
            task_str_list = script(keys=[self._queue_name, self._unack_zset_name], args=[time.time()])
            if task_str_list:
                self._print_message_get_from_broker( task_str_list)
                # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {task_str_list}  ')
                for task_str in task_str_list:
                    kw = {'body': task_str, 'task_str': task_str}
                    self._submit_task(kw)
            else:
                time.sleep(0.2)

    def _requeue(self, kw):
        self.redis_db_frame.rpush(self._queue_name, json.dumps(kw['body']))

`````

--- **end of file: funboost/consumers/redis_consumer_ack_able.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_consumer_ack_using_timeout.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_consumer_ack_using_timeout.py`

#### 📦 Imports

- `import json`
- `import time`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.serialization import Serialization`
- `from funboost.utils.decorators import RedisDistributedLockContextManager`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisConsumerAckUsingTimeout(AbstractConsumer, RedisMixin)`
*Line: 12*

**Docstring:**
`````
redis作为中间件实现的。
使用超时未能ack就自动重入消息队列，例如消息取出后，由于突然断电或重启或其他原因，导致消息以后再也不能主动ack了，超过一定时间就重新放入消息队列
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
﻿# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2024/8/8 0008 13:32
import json
import time
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.serialization import Serialization
from funboost.utils.decorators import RedisDistributedLockContextManager
from funboost.utils.redis_manager import RedisMixin


class RedisConsumerAckUsingTimeout(AbstractConsumer, RedisMixin):
    """
    redis作为中间件实现的。
    使用超时未能ack就自动重入消息队列，例如消息取出后，由于突然断电或重启或其他原因，导致消息以后再也不能主动ack了，超过一定时间就重新放入消息队列
    """





    def custom_init(self):
        self._unack_zset_name = f'{self._queue_name}__unack_using_timeout'
        self._ack_timeout = self.consumer_params.broker_exclusive_config['ack_timeout']
        self._last_show_unack_ts = time.time()

    def start_consuming_message(self):
        self.consumer_params.is_send_consumer_heartbeat_to_redis = True
        super().start_consuming_message()
        self.keep_circulating(10, block=False)(self._requeue_tasks_which_unconfirmed)()

    # def _add_task_str_to_unack_zset(self, task_str, ):
    #     self.redis_db_frame.zadd(self._unack_zset_name, {task_str: time.time()})

    def _confirm_consume(self, kw):
        self.redis_db_frame.zrem(self._unack_zset_name, kw['task_str'])

    def _requeue(self, kw):
        self.redis_db_frame.rpush(self._queue_name, Serialization.to_json_str(kw['body']))

    def _dispatch_task(self):
        lua = '''
                     local v = redis.call("lpop", KEYS[1])
                     if v then
                     redis.call('zadd',KEYS[2],ARGV[1],v)
                      end
                     return v
                '''
        script = self.redis_db_frame.register_script(lua)
        while True:
            return_v = script(keys=[self._queue_name, self._unack_zset_name], args=[time.time()])
            if return_v:
                task_str = return_v
                kw = {'body': task_str, 'task_str': task_str}
                self._submit_task(kw)
            else:
                time.sleep(0.1)

    def _requeue_tasks_which_unconfirmed(self):
        """不使用这种方案，不适合本来来就需要长耗时的函数，很死板"""
        # 防止在多个进程或多个机器中同时做扫描和放入未确认消费的任务。使用个分布式锁。
        lock_key = f'funboost_lock__requeue_tasks_which_unconfirmed_timeout:{self._queue_name}'
        with RedisDistributedLockContextManager(self.redis_db_frame, lock_key, ) as lock:
            if lock.has_aquire_lock:
                time_max = time.time() - self._ack_timeout
                for value in self.redis_db_frame.zrangebyscore(self._unack_zset_name, 0, time_max):
                    self.logger.warning(f'超过了 {self._ack_timeout} 秒未能确认消费, 向 {self._queue_name} 队列重新放入未消费确认的任务 {value} ,')
                    self._requeue({'body': value})
                    self.redis_db_frame.zrem(self._unack_zset_name, value)
                if time.time() - self._last_show_unack_ts > 600:  # 不要频繁提示打扰
                    self.logger.info(f'{self._unack_zset_name} 中有待确认消费任务的数量是'
                                     f' {self.redis_db_frame.zcard(self._unack_zset_name)}')
                    self._last_show_unack_ts = time.time()

`````

--- **end of file: funboost/consumers/redis_consumer_ack_using_timeout.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_consumer_priority.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_consumer_priority.py`

#### 📝 Module Docstring

`````
这个是加强版的可确认消费的redis消费实现，所以比redis_conusmer实现复杂很多。
这个可以确保随意反复多次停止重启脚本，任务不丢失，没人采用lua，随意反复重启代码极小概率丢失一个任务。

这个是支持任务优先级的redis队列实现。
`````

#### 📦 Imports

- `import json`
- `import time`
- `import redis5`
- `from funboost.consumers.redis_consumer_ack_able import RedisConsumerAckAble`

#### 🏛️ Classes (1)

##### 📌 `class RedisPriorityConsumer(RedisConsumerAckAble)`
*Line: 19*

**Docstring:**
`````
使用多个redis list来实现redis支持队列优先级。brpop可以支持监听多个redis键。
根据消息的 priroty 来决定发送到哪个队列。我这个想法和celery依赖的kombu实现的redis具有队列优先级是一样的。

注意：  rabbitmq、celery队列优先级都指的是同一个队列中的每个消息具有不同的优先级，消息可以不遵守先进先出，而是优先级越高的消息越先取出来。
       队列优先级其实是某个队列中的消息的优先级，这是队列的 x-max-priority 的原生概念。

       队列优先级有的人错误的以为是 queuexx 和queueyy两个队列，以为是优先消费queuexx的消息，这是大错特错的想法。
       队列优先级是指某个队列中的每个消息可以具有不同的优先级，不是在不同队列名之间来比较哪个队列名具有更高的优先级。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
"""

这个是加强版的可确认消费的redis消费实现，所以比redis_conusmer实现复杂很多。
这个可以确保随意反复多次停止重启脚本，任务不丢失，没人采用lua，随意反复重启代码极小概率丢失一个任务。

这个是支持任务优先级的redis队列实现。
"""
import json
import time

import redis5

from funboost.consumers.redis_consumer_ack_able import RedisConsumerAckAble


class RedisPriorityConsumer(RedisConsumerAckAble):
    """
       使用多个redis list来实现redis支持队列优先级。brpop可以支持监听多个redis键。
       根据消息的 priroty 来决定发送到哪个队列。我这个想法和celery依赖的kombu实现的redis具有队列优先级是一样的。

       注意：  rabbitmq、celery队列优先级都指的是同一个队列中的每个消息具有不同的优先级，消息可以不遵守先进先出，而是优先级越高的消息越先取出来。
              队列优先级其实是某个队列中的消息的优先级，这是队列的 x-max-priority 的原生概念。

              队列优先级有的人错误的以为是 queuexx 和queueyy两个队列，以为是优先消费queuexx的消息，这是大错特错的想法。
              队列优先级是指某个队列中的每个消息可以具有不同的优先级，不是在不同队列名之间来比较哪个队列名具有更高的优先级。
    """
    """用法如下。
    第一，如果使用redis做支持优先级的消息队列， @boost中要选择 broker_kind = BrokerEnum.REDIS_PRIORITY
    第二，broker_exclusive_config={'x-max-priority':4} 意思是这个队列中的任务消息支持多少种优先级，一般写5就完全够用了。
    第三，发布消息时候要使用publish而非push,发布要加入参  task_options=TaskOptions(other_extra_params={'priroty': priorityxx})，
         其中 priorityxx 必须是整数，要大于等于0且小于队列的x-max-priority。x-max-priority这个概念是rabbitmq的原生概念，celery中也是这样的参数名字。

         发布的消息priroty 越大，那么该消息就越先被取出来，这样就达到了打破先进先出的规律。比如优先级高的消息可以给vip用户来运行函数实时，优先级低的消息可以离线跑批。

    from funboost import register_custom_broker, boost, TaskOptions,BrokerEnum

    @boost('test_redis_priority_queue3', broker_kind=BrokerEnum.REDIS_PRIORITY, qps=5,concurrent_num=2,broker_exclusive_config={'x-max-priority':4})
    def f(x):
        print(x)


    if __name__ == '__main__':
        for i in range(1000):
            randx = random.randint(1, 4)
            f.publish({'x': randx}, task_options=TaskOptions(other_extra_params={'priroty': randx}))
        print(f.get_message_count())
        f.consume()
    """



    def _dispatch_task0000(self):

        while True:
            # task_str_list = script(keys=[queues_str, self._unack_zset_name], args=[time.time()])
            task_tuple = self.redis_db_frame.blpop(keys=self.publisher_of_same_queue.queue_list, timeout=60)  # 监听了多个键名，所以间接实现了优先级，和kombu的redis 支持优先级的设计思路不谋而合。
            if task_tuple:
                msg = task_tuple[1]
                self.redis_db_frame.zadd(self._unack_zset_name, {msg: time.time()})
                # self.logger.debug(task_tuple)
                # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {task_str_list}  ')
                kw = {'body': msg, 'task_str': msg}
                self._submit_task(kw)

    def _dispatch_task(self):
        """https://redis.readthedocs.io/en/latest/advanced_features.html#default-pipelines """
        while True:
            # task_str_list = script(keys=[queues_str, self._unack_zset_name], args=[time.time()])
            while True:
                try:
                    with self.redis_db_frame.pipeline() as p:
                        p.watch(self._unack_zset_name, *self.publisher_of_same_queue.queue_list, )
                        task_tuple = p.blpop(keys=self.publisher_of_same_queue.queue_list, timeout=60)  # 监听了多个键名，所以间接实现了优先级，和kombu的redis 支持优先级的设计思路不谋而合。
                        # print(task_tuple)
                        if task_tuple:
                            msg = task_tuple[1]
                            p.zadd(self._unack_zset_name, {msg: time.time()})
                            # self.logger.debug(task_tuple)
                            p.unwatch()
                            p.execute()
                            break
                except redis5.WatchError:
                    continue
            if task_tuple:
                # self.logger.debug(f'从redis的 [{self._queue_name}] 队列中 取出的消息是：  {task_str_list}  ')
                kw = {'body': msg, 'task_str': msg}
                self._submit_task(kw)

    def _requeue(self, kw):
        self.publisher_of_same_queue.publish(kw['body'])

`````

--- **end of file: funboost/consumers/redis_consumer_priority.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_consumer_simple.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_consumer_simple.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.serialization import Serialization`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisConsumer(AbstractConsumer, RedisMixin)`
*Line: 11*

**Docstring:**
`````
redis作为中间件实现的。
`````


---

`````python
﻿# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 13:32
import json
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.serialization import Serialization
from funboost.utils.redis_manager import RedisMixin


class RedisConsumer(AbstractConsumer, RedisMixin):
    """
    redis作为中间件实现的。
    """


    def _dispatch_task(self):
        while True:
            result = self.redis_db_frame.blpop(self._queue_name,timeout=60)
            if result:
                kw = {'body': result[1]}
                self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass  # redis没有确认消费的功能。

    def _requeue(self, kw):
        self.redis_db_frame.rpush(self._queue_name, Serialization.to_json_str(kw['body']))



`````

--- **end of file: funboost/consumers/redis_consumer_simple.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_filter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_filter.py`

#### 📝 Module Docstring

`````
任务消费完成后，如果重复发布则过滤。分别实现永久性过滤重复任务和过滤有效期内的重复任务。
任务过滤 = 函数参数过滤 = 字典过滤 = 排序后的键值对json字符串过滤。
`````

#### 📦 Imports

- `import json`
- `import time`
- `from collections import OrderedDict`
- `import typing`
- `from funboost.core.serialization import Serialization`
- `from funboost.utils import decorators`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (3)

##### 📌 `class RedisFilter(RedisMixin, FunboostFileLoggerMixin)`
*Line: 21*

**Docstring:**
`````
使用set结构，
基于函数参数的任务过滤。这个是永久性的过滤，除非自己手动删除这个键。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, redis_key_name, redis_filter_task_expire_seconds)`
  - **Docstring:**
  `````
  :param redis_key_name: 任务过滤键
  :param redis_filter_task_expire_seconds: 任务过滤的过期时间
  `````
  - **Parameters:**
    - `self`
    - `redis_key_name`
    - `redis_filter_task_expire_seconds`

**Public Methods (5):**
- `def generate_filter_str(value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)` `staticmethod`
  - *对json的键值对在redis中进行过滤，需要先把键值对排序，否则过滤会不准确如 {"a":1,"b":2} 和 {"b":2,"a":1}*
- `def add_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)`
- `def manual_delete_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)`
- `def check_value_exists(self, value, filter_str: typing.Optional[str] = None)`
- `def delete_expire_filter_task_cycle(self)`

##### 📌 `class RedisImpermanencyFilter(RedisFilter)`
*Line: 70*

**Docstring:**
`````
使用zset结构
基于函数参数的任务过滤。这个是非永久性的过滤，例如设置过滤过期时间是1800秒 ，30分钟前发布过1 + 2 的任务，现在仍然执行，
如果是30分钟内发布过这个任务，则不执行1 + 2，现在把这个逻辑集成到框架，一般用于接口缓存。
`````

**Public Methods (5):**
- `def add_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)`
- `def manual_delete_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)`
- `def check_value_exists(self, value, filter_str: typing.Optional[str] = None)`
- `def delete_expire_filter_task_cycle000(self)` `decorators.keep_circulating(60, block=False)`
  - **Docstring:**
  `````
  一直循环删除过期的过滤任务。
  # REMIND 任务过滤过期时间最好不要小于60秒，否则删除会不及时,导致发布的新任务由于命中了任务过滤，而不能触发执行。一般实时价格接口是缓存5分钟或30分钟没有问题。
  :return:
  `````
- `def delete_expire_filter_task_cycle(self)` `decorators.keep_circulating(60, block=False)`
  - **Docstring:**
  `````
  一直循环删除过期的过滤任务。任务过滤过期时间最好不要小于60秒，否则删除会不及时,导致发布的新任务不能触发执行。一般实时价格接口是缓存5分钟或30分钟。
  :return:
  `````

##### 📌 `class RedisImpermanencyFilterUsingRedisKey(RedisFilter)`
*Line: 114*

**Docstring:**
`````
直接把任务当做redis的key，使用redis自带的过期机制删除过期的过滤任务。
基于函数参数的任务过滤。这个是非永久性的过滤，例如设置过滤过期时间是1800秒 ，30分钟前发布过1 + 2 的任务，现在仍然执行，
如果是30分钟内发布过这个任务，则不执行1 + 2，现在把这个逻辑集成到框架，一般用于接口缓存。
这种过滤模式键太多了，很难看，固定放到 redis_db_filter_and_rpc_result ，不放到消息队列的db里面。
`````

**Public Methods (4):**
- `def add_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)`
- `def manual_delete_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None)`
- `def check_value_exists(self, value, filter_str: typing.Optional[str] = None)`
- `def delete_expire_filter_task_cycle(self)`
  - **Docstring:**
  `````
  redis服务端会自动删除过期的过滤任务键。不用在客户端管理。
  :return:
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:10
"""
任务消费完成后，如果重复发布则过滤。分别实现永久性过滤重复任务和过滤有效期内的重复任务。
任务过滤 = 函数参数过滤 = 字典过滤 = 排序后的键值对json字符串过滤。
"""

import json
import time
from collections import OrderedDict
import typing

from funboost.core.serialization import Serialization
from funboost.utils import  decorators
from funboost.core.loggers import FunboostFileLoggerMixin

from funboost.utils.redis_manager import RedisMixin


class RedisFilter(RedisMixin, FunboostFileLoggerMixin):
    """
    使用set结构，
    基于函数参数的任务过滤。这个是永久性的过滤，除非自己手动删除这个键。
    """

    def __init__(self, redis_key_name, redis_filter_task_expire_seconds):
        """
        :param redis_key_name: 任务过滤键
        :param redis_filter_task_expire_seconds: 任务过滤的过期时间
        """
        self._redis_key_name = redis_key_name
        self._redis_filter_task_expire_seconds = redis_filter_task_expire_seconds

        # @staticmethod
        # def _get_ordered_str(value):
        #     """对json的键值对在redis中进行过滤，需要先把键值对排序，否则过滤会不准确如 {"a":1,"b":2} 和 {"b":2,"a":1}"""
        #     value = Serialization.to_dict(value)
        #     ordered_dict = OrderedDict()
        #     for k in sorted(value):
        #         ordered_dict[k] = value[k]
        #     return json.dumps(ordered_dict)
    
    @staticmethod
    def generate_filter_str(value: typing.Union[str, dict],  filter_str: typing.Optional[str] = None):
        """对json的键值对在redis中进行过滤，需要先把键值对排序，否则过滤会不准确如 {"a":1,"b":2} 和 {"b":2,"a":1}"""
        if filter_str: # 如果用户单独指定了过滤字符串，就使用使用户指定的过滤字符串，否则使用排序后的键值对字符串
            return filter_str
        value = Serialization.to_dict(value)
        ordered_dict = OrderedDict()
        for k in sorted(value):
            ordered_dict[k] = value[k]
        # print(ordered_dict,filter_str)
        return json.dumps(ordered_dict)


    def add_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None):
        self.redis_db_filter_and_rpc_result.sadd(self._redis_key_name, self.generate_filter_str(value, filter_str))

    def manual_delete_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None):
        self.redis_db_filter_and_rpc_result.srem(self._redis_key_name, self.generate_filter_str(value, filter_str))

    def check_value_exists(self, value, filter_str: typing.Optional[str] = None):
        return self.redis_db_filter_and_rpc_result.sismember(self._redis_key_name, self.generate_filter_str(value, filter_str))

    def delete_expire_filter_task_cycle(self):
        pass


class RedisImpermanencyFilter(RedisFilter):
    """
    使用zset结构
    基于函数参数的任务过滤。这个是非永久性的过滤，例如设置过滤过期时间是1800秒 ，30分钟前发布过1 + 2 的任务，现在仍然执行，
    如果是30分钟内发布过这个任务，则不执行1 + 2，现在把这个逻辑集成到框架，一般用于接口缓存。
    """

    def add_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None):
        self.redis_db_filter_and_rpc_result.zadd(self._redis_key_name, {self.generate_filter_str(value, filter_str):time.time()})

    def manual_delete_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None):
        self.redis_db_filter_and_rpc_result.zrem(self._redis_key_name, self.generate_filter_str(value, filter_str))

    def check_value_exists(self, value, filter_str: typing.Optional[str] = None):
        # print(self.redis_db_filter_and_rpc_result.zrank(self._redis_key_name, self.generate_filter_str(value, filter_str)))
        is_exists = False if self.redis_db_filter_and_rpc_result.zscore(self._redis_key_name, self.generate_filter_str(value, filter_str)) is None else True
        # print(is_exists,value,filter_str,self.generate_filter_str(value, filter_str))
        return is_exists   

    @decorators.keep_circulating(60, block=False)
    def delete_expire_filter_task_cycle000(self):
        """
        一直循环删除过期的过滤任务。
        # REMIND 任务过滤过期时间最好不要小于60秒，否则删除会不及时,导致发布的新任务由于命中了任务过滤，而不能触发执行。一般实时价格接口是缓存5分钟或30分钟没有问题。
        :return:
        """
        time_max = time.time() - self._redis_filter_task_expire_seconds
        for value in self.redis_db_filter_and_rpc_result.zrangebyscore(self._redis_key_name, 0, time_max):
            self.logger.info(f'删除 {self._redis_key_name} 键中的过滤任务 {value}')
            self.redis_db_filter_and_rpc_result.zrem(self._redis_key_name, value)

    @decorators.keep_circulating(60, block=False)
    def delete_expire_filter_task_cycle(self):
        """

        一直循环删除过期的过滤任务。任务过滤过期时间最好不要小于60秒，否则删除会不及时,导致发布的新任务不能触发执行。一般实时价格接口是缓存5分钟或30分钟。
        :return:
        """
        time_max = time.time() - self._redis_filter_task_expire_seconds
        delete_num = self.redis_db_filter_and_rpc_result.zremrangebyscore(self._redis_key_name, 0, time_max)
        self.logger.warning(f'从{self._redis_key_name}  键删除 {delete_num} 个过期的过滤任务')
        self.logger.warning(f'{self._redis_key_name}  键中有 {self.redis_db_filter_and_rpc_result.zcard(self._redis_key_name)} 个没有过期的过滤任务')


class RedisImpermanencyFilterUsingRedisKey(RedisFilter):
    """
    直接把任务当做redis的key，使用redis自带的过期机制删除过期的过滤任务。
    基于函数参数的任务过滤。这个是非永久性的过滤，例如设置过滤过期时间是1800秒 ，30分钟前发布过1 + 2 的任务，现在仍然执行，
    如果是30分钟内发布过这个任务，则不执行1 + 2，现在把这个逻辑集成到框架，一般用于接口缓存。
    这种过滤模式键太多了，很难看，固定放到 redis_db_filter_and_rpc_result ，不放到消息队列的db里面。
    """

    def __add_dir_prefix(self, value):
        """
        添加一个前缀，以便redis形成一个树形文件夹，方便批量删除和折叠
        :return:
        """
        return f'{self._redis_key_name}:{value.replace(":", "：")}'  # 任务是json，带有：会形成很多树，换成中文冒号。

    def add_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None):
        redis_key = self.__add_dir_prefix(self.generate_filter_str(value, filter_str))
        self.redis_db_filter_and_rpc_result.set(redis_key, 1)
        self.redis_db_filter_and_rpc_result.expire(redis_key, self._redis_filter_task_expire_seconds)

    def manual_delete_a_value(self, value: typing.Union[str, dict], filter_str: typing.Optional[str] = None):
        self.redis_db_filter_and_rpc_result.delete(self.__add_dir_prefix(self.generate_filter_str(value, filter_str)))

    def check_value_exists(self, value, filter_str: typing.Optional[str] = None):
        return True if self.redis_db_filter_and_rpc_result.exists(self.__add_dir_prefix(self.generate_filter_str(value, filter_str))) else True

    def delete_expire_filter_task_cycle(self):
        """
        redis服务端会自动删除过期的过滤任务键。不用在客户端管理。
        :return:
        """
        pass


if __name__ == '__main__':
    # params_filter = RedisFilter('filter_set:abcdefgh2', 120)
    params_filter = RedisImpermanencyFilter('filter_zset:abcdef2', 120)
    # params_filter = RedisImpermanencyFilterUsingRedisKey('filter_dir', 300)
    for i in range(10):
        # params_filter.add_a_value({'x': i, 'y': i * 2},str(i))
        params_filter.add_a_value({'x': i, 'y': i * 2},None)

    # params_filter.manual_delete_a_value({'a': 1, 'b': 2})
    print(params_filter.check_value_exists({'x': 1, 'y': 2}))
    # params_filter.delete_expire_filter_task_cycle()
    # params_filter.add_a_value({'a': 1, 'b': 5})
    # print(params_filter.check_value_exists({'a': 1, 'b': 2}))
    # time.sleep(130)
    # print(params_filter.check_value_exists({'a': 1, 'b': 2}))

`````

--- **end of file: funboost/consumers/redis_filter.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_pubsub_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_pubsub_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisPbSubConsumer(AbstractConsumer, RedisMixin)`
*Line: 10*

**Docstring:**
`````
redis作为中间件实现的。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.utils.redis_manager import RedisMixin


class RedisPbSubConsumer(AbstractConsumer, RedisMixin):
    """
    redis作为中间件实现的。
    """


    def _dispatch_task0000(self):
        pub = self.redis_db_frame.pubsub()
        pub.subscribe(self.queue_name)
        for item in pub.listen():
            if item['type'] == 'message':

                kw = {'body': item['data']}
                self._submit_task(kw)

    def _dispatch_task(self):
        pub = self.redis_db_frame.pubsub()
        pub.subscribe(self.queue_name)
        pub.parse_response()
        while True:  # 无限循环
            msg_list = pub.parse_response(timeout=60)  # 得到消息内容
            if msg_list:
                kw = {'body': msg_list[2]}
                self._submit_task(kw)



    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/redis_pubsub_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/redis_stream_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/redis_stream_consumer.py`

#### 📦 Imports

- `import json`
- `import redis5`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.utils import decorators`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisStreamConsumer(AbstractConsumer, RedisMixin)`
*Line: 12*

**Docstring:**
`````
redis 的 stream 结构 作为中间件实现的。需要redis 5.0以上，redis stream结构 是redis的消息队列，概念类似kafka，功能远超 list结构。
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2021/4/3 0008 13:32
import json
import redis5
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.utils import decorators
from funboost.utils.redis_manager import RedisMixin


class RedisStreamConsumer(AbstractConsumer, RedisMixin):
    """
    redis 的 stream 结构 作为中间件实现的。需要redis 5.0以上，redis stream结构 是redis的消息队列，概念类似kafka，功能远超 list结构。
    """

    def custom_init(self):
        self.group = self.consumer_params.broker_exclusive_config['group']

    def start_consuming_message(self):
        redis_server_info_dict = self.redis_db_frame.info()
        # print(redis_server_info_dict)
        if float(redis_server_info_dict['redis_version'][0]) < 5:
            raise EnvironmentError('必须是5.0版本以上redis服务端才能支持  stream 数据结构，'
                                   '请升级服务端，否则使用 REDIS_ACK_ABLE 方式使用redis 的 list 结构')
        if self.redis_db_frame.type(self._queue_name) == 'list':
            raise EnvironmentError(f'检测到已存在 {self._queue_name} 这个键，且类型是list， 必须换个队列名字或者删除这个 list 类型的键。'
                                   f'RedisStreamConsumer 使用的是 stream 数据结构')
        self.consumer_params.is_send_consumer_heartbeat_to_redis = True
        super().start_consuming_message()
        self.keep_circulating(60, block=False)(self._requeue_tasks_which_unconfirmed)()

    def _dispatch_task(self):
        pull_msg_batch_size = self.consumer_params.broker_exclusive_config['pull_msg_batch_size']

        try:
            self.redis_db_frame.xgroup_create(self._queue_name,self.group , id=0, mkstream=True)
        except redis5.exceptions.ResponseError as e:
            self.logger.info(e)  # BUSYGROUP Consumer Group name already exists  不能重复创建消费者组。
        while True:
            # redis服务端必须是5.0以上，并且确保这个键的类型是stream不能是list数据结构。
            results = self.redis_db_frame.xreadgroup(self.group, self.consumer_identification,
                                                              {self.queue_name: ">"}, count=pull_msg_batch_size, block=60 * 1000)
            if results:
                # self.logger.debug(f'从redis的 [{self._queue_name}] stream 中 取出的消息是：  {results}  ')
                self._print_message_get_from_broker( results)
                # print(results[0][1])
                for msg_id, msg in results[0][1]:
                    kw = {'body': msg[''], 'msg_id': msg_id}
                    self._submit_task(kw)

    def _confirm_consume(self, kw):
        # self.redis_db_frame.xack(self._queue_name, 'distributed_frame_group', kw['msg_id'])
        # self.redis_db_frame.xdel(self._queue_name, kw['msg_id']) # 便于xlen
        with self.redis_db_frame.pipeline() as pipe:
            pipe.xack(self._queue_name, self.group, kw['msg_id'])
            pipe.xdel(self._queue_name, kw['msg_id'])  # 直接删除不需要保留， 便于xlen
            pipe.execute()

    def _requeue(self, kw):
        self.redis_db_frame.xack(self._queue_name, self.group, kw['msg_id'])
        self.redis_db_frame.xadd(self._queue_name, {'': json.dumps(kw['body'])})
        # print(self.redis_db_frame.xclaim(self._queue_name,
        #                                     'distributed_frame_group', self.consumer_identification,
        #                                     min_idle_time=0, message_ids=[kw['msg_id']]))

    def _requeue_tasks_which_unconfirmed(self):
        lock_key = f'funboost_lock__requeue_tasks_which_unconfirmed:{self._queue_name}'
        with decorators.RedisDistributedLockContextManager(self.redis_db_frame, lock_key, ) as lock:
            if lock.has_aquire_lock:
                self._distributed_consumer_statistics.send_heartbeat()
                current_queue_hearbeat_ids = self._distributed_consumer_statistics.get_queue_heartbeat_ids(without_time=True)
                xinfo_consumers = self.redis_db_frame.xinfo_consumers(self._queue_name, self.group)
                # print(current_queue_hearbeat_ids)
                # print(xinfo_consumers)
                for xinfo_item in xinfo_consumers:
                    # print(xinfo_item)
                    if xinfo_item['idle'] > 7 * 24 * 3600 * 1000 and xinfo_item['pending'] == 0:
                        self.redis_db_frame.xgroup_delconsumer(self._queue_name, self.group, xinfo_item['name'])
                    if xinfo_item['name'] not in current_queue_hearbeat_ids and xinfo_item['pending'] > 0:  # 说明这个消费者掉线断开或者关闭了。
                        pending_msg_list = self.redis_db_frame.xpending_range(
                            self._queue_name, self.group, '-', '+', 1000, xinfo_item['name'])
                        if pending_msg_list:
                            # min_idle_time 不需要，因为加了分布式锁，所以不需要基于idle最小时间的判断，并且启动了基于心跳的确认消费助手，检测消费者掉线或关闭或断开的准确率100%。
                            xclaim_task_list = self.redis_db_frame.xclaim(self._queue_name, self.group,
                                                                                   self.consumer_identification, force=True,
                                                                                   min_idle_time=0 * 1000,
                                                                                   message_ids=[task_item['message_id'] for task_item in pending_msg_list])
                            if xclaim_task_list:
                                self.logger.warning(f' {self._queue_name}  的分组 {self.group} 的消费者 {self.consumer_identification} 夺取 断开的消费者 {xinfo_item["name"]}'
                                                    f'  {len(xclaim_task_list)} 个任务，详细是 {xclaim_task_list} ')
                                for task in xclaim_task_list:
                                    kw = {'body': task[1][''], 'msg_id': task[0]}
                                    self._submit_task(kw)

`````

--- **end of file: funboost/consumers/redis_stream_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/rocketmq_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/rocketmq_consumer.py`

#### 📦 Imports

- `import json`
- `import time`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.rocketmq_publisher import RocketmqPublisher`
- `from funboost.core.func_params_model import PublisherParams`
- `from rocketmq.client import PushConsumer`

#### 🏛️ Classes (1)

##### 📌 `class RocketmqConsumer(AbstractConsumer)`
*Line: 12*

**Docstring:**
`````
安装
`````

**Class Variables (1):**
- `GROUP_ID = 'g_funboost'`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/7/8 0008 13:27
import json
import time
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.rocketmq_publisher import RocketmqPublisher
from funboost.core.func_params_model import PublisherParams

class RocketmqConsumer(AbstractConsumer):
    """
    安装
    """

    GROUP_ID = 'g_funboost'

    def _dispatch_task(self):
        try:
            from rocketmq.client import PushConsumer
        except BaseException as e:
            # print(traceback.format_exc())
            raise ImportError(f'rocketmq包 只支持linux和mac {e}')
        consumer = PushConsumer(f'{self.GROUP_ID}_{self._queue_name}')
        consumer.set_namesrv_addr(BrokerConnConfig.ROCKETMQ_NAMESRV_ADDR)
        consumer.set_thread_count(1)
        consumer.set_message_batch_max_size(self.consumer_params.concurrent_num)

        self._publisher = RocketmqPublisher(publisher_params=PublisherParams(queue_name=self._queue_name,))

        def callback(rocketmq_msg):
            # self.logger.debug(f'从rocketmq的 [{self._queue_name}] 主题的queue_id {rocketmq_msg.queue_id} 中 取出的消息是：{rocketmq_msg.body}')

            kw = {'body': rocketmq_msg.body, 'rocketmq_msg': rocketmq_msg}
            self._submit_task(kw)

        consumer.subscribe(self._queue_name, callback)
        consumer.start()

        while True:
            time.sleep(3600)

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        self._publisher.publish(kw['body'])

`````

--- **end of file: funboost/consumers/rocketmq_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/rq_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/rq_consumer.py`

#### 📦 Imports

- `import time`
- `from funboost.assist.rq_helper import RqHelper`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from rq.decorators import job`

#### 🏛️ Classes (1)

##### 📌 `class RqConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
redis作为中间件实现的。
`````

**Public Methods (2):**
- `def custom_init(self)`
- `def start_consuming_message(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 13:32

import time
from funboost.assist.rq_helper import RqHelper
from funboost.consumers.base_consumer import AbstractConsumer
from rq.decorators import job


class RqConsumer(AbstractConsumer):
    """
    redis作为中间件实现的。
    """

    def custom_init(self):
        self.rq_job = job(queue=self.queue_name, connection=RqHelper.redis_conn)(self.consuming_function)
        RqHelper.queue_name__rq_job_map[self.queue_name] = self.rq_job

    def start_consuming_message(self):
        RqHelper.to_be_start_work_rq_queue_name_set.add(self.queue_name)
        super().start_consuming_message()

    def _dispatch_task(self):
        while 1:
            time.sleep(100)

    def _confirm_consume(self, kw):
        pass

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/rq_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/sqlachemy_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/sqlachemy_consumer.py`

#### 📦 Imports

- `import json`
- `from funboost.constant import BrokerEnum`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.queues import sqla_queue`

#### 🏛️ Classes (1)

##### 📌 `class SqlachemyConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
sqlachemy实现的操作5种数据库模拟消息队列，支持消费确认。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:33
import json
from funboost.constant import BrokerEnum
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.queues import sqla_queue


class SqlachemyConsumer(AbstractConsumer):
    """
    sqlachemy实现的操作5种数据库模拟消息队列，支持消费确认。
    """


    def _dispatch_task(self):
        self.queue = sqla_queue.SqlaQueue(self._queue_name, BrokerConnConfig.SQLACHEMY_ENGINE_URL)
        while True:
            sqla_task_dict = self.queue.get()
            # self.logger.debug(f'从数据库 {frame_config.SQLACHEMY_ENGINE_URL[:25]}。。 的 [{self._queue_name}] 队列中 取出的消息是：   消息是：  {sqla_task_dict}')
            self._print_message_get_from_broker(f'从数据库 {BrokerConnConfig.SQLACHEMY_ENGINE_URL[:25]}', sqla_task_dict)
            kw = {'body': sqla_task_dict['body'], 'sqla_task_dict': sqla_task_dict}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        self.queue.set_success(kw['sqla_task_dict'])

    def _requeue(self, kw):
        self.queue.set_task_status(kw['sqla_task_dict'], sqla_queue.TaskStatus.REQUEUE)


`````

--- **end of file: funboost/consumers/sqlachemy_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/tcp_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/tcp_consumer.py`

#### 📦 Imports

- `import json`
- `from threading import Thread`
- `import socket`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`

#### 🏛️ Classes (1)

##### 📌 `class TCPConsumer(AbstractConsumer)`
*Line: 11*

**Docstring:**
`````
socket 实现消息队列，不支持持久化，但不需要安装软件。
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
from threading import Thread
import socket
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer


class TCPConsumer(AbstractConsumer, ):
    """
    socket 实现消息队列，不支持持久化，但不需要安装软件。
    """



    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        # ip__port_str = self.queue_name.split(':')
        # ip_port = (ip__port_str[0], int(ip__port_str[1]))
        # self._ip_port_raw = ip_port
        # self._ip_port = ('', ip_port[1])
        # ip_port = ('', 9999)
        self._ip_port = (self.consumer_params.broker_exclusive_config['host'],
                         self.consumer_params.broker_exclusive_config['port'])
        self.bufsize = self.consumer_params.broker_exclusive_config['bufsize']

    # noinspection DuplicatedCode
    def _dispatch_task(self):
      
        server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)  # tcp协议
        server.bind(self._ip_port)
        server.listen(128)
        self._server = server
        while True:
            tcp_cli_sock, addr = self._server.accept()
            Thread(target=self.__handle_conn, args=(tcp_cli_sock,)).start()  # 服务端多线程，可以同时处理多个tcp长链接客户端发来的消息。

    def __handle_conn(self, tcp_cli_sock):
        try:
            while True:
                data = tcp_cli_sock.recv(self.bufsize)
                # print('server收到的数据', data)
                if not data:
                    break
                # self._print_message_get_from_broker(f'udp {self._ip_port_raw}', data.decode())
                tcp_cli_sock.send('has_recived'.encode())
                # tcp_cli_sock.close()
                kw = {'body': data}
                self._submit_task(kw)
            tcp_cli_sock.close()
        except ConnectionResetError:
            pass

    def _confirm_consume(self, kw):
        pass  # 没有确认消费的功能。

    def _requeue(self, kw):
        pass

`````

--- **end of file: funboost/consumers/tcp_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/txt_file_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/txt_file_consumer.py`

#### 📦 Imports

- `from pathlib import Path`
- `from nb_filelock import FileLock`
- `from persistqueue import Queue`
- `import json`
- `from persistqueue.serializers import json as json_serializer`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class TxtFileConsumer(AbstractConsumer)`
*Line: 12*

**Docstring:**
`````
txt文件作为消息队列
这个不想做消费确认了,要消费确认请选 SQLITE_QUEUE 、PERSISTQUEUE中间件
`````


---

`````python
﻿from pathlib import Path

from nb_filelock import FileLock
from persistqueue import Queue
import json
from persistqueue.serializers import json as json_serializer
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.funboost_config_deafult import BrokerConnConfig


class TxtFileConsumer(AbstractConsumer, ):
    """
    txt文件作为消息队列
    这个不想做消费确认了,要消费确认请选 SQLITE_QUEUE 、PERSISTQUEUE中间件
    """

    def _dispatch_task(self):
        file_queue_path = str((Path(BrokerConnConfig.TXT_FILE_PATH) / self.queue_name).absolute())
        file_lock = FileLock(Path(file_queue_path) / f'_funboost_txtfile_{self.queue_name}.lock')
        queue = Queue(str((Path(BrokerConnConfig.TXT_FILE_PATH) / self.queue_name).absolute()), autosave=True, serializer=json_serializer)
        while True:
            with file_lock:
                item = queue.get()

                kw = {'body': item, 'q': queue, 'item': item}
                self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass
        # kw['q'].task_done()

    def _requeue(self, kw):
        pass
        # kw['q'].nack(kw['item'])

`````

--- **end of file: funboost/consumers/txt_file_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/udp_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/udp_consumer.py`

#### 📦 Imports

- `import json`
- `import socket`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`

#### 🏛️ Classes (1)

##### 📌 `class UDPConsumer(AbstractConsumer)`
*Line: 10*

**Docstring:**
`````
socket 实现消息队列，不支持持久化，但不需要安装软件。
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:32
import json
import socket
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer


class UDPConsumer(AbstractConsumer, ):
    """
    socket 实现消息队列，不支持持久化，但不需要安装软件。
    """



    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        
        self.__udp_client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        # ip__port_str = self.queue_name.split(':')
        # self.__ip_port = (ip__port_str[0], int(ip__port_str[1]))
        self.__ip_port = (self.consumer_params.broker_exclusive_config['host'],
                          self.consumer_params.broker_exclusive_config['port'])
        self._bufsize = self.consumer_params.broker_exclusive_config['bufsize']
        self.__udp_client.connect(self.__ip_port)

    # noinspection DuplicatedCode
    def _dispatch_task(self):
        ip_port = ('', self.__ip_port[1])
        # ip_port = ('', 9999)
        server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # udp协议
        server.bind(ip_port)
        while True:
            data, client_addr = server.recvfrom(self._bufsize)
            # print('server收到的数据', data)
            # self._print_message_get_from_broker(f'udp {ip_port}', data.decode())
            server.sendto('has_recived'.encode(), client_addr)
            kw = {'body': data}
            self._submit_task(kw)

    def _confirm_consume(self, kw):
        pass  # 没有确认消费的功能。

    def _requeue(self, kw):
        self.__udp_client.send(json.dumps(kw['body']).encode())
        data = self.__udp_client.recv(self._bufsize)

`````

--- **end of file: funboost/consumers/udp_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/zeromq_consumer.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/zeromq_consumer.py`

#### 📦 Imports

- `import os`
- `import socket`
- `import json`
- `import multiprocessing`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.lazy_impoter import ZmqImporter`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🏛️ Classes (1)

##### 📌 `class ZeroMqConsumer(AbstractConsumer)`
*Line: 65*

**Docstring:**
`````
zeromq 中间件的消费者，zeromq基于socket代码，不会持久化，且不需要安装软件。
`````

**Public Methods (1):**
- `def custom_init(self)`

#### 🔧 Public Functions (2)

- `def check_port_is_used(ip, port)`
  - *Line: 17*

- `def start_broker(port_router: int, port_dealer: int)`
  - *Line: 34*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
import os
import socket
import json
# import time
# import zmq
import multiprocessing
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.lazy_impoter import ZmqImporter
# from nb_log import get_logger
from funboost.core.loggers import get_funboost_file_logger


# noinspection PyPep8
def check_port_is_used(ip, port):
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    # noinspection PyPep8,PyBroadException
    try:
        s.connect((ip, int(port)))
        s.shutdown(2)
        # 利用shutdown()函数使socket双向数据传输变为单向数据传输。shutdown()需要一个单独的参数，
        # 该参数表示了如何关闭socket。具体为：0表示禁止将来读；1表示禁止将来写；2表示禁止将来读和写。
        return True
    except BaseException:
        return False


logger_zeromq_broker = get_funboost_file_logger('zeromq_broker')


# noinspection PyUnresolvedReferences
def start_broker(port_router: int, port_dealer: int):
    try:
        context = ZmqImporter().zmq.Context()
        # noinspection PyUnresolvedReferences
        frontend = context.socket(ZmqImporter().zmq.ROUTER)
        backend = context.socket(ZmqImporter().zmq.DEALER)
        frontend.bind(f"tcp://*:{port_router}")
        backend.bind(f"tcp://*:{port_dealer}")

        # Initialize poll set
        poller = ZmqImporter().zmq.Poller()
        poller.register(frontend, ZmqImporter().zmq.POLLIN)
        poller.register(backend, ZmqImporter().zmq.POLLIN)
        logger_zeromq_broker.info(f'broker 绑定端口  {port_router}   {port_dealer}  成功')

        # Switch messages between sockets
        # noinspection DuplicatedCode
        while True:
            socks = dict(poller.poll())  # 轮询器 循环接收

            if socks.get(frontend) == ZmqImporter().zmq.POLLIN:
                message = frontend.recv_multipart()
                backend.send_multipart(message)

            if socks.get(backend) == ZmqImporter().zmq.POLLIN:
                message = backend.recv_multipart()
                frontend.send_multipart(message)
    except BaseException as e:
        logger_zeromq_broker.warning(e)


class ZeroMqConsumer(AbstractConsumer):
    """
    zeromq 中间件的消费者，zeromq基于socket代码，不会持久化，且不需要安装软件。
    """



    def custom_init(self):
        self._port = self.consumer_params.broker_exclusive_config['port']
        if self._port is None:
            raise ValueError('please specify port')

    def _start_broker_port(self):
        # threading.Thread(target=self._start_broker).start()
        # noinspection PyBroadException
        try:
            if not (10000 < int(self._port) < 65535):
                raise ValueError("请设置port是一个 10000到65535的之间的一个端口数字")
        except BaseException:
            self.logger.critical(f" 请设置port是一个 10000到65535的之间的一个端口数字")
            # noinspection PyProtectedMember
            os._exit(444)
        if check_port_is_used('127.0.0.1', int(self._port)):
            self.logger.debug(f"""{int(self._port)} router端口已经启动(或占用) """)
            return
        if check_port_is_used('127.0.0.1', int(self._port) + 1):
            self.logger.debug(f"""{int(self._port) + 1} dealer 端口已经启动(或占用) """)
            return
        multiprocessing.Process(target=start_broker, args=(int(self._port), int(self._port) + 1)).start()

    # noinspection DuplicatedCode
    def _dispatch_task(self):
        self._start_broker_port()
        context = ZmqImporter().zmq.Context()
        # noinspection PyUnresolvedReferences
        zsocket = context.socket(ZmqImporter().zmq.REP)
        zsocket.connect(f"tcp://localhost:{int(self._port) + 1}")

        while True:
            message = zsocket.recv()
            # self.logger.debug(f""" 从 zeromq 取出的消息是 {message}""")
            self._submit_task({'body': message})
            zsocket.send('recv ok'.encode())

    def _confirm_consume(self, kw):
        pass  #

    def _requeue(self, kw):
        self.publisher_of_same_queue.publish(kw['body'])

`````

--- **end of file: funboost/consumers/zeromq_consumer.py** (project: funboost) --- 

---


--- **start of file: funboost/consumers/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/consumers/__init__.py`

#### 📝 Module Docstring

`````
实现基于各种中间件的消费者
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:09
"""
实现基于各种中间件的消费者
"""
`````

--- **end of file: funboost/consumers/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/api_publish_msg.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/api_publish_msg.py`

#### 📝 Module Docstring

`````
这是个简单例子，演示web中如何发布和获取结果。

更建议使用  from funboost.fass ,见教程第15章节。
因为是一键开箱即用，还能更好的和你的fastapi 融合成一个服务端口，而且支持的url路由更多
`````

#### 📦 Imports

- `import traceback`
- `import typing`
- `from funboost import AioAsyncResult`
- `from funboost import AsyncResult`
- `from funboost import TaskOptions`
- `from funboost.core.cli.discovery_boosters import BoosterDiscovery`
- `from funboost import BoostersManager`
- `from fastapi import FastAPI`
- `from pydantic import BaseModel`
- `import uvicorn`

#### 🏛️ Classes (2)

##### 📌 `class MsgItem(BaseModel)`
*Line: 20*

**Class Variables (4):**
- `queue_name: str`
- `msg_body: dict`
- `need_result: bool = False`
- `timeout: int = 60`

##### 📌 `class PublishResponse(BaseModel)`
*Line: 27*

**Class Variables (3):**
- `succ: bool`
- `msg: str`
- `status_and_result: typing.Optional[dict] = None`

#### 🔧 Public Functions (1)

- `async def publish_msg(msg_item: MsgItem)` `app.post('/funboost_publish_msg')`
  - *Line: 43*


---

`````python
"""
这是个简单例子，演示web中如何发布和获取结果。

更建议使用  from funboost.fass ,见教程第15章节。
因为是一键开箱即用，还能更好的和你的fastapi 融合成一个服务端口，而且支持的url路由更多

"""

import traceback
import typing

from funboost import AioAsyncResult, AsyncResult,TaskOptions

from funboost.core.cli.discovery_boosters import BoosterDiscovery
from funboost import BoostersManager
from fastapi import FastAPI
from pydantic import BaseModel


class MsgItem(BaseModel):
    queue_name: str  # 队列名
    msg_body: dict  # 消息体,就是boost函数的入参字典,例如 {"x":1,"y":2}
    need_result: bool = False  # 发布消息后,是否需要返回结果
    timeout: int = 60  # 等待结果返回的最大等待时间.


class PublishResponse(BaseModel):
    succ: bool
    msg: str
    status_and_result: typing.Optional[dict] = None  # 消费函数的消费状态和结果.


# 创建 FastAPI 应用实例
app = FastAPI()

'''
如果你在发布消息后还需要获取函数执行结果,
那么推荐使用asyncio类型的web框架例如 fastapi tornado,而不是使用flask django,更好的应付由于获取结果而需要的阻塞时间.不使用asyncio的话web框架需要设置开启很高的线程才行.
'''


@app.post("/funboost_publish_msg")
async def publish_msg(msg_item: MsgItem):
    status_and_result = None
    try:
        booster = BoostersManager.get_or_create_booster_by_queue_name(msg_item.queue_name)
        if msg_item.need_result:
            if booster.boost_params.is_using_rpc_mode is False:
                raise ValueError(f' need_result 为true,{booster.queue_name} 队列消费者 需要@boost设置支持rpc模式')
            async_result = await booster.aio_publish(msg_item.msg_body,task_options=TaskOptions(is_using_rpc_mode=True))
            status_and_result = await AioAsyncResult(async_result.task_id, timeout=msg_item.timeout).status_and_result
            print(status_and_result)
            # status_and_result = AsyncResult(async_result.task_id, timeout=msg_item.timeout).status_and_result
        else:
            await booster.aio_publish(msg_item.msg_body)
        return PublishResponse(succ=True, msg=f'{msg_item.queue_name} 队列,消息发布成功', status_and_result=status_and_result)
    except Exception as e:
        return PublishResponse(succ=False, msg=f'{msg_item.queue_name} 队列,消息发布失败 {type(e)} {e} {traceback.format_exc()}',
                               status_and_result=status_and_result)


# 运行应用
if __name__ == "__main__":
    import uvicorn

    uvicorn.run('funboost.contrib.api_publish_msg:app', host="0.0.0.0", port=16666, workers=4)

    '''
    test_frame/test_api_publish_msg 中有使用例子.
    '''

`````

--- **end of file: funboost/contrib/api_publish_msg.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/django_db_deco.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/django_db_deco.py`

#### 📦 Imports

- `from django.db import close_old_connections`

#### 🔧 Public Functions (1)

- `def close_old_connections_deco(f)`
  - *Line: 4*
  - **Docstring:**
  `````
  如果是消费函数里面需要操作django orm,那么请写上 consuming_function_decorator=close_old_connections_deco
  @boost(BoosterParams(queue_name='create_student_queue',
                       broker_kind=BrokerEnum.REDIS_ACK_ABLE,
                       consuming_function_decorator=close_old_connections_deco, # 如果gone away 一直好不了,可以加这个装饰器. django_celery django-apschrduler 这些源码中 也是调用了 close_old_connections_deco方法.
  
                       )
         )
  `````


---

`````python
from django.db import close_old_connections


def close_old_connections_deco(f):
    """
    如果是消费函数里面需要操作django orm,那么请写上 consuming_function_decorator=close_old_connections_deco
    @boost(BoosterParams(queue_name='create_student_queue',
                         broker_kind=BrokerEnum.REDIS_ACK_ABLE,
                         consuming_function_decorator=close_old_connections_deco, # 如果gone away 一直好不了,可以加这个装饰器. django_celery django-apschrduler 这些源码中 也是调用了 close_old_connections_deco方法.

                         )
           )
    """

    def _inner(*args, **kwargs):
        close_old_connections()
        try:
            result = f(*args, **kwargs)
        finally:
            close_old_connections()

        return result

    return _inner

`````

--- **end of file: funboost/contrib/django_db_deco.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/funboost框架的额外贡献功能.md** (project: funboost) --- 

`````markdown

## 这里是框架额外贡献的功能.

是作者自带贡献,不是框架运行所必须的.
`````

--- **end of file: funboost/contrib/funboost框架的额外贡献功能.md** (project: funboost) --- 

---


--- **start of file: funboost/contrib/queue2queue.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/queue2queue.py`

#### 📦 Imports

- `import os`
- `import time`
- `import typing`
- `from multiprocessing import Process`
- `import logging`
- `import threading`
- `from funboost import get_publisher`
- `from funboost import get_consumer`
- `from funboost import BrokerEnum`
- `from funboost import wait_for_possible_has_finish_all_tasks_by_conusmer_list`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParams`

#### 🔧 Public Functions (2)

- `def consume_and_push_to_another_queue(source_queue_name: str, source_broker_kind: str, target_queue_name: str, target_broker_kind: str, log_level: int = logging.DEBUG, exit_script_when_finish = False)`
  - *Line: 14*
  - *将队列中的消息移到另一个队列名中，例如把死信队列的消息移到正常队列。*

- `def multi_prcocess_queue2queue(source_target_list: typing.List[typing.List], log_level: int = logging.DEBUG, exit_script_when_finish = False, n = 1)`
  - *Line: 51*
  - **Docstring:**
  `````
  转移多个队列，并使用多进程。
  :param source_target_list:  入参例如  [['test_queue77h5', BrokerEnum.RABBITMQ_AMQPSTORM, 'test_queue77h4', BrokerEnum.RABBITMQ_AMQPSTORM],['test_queue77h6', BrokerEnum.RABBITMQ_AMQPSTORM, 'test_queue77h7', BrokerEnum.REDIS]]
  :param log_level:
  :param exit_script_when_finish:
  :param n:
  :return:
  `````


---

`````python
import os
import time
import typing
from multiprocessing import Process
import logging
import threading

from funboost import get_publisher, get_consumer, BrokerEnum, wait_for_possible_has_finish_all_tasks_by_conusmer_list
from funboost.core.func_params_model import PublisherParams, BoosterParams

""" 将队列中的消息移到另一个队列名中，例如把死信队列的消息移到正常队列。"""


def consume_and_push_to_another_queue(source_queue_name: str, source_broker_kind: str,
                                      target_queue_name: str, target_broker_kind: str,
                                      log_level: int = logging.DEBUG,
                                      exit_script_when_finish=False):
    """ 将队列中的消息移到另一个队列名中，例如把死信队列的消息移到正常队列。"""
    if source_queue_name == target_queue_name and source_broker_kind == target_broker_kind:
        raise ValueError('不能转移消息到当前队列名，否则死循环')

    target_publisher = get_publisher(publisher_params=PublisherParams(queue_name=target_queue_name, broker_kind=target_broker_kind, log_level=log_level))
    msg_cnt = 0
    msg_cnt_lock = threading.Lock()

    def _task_fun(**kwargs):
        # print(kwargs)
        nonlocal msg_cnt
        target_publisher.publish(kwargs)
        with msg_cnt_lock:
            msg_cnt += 1

    source_consumer = get_consumer(boost_params=BoosterParams(queue_name=source_queue_name, broker_kind=source_broker_kind, consuming_function=_task_fun, log_level=log_level))
    source_consumer._set_do_not_delete_extra_from_msg()
    source_consumer.start_consuming_message()
    if exit_script_when_finish:
        source_consumer.wait_for_possible_has_finish_all_tasks(2)
        print(f'消息转移完成，结束脚本,累计从 {source_queue_name} 转移消息到 {target_queue_name} 队列 总数是 {msg_cnt}')
        os._exit(888)  # 结束脚本


def _consume_and_push_to_another_queue_for_multi_process(source_queue_name: str, source_broker_kind: str,
                                                         target_queue_name: str, target_broker_kind: str,
                                                         log_level: int = logging.DEBUG,
                                                         ):
    consume_and_push_to_another_queue(source_queue_name, source_broker_kind, target_queue_name, target_broker_kind, log_level, False)
    while 1:
        time.sleep(3600)


def multi_prcocess_queue2queue(source_target_list: typing.List[typing.List],
                               log_level: int = logging.DEBUG, exit_script_when_finish=False, n=1):
    """
    转移多个队列，并使用多进程。
    :param source_target_list:  入参例如  [['test_queue77h5', BrokerEnum.RABBITMQ_AMQPSTORM, 'test_queue77h4', BrokerEnum.RABBITMQ_AMQPSTORM],['test_queue77h6', BrokerEnum.RABBITMQ_AMQPSTORM, 'test_queue77h7', BrokerEnum.REDIS]]
    :param log_level:
    :param exit_script_when_finish:
    :param n:
    :return:
    """
    source_consumer_list = []
    for (source_queue_name, source_broker_kind, target_queue_name, target_broker_kind) in source_target_list:
        for i in range(n):
            Process(target=_consume_and_push_to_another_queue_for_multi_process,
                    args=(source_queue_name, source_broker_kind, target_queue_name, target_broker_kind, log_level)).start()
        if exit_script_when_finish:
            def _fun():
                pass

            source_consumer = get_consumer(boost_params=BoosterParams(queue_name=source_queue_name, broker_kind=source_broker_kind, consuming_function=_fun,
                                                                      log_level=log_level))
            source_consumer_list.append(source_consumer)
    if exit_script_when_finish:
        wait_for_possible_has_finish_all_tasks_by_conusmer_list(consumer_list=source_consumer_list, minutes=2)
        for (source_queue_name, source_broker_kind, target_queue_name, target_broker_kind) in source_target_list:
            print(f'{source_queue_name}  转移到 {target_queue_name} 消息转移完成，结束脚本')
        os._exit(999)  #


if __name__ == '__main__':
    # 一次转移一个队列，使用单进程
    consume_and_push_to_another_queue('test_queue77h3_dlx', BrokerEnum.REDIS_PRIORITY,
                                      'test_queue77h3', BrokerEnum.REDIS_PRIORITY,
                                      log_level=logging.INFO, exit_script_when_finish=True)

    # 转移多个队列，并使用多进程。
    multi_prcocess_queue2queue([['test_queue77h5', BrokerEnum.RABBITMQ_AMQPSTORM, 'test_queue77h4', BrokerEnum.RABBITMQ_AMQPSTORM]],
                               log_level=logging.INFO, exit_script_when_finish=True, n=6)

`````

--- **end of file: funboost/contrib/queue2queue.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/redis_consume_latest_msg_broker.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/redis_consume_latest_msg_broker.py`

#### 📦 Imports

- `from funboost import register_custom_broker`
- `from funboost import boost`
- `from funboost import FunctionResultStatus`
- `from funboost import BoosterParams`
- `from funboost.consumers.redis_consumer_simple import RedisConsumer`
- `from funboost.publishers.redis_publisher_simple import RedisPublisher`

#### 🏛️ Classes (2)

##### 📌 `class RedisConsumeLatestPublisher(RedisPublisher)`
*Line: 16*

##### 📌 `class RedisConsumeLatestConsumer(RedisConsumer)`
*Line: 21*

#### 🔧 Public Functions (1)

- `def f(x)` `boost(boost_params=BoosterParams(queue_name='test_list_queue2', broker_kind=BROKER_KIND_REDIS_CONSUME_LATEST, qps=10))`
  - *Line: 30*


---

`````python
from funboost import register_custom_broker
from funboost import boost, FunctionResultStatus, BoosterParams
from funboost.consumers.redis_consumer_simple import RedisConsumer
from funboost.publishers.redis_publisher_simple import RedisPublisher

"""
此文件是演示添加自定义类型的中间件,演示怎么使用redis 实现先进后出 后进先出的队列，就是消费总是拉取最晚发布的消息，而不是优先消费最早发布的消息
lpush + lpop 或者 rpush + rpop 就会消费最新发布的消息，如果是 lpush + rpop 或者 rpush + lpop 则会先消费最早发布的消息(框架内置的目前就是消费最早发布的消息)。

此种方式也可以在子类中重写来更改 AbstractConsumer 基类的逻辑,例如你想在任务执行完成后把结果插入到mysql或者做更精细化的定制流程，可以不使用原来推荐的装饰器叠加方式
而是在类中直接重写方法

"""


class RedisConsumeLatestPublisher(RedisPublisher):
    def _publish_impl(self, msg):
        self.redis_db_frame.lpush(self._queue_name, msg)


class RedisConsumeLatestConsumer(RedisConsumer):
    pass


BROKER_KIND_REDIS_CONSUME_LATEST = 'BROKER_KIND_REDIS_CONSUME_LATEST'
register_custom_broker(BROKER_KIND_REDIS_CONSUME_LATEST, RedisConsumeLatestPublisher, RedisConsumeLatestConsumer)  # 核心，这就是将自己写的类注册到框架中，框架可以自动使用用户的类，这样用户无需修改框架的源代码了。

if __name__ == '__main__':
    @boost(boost_params=BoosterParams(queue_name='test_list_queue2', broker_kind=BROKER_KIND_REDIS_CONSUME_LATEST, qps=10, ))
    def f(x):
        print(x * 10)


    f.clear()
    for i in range(50):
        f.push(i)
    print(f.publisher.get_message_count())
    f.consume()  # 从可以看到事从最后发布的消息开始消费。

`````

--- **end of file: funboost/contrib/redis_consume_latest_msg_broker.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/__init__.py`


---

`````python

`````

--- **end of file: funboost/contrib/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/cdc/mysql2mysql.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/cdc/mysql2mysql.py`

#### 📦 Imports

- `import dataset`
- `from typing import Dict`

#### 🏛️ Classes (1)

##### 📌 `class MySql2Mysql`
*Line: 4*

**Docstring:**
`````
使用dataset封装的mysql binlog消息数据,保存到目标库中
有了这个贡献类, 用户只需要一行代码就能通过cdc 实现 mysql2mysql,非常方便把数据库实例1的源表a,自动实时同步到数据库实例2的目标表a

这个只是贡献类,用户想怎么插入表,想怎么清洗都可以,可以参考这个例子,dataset把一个字典保存到mysql的一行,真的很方便.
用户还可以自定义批量插入目标表,都可以. 这个类不是必须使用,是做个示范.
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, primary_key: str, target_table_name: str, target_sink_db: dataset.Database)`
  - **Parameters:**
    - `self`
    - `primary_key: str`
    - `target_table_name: str`
    - `target_sink_db: dataset.Database`

**Public Methods (1):**
- `def sync_data(self, event_type: str, schema: str, table: str, timestamp: int, row_data: Dict)`


---

`````python
import dataset
from typing import Dict

class MySql2Mysql:
    """
    使用dataset封装的mysql binlog消息数据,保存到目标库中
    有了这个贡献类, 用户只需要一行代码就能通过cdc 实现 mysql2mysql,非常方便把数据库实例1的源表a,自动实时同步到数据库实例2的目标表a

    这个只是贡献类,用户想怎么插入表,想怎么清洗都可以,可以参考这个例子,dataset把一个字典保存到mysql的一行,真的很方便.
    用户还可以自定义批量插入目标表,都可以. 这个类不是必须使用,是做个示范.
    """
    def __init__(self, primary_key: str,
                 target_table_name: str,
                 target_sink_db: dataset.Database, ):
        self.primary_key = primary_key
        self.target_table_name = target_table_name
        self.target_sink_db = target_sink_db

    def sync_data(self, event_type: str,
                  schema: str,
                  table: str,
                  timestamp: int,
                  row_data: Dict, ):
        # 例如把这个表里面的数据原封不动 插入到 testdb7.users 表里面
        target_table: dataset.Table = self.target_sink_db[self.target_table_name]  # dataset会根据表名自动获取或创建表
        print(f"接收到事件: {event_type} on schema: {schema},  table: {table}, timestamp: {timestamp}")

        if event_type == 'INSERT':
            # `row_data` 中包含 'values' 字典
            data_to_insert = row_data['values']
            target_table.upsert(data_to_insert, [self.primary_key])
            print(f"  [INSERT] 成功同步数据: {data_to_insert}")

        elif event_type == 'UPDATE':
            # `row_data` 中包含 'before_values' 和 'after_values'
            data_to_update = row_data['after_values']
            target_table.upsert(data_to_update, [self.primary_key])
            print(f"  [UPDATE] 成功同步数据: {data_to_update}")

        elif event_type == 'DELETE':
            # `row_data` 中包含 'values' 字典，即被删除的行的数据
            data_to_delete = row_data['values']
            target_table.delete(**{self.primary_key: data_to_delete[self.primary_key]})
            print(f"  [DELETE] 成功同步数据: {data_to_delete}")
`````

--- **end of file: funboost/contrib/cdc/mysql2mysql.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/cdc/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/cdc/__init__.py`


---

`````python

`````

--- **end of file: funboost/contrib/cdc/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/override_publisher_consumer_cls/funboost_otel_mixin.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/override_publisher_consumer_cls/funboost_otel_mixin.py`

#### 📝 Module Docstring

`````
1.
```md
🚀 Funboost：唯一原生支持 OpenTelemetry 分布式链路追踪的 Python 任务队列框架

✅ 1 行代码接入链路追踪（BoosterParams → OtelBoosterParams）
✅ 跨队列、跨服务完整链路可视化
✅ 与 Jaeger/Zipkin/SkyWalking 无缝对接
✅ 生产级可观测性，排查问题如探囊取物
```

2.
非常牛的 opentelemetry 链路追踪 mixin，完美对接知名 opentelemetry 链路追踪中间件，例如 Jaeger/Zipkin/SkyWalking 等。

3.
用法demo见 test_frame/test_otel/test_otel_override.py

4.funboost 中实现的 OTel Mixin，确实是生产环境的救命稻草。没有它，排查分布式死循环基本靠运气和发际线。
例如你fa向fb发布，fb给fc发布，fc给fa发布，无限懵逼死循环，完蛋了传统的taskid排查不够用，不知道消息是哪来的。

fa -> fb -> fc -> fa -> ...

#### 在 Jaeger / SkyWalking / Funboost TreeExporter 中的视觉效果：
你会看到一个 **“死亡阶梯”** (Staircase to Hell)：

```text
└── 📤 fa send
    └── 📥 fa process
        └── 📤 fb send
            └── 📥 fb process
                └── 📤 fc send
                    └── 📥 fc process
                        └── 📤 fa send  <-- 再次调用 fa
                            └── 📥 fa process
`````

#### 📦 Imports

- `from opentelemetry import trace`
- `from opentelemetry import context`
- `from opentelemetry.propagate import inject`
- `from opentelemetry.propagate import extract`
- `from opentelemetry.trace import Status`
- `from opentelemetry.trace import StatusCode`
- `from opentelemetry.trace import SpanKind`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.func_params_model import BoosterParams`
- `import copy`
- `import typing`

#### 🏛️ Classes (3)

##### 📌 `class AutoOtelPublisherMixin(AbstractPublisher)`
*Line: 73*

**Docstring:**
`````
智能 OTel 发布者：
1. 优先检查消息中是否已携带 otel_context (用户手动传递)
2. 如果没有，则自动使用当前线程的上下文
3. 生成 Producer Span 并注入/覆盖到消息中
`````

**Public Methods (2):**
- `def publish(self, msg, task_id = None, task_options = None)`
- `async def aio_publish(self, msg, task_id = None, task_options = None)`
  - **Docstring:**
  `````
  asyncio 生态下的 OTel 链路追踪发布
  
  关键问题：父类 aio_publish 使用 run_in_executor 在线程池执行 publish，
  但 OTel 上下文是线程本地的，跨线程会丢失。
  
  解决方案：
  1. 在当前 asyncio 线程先捕获 OTel 上下文
  2. 注入到消息的 extra.otel_context 中
  3. 然后调用父类的 aio_publish（在 executor 线程中执行 publish）
  4. publish 方法检测到 otel_context 已存在，会使用它作为父上下文
  `````

##### 📌 `class AutoOtelConsumerMixin(AbstractConsumer)`
*Line: 174*

**Docstring:**
`````
消费者 OTEL Mixin：从消息中提取 Context 并作为 Parent 运行
同时支持同步 (_run) 和异步 (_async_run) 消费函数
`````

##### 📌 `class OtelBoosterParams(BoosterParams)`
*Line: 226*

**Docstring:**
`````
预配置了 OTEL 链路追踪的 BoosterParams
使用这个类可以省去每次手动指定 consumer_override_cls 和 publisher_override_cls
`````

**Class Variables (2):**
- `consumer_override_cls: typing.Type[AutoOtelConsumerMixin] = AutoOtelConsumerMixin`
- `publisher_override_cls: typing.Type[AutoOtelPublisherMixin] = AutoOtelPublisherMixin`

#### 🔧 Public Functions (1)

- `def extract_otel_context_from_funboost_msg(msg: dict)`
  - *Line: 53*
  - **Docstring:**
  `````
  从 msg 的 extra.otel_context 中提取 OTel 上下文 - Publisher 和 Consumer 公共逻辑
  
  :param msg: 消息字典，包含 extra.otel_context 字段
  :return: OTel Context 对象
  
  使用场景：
  - Publisher: extract_otel_context_from_funboost_msg(msg)
  - Consumer: extract_otel_context_from_funboost_msg(kw['body'])
  `````


---

`````python
"""
1.
```md
🚀 Funboost：唯一原生支持 OpenTelemetry 分布式链路追踪的 Python 任务队列框架

✅ 1 行代码接入链路追踪（BoosterParams → OtelBoosterParams）
✅ 跨队列、跨服务完整链路可视化
✅ 与 Jaeger/Zipkin/SkyWalking 无缝对接
✅ 生产级可观测性，排查问题如探囊取物
```

2.
非常牛的 opentelemetry 链路追踪 mixin，完美对接知名 opentelemetry 链路追踪中间件，例如 Jaeger/Zipkin/SkyWalking 等。

3.
用法demo见 test_frame/test_otel/test_otel_override.py

4.funboost 中实现的 OTel Mixin，确实是生产环境的救命稻草。没有它，排查分布式死循环基本靠运气和发际线。
例如你fa向fb发布，fb给fc发布，fc给fa发布，无限懵逼死循环，完蛋了传统的taskid排查不够用，不知道消息是哪来的。

fa -> fb -> fc -> fa -> ...

#### 在 Jaeger / SkyWalking / Funboost TreeExporter 中的视觉效果：
你会看到一个 **“死亡阶梯”** (Staircase to Hell)：

```text
└── 📤 fa send
    └── 📥 fa process
        └── 📤 fb send
            └── 📥 fb process
                └── 📤 fc send
                    └── 📥 fc process
                        └── 📤 fa send  <-- 再次调用 fa
                            └── 📥 fa process

"""



from opentelemetry import trace, context
from opentelemetry.propagate import inject, extract
from opentelemetry.trace import Status, StatusCode, SpanKind
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.serialization import Serialization
from funboost.core.func_params_model import BoosterParams
import copy
import typing

tracer = trace.get_tracer("funboost")


def extract_otel_context_from_funboost_msg(msg: dict):
    """
    从 msg 的 extra.otel_context 中提取 OTel 上下文 - Publisher 和 Consumer 公共逻辑
    
    :param msg: 消息字典，包含 extra.otel_context 字段
    :return: OTel Context 对象
    
    使用场景：
    - Publisher: extract_otel_context_from_funboost_msg(msg)
    - Consumer: extract_otel_context_from_funboost_msg(kw['body'])
    """
    carrier = msg.get('extra', {}).get('otel_context')
    if carrier:
        # 【显式】：carrier 存在，从中提取上下文（解决跨线程/手动透传问题）
        return extract(carrier)
    else:
        # 【隐式】：carrier 不存在，使用当前线程上下文
        return context.get_current()


class AutoOtelPublisherMixin(AbstractPublisher):
    """
    智能 OTel 发布者：
    1. 优先检查消息中是否已携带 otel_context (用户手动传递)
    2. 如果没有，则自动使用当前线程的上下文
    3. 生成 Producer Span 并注入/覆盖到消息中
    """
    
    def _get_parent_context(self, msg: dict):
        """确定父级上下文 (Parent Context)"""
        return extract_otel_context_from_funboost_msg(msg)
    
    def _inject_otel_context_to_msg(self, msg: dict):
        """
        将当前线程的 OTel 上下文注入到消息的 extra.otel_context 中
        用于 aio_publish 场景：在 asyncio 线程先捕获上下文，
        然后通过消息传递到 executor 线程
        """
        if 'extra' not in msg:
            msg['extra'] = {}
        
        # 只有当用户没有手动传递 otel_context 时才注入
        if not msg['extra'].get('otel_context'):
            carrier = {}
            inject(carrier)  # 将当前线程的上下文注入到 carrier
            msg['extra']['otel_context'] = carrier
    
    def publish(self, msg, task_id=None, task_options=None):
        msg = copy.deepcopy(msg)  # 字典是可变对象,不要改变影响用户自身的传参字典. 用户可能继续使用这个传参字典.
        msg, msg_function_kw, extra_params, task_id = self._convert_msg(msg, task_id, task_options)
        
        # -------------------------------------------------------
        # 2. 确定父级上下文 (Parent Context)
        # -------------------------------------------------------
        parent_ctx = self._get_parent_context(msg)

        # -------------------------------------------------------
        # 3. 开启 Producer Span (链接到 parent_ctx)
        # -------------------------------------------------------
        span_name = f"{self.queue_name} send"
        
        with tracer.start_as_current_span(
            span_name, 
            context=parent_ctx, # 关键：使用刚才确定的父级
            kind=SpanKind.PRODUCER
        ) as span:
            
            span.set_attribute("messaging.system", "funboost")
            span.set_attribute("messaging.destination", self.queue_name)

            
            # ---------------------------------------------------
            # 4. 注入新的 Context (Inject)
            # ---------------------------------------------------
            # 无论之前有没有 context，这里都要注入当前 Producer Span 的 context
            # 这样下游消费者看到的父节点才是这个 Producer Span，保证链路完整：
            # Upstream -> Producer(Send) -> Consumer(Process)
            
            carrier = {}
            inject(carrier) # 将当前 Span (Producer) 注入到 carrier
            
            if 'extra' not in msg:
                msg['extra'] = {}
            
            # 覆盖/写入最新的链路信息
            msg['extra']['otel_context'] = carrier
            
            # 记录 Task ID
            span.set_attribute("messaging.message_id", task_id)

            try:
                return super().publish(msg, task_id, task_options)
            except Exception as e:
                span.record_exception(e)
                span.set_status(Status(StatusCode.ERROR))
                raise e

    async def aio_publish(self, msg, task_id=None, task_options=None):
        """
        asyncio 生态下的 OTel 链路追踪发布
        
        关键问题：父类 aio_publish 使用 run_in_executor 在线程池执行 publish，
        但 OTel 上下文是线程本地的，跨线程会丢失。
        
        解决方案：
        1. 在当前 asyncio 线程先捕获 OTel 上下文
        2. 注入到消息的 extra.otel_context 中
        3. 然后调用父类的 aio_publish（在 executor 线程中执行 publish）
        4. publish 方法检测到 otel_context 已存在，会使用它作为父上下文
        """
        msg = copy.deepcopy(msg)  # 字典是可变对象,不要改变影响用户自身的传参字典
        
        # 在当前 asyncio 线程捕获 OTel 上下文并注入到消息中
        # 这样当 publish 在 executor 线程执行时，能从消息中恢复正确的父上下文
        self._inject_otel_context_to_msg(msg) # 这是核心，
        
        # 调用父类的 aio_publish，它会在 executor 中调用 self.publish
        # publish 方法会检测到 msg['extra']['otel_context'] 并使用它
        return await super().aio_publish(msg, task_id, task_options)


class AutoOtelConsumerMixin(AbstractConsumer):
    """
    消费者 OTEL Mixin：从消息中提取 Context 并作为 Parent 运行
    同时支持同步 (_run) 和异步 (_async_run) 消费函数
    """
    
    def _extract_otel_context(self, kw: dict):
        """提取 OTEL 上下文"""
        return extract_otel_context_from_funboost_msg(kw['body'])
    
    def _set_span_attributes(self, span, kw: dict):
        """设置 Span 属性（公共逻辑）"""
        span.set_attribute("messaging.system", "funboost")
        span.set_attribute("messaging.destination", self.queue_name)
        span.set_attribute("messaging.message_id", kw['body']['extra']['task_id'])
        span.set_attribute("messaging.operation", "process")
        span.set_attribute("funboost.function_params", Serialization.to_json_str(kw['function_only_params'])[:200])

    def _run(self, kw: dict):
        """同步消费函数的链路追踪"""
        ctx = self._extract_otel_context(kw)
        span_name = f"{self.queue_name} process"
        
        with tracer.start_as_current_span(span_name, context=ctx, kind=SpanKind.CONSUMER) as span:
            self._set_span_attributes(span, kw)
            try:
                return super()._run(kw)
            except Exception as e:
                span.record_exception(e)
                span.set_status(Status(StatusCode.ERROR))
                raise 
                # raise e 这个不好，没有直接raise好

    async def _async_run(self, kw: dict):
        """异步消费函数的链路追踪
        
        """
        ctx = self._extract_otel_context(kw)
        span_name = f"{self.queue_name} process"
        
        with tracer.start_as_current_span(span_name, context=ctx, kind=SpanKind.CONSUMER) as span:
            self._set_span_attributes(span, kw)
            try:
                return await super()._async_run(kw)
            except Exception as e:
                span.record_exception(e)
                span.set_status(Status(StatusCode.ERROR))
                raise 




class OtelBoosterParams(BoosterParams):
    """
    预配置了 OTEL 链路追踪的 BoosterParams
    使用这个类可以省去每次手动指定 consumer_override_cls 和 publisher_override_cls
    """
    consumer_override_cls: typing.Type[AutoOtelConsumerMixin] = AutoOtelConsumerMixin
    publisher_override_cls: typing.Type[AutoOtelPublisherMixin] = AutoOtelPublisherMixin
`````

--- **end of file: funboost/contrib/override_publisher_consumer_cls/funboost_otel_mixin.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/override_publisher_consumer_cls/otel_tree_span_exporter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/override_publisher_consumer_cls/otel_tree_span_exporter.py`

#### 📝 Module Docstring

`````
TreeSpanExporter - 在控制台显示树状链路追踪图

无需安装 Jaeger 等中间件，直接在控制台查看树状结构的链路追踪图，这个是在测试环境用户自己使用的，生产环境不要用这。
生产环境强烈建议使用专业的 opentelemetry 链路追踪中间件，例如 Jaeger/Zipkin/SkyWalking 等。

用法demo见 test_frame/test_otel/test_otel_tree_view.py
`````

#### 📦 Imports

- `import atexit`
- `import threading`
- `from collections import defaultdict`
- `from typing import Sequence`
- `from typing import Dict`
- `from typing import List`
- `from typing import Optional`
- `from opentelemetry.sdk.trace import ReadableSpan`
- `from opentelemetry.sdk.trace.export import SpanExporter`
- `from opentelemetry.sdk.trace.export import SpanExportResult`
- `from nb_log import print_raw`

#### 🏛️ Classes (1)

##### 📌 `class TreeSpanExporter(SpanExporter)`
*Line: 97*

**Docstring:**
`````
树状结构 Span 导出器

收集所有 Span，在程序结束时或手动调用 print_tree() 时，
以树状结构打印链路追踪图。

使用方式:
    tree_exporter = TreeSpanExporter()
    provider.add_span_processor(BatchSpanProcessor(tree_exporter))
    
    # 程序结束时自动打印，或手动调用：
    tree_exporter.print_tree()
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, auto_print_on_exit: bool = False)`
  - **Docstring:**
  `````
  初始化 TreeSpanExporter
  
  Args:
      auto_print_on_exit: 是否在程序退出时自动打印树状图，默认 False
                         （funboost 消费者是永久运行的，atexit 通常不会触发，
                          建议使用 wait_for_possible_has_finish_all_tasks 判断完成后手动调用 print_tree()）
  `````
  - **Parameters:**
    - `self`
    - `auto_print_on_exit: bool = False`

**Public Methods (5):**
- `def export(self, spans: Sequence[ReadableSpan]) -> SpanExportResult`
  - *导出 Span（收集到内存中）*
- `def shutdown(self) -> None`
  - *关闭导出器*
- `def force_flush(self, timeout_millis: int = 30000) -> bool`
  - *强制刷新*
- `def print_tree(self) -> None`
  - *打印所有链路的树状结构图*
- `def clear(self) -> None`
  - *清空已收集的 Span 数据*

#### 🔧 Public Functions (2)

- `def get_tree_exporter(auto_print_on_exit: bool = False) -> TreeSpanExporter`
  - *Line: 265*
  - *获取全局 TreeSpanExporter 单例*

- `def print_trace_tree() -> None`
  - *Line: 273*
  - *打印全局 TreeSpanExporter 中收集的链路树*


---

`````python
# -*- coding: utf-8 -*-
"""
TreeSpanExporter - 在控制台显示树状链路追踪图

无需安装 Jaeger 等中间件，直接在控制台查看树状结构的链路追踪图，这个是在测试环境用户自己使用的，生产环境不要用这。
生产环境强烈建议使用专业的 opentelemetry 链路追踪中间件，例如 Jaeger/Zipkin/SkyWalking 等。

用法demo见 test_frame/test_otel/test_otel_tree_view.py
"""

# 完美的树状结构图，能清的看到消息流转过程。
# task_entry 发布2个任务到otel_tree_task_process，otel_tree_task_process 再发布1个任务到otel_tree_task_notify
"""
================================================================================
🌳 链路追踪树状结构图
================================================================================

📍 Trace ID: f50f7a80f0b8f88b97788093157c4ae2
------------------------------------------------------------
└── 📤 otel_tree_task_entry send [PRODUCER] ✅ 11.0ms
       🆔 span_id: 0x1c167373656fdc13    parent_id: null
       📋 task_id: 019b4ed4-144d-76b2-86b0-7d4939fc94dc
    └── 📥 otel_tree_task_entry process [CONSUMER] ✅ 323.2ms
           🆔 span_id: 0xbc7fa8b030d5f600    parent_id: 0x1c167373656fdc13
           📋 task_id: 019b4ed4-144d-76b2-86b0-7d4939fc94dc
        ├── 📤 otel_tree_task_process send [PRODUCER] ✅ 2.0ms
        │      🆔 span_id: 0xc1a5e958ffd61344    parent_id: 0xbc7fa8b030d5f600
        │      📋 task_id: 019b4ed4-1a6d-7be3-8516-192449685f6d
        │   └── 📥 otel_tree_task_process process [CONSUMER] ✅ 215.9ms
        │          🆔 span_id: 0x575c4f47a70564b9    parent_id: 0xc1a5e958ffd61344
        │          📋 task_id: 019b4ed4-1a6d-7be3-8516-192449685f6d
        │       └── 📤 otel_tree_task_notify send [PRODUCER] ✅ 2.0ms
        │              🆔 span_id: 0x81e9758e44a4ba61    parent_id: 0x575c4f47a70564b9      
        │              📋 task_id: 019b4ed4-4118-79fd-965c-c080bb0ca775
        │           └── 📥 otel_tree_task_notify process [CONSUMER] ✅ 118.5ms
        │                  🆔 span_id: 0x669734d0fa7eae20    parent_id: 0x81e9758e44a4ba61  
        │                  📋 task_id: 019b4ed4-4118-79fd-965c-c080bb0ca775
        └── 📤 otel_tree_task_process send [PRODUCER] ✅ 2.3ms
               🆔 span_id: 0x986af7dffd837e77    parent_id: 0xbc7fa8b030d5f600
               📋 task_id: 019b4ed4-1a70-7d62-99cd-7e6e0f9038bf
            └── 📥 otel_tree_task_process process [CONSUMER] ✅ 212.6ms
                   🆔 span_id: 0xdb03f7288701f9bd    parent_id: 0x986af7dffd837e77
                   📋 task_id: 019b4ed4-1a70-7d62-99cd-7e6e0f9038bf
                └── 📤 otel_tree_task_notify send [PRODUCER] ✅ 2.0ms
                       🆔 span_id: 0x5ad4e057be91c960    parent_id: 0xdb03f7288701f9bd      
                       📋 task_id: 019b4ed4-4120-7c53-8a5f-4f653d4e486f
                    └── 📥 otel_tree_task_notify process [CONSUMER] ✅ 107.7ms
                           🆔 span_id: 0xff4fd0fdf38fed92    parent_id: 0x5ad4e057be91c960  
                           📋 task_id: 019b4ed4-4120-7c53-8a5f-4f653d4e486f

📍 Trace ID: 6b0053464b0d8649a7ff5a09e34a6813
------------------------------------------------------------
└── 📤 otel_tree_task_entry send [PRODUCER] ✅ 6.5ms
       🆔 span_id: 0xe0d40211831caab2    parent_id: null
       📋 task_id: 019b4ed4-145b-7dcf-8e0b-ff2e334ec309
    └── 📥 otel_tree_task_entry process [CONSUMER] ✅ 321.0ms
           🆔 span_id: 0x607c15d155921877    parent_id: 0xe0d40211831caab2
           📋 task_id: 019b4ed4-145b-7dcf-8e0b-ff2e334ec309
        ├── 📤 otel_tree_task_process send [PRODUCER] ✅ 2.3ms
        │      🆔 span_id: 0xb7e76886ba6b0ab0    parent_id: 0x607c15d155921877
        │      📋 task_id: 019b4ed4-1a6e-7a1d-ad82-5231ec9bc56e
        │   └── 📥 otel_tree_task_process process [CONSUMER] ✅ 214.6ms
        │          🆔 span_id: 0x9a1d938da26d9eb8    parent_id: 0xb7e76886ba6b0ab0
        │          📋 task_id: 019b4ed4-1a6e-7a1d-ad82-5231ec9bc56e
        │       └── 📤 otel_tree_task_notify send [PRODUCER] ✅ 1.8ms
        │              🆔 span_id: 0x6e66697fcee92094    parent_id: 0x9a1d938da26d9eb8      
        │              📋 task_id: 019b4ed4-411d-775c-b592-84396f0857b4
        │           └── 📥 otel_tree_task_notify process [CONSUMER] ✅ 115.8ms
        │                  🆔 span_id: 0xd1d7235f6b247456    parent_id: 0x6e66697fcee92094  
        │                  📋 task_id: 019b4ed4-411d-775c-b592-84396f0857b4
        └── 📤 otel_tree_task_process send [PRODUCER] ✅ 1.5ms
               🆔 span_id: 0xa22a5683b764f63b    parent_id: 0x607c15d155921877
               📋 task_id: 019b4ed4-1a71-741a-ad95-5cf65ce9b8f0
            └── 📥 otel_tree_task_process process [CONSUMER] ✅ 220.8ms
                   🆔 span_id: 0x14963a0749d609b8    parent_id: 0xa22a5683b764f63b
                   📋 task_id: 019b4ed4-1a71-741a-ad95-5cf65ce9b8f0
                └── 📤 otel_tree_task_notify send [PRODUCER] ✅ 5.1ms
                       🆔 span_id: 0x6056d9ba300a795f    parent_id: 0x14963a0749d609b8      
                       📋 task_id: 019b4ed4-41ff-7146-8766-7e2bbe5e97fd
                    └── 📥 otel_tree_task_notify process [CONSUMER] ✅ 106.6ms
                           🆔 span_id: 0x911ac90dd90b901d    parent_id: 0x6056d9ba300a795f  
                           📋 task_id: 019b4ed4-41ff-7146-8766-7e2bbe5e97fd
================================================================================
"""

import atexit
import threading
from collections import defaultdict
from typing import Sequence, Dict, List, Optional

from opentelemetry.sdk.trace import ReadableSpan
from opentelemetry.sdk.trace.export import SpanExporter, SpanExportResult

from nb_log import print_raw


class TreeSpanExporter(SpanExporter):
    """
    树状结构 Span 导出器
    
    收集所有 Span，在程序结束时或手动调用 print_tree() 时，
    以树状结构打印链路追踪图。
    
    使用方式:
        tree_exporter = TreeSpanExporter()
        provider.add_span_processor(BatchSpanProcessor(tree_exporter))
        
        # 程序结束时自动打印，或手动调用：
        tree_exporter.print_tree()
    """
    
    def __init__(self, auto_print_on_exit: bool = False):
        """
        初始化 TreeSpanExporter
        
        Args:
            auto_print_on_exit: 是否在程序退出时自动打印树状图，默认 False
                               （funboost 消费者是永久运行的，atexit 通常不会触发，
                                建议使用 wait_for_possible_has_finish_all_tasks 判断完成后手动调用 print_tree()）
        """
        self._spans: Dict[str, List[ReadableSpan]] = defaultdict(list)  # trace_id -> spans
        self._lock = threading.Lock()
        self._shutdown = False
        
        if auto_print_on_exit:
            atexit.register(self.print_tree)
    
    def export(self, spans: Sequence[ReadableSpan]) -> SpanExportResult:
        """导出 Span（收集到内存中）"""
        if self._shutdown:
            return SpanExportResult.SUCCESS
            
        with self._lock:
            for span in spans:
                trace_id = format(span.context.trace_id, '032x')
                self._spans[trace_id].append(span)
        
        return SpanExportResult.SUCCESS
    
    def shutdown(self) -> None:
        """关闭导出器"""
        self._shutdown = True
    
    def force_flush(self, timeout_millis: int = 30000) -> bool:
        """强制刷新"""
        return True
    
    def print_tree(self) -> None:
        """打印所有链路的树状结构图"""
        with self._lock:
            if not self._spans:
                print_raw("\n📭 没有收集到任何链路追踪数据\n")
                return
            
            print_raw("\n" + "=" * 80)
            print_raw("🌳 链路追踪树状结构图")
            print_raw("=" * 80)
            
            for trace_id, spans in self._spans.items():
                self._print_trace_tree(trace_id, spans)
            
            print_raw("=" * 80 + "\n")
    
    def _print_trace_tree(self, trace_id: str, spans: List[ReadableSpan]) -> None:
        """打印单条链路的树状结构"""
        print_raw(f"\n📍 Trace ID: {trace_id}")
        print_raw("-" * 60)
        
        # 构建 span_id -> span 的映射
        span_map: Dict[str, ReadableSpan] = {}
        for span in spans:
            span_id = format(span.context.span_id, '016x')
            span_map[span_id] = span
        
        # 构建 parent_id -> children 的映射
        children_map: Dict[Optional[str], List[str]] = defaultdict(list)
        for span in spans:
            span_id = format(span.context.span_id, '016x')
            parent_id = format(span.parent.span_id, '016x') if span.parent else None
            children_map[parent_id].append(span_id)
        
        # 找到根节点（没有 parent 或 parent 不在当前 trace 中）
        root_spans = []
        for span in spans:
            span_id = format(span.context.span_id, '016x')
            parent_id = format(span.parent.span_id, '016x') if span.parent else None
            if parent_id is None or parent_id not in span_map:
                root_spans.append(span_id)
        
        # 按时间排序根节点
        root_spans.sort(key=lambda sid: span_map[sid].start_time)
        
        # 递归打印树
        for root_id in root_spans:
            self._print_span_tree(span_map, children_map, root_id, prefix="", is_last=True)
    
    def _print_span_tree(
        self, 
        span_map: Dict[str, ReadableSpan],
        children_map: Dict[Optional[str], List[str]],
        span_id: str,
        prefix: str,
        is_last: bool
    ) -> None:
        """递归打印 Span 树"""
        span = span_map[span_id]
        
        # 计算耗时
        duration_ns = span.end_time - span.start_time if span.end_time else 0
        duration_ms = duration_ns / 1_000_000
        
        # 确定图标
        kind = str(span.kind).split('.')[-1]
        if kind == "PRODUCER":
            icon = "📤"
        elif kind == "CONSUMER":
            icon = "📥"
        else:
            icon = "⚡"
        
        # 获取状态
        status = span.status.status_code.name if span.status else "UNSET"
        status_icon = "✅" if status in ("UNSET", "OK") else "❌"
        
        # 构建连接线
        connector = "└── " if is_last else "├── "
        
        # 打印当前节点
        print_raw(f"{prefix}{connector}{icon} {span.name} [{kind}] {status_icon} {duration_ms:.1f}ms")

        # 打印 span_id / parent_id（用于排查链路父子关系）
        parent_span_id = format(span.parent.span_id, '016x') if span.parent else None
        child_prefix = prefix + ("    " if is_last else "│   ")
        print_raw(
            f"{child_prefix}   🆔 span_id: 0x{span_id}    parent_id: "
            f"{('null' if parent_span_id is None else ('0x' + parent_span_id))}"
        )
        
        # 打印属性（简化版）
        if span.attributes:
            msg_id = span.attributes.get("messaging.message_id", "")
            if msg_id:
                print_raw(f"{child_prefix}   📋 task_id: {msg_id}")
        
        # 递归打印子节点
        children = children_map.get(span_id, [])
        # 按时间排序
        children.sort(key=lambda sid: span_map[sid].start_time)
        
        for i, child_id in enumerate(children):
            child_prefix = prefix + ("    " if is_last else "│   ")
            child_is_last = (i == len(children) - 1)
            self._print_span_tree(span_map, children_map, child_id, child_prefix, child_is_last)
    
    def clear(self) -> None:
        """清空已收集的 Span 数据"""
        with self._lock:
            self._spans.clear()


# 全局单例，方便使用
_global_tree_exporter: Optional[TreeSpanExporter] = None


def get_tree_exporter(auto_print_on_exit: bool = False) -> TreeSpanExporter:
    """获取全局 TreeSpanExporter 单例"""
    global _global_tree_exporter
    if _global_tree_exporter is None:
        _global_tree_exporter = TreeSpanExporter(auto_print_on_exit=auto_print_on_exit)
    return _global_tree_exporter


def print_trace_tree() -> None:
    """打印全局 TreeSpanExporter 中收集的链路树"""
    if _global_tree_exporter:
        _global_tree_exporter.print_tree()
    else:
        print_raw("⚠️ TreeSpanExporter 尚未初始化")


`````

--- **end of file: funboost/contrib/override_publisher_consumer_cls/otel_tree_span_exporter.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/override_publisher_consumer_cls/README.md** (project: funboost) --- 

`````markdown
# override_publisher_consumer_cls 目录介绍

## 1.1 `funboost/contrib/override_publisher_consumer_cls` 目录下是放各种 贡献者贡献的 `consumer_override_cls` 和 `publisher_override_cls` 的实现。

用户可以非常方便的直接使用这里面的mixin父类。

用法见funboost教程4.21章节。    
@boost(BoosterParams(
    consumer_override_cls=XXXXConsumerMixin, 
    publisher_override_cls=XXXXPublisherMixin
)


# 2.1 funboost_otel_mixin.py，opentelemetry 全链路任务追踪可观测，是funboost的一个生产级别的重要战略级功能

使用方式，就是可以直接使用OtelBoosterParams  
或者你在你的BoosterParams中指定consumer_override_cls和publisher_override_cls为OtelConsumerMixin和OtelPublisherMixin。

```python
@boost(OtelBoosterParams(
    queue_name='otel_tree_task_entry',
))
```


Funboost 的 OTel 实现写得**非常出色，且极其重要**。它是 Funboost 作为一个现代分布式框架的“皇冠上的明珠”。作者通过极其优雅的 **Mixin（混入）模式** 和 **上下文注入** 技术，以**零侵入**的方式实现了标准化的全链路追踪。

## 2.1.1 **优雅的非侵入式设计 (Mixin Pattern)**
这也是 Funboost 架构灵活性的体现。作者没有修改 `Booster` 或 `AbstractConsumer` 的核心源码来硬塞追踪逻辑，而是利用了 `consumer_override_cls` 和 `publisher_override_cls` 接口。
*   **代码位置**: `funboost/contrib/override_publisher_consumer_cls/funboost_otel_mixin.py`
*   **使用demo**：`test_frame/test_otel`
*   **实现方式**:
    *   `AutoOtelPublisherMixin`: 重写 `publish`，在发送消息前创建 `PRODUCER` span，并将 trace context **注入 (Inject)** 到消息体 `msg['extra']` 中。
    *   `AutoOtelConsumerMixin`: 重写 `_run` (同步) 和 `_async_run` (异步)，从消息体取出 context 进行 **提取 (Extract)**，并以此为父节点创建 `CONSUMER` span。
*   **优点**: 这种设计完全解耦。不想用 OTel 的人，核心代码里没有任何 OTel 的痕迹（包体积小）；想用的人，只需替换类即可。

### 2.1.2 **标准化的上下文传播 (Context Propagation)**
这是分布式追踪最难也是最核心的部分。
*   **生产者端**: 使用 `opentelemetry.propagate.inject` 将当前的 TraceID/SpanID 塞入消息字典。
*   **消费者端**: 使用 `opentelemetry.propagate.extract` 从消息中恢复上下文。
*   **效果**: 这保证了 `上游服务 -> Redis/RabbitMQ -> Funboost消费者` 这条链路是不断的。如果没有这一步，消费者生成的 Span 就会是一个新的孤立 Trace，失去了追踪的意义。

### 2.1.3 **极致的扩展性：架构层面完胜 Celery**
这一实现完美诠释了 Funboost 在架构设计上的**高可扩展性与自定义能力**。
在 Celery 中，若想手动侵入核心链路来实现类似 `funboost_otel_mixin.py` 的上下文注入功能，通常需要深入研究复杂的 Signal 信号机制、自定义 Task 类甚至魔改底层 Kombu 库，实现门槛极高且难以维护。
而在 Funboost 中，得益于开放的 `override_cls` 接口，开发者仅需通过标准的 **OOP 继承与 Mixin 模式** 即可轻松切入框架核心流程，实现从简单的日志记录到复杂的全链路追踪等任意定制化需求。
`````

--- **end of file: funboost/contrib/override_publisher_consumer_cls/README.md** (project: funboost) --- 

---


--- **start of file: funboost/contrib/save_function_result_status/readme.md** (project: funboost) --- 

`````markdown


# 用户想保存函数消费结果状态到mysql,可以建表如下

如果用户想保存funboost 消费函数结果状态,到mysql ,可以创建一个表,例如
(使用dataset,可以直接保存字典时候自动建表)

```sql
CREATE TABLE funboost_consume_results
(

    _id                       varchar(255) not null,
    `function`                varchar(255) null,
    host_name                 varchar(255) null,
    host_process              varchar(255) null,
    insert_minutes            varchar(255) null,
    insert_time               datetime     null,
    insert_time_str           varchar(255) null,
    publish_time              float        null,
    publish_time_format       varchar(255) null,
    msg_dict                  json         null,
    params                    json         null,
    params_str                varchar(255) null,
    process_id                bigint       null,
    queue_name                varchar(255) null,
    result                    text null,
    run_times                 int          null,
    script_name               varchar(255) null,
    script_name_long          varchar(255) null,
    success                   tinyint(1)   null,
    task_id                   varchar(255) null,
    thread_id                 bigint       null,
    time_cost                 float        null,
    time_end                  float        null,
    time_start                float        null,
    total_thread              int          null,
    utime                     varchar(255) null,
    exception                 mediumtext   null,
    rpc_result_expire_seconds bigint       null,
    exception_type            varchar(255) null,
    exception_msg             text         null,
    rpc_chain_error_msg_dict  text         null,
    run_status                varchar(255) null,

    primary key (_id),
    key idx_insert_time (insert_time),
    key idx_queue_name_insert_time (queue_name, insert_time),
    key idx_params_str (params_str)
)
```
`````

--- **end of file: funboost/contrib/save_function_result_status/readme.md** (project: funboost) --- 

---


--- **start of file: funboost/contrib/save_function_result_status/save_result_status_to_sqldb.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/save_function_result_status/save_result_status_to_sqldb.py`

#### 📝 Module Docstring

`````
一个贡献,保存函数结果状态到 mysql postgre 等等,因为默认是使用mongo保存.

可以在 @boost里面指定 user_custom_record_process_info_func= save_result_status_to_sqlalchemy
`````

#### 📦 Imports

- `import copy`
- `import functools`
- `import json`
- `from db_libs.sqla_lib import SqlaReflectHelper`
- `from sqlalchemy import create_engine`
- `from funboost import boost`
- `from funboost import FunctionResultStatus`
- `from funboost import funboost_config_deafult`

#### 🔧 Public Functions (2)

- `def get_sqla_helper()` `functools.lru_cache()`
  - *Line: 52*

- `def save_result_status_to_sqlalchemy(function_result_status: FunctionResultStatus)`
  - *Line: 65*
  - **Docstring:**
  `````
  function_result_status变量上有各种丰富的信息 ,用户可以使用其中的信息
  用户自定义记录函数消费信息的钩子函数
  
  例如  @boost('test_user_custom', user_custom_record_process_info_func=save_result_status_to_sqlalchemy)
  `````


---

`````python

"""
一个贡献,保存函数结果状态到 mysql postgre 等等,因为默认是使用mongo保存.

可以在 @boost里面指定 user_custom_record_process_info_func= save_result_status_to_sqlalchemy
"""


import copy
import functools
import json

from db_libs.sqla_lib import SqlaReflectHelper
from sqlalchemy import create_engine

from funboost import boost, FunctionResultStatus, funboost_config_deafult




def _gen_insert_sql_and_values_by_dict(dictx: dict):
    key_list = [f'`{k}`' for k in dictx.keys()]
    fields = ", ".join(key_list)

    # 构建占位符字符串
    placeholders = ", ".join(['%s'] * len(dictx))

    # 构建插入语句
    insert_sql = f"INSERT INTO funboost_consume_results ({fields}) VALUES ({placeholders})"

    # 获取数据字典的值作为插入的值
    values = tuple(dictx.values())
    values_new = tuple([json.dumps(v) if isinstance(v, dict) else v for v in values])
    return insert_sql, values_new


def _gen_insert_sqlalchemy(dictx: dict):
    key_list = [f'`{k}`' for k in dictx.keys()]
    fields = ", ".join(key_list)

    value_list = dictx.keys()
    value_list_2 = [f':{f}' for f in value_list]
    values = ", ".join(value_list_2)

    # 构建插入语句
    insert_sql = f"INSERT INTO funboost_consume_results ({fields}) VALUES ({values})"

    return insert_sql


@functools.lru_cache()
def get_sqla_helper():
    enginex = create_engine(
        funboost_config_deafult.BrokerConnConfig.SQLACHEMY_ENGINE_URL,
        max_overflow=10,  # 超过连接池大小外最多创建的连接
        pool_size=50,  # 连接池大小
        pool_timeout=30,  # 池中没有线程最多等待的时间，否则报错
        pool_recycle=3600,  # 多久之后对线程池中的线程进行一次连接的回收（重置）
        echo=True)
    sqla_helper = SqlaReflectHelper(enginex)
    t_funboost_consume_results = sqla_helper.base_classes.funboost_consume_results
    return enginex, sqla_helper, t_funboost_consume_results


def save_result_status_to_sqlalchemy(function_result_status: FunctionResultStatus):
    """ function_result_status变量上有各种丰富的信息 ,用户可以使用其中的信息
    用户自定义记录函数消费信息的钩子函数

    例如  @boost('test_user_custom', user_custom_record_process_info_func=save_result_status_to_sqlalchemy)
    """
    enginex, sqla_helper, t_funboost_consume_results = get_sqla_helper()

    with sqla_helper.session as ss:
        status_dict = function_result_status.get_status_dict()
        status_dict_new = copy.copy(status_dict)
        for k, v in status_dict.items():
            if isinstance(v, dict):
                status_dict_new[k] = json.dumps(v)
        # sql = _gen_insert_sqlalchemy(status_dict) # 这种是sqlahemy sql方式插入.
        # ss.execute(sql, status_dict_new)
        ss.merge(t_funboost_consume_results(**status_dict_new)) # 这种是orm方式插入.

`````

--- **end of file: funboost/contrib/save_function_result_status/save_result_status_to_sqldb.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/save_function_result_status/save_result_status_use_dataset.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/save_function_result_status/save_result_status_use_dataset.py`

#### 📝 Module Docstring

`````
一个贡献,保存函数结果状态到 mysql postgre 等等,因为默认是使用mongo保存.

可以在 @boost里面指定 user_custom_record_process_info_func= save_result_status_to_sqlalchemy
`````

#### 📦 Imports

- `import os`
- `import copy`
- `import functools`
- `import json`
- `import threading`
- `import dataset`
- `from funboost import boost`
- `from funboost import FunctionResultStatus`
- `from funboost import funboost_config_deafult`
- `from funboost import AbstractConsumer`

#### 🏛️ Classes (1)

##### 📌 `class ResultStatusUseDatasetMixin(AbstractConsumer)`
*Line: 42*

**Public Methods (1):**
- `def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus)`

#### 🔧 Public Functions (2)

- `def get_db(connect_url) -> dataset.Database`
  - *Line: 22*
  - *封装一个函数，判断pid*

- `def save_result_status_use_dataset(result_status: FunctionResultStatus)`
  - *Line: 36*


---

`````python

"""
一个贡献,保存函数结果状态到 mysql postgre 等等,因为默认是使用mongo保存.

可以在 @boost里面指定 user_custom_record_process_info_func= save_result_status_to_sqlalchemy
"""

import os
import copy
import functools
import json
import threading

import dataset

from funboost import boost, FunctionResultStatus, funboost_config_deafult,AbstractConsumer



pid__db_map = {}
_lock = threading.Lock()
def get_db(connect_url) -> dataset.Database:
    """封装一个函数，判断pid"""
    pid = os.getpid()
    key = (pid, connect_url,)
    if key not in pid__db_map:
        with _lock:
            if key not in pid__db_map:
                pid__db_map[key] =  dataset.connect(connect_url)
    return pid__db_map[key]


connect_url ='mysql+pymysql://root:123456@127.0.0.1:3306/testdb7' # dataset或 SQLAlchemy 的url连接形式

# 方式一:@boost 装饰器里面使用函数钩子,user_custom_record_process_info_func
def save_result_status_use_dataset(result_status: FunctionResultStatus):
    db = get_db(connect_url)
    table = db['funboost_consume_results']
    table.upsert(result_status.get_status_dict(), ['_id'])

# 方式二:装饰器里面使用 consumer_override_cls,重写 user_custom_record_process_info_func
class ResultStatusUseDatasetMixin(AbstractConsumer):
    def user_custom_record_process_info_func(self, current_function_result_status: FunctionResultStatus):
        # print(current_function_result_status.get_status_dict())
        db = get_db(connect_url)
        table = db['funboost_consume_results']
        table.upsert(current_function_result_status.get_status_dict(), ['_id'])
`````

--- **end of file: funboost/contrib/save_function_result_status/save_result_status_use_dataset.py** (project: funboost) --- 

---


--- **start of file: funboost/contrib/save_function_result_status/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/contrib/save_function_result_status/__init__.py`


---

`````python

`````

--- **end of file: funboost/contrib/save_function_result_status/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/core/active_cousumer_info_getter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/active_cousumer_info_getter.py`

#### 📝 Module Docstring

`````
此模块的功能非常适合拿来开发对funboost的监控面板，或者管理后台。
    - ActiveCousumerProcessInfoGetter  获取队列的活跃消费进程信息
    - QueuesConusmerParamsGetter  获取所有队列配置参数 和 运行信息
    - SingleQueueConusmerParamsGetter  获取单个队列配置参数 和 运行信息


下面3个python文件的web接口中，funboost.faas 主要就是使用了此模块的功能。
 



care_project_name 的作用是：
    - None : 关心所有redis中存储的队列信息
    - str : 只关心指定project_name的队列信息
   
`````

#### 📦 Imports

- `import json`
- `import threading`
- `import time`
- `import typing`
- `import uuid`
- `import os`
- `from funboost.factories.consumer_factory import ConsumerCacheProxy`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import nb_log_config_default`
- `from funboost.core.serialization import Serialization`
- `from funboost.constant import RedisKeys`
- `from funboost.core.booster import Booster`
- `from funboost.core.booster import BoosterRegistry`
- `from funboost.core.booster import booster_registry_default`
- `from funboost.core.booster import gen_pid_queue_name_key`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import BaseJsonAbleModel`
- `from funboost.core.function_result_status_saver import FunctionResultStatusPersistanceConfig`
- `from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator`
- `from funboost.core.exceptions import QueueNameNotExists`
- `from funboost.timing_job.timing_push import ApsJobAdder`
- `from funboost.constant import EnvConst`

#### 🏛️ Classes (5)

##### 📌 `class CareProjectNameEnv`
*Line: 43*

**Public Methods (2):**
- `def set(cls, care_project_name: str)` `classmethod`
- `def get(cls) -> typing.Optional[bool]` `classmethod`

**Class Variables (1):**
- `env_name = EnvConst.FUNBOOST_FAAS_CARE_PROJECT_NAME`

##### 📌 `class RedisReportInfoGetterMixin`
*Line: 60*

**Public Methods (4):**
- `def get_all_queue_names(self) -> list`
  - *获取所有队列名称，带30秒缓存（类级别缓存，所有实例共享）*
- `def get_queue_names_by_project_name(self, project_name: str) -> list`
  - *根据项目名称获取队列名称，带30秒缓存（类级别缓存，所有实例共享）*
- `def hmget_many_by_all_queue_names(self, key)`
- `def get_all_project_names(self)`

**Properties (2):**
- `@property all_queue_names`
- `@property project_name_queues`

**Class Variables (4):**
- `_cache_all_queue_names = None`
- `_cache_all_queue_names_ts = 0`
- `_cache_queue_names_by_project = {}`
- `_cache_ttl = 30`

##### 📌 `class ActiveCousumerProcessInfoGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 180*

**Docstring:**
`````
获取分布式环境中的消费进程信息。
使用这里面的4个方法需要相应函数的@boost装饰器设置 is_send_consumer_heartbeat_to_redis=True，这样会自动发送活跃心跳到redis。否则查询不到该函数的消费者进程信息。
要想使用消费者进程信息统计功能，用户无论使用何种消息队列中间件类型，用户都必须安装redis，并在 funboost_config.py 中配置好redis链接信息
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, care_project_name: typing.Optional[str] = None)`
  - **Parameters:**
    - `self`
    - `care_project_name: typing.Optional[str] = None`

**Public Methods (5):**
- `def get_all_hearbeat_info_by_queue_name(self, queue_name) -> typing.List[typing.Dict]`
  - **Docstring:**
  `````
  根据队列名查询有哪些活跃的消费者进程
  返回结果例子：
  [{
          "code_filename": "/codes/funboost/test_frame/my/test_consume.py",
          "computer_ip": "172.16.0.9",
          "computer_name": "VM_0_9_centos",
          "consumer_id": 140477437684048,
          "consumer_uuid": "79473629-b417-4115-b516-4365b3cdf383",
          "consuming_function": "f2",
          "hearbeat_datetime_str": "2021-12-27 19:22:04",
          "hearbeat_timestamp": 1640604124.4643965,
          "process_id": 9665,
          "queue_name": "test_queue72c",
          "start_datetime_str": "2021-12-27 19:21:24",
          "start_timestamp": 1640604084.0780013
      }, ...............]
  `````
- `def get_all_hearbeat_info_by_ip(self, ip = None) -> typing.List[typing.Dict]`
  - **Docstring:**
  `````
  根据机器的ip查询有哪些活跃的消费者进程，ip不传参就查本机ip使用funboost框架运行了哪些消费进程，传参则查询任意机器的消费者进程信息。
  返回结果的格式和上面的 get_all_hearbeat_dict_by_queue_name 方法相同。
  `````
- `def get_all_ips(self)`
- `def get_all_hearbeat_info_partition_by_queue_name(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]`
  - *获取所有队列对应的活跃消费者进程信息，按队列名划分,不需要传入队列名，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对*
- `def get_all_hearbeat_info_partition_by_ip(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]`
  - *获取所有机器ip对应的活跃消费者进程信息，按机器ip划分,不需要传入机器ip，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对*

##### 📌 `class QueuesConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 299*

**Docstring:**
`````
获取所有队列的运行信息，
方法 get_queues_params_and_active_consumers 返回信息最丰富
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, care_project_name: typing.Optional[str] = None)`
  - **Parameters:**
    - `self`
    - `care_project_name: typing.Optional[str] = None`

**Public Methods (7):**
- `def get_queues_params(self) -> dict`
- `def get_pause_flag(self)`
- `def get_msg_num(self, ignore_report_ts = False)`
- `def get_queues_history_run_count(self)`
- `def get_queues_history_run_fail_count(self)`
- `def get_queues_params_and_active_consumers(self)`
  - *获取所有队列的参数和活跃消费者*
- `def cycle_get_queues_params_and_active_consumers_and_report(self, daemon = False)`

##### 📌 `class SingleQueueConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin, FunboostFileLoggerMixin)`
*Line: 422*

**Docstring:**
`````
获取单个队列的运行信息，
方法 get_one_queue_params_and_active_consumers 返回信息最丰富
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: str, care_project_name: typing.Optional[str] = None, is_use_local_booster: bool = None)`
  - **Parameters:**
    - `self`
    - `queue_name: str`
    - `care_project_name: typing.Optional[str] = None`
    - `is_use_local_booster: bool = None`

**Public Methods (13):**
- `def get_one_queue_params(self) -> dict`
  - **Docstring:**
  `````
          类似于这样，就是booster_params的字符串json序列化
  
          ```json
          {
    "queue_name": "test_funboost_faas_queue2",
    "broker_kind": "REDIS",
    "project_name": "test_project1",
    "concurrent_mode": "threading",
    "concurrent_num": 50,
    "specify_concurrent_pool": null,
    "specify_async_loop": null,
    "is_auto_start_specify_async_loop_in_child_thread": true,
    "qps": null,
    "is_using_distributed_frequency_control": false,
    "is_send_consumer_heartbeat_to_redis": true,
    "max_retry_times": 3,
    "retry_interval": 0,
    "is_push_to_dlx_queue_when_retry_max_times": false,
    "consuming_function_decorator": null,
    "function_timeout": null,
    "is_support_remote_kill_task": false,
    "log_level": 10,
    "logger_prefix": "",
    "create_logger_file": true,
    "logger_name": "",
    "log_filename": null,
    "is_show_message_get_from_broker": false,
    "is_print_detail_exception": true,
    "publish_msg_log_use_full_msg": false,
    "msg_expire_seconds": null,
    "do_task_filtering": false,
    "task_filtering_expire_seconds": 0,
    "function_result_status_persistance_conf": {
      "is_save_status": false,
      "is_save_result": false,
      "expire_seconds": 604800,
      "is_use_bulk_insert": false
    },
    "user_custom_record_process_info_func": null,
    "is_using_rpc_mode": true,
    "rpc_result_expire_seconds": 1800,
    "rpc_timeout": 1800,
    "delay_task_apscheduler_jobstores_kind": "redis",
    "is_do_not_run_by_specify_time_effect": false,
    "do_not_run_by_specify_time": [
      "10:00:00",
      "22:00:00"
    ],
    "schedule_tasks_on_main_thread": false,
    "is_auto_start_consuming_message": false,
    "booster_group": "test_group1",
    "consuming_function": "<function sub at 0x00000272649BBA60>",
    "consuming_function_raw": "<function sub at 0x00000272649BBA60>",
    "consuming_function_name": "sub",
    "broker_exclusive_config": {
      "redis_bulk_push": 1,
      "pull_msg_batch_size": 100
    },
    "should_check_publish_func_params": true,
    "manual_func_input_params": {
      "is_manual_func_input_params": false,
      "must_arg_name_list": [],
      "optional_arg_name_list": []
    },
    "consumer_override_cls": null,
    "publisher_override_cls": null,
    "consuming_function_kind": "COMMON_FUNCTION",
    "user_options": {
      
    },
    "auto_generate_info": {
      "where_to_instantiate": "D:\codes\funboost\examples\example_faas\task_funs_dir\sub.py:5",
      "final_func_input_params_info": {
        "func_name": "sub",
        "func_position": "<function sub at 0x00000272649BBA60>",
        "is_manual_func_input_params": false,
        "all_arg_name_list": [
          "a",
          "b"
        ],
        "must_arg_name_list": [
          "a",
          "b"
        ],
        "optional_arg_name_list": []
      }
    }
  }
  
  
          ```
          
  `````
- `def get_one_queue_params_use_cache(self) -> dict`
- `def gen_booster_for_faas(self) -> Booster`
- `def gen_publisher_for_faas(self) -> Booster`
- `def generate_aps_job_adder(self, job_store_kind = 'redis', is_auto_start = True, is_auto_paused = True) -> ApsJobAdder`
- `def get_one_queue_pause_flag(self) -> int`
  - *返回队列的暂停状态，-1 表示队列不存在，0 表示队列未暂停，1 表示队列已暂停*
- `def get_one_queue_history_run_count(self) -> int`
- `def get_one_queue_history_run_fail_count(self) -> int`
- `def get_one_queue_msg_num(self, ignore_report_ts = False) -> int`
  - **Docstring:**
  `````
  从上报到redis的心跳信息中获取的消息数量，
  如果 ignore_report_ts 为 True 并且最近一次上报时间是很久之前的，消息数量就不准
  上报线程是随着消费一起自动运行的，如果没有启动消息，就会停止心跳信息上报。
  `````
- `def get_one_queue_msg_num_realtime(self) -> int`
  - *实时从broker获取的消息数量，*
- `def get_one_queue_params_and_active_consumers(self) -> dict`
- `def get_one_queue_time_series_data(self, start_ts = None, end_ts = None, curve_samples_count = None)`
- `def deprecate_queue(self)`
  - **Docstring:**
  `````
  废弃队列 - 从 Redis 中移除队列名
  1. 从 funboost_all_queue_names set 中移除
  2. 从 funboost.project_name:{project_name} set 中移除
  `````

**Class Variables (2):**
- `queue__booster_params_cache: dict = {}`
- `_lock_for_generate_publisher_booster = threading.Lock()`


---

`````python
"""
此模块的功能非常适合拿来开发对funboost的监控面板，或者管理后台。
    - ActiveCousumerProcessInfoGetter  获取队列的活跃消费进程信息
    - QueuesConusmerParamsGetter  获取所有队列配置参数 和 运行信息
    - SingleQueueConusmerParamsGetter  获取单个队列配置参数 和 运行信息


下面3个python文件的web接口中，funboost.faas 主要就是使用了此模块的功能。
 



care_project_name 的作用是：
    - None : 关心所有redis中存储的队列信息
    - str : 只关心指定project_name的队列信息
   
"""


import json
import threading
import time
import typing
import uuid
import os

from funboost.factories.consumer_factory import ConsumerCacheProxy
from funboost.factories.publisher_factotry import get_publisher
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.utils.redis_manager import RedisMixin

from funboost.core.loggers import FunboostFileLoggerMixin,nb_log_config_default
from funboost.core.serialization import Serialization
from funboost.constant import RedisKeys
from funboost.core.booster import  Booster,BoosterRegistry, booster_registry_default,gen_pid_queue_name_key
from funboost.core.func_params_model import PublisherParams, BoosterParams, BaseJsonAbleModel
from funboost.core.function_result_status_saver import FunctionResultStatusPersistanceConfig
from funboost.core.consuming_func_iniput_params_check import FakeFunGenerator
from funboost.core.exceptions import QueueNameNotExists
from funboost.timing_job.timing_push import ApsJobAdder
from funboost.constant import EnvConst

class CareProjectNameEnv:
    env_name = EnvConst.FUNBOOST_FAAS_CARE_PROJECT_NAME
    @classmethod
    def set(cls, care_project_name: str):
        os.environ[cls.env_name] = care_project_name

    @classmethod
    def get(cls) -> typing.Optional[bool]:
        care_project_name =  os.environ.get(cls.env_name, None)
        if care_project_name in ('','all','None','null','none',None):
            return None
        return care_project_name

booster_registry_for_faas = BoosterRegistry(
    booster_registry_name='booster_registry_for_faas')


class RedisReportInfoGetterMixin:
    # 类属性：所有实例共享的缓存
    _cache_all_queue_names = None
    _cache_all_queue_names_ts = 0
    _cache_queue_names_by_project = {}  # {project_name: {'data': [...], 'ts': timestamp}}
    _cache_ttl = 30  # 缓存30秒
    
    def _init(self,care_project_name:typing.Optional[str]=None,):
        """
        参数:
            care_project_name
            只关注指定project_name相关的boosters，只获取这些队列在redis中的运行信息

            避免获取redis中不相关的 boosters信息，减少信息干扰和提升性能。
        """
        if care_project_name is not None:
            self.care_project_name = care_project_name
        else:
            self.care_project_name = CareProjectNameEnv.get()

    def get_all_queue_names(self) ->list:
        """获取所有队列名称，带30秒缓存（类级别缓存，所有实例共享）"""
        current_time = time.time()
        
        # 检查缓存是否有效
        if self._cache_all_queue_names is not None and (current_time - self._cache_all_queue_names_ts) < self._cache_ttl:
            return self._cache_all_queue_names
        
        # 缓存失效，重新从redis获取
        if self.care_project_name:
            result = self.project_name_queues
        else:
            result = list(self.redis_db_frame.smembers(RedisKeys.FUNBOOST_ALL_QUEUE_NAMES))
        
        # 更新缓存
        self.__class__._cache_all_queue_names = result
        self.__class__._cache_all_queue_names_ts = current_time
        
        return result

    def get_queue_names_by_project_name(self,project_name:str) ->list:
        """根据项目名称获取队列名称，带30秒缓存（类级别缓存，所有实例共享）"""
        current_time = time.time()
        
        # 检查缓存是否有效
        if project_name in self._cache_queue_names_by_project:
            cache_entry = self._cache_queue_names_by_project[project_name]
            if (current_time - cache_entry['ts']) < self._cache_ttl:
                return cache_entry['data']
        
        # 缓存失效，重新从redis获取
        result = list(self.redis_db_frame.smembers(RedisKeys.gen_funboost_project_name_key(project_name)))
        
        # 更新缓存
        self.__class__._cache_queue_names_by_project[project_name] = {
            'data': result,
            'ts': current_time
        }
        
        return result
    
    @property
    def all_queue_names(self):
        return self.get_all_queue_names()

    @property
    def project_name_queues(self):
        return self.get_queue_names_by_project_name(self.care_project_name)

    def hmget_many_by_all_queue_names(self,key):
        # if self.care_project_name is False:
        #     return self.redis_db_frame.hgetall(key)
        # ret_list = self.redis_db_frame.hmget(key,fileds)
        # return  dict(zip(fileds, ret_list))
        if len(self.all_queue_names) == 0:
            err_msg  = f"""
            care_project_name is set to {self.care_project_name},

            make sure  you have set @boost(BoosterParams(is_send_consumer_heartbeat_to_redis=True,project_name=$project_name))

            """
            self.logger.error(err_msg)
            return {}
        ret_list = self.redis_db_frame.hmget(key,self.all_queue_names)
        ret_list_exlude_none = [i for i in ret_list if i is not None]
        return  dict(zip(self.all_queue_names, ret_list_exlude_none))
    
    def get_all_project_names(self):
        return list(self.redis_db_frame.smembers(RedisKeys.FUNBOOST_ALL_PROJECT_NAMES))
    
    
    


def _cvt_int(str_value:typing.Optional[str])->typing.Optional[int]:
    if str_value is None:
        return None
    return int(str_value)


def _sum_filed_from_active_consumers(active_consumers:typing.List[dict],filed:str):
    s = 0
    for c in active_consumers:
        # print(c)
        if c[filed]:
            # print(c[filed])
            s+=c[filed]
    return s


def _max_filed_from_active_consumers(active_consumers:typing.List[dict],filed:str):
    """取所有消费者中某个字段的最大值"""
    max_val = None
    for c in active_consumers:
        val = c.get(filed)
        if val is not None:
            if max_val is None or val > max_val:
                max_val = val
    return max_val

class ActiveCousumerProcessInfoGetter(RedisMixin,RedisReportInfoGetterMixin,FunboostFileLoggerMixin):
    """

    获取分布式环境中的消费进程信息。
    使用这里面的4个方法需要相应函数的@boost装饰器设置 is_send_consumer_heartbeat_to_redis=True，这样会自动发送活跃心跳到redis。否则查询不到该函数的消费者进程信息。
    要想使用消费者进程信息统计功能，用户无论使用何种消息队列中间件类型，用户都必须安装redis，并在 funboost_config.py 中配置好redis链接信息
    """

    def __init__(self,care_project_name:typing.Optional[str]=None):
        RedisReportInfoGetterMixin._init(self,care_project_name)

        

    def _get_all_hearbeat_info_by_redis_key_name(self, redis_key):
        results = self.redis_db_frame.smembers(redis_key)
        # print(type(results))
        # print(results)
        # 如果所有机器所有进程都全部关掉了，就没办法还剩一个线程执行删除了，这里还需要判断一次15秒。
        active_consumers_processor_info_list = []
        for result in results:
            result_dict = json.loads(result)
            if  result_dict['queue_name'] not in self.get_all_queue_names():
                continue
            if self.timestamp() - result_dict['hearbeat_timestamp'] < 15:
                active_consumers_processor_info_list.append(result_dict)
                if self.timestamp() - result_dict['current_time_for_execute_task_times_every_unit_time'] > 30:
                    result_dict['last_x_s_execute_count'] = 0
                    result_dict['last_x_s_execute_count_fail'] = 0
        return active_consumers_processor_info_list

    def get_all_hearbeat_info_by_queue_name(self, queue_name) -> typing.List[typing.Dict]:
        """
        根据队列名查询有哪些活跃的消费者进程
        返回结果例子：
        [{
                "code_filename": "/codes/funboost/test_frame/my/test_consume.py",
                "computer_ip": "172.16.0.9",
                "computer_name": "VM_0_9_centos",
                "consumer_id": 140477437684048,
                "consumer_uuid": "79473629-b417-4115-b516-4365b3cdf383",
                "consuming_function": "f2",
                "hearbeat_datetime_str": "2021-12-27 19:22:04",
                "hearbeat_timestamp": 1640604124.4643965,
                "process_id": 9665,
                "queue_name": "test_queue72c",
                "start_datetime_str": "2021-12-27 19:21:24",
                "start_timestamp": 1640604084.0780013
            }, ...............]
        """
        redis_key = RedisKeys.gen_funboost_hearbeat_queue__dict_key_by_queue_name(queue_name)
        return self._get_all_hearbeat_info_by_redis_key_name(redis_key)

    def get_all_hearbeat_info_by_ip(self, ip=None) -> typing.List[typing.Dict]:
        """
        根据机器的ip查询有哪些活跃的消费者进程，ip不传参就查本机ip使用funboost框架运行了哪些消费进程，传参则查询任意机器的消费者进程信息。
        返回结果的格式和上面的 get_all_hearbeat_dict_by_queue_name 方法相同。
        """
        ip = ip or nb_log_config_default.computer_ip
        redis_key = RedisKeys.gen_funboost_hearbeat_server__dict_key_by_ip(ip)
        return self._get_all_hearbeat_info_by_redis_key_name(redis_key)

    # def _get_all_hearbeat_info_partition_by_redis_key_prefix(self, redis_key_prefix):
    #     keys = self.redis_db_frame.scan(0, f'{redis_key_prefix}*', count=10000)[1]
    #     infos_map = {}
    #     for key in keys:
    #         infos = self.redis_db_frame.smembers(key)
    #         dict_key = key.replace(redis_key_prefix, '')
    #         infos_map[dict_key] = []
    #         for info_str in infos:
    #             info_dict = json.loads(info_str)
    #             if self.timestamp() - info_dict['hearbeat_timestamp'] < 15:
    #                 infos_map[dict_key].append(info_dict)
    #                 if self.timestamp() - info_dict['current_time_for_execute_task_times_every_unit_time'] > 30:
    #                     info_dict['last_x_s_execute_count'] = 0
    #                     info_dict['last_x_s_execute_count_fail'] = 0
    #     return infos_map

    
    
    def get_all_ips(self):
        return self.redis_db_frame.smembers(RedisKeys.FUNBOOST_ALL_IPS)
    
    def _get_all_hearbeat_info_partition_by_redis_keys(self, keys):
        
        # keys = [f'{redis_key_prefix}{queue_name}' for queue_name in queue_names]
        infos_map = {}
        for key in keys:
            infos = self.redis_db_frame.smembers(key)
            dict_key = key.replace(RedisKeys.FUNBOOST_HEARTBEAT_QUEUE__DICT_PREFIX, '').replace(RedisKeys.FUNBOOST_HEARTBEAT_SERVER__DICT_PREFIX, '')
            infos_map[dict_key] = []
            for info_str in infos:
                info_dict = json.loads(info_str)
                if  info_dict['queue_name'] not in self.get_all_queue_names():
                    continue
                if self.timestamp() - info_dict['hearbeat_timestamp'] < 15:
                    infos_map[dict_key].append(info_dict)
                    if self.timestamp() - info_dict['current_time_for_execute_task_times_every_unit_time'] > 30:
                        info_dict['last_x_s_execute_count'] = 0
                        info_dict['last_x_s_execute_count_fail'] = 0
        return infos_map

    def get_all_hearbeat_info_partition_by_queue_name(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]:
        """获取所有队列对应的活跃消费者进程信息，按队列名划分,不需要传入队列名，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对"""
        queue_names = self.get_all_queue_names()
        infos_map = self._get_all_hearbeat_info_partition_by_redis_keys([RedisKeys.gen_funboost_hearbeat_queue__dict_key_by_queue_name(queue_name) for queue_name in queue_names])
        # self.logger.info(f'获取所有队列对应的活跃消费者进程信息，按队列名划分，结果是 {json.dumps(infos_map, indent=4)}')
        return infos_map

    def get_all_hearbeat_info_partition_by_ip(self) -> typing.Dict[typing.AnyStr, typing.List[typing.Dict]]:
        """获取所有机器ip对应的活跃消费者进程信息，按机器ip划分,不需要传入机器ip，自动扫描redis键。请不要在 funboost_config.py 的redis 指定的db中放太多其他业务的缓存键值对 """
        ips = self.get_all_ips()
        infos_map = self._get_all_hearbeat_info_partition_by_redis_keys([RedisKeys.gen_funboost_hearbeat_server__dict_key_by_ip(ip) for ip in ips])
        self.logger.info(f'获取所有机器ip对应的活跃消费者进程信息，按机器ip划分，结果是 {json.dumps(infos_map, indent=4)}')
        return infos_map





class QueuesConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin,FunboostFileLoggerMixin):
    """
    获取所有队列的运行信息，
    方法 get_queues_params_and_active_consumers 返回信息最丰富
    """
    def __init__(self,care_project_name:typing.Optional[str]=None):
        RedisReportInfoGetterMixin._init(self,care_project_name)


    def get_queues_params(self,)->dict:
        queue__consumer_params_map = self.hmget_many_by_all_queue_names(RedisKeys.FUNBOOST_QUEUE__CONSUMER_PARAMS,)   
        return {k:Serialization.to_dict(v)  for k,v in queue__consumer_params_map.items()}

    def get_pause_flag(self):
        queue__pause_map = self.hmget_many_by_all_queue_names(RedisKeys.REDIS_KEY_PAUSE_FLAG,)
        return {k:_cvt_int(v)  for k,v in queue__pause_map.items()}

    def get_msg_num(self,ignore_report_ts=False):
        queue__msg_count_info_map = self.hmget_many_by_all_queue_names(RedisKeys.QUEUE__MSG_COUNT_MAP,)
        queue__msg_count_dict = {}
        # print(queue__msg_count_info_map)
        for queue_name,info_json in queue__msg_count_info_map.items():
            info_dict = json.loads(info_json)
            if ignore_report_ts or (info_dict['report_ts'] > time.time() - 15 and info_dict['last_get_msg_num_ts'] > time.time() - 1200):
                queue__msg_count_dict[queue_name] = info_dict['msg_num_in_broker']
        return queue__msg_count_dict

    def get_queues_history_run_count(self,):
        queue__run_count_map = self.hmget_many_by_all_queue_names(RedisKeys.FUNBOOST_QUEUE__RUN_COUNT_MAP,)
        return {k:_cvt_int(v) for k,v in queue__run_count_map.items()}
    
    def get_queues_history_run_fail_count(self,):
        queue__run_fail_count_map = self.hmget_many_by_all_queue_names(RedisKeys.FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP,)
        return {k:_cvt_int(v) for k,v in queue__run_fail_count_map.items()}
    
    def get_queues_params_and_active_consumers(self):
        """获取所有队列的参数和活跃消费者"""
        queue__active_consumers_map = ActiveCousumerProcessInfoGetter(
            care_project_name=self.care_project_name
            ).get_all_hearbeat_info_partition_by_queue_name()

        queue__history_run_count_map = self.get_queues_history_run_count()
        queue__history_run_fail_count_map = self.get_queues_history_run_fail_count()

        queue__consumer_params_map  = self.get_queues_params()
        queue__pause_map = self.get_pause_flag()
        queue__msg_count_dict = self.get_msg_num(ignore_report_ts=True)
        queue_params_and_active_consumers = {}

        for queue, consumer_params in  queue__consumer_params_map.items():
            
            active_consumers = queue__active_consumers_map.get(queue, [])
            # print(queue,active_consumers)
            all_consumers_last_x_s_execute_count = _sum_filed_from_active_consumers(active_consumers,'last_x_s_execute_count')
            all_consumers_last_x_s_execute_count_fail = _sum_filed_from_active_consumers(active_consumers, 'last_x_s_execute_count_fail')
            all_consumers_last_x_s_total_cost_time = _sum_filed_from_active_consumers(active_consumers, 'last_x_s_total_cost_time')
            all_consumers_last_x_s_avarage_function_spend_time = round( all_consumers_last_x_s_total_cost_time / all_consumers_last_x_s_execute_count,3) if all_consumers_last_x_s_execute_count else None
            all_consumers_last_execute_task_time = _max_filed_from_active_consumers(active_consumers, 'last_execute_task_time')
            
            all_consumers_total_consume_count_from_start = _sum_filed_from_active_consumers(active_consumers, 'total_consume_count_from_start')
            all_consumers_total_cost_time_from_start =_sum_filed_from_active_consumers(active_consumers, 'total_cost_time_from_start')
            all_consumers_avarage_function_spend_time_from_start = round(all_consumers_total_cost_time_from_start / all_consumers_total_consume_count_from_start,3) if all_consumers_total_consume_count_from_start else None

            queue_params_and_active_consumers[queue] = {
                'queue_params':consumer_params,
                'active_consumers':active_consumers,
                'pause_flag':queue__pause_map.get(queue,-1),
                'msg_num_in_broker':queue__msg_count_dict.get(queue,None),
                
                'history_run_count':queue__history_run_count_map.get(queue,None),
                'history_run_fail_count':queue__history_run_fail_count_map.get(queue,None),

                'all_consumers_last_x_s_execute_count':all_consumers_last_x_s_execute_count,
                'all_consumers_last_x_s_execute_count_fail':all_consumers_last_x_s_execute_count_fail,
                'all_consumers_last_x_s_avarage_function_spend_time':all_consumers_last_x_s_avarage_function_spend_time,
                'all_consumers_avarage_function_spend_time_from_start':all_consumers_avarage_function_spend_time_from_start,
                'all_consumers_total_consume_count_from_start':_sum_filed_from_active_consumers(active_consumers, 'total_consume_count_from_start'),
                'all_consumers_total_consume_count_from_start_fail':_sum_filed_from_active_consumers(active_consumers, 'total_consume_count_from_start_fail'),
                'all_consumers_last_execute_task_time':all_consumers_last_execute_task_time,
            }
        return queue_params_and_active_consumers
    
    def cycle_get_queues_params_and_active_consumers_and_report(self,daemon=False):
        time_interval = 10
        report_uuid = str(uuid.uuid4()) 
        def _inner():
            while True:
                t_start = time.time()
                # 这个函数确保只有一个地方在上报数据，避免重复采集上报
                report_ts = self.timestamp()
                redis_report_uuid_ts_str = self.redis_db_frame.get(RedisKeys.FUNBOOST_LAST_GET_QUEUES_PARAMS_AND_ACTIVE_CONSUMERS_AND_REPORT__UUID_TS, )
                if redis_report_uuid_ts_str:
                    redis_report_uuid_ts = Serialization.to_dict(redis_report_uuid_ts_str)
                    if redis_report_uuid_ts['report_uuid'] != report_uuid and redis_report_uuid_ts['report_ts'] > report_ts - time_interval - 10 :
                        time.sleep(5) # 防止cpu空转
                        continue
                self.redis_db_frame.set(RedisKeys.FUNBOOST_LAST_GET_QUEUES_PARAMS_AND_ACTIVE_CONSUMERS_AND_REPORT__UUID_TS,
                                        Serialization.to_json_str({'report_uuid':report_uuid, 'report_ts':report_ts}))
                
                queue_params_and_active_consumers = self.get_queues_params_and_active_consumers()
                for queue,item in queue_params_and_active_consumers.items():
                    if len(item['active_consumers']) == 0:
                        continue
                    report_data = {k:v for k,v in item.items() if k not in ['queue_params','active_consumers']}
                    
                    report_data['report_ts'] = report_ts
                    self.redis_db_frame.zadd(RedisKeys.gen_funboost_queue_time_series_data_key_by_queue_name(queue),
                                            {Serialization.to_json_str(report_data):report_ts} )
                    # 删除过期时序数据,只保留最近1天数据
                    self.redis_db_frame.zremrangebyscore(
                        RedisKeys.gen_funboost_queue_time_series_data_key_by_queue_name(queue),
                        0, report_ts - 86400
                    )
                self.logger.info(f'采集上报时序数据耗时 {time.time() - t_start} 秒')

                time.sleep(time_interval)
        threading.Thread(target=_inner, daemon=daemon).start()

    
        



class SingleQueueConusmerParamsGetter(RedisMixin, RedisReportInfoGetterMixin,FunboostFileLoggerMixin):
    """
    获取单个队列的运行信息，
    方法 get_one_queue_params_and_active_consumers 返回信息最丰富
    """
    queue__booster_params_cache :dict= {}
    # _pid_broker_kind_queue_name__booster_map = {}
    # _pid_broker_kind_queue_name__publisher_map = {}
    _lock_for_generate_publisher_booster = threading.Lock()
    


    def __init__(self,queue_name:str,care_project_name:typing.Optional[str]=None,is_use_local_booster:bool=None):
        RedisReportInfoGetterMixin._init(self,care_project_name)
        self.queue_name = queue_name
        self._check_booster_exists()
        self.is_use_local_booster = is_use_local_booster if is_use_local_booster is not None else os.environ.get(EnvConst.FUNBOOST_FAAS_IS_USE_LOCAL_BOOSTER, 'false').lower() == 'true'
        self._last_update_consuming_func_input_params_checker = 0
     
    
    def _check_booster_exists(self):
        if self.queue_name not in self.all_queue_names:
            err_msg = f'''
            queue_name {self.queue_name} not in all_queue_names {self.all_queue_names},  

            you have set care_project_name={self.care_project_name},

            '''
            self.logger.error(err_msg)
            raise QueueNameNotExists(err_msg,error_data={'queue_name':self.queue_name,'care_project_name':self.care_project_name})

    def get_one_queue_params(self)->dict:
        """
        类似于这样，就是booster_params的字符串json序列化

        ```json
        {
  "queue_name": "test_funboost_faas_queue2",
  "broker_kind": "REDIS",
  "project_name": "test_project1",
  "concurrent_mode": "threading",
  "concurrent_num": 50,
  "specify_concurrent_pool": null,
  "specify_async_loop": null,
  "is_auto_start_specify_async_loop_in_child_thread": true,
  "qps": null,
  "is_using_distributed_frequency_control": false,
  "is_send_consumer_heartbeat_to_redis": true,
  "max_retry_times": 3,
  "retry_interval": 0,
  "is_push_to_dlx_queue_when_retry_max_times": false,
  "consuming_function_decorator": null,
  "function_timeout": null,
  "is_support_remote_kill_task": false,
  "log_level": 10,
  "logger_prefix": "",
  "create_logger_file": true,
  "logger_name": "",
  "log_filename": null,
  "is_show_message_get_from_broker": false,
  "is_print_detail_exception": true,
  "publish_msg_log_use_full_msg": false,
  "msg_expire_seconds": null,
  "do_task_filtering": false,
  "task_filtering_expire_seconds": 0,
  "function_result_status_persistance_conf": {
    "is_save_status": false,
    "is_save_result": false,
    "expire_seconds": 604800,
    "is_use_bulk_insert": false
  },
  "user_custom_record_process_info_func": null,
  "is_using_rpc_mode": true,
  "rpc_result_expire_seconds": 1800,
  "rpc_timeout": 1800,
  "delay_task_apscheduler_jobstores_kind": "redis",
  "is_do_not_run_by_specify_time_effect": false,
  "do_not_run_by_specify_time": [
    "10:00:00",
    "22:00:00"
  ],
  "schedule_tasks_on_main_thread": false,
  "is_auto_start_consuming_message": false,
  "booster_group": "test_group1",
  "consuming_function": "<function sub at 0x00000272649BBA60>",
  "consuming_function_raw": "<function sub at 0x00000272649BBA60>",
  "consuming_function_name": "sub",
  "broker_exclusive_config": {
    "redis_bulk_push": 1,
    "pull_msg_batch_size": 100
  },
  "should_check_publish_func_params": true,
  "manual_func_input_params": {
    "is_manual_func_input_params": false,
    "must_arg_name_list": [],
    "optional_arg_name_list": []
  },
  "consumer_override_cls": null,
  "publisher_override_cls": null,
  "consuming_function_kind": "COMMON_FUNCTION",
  "user_options": {
    
  },
  "auto_generate_info": {
    "where_to_instantiate": "D:\\codes\\funboost\\examples\\example_faas\\task_funs_dir\\sub.py:5",
    "final_func_input_params_info": {
      "func_name": "sub",
      "func_position": "<function sub at 0x00000272649BBA60>",
      "is_manual_func_input_params": false,
      "all_arg_name_list": [
        "a",
        "b"
      ],
      "must_arg_name_list": [
        "a",
        "b"
      ],
      "optional_arg_name_list": []
    }
  }
}


        ```
        """
        one_queue_params =  self.redis_db_frame.hget('funboost_queue__consumer_parmas',self.queue_name)
        return Serialization.to_dict(one_queue_params)

    def get_one_queue_params_use_cache(self)->dict:
        if self.queue_name not in self.queue__booster_params_cache or time.time() - self.queue__booster_params_cache[self.queue_name]['get_from_redis_ts'] > 60:
            booster_params = self.get_one_queue_params()
            get_from_redis_ts = time.time()
            self.queue__booster_params_cache[self.queue_name] = {'booster_params':booster_params,'get_from_redis_ts':get_from_redis_ts}
        return self.queue__booster_params_cache[self.queue_name]['booster_params']
    

   
    def _gen_booster_by_local_booster(self) -> Booster:
        # 使用本地booster，这种也可以，每个项目单独自己起一个 funboost web manager 就可以，
        # 启动  funboost web manager  之前，先导入相关的 booster所在模块,再调用 `start_funboost_web_manager()` 函数
        
        booster = booster_registry_default.get_or_create_booster_by_queue_name(self.queue_name)
        return booster

    def _gen_booster_by_redis_meta_info(self) -> Booster:
        # 使用redis元信息生成假的fake booster，部分booster配置因为不可json序列化原因，直接赋值None了，缺点是不是真booster  
        # 优点是支持跨项目管理booster，支持热加载。
        booster_params = self.get_one_queue_params_use_cache()
        current_broker_kind = booster_params['broker_kind']
        
        # 利用 registry 的实例属性字典缓存
        key = gen_pid_queue_name_key(self.queue_name)
        existing_booster = booster_registry_for_faas.pid_queue_name__booster_map.get(key)
        
        if existing_booster:
            """
            faas 模式支持热加载不重启web服务就能发布，如果中间件先使用redis，后使用rabbitmq这种极端场景，
            为了支持热加载，需要重新实例化booster。
            """
            if existing_booster.boost_params.broker_kind == current_broker_kind: 
                 self._update_publisher_params_checker(existing_booster.publisher, booster_params)
                 return existing_booster

        with self._lock_for_generate_publisher_booster:
             # 双重检查
             existing_booster = booster_registry_for_faas.pid_queue_name__booster_map.get(key)
             if existing_booster and existing_booster.boost_params.broker_kind == current_broker_kind:
                 return existing_booster

             # 生成新的 booster
             redis_final_func_input_params_info = booster_params['auto_generate_info']['final_func_input_params_info']
             fake_fun = FakeFunGenerator.gen_fake_fun_by_params(redis_final_func_input_params_info)
             booster_params['consuming_function'] = fake_fun
             booster_params['consuming_function_raw'] = fake_fun

             booster_params['specify_concurrent_pool'] = None
             booster_params['specify_async_loop'] = None
             booster_params['consuming_function_decorator'] = None
             booster_params['function_result_status_persistance_conf'] = FunctionResultStatusPersistanceConfig(is_save_status=False,is_save_result=False)
             booster_params['user_custom_record_process_info_func'] = None
             booster_params['consumer_override_cls'] = None
             booster_params['publisher_override_cls'] = None

             booster_params['is_fake_booster'] = True 
             # 关键：指定 registry，这样实例化时会自动注册到 booster_registry_for_faas，覆盖旧的 key
             booster_params['booster_registry_name'] = 'booster_registry_for_faas'

             booster_params_model = BoosterParams(**booster_params)
             
             booster = Booster(booster_params_model)(booster_params_model.consuming_function)
             
             self._update_publisher_params_checker(booster.publisher, booster_params)
             return booster

    def gen_booster_for_faas(self) -> Booster:
        if self.is_use_local_booster:
            return self._gen_booster_by_local_booster()
        return self._gen_booster_by_redis_meta_info()
    
    def gen_publisher_for_faas(self)->Booster:
        booster = self.gen_booster_for_faas()
        return booster.publisher
    
   
    def generate_aps_job_adder(self,job_store_kind='redis',is_auto_start=True,is_auto_paused=True) -> ApsJobAdder:
        booster = self.gen_booster_for_faas()
        job_adder = ApsJobAdder(booster, job_store_kind=job_store_kind, is_auto_start=is_auto_start,is_auto_paused=is_auto_paused)
        return job_adder


    def _update_publisher_params_checker(self,publisher:AbstractPublisher,booster_params:dict):
        """ 
        如果函数上线后，中途又修改函数入参定义，所以任然需要更新 publish_params_checker， 这样才能持续正确校验发布消息时候的入参是否合法
        """
        if  self._last_update_consuming_func_input_params_checker < time.time() - 60:
            self._last_update_consuming_func_input_params_checker = time.time()
            final_func_input_params_info = booster_params['auto_generate_info'].get('final_func_input_params_info',None)
            if final_func_input_params_info:
                publisher.publish_params_checker.update_check_params(final_func_input_params_info)



    def get_one_queue_pause_flag(self) ->int:
        """
        返回队列的暂停状态，-1 表示队列不存在，0 表示队列未暂停，1 表示队列已暂停
        """
        pause_flag = self.redis_db_frame.hget(RedisKeys.REDIS_KEY_PAUSE_FLAG,self.queue_name)
        if pause_flag is None:
            return -1
        return int(pause_flag)

    def get_one_queue_history_run_count(self,) ->int:
        return _cvt_int(self.redis_db_frame.hget(RedisKeys.FUNBOOST_QUEUE__RUN_COUNT_MAP,self.queue_name))
    
    def get_one_queue_history_run_fail_count(self,) ->int:
        return _cvt_int(self.redis_db_frame.hget(RedisKeys.FUNBOOST_QUEUE__RUN_FAIL_COUNT_MAP,self.queue_name))

    def get_one_queue_msg_num(self,ignore_report_ts=False) ->int:
        """
        从上报到redis的心跳信息中获取的消息数量，
        如果 ignore_report_ts 为 True 并且最近一次上报时间是很久之前的，消息数量就不准
        上报线程是随着消费一起自动运行的，如果没有启动消息，就会停止心跳信息上报。
        """
        msg_count_info = self.redis_db_frame.hget(RedisKeys.QUEUE__MSG_COUNT_MAP,self.queue_name)
        info_dict = json.loads(msg_count_info)
        if ignore_report_ts or (info_dict['report_ts'] > time.time() - 15 and info_dict['last_get_msg_num_ts'] > time.time() - 1200):
            return info_dict['msg_num_in_broker']
        return -1

    def get_one_queue_msg_num_realtime(self,) ->int:   
        """
        实时从broker获取的消息数量，
        """
        try:
            publisher = self.gen_publisher_for_faas()
            return publisher.get_message_count()
        except Exception as e:
            self.logger.exception(f'实时获取队列消息数失败 {e}')
            return -1



    def get_one_queue_params_and_active_consumers(self)->dict:
        active_consumers = ActiveCousumerProcessInfoGetter(
            care_project_name=self.care_project_name
            ).get_all_hearbeat_info_by_queue_name(self.queue_name)

        history_run_count = self.get_one_queue_history_run_count()
        history_run_fail_count = self.get_one_queue_history_run_fail_count()

        consumer_params  = self.get_one_queue_params()
        pause_flag = self.get_one_queue_pause_flag()
        # msg_num = self.get_one_queue_msg_num(ignore_report_ts=True)
        msg_num = self.get_one_queue_msg_num_realtime()

        # print(queue,active_consumers)
        all_consumers_last_x_s_execute_count = _sum_filed_from_active_consumers(active_consumers,'last_x_s_execute_count')
        all_consumers_last_x_s_execute_count_fail = _sum_filed_from_active_consumers(active_consumers, 'last_x_s_execute_count_fail')
        all_consumers_last_x_s_total_cost_time = _sum_filed_from_active_consumers(active_consumers, 'last_x_s_total_cost_time')
        all_consumers_last_x_s_avarage_function_spend_time = round( all_consumers_last_x_s_total_cost_time / all_consumers_last_x_s_execute_count,3) if all_consumers_last_x_s_execute_count else None
        all_consumers_last_execute_task_time = _max_filed_from_active_consumers(active_consumers, 'last_execute_task_time')
        
        all_consumers_total_consume_count_from_start = _sum_filed_from_active_consumers(active_consumers, 'total_consume_count_from_start')
        all_consumers_total_cost_time_from_start =_sum_filed_from_active_consumers(active_consumers, 'total_cost_time_from_start')
        all_consumers_avarage_function_spend_time_from_start = round(all_consumers_total_cost_time_from_start / all_consumers_total_consume_count_from_start,3) if all_consumers_total_consume_count_from_start else None

        params_and_active_consumers = {
            'queue_params':consumer_params,
            'active_consumers':active_consumers,
            'pause_flag':pause_flag,
            'msg_num_in_broker':msg_num,
            
            'history_run_count':history_run_count,
            'history_run_fail_count':history_run_fail_count,

            'all_consumers_last_x_s_execute_count':all_consumers_last_x_s_execute_count,
            'all_consumers_last_x_s_execute_count_fail':all_consumers_last_x_s_execute_count_fail,
            'all_consumers_last_x_s_avarage_function_spend_time':all_consumers_last_x_s_avarage_function_spend_time,
            'all_consumers_avarage_function_spend_time_from_start':all_consumers_avarage_function_spend_time_from_start,
            'all_consumers_total_consume_count_from_start':_sum_filed_from_active_consumers(active_consumers, 'total_consume_count_from_start'),
            'all_consumers_total_consume_count_from_start_fail':_sum_filed_from_active_consumers(active_consumers, 'total_consume_count_from_start_fail'),
            'all_consumers_last_execute_task_time':all_consumers_last_execute_task_time,
        }
        return params_and_active_consumers

    
    def get_one_queue_time_series_data(self,start_ts=None,end_ts=None,curve_samples_count=None):
        res = self.redis_db_frame.zrangebyscore(
            RedisKeys.gen_funboost_queue_time_series_data_key_by_queue_name(self.queue_name),
            max(float(start_ts or 0),self.timestamp() - 86400) ,float(end_ts or -1),withscores=True)
        # print(res)
        series_data_all= [{'report_data':Serialization.to_dict(item[0]),'report_ts':item[1]} for item in res]
        if curve_samples_count is None:
            return series_data_all
        
        # 曲线采样数量
        total_count = len(series_data_all)
        if total_count <= curve_samples_count:
            # 如果原始数据量小于等于需要的样本数，直接返回全部数据
            return series_data_all
        
        # 计算采样步长
        step = total_count / curve_samples_count
        sampled_data = []
        
        # 按照步长进行采样
        for i in range(curve_samples_count):
            index = int(i * step)
            if index < total_count:
                sampled_data.append(series_data_all[index])
        
        return sampled_data

    def deprecate_queue(self):
        """
        废弃队列 - 从 Redis 中移除队列名
        1. 从 funboost_all_queue_names set 中移除
        2. 从 funboost.project_name:{project_name} set 中移除
        """
        # 从所有队列名 set 中移除
        self.redis_db_frame.srem(RedisKeys.FUNBOOST_ALL_QUEUE_NAMES, self.queue_name)
        # 从项目队列名 set 中移除
        self.redis_db_frame.srem(RedisKeys.gen_funboost_project_name_key(self.care_project_name), self.queue_name)

    



if __name__ == '__main__':
    CareProjectNameEnv.set('test_project1')
    print(Serialization.to_json_str(QueuesConusmerParamsGetter().get_queues_params_and_active_consumers()))
    print(Serialization.to_json_str(ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_queue_name()))
    # QueuesConusmerParamsGetter().cycle_get_queues_params_and_active_consumers_and_report()
    print(SingleQueueConusmerParamsGetter('queue_test_g03t').get_one_queue_time_series_data(1749617883,1749621483))
   


    print(SingleQueueConusmerParamsGetter('test_funboost_faas_queue').get_one_queue_params_and_active_consumers())
    
`````

--- **end of file: funboost/core/active_cousumer_info_getter.py** (project: funboost) --- 

---


--- **start of file: funboost/core/booster.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/booster.py`

#### 📦 Imports

- `from __future__ import annotations`
- `import copy`
- `import inspect`
- `from multiprocessing import Process`
- `import os`
- `import sys`
- `import types`
- `import typing`
- `import threading`
- `from funboost.concurrent_pool import FlexibleThreadPool`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.constant import FunctionKind`
- `from funboost.constant import StrConst`
- `from funboost.utils.class_utils import ClsHelper`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.utils.decorators import flyweight`
- `from funboost.core.loggers import flogger`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.loggers import logger_prompt`
- `from functools import wraps`
- `from funboost.core.exceptions import BoostDecoParamsIsOldVersion`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.factories.consumer_factory import get_consumer`
- `from funboost.factories.consumer_factory import ConsumerCacheProxy`
- `from funboost.factories.publisher_factotry import get_publisher`
- `from funboost.factories.publisher_factotry import PublisherCacheProxy`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.msg_result_getter import AioAsyncResult`
- `from funboost.core.muliti_process_enhance import run_consumer_with_multi_process`
- `from funboost.core.muliti_process_enhance import multi_process_pub_params_list`
- `from funboost.core.fabric_deploy_helper import fabric_deploy`

#### 🏛️ Classes (2)

##### 📌 `class Booster`
*Line: 39*

**Docstring:**
`````
funboost极其重视代码能在pycharm下自动补全。元编程经常造成在pycharm下代码无法自动补全提示，主要是实现代码补全难。
这种__call__写法在pycahrm下 不仅能补全消费函数的 push consume等方法，也能补全函数本身的入参，一举两得。代码能自动补全很重要。
一个函数fun被 boost装饰器装饰后， isinstance(fun,Booster) 为True.

pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

Booster 是把Consumer 和 Publisher的方法集为一体。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: typing.Union[BoosterParams, str] = None, **kwargs)`
  - **Docstring:**
  `````
  @boost 这是funboost框架最重要的一个函数，必须看懂BoosterParams里面的入参有哪些。
  建议永远使用 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) 这种传参方式。
  
  
  pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.
  (高版本的pycharm pydantic是内置支持代码补全的,由此可见,pydantic太好了,pycharm官方都来支持)
  
  强烈建议所有入参放在 BoosterParams() 中,不要直接在BoosterParams之外传参.现在是兼容老的直接在@boost中传参方式.
  建议不要给第一个入参queue_name传递字符串，而是永远传递BoosterParams类型， 例如 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  
  
  ```python
  # @boost('queue_test_f01', qps=0.2, ) # 老的入参方式
  @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) # 新的入参方式,所有入参放在 最流行的三方包 pydantic model BoosterParams 里面.
  def f(a, b):
      print(a + b)
  
  for i in range(10, 20):
      f.pub(dict(a=i, b=i * 2))
      f.push(i, i * 2)
  f.consume()
  # f.multi_process_conusme(8)             # # 这个是新加的方法，细粒度 线程 协程并发 同时叠加8个进程，速度炸裂。
  ```
  
  
  @boost('queue_test_f01', qps=0.2, )
  @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  @Booster(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
  @BoosterParams(queue_name='queue_test_f01', qps=0.2, )
  以上4种写法等效。
  `````
  - **Parameters:**
    - `self`
    - `queue_name: typing.Union[BoosterParams, str] = None`
    - `**kwargs`

**Public Methods (3):**
- `def multi_process_consume(self, process_num = 1)`
  - *超高速多进程消费*
- `def multi_process_pub_params_list(self, params_list, process_num = 16)`
  - *超高速多进程发布，例如先快速发布1000万个任务到中间件，以后慢慢消费*
- `def fabric_deploy(self, host, port, user, password, path_pattern_exluded_tuple = ('/.git/', '/.idea/', '/dist/', '/build/'), file_suffix_tuple_exluded = ('.pyc', '.log', '.gz'), only_upload_within_the_last_modify_time = 3650 * 24 * 60 * 60, file_volume_limit = 1000 * 1000, sftp_log_level = 20, extra_shell_str = '', invoke_runner_kwargs = {'hide': None, 'pty': True, 'warn': False}, python_interpreter = 'python3', process_num = 1, pkey_file_path = None)`
  - *入参见 fabric_deploy 函数。这里重复入参是为了代码在pycharm补全提示。*

**Class Variables (2):**
- `multi_process_start = multi_process_consume`
- `mp_consume = multi_process_consume`

##### 📌 `class BoosterRegistry`
*Line: 273*

**Docstring:**
`````
管理boosters，可以一键启动多个消费函数或者启动一组消费函数。

BoosterRegistry 是后加的， 原来的 BoostersManager 类是一个包含多个classmethod的类，和现在的方法名和入参一样。
为了兼容老的 BoostersManager 这个用法，现在的 BoostersManager 是 BoosterRegistry 其中一个实例。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, booster_registry_name)`
  - **Parameters:**
    - `self`
    - `booster_registry_name`

**Public Methods (17):**
- `def regist_booster(self, booster: Booster)`
  - *这个是框架在@boost时候自动调用的,无需用户亲自调用*
- `def show_all_boosters(self)`
- `def get_all_queues(self) -> list`
- `def get_all_queue_name__boost_params_unstrict_dict(self)`
  - **Docstring:**
  `````
  主要用来给前端或可视化观看的。
  
  返回一个字典,键是队列名,值是@boost的 BoosterParams 入参字典,
  因为 BoosterParams 有的入参是复杂对象类型,不能json序列化
  `````
- `def get_booster(self, queue_name: str) -> Booster`
  - **Docstring:**
  `````
  当前进程获得booster对象。注意和下面的get_or_create_booster_by_queue_name方法的区别,主要是开了多进程时候有区别.
  :param queue_name:
  :return:
  `````
- `def get_or_create_booster_by_queue_name(self, queue_name) -> Booster`
  - **Docstring:**
  `````
  当前进程获得booster对象，如果是多进程,会在新的进程内部创建一个新的booster对象,因为多进程操作有些中间件的同一个conn不行.
  :param queue_name: 就是 @boost的入参。
  :return:
  `````
- `def get_boost_params(self, queue_name: str) -> (dict, typing.Callable)`
  - **Docstring:**
  `````
  这个函数是为了在别的进程实例化 booster，consumer和publisher,获取queue_name队列对应的booster的当时的入参。
  有些中间件python包的对中间件连接对象不是多进程安全的，不要在进程2中去操作进程1中生成的booster consumer publisher等对象。
  `````
- `def build_booster(self, boost_params: BoosterParams) -> Booster`
  - **Docstring:**
  `````
  当前进程获得或者创建booster对象。方便有的人需要在函数内部临时动态根据队列名创建booster,不会无数次临时生成消费者、生产者、创建消息队列连接。
  :param boost_params: 就是 @boost的入参。
  :param consuming_function: 消费函数
  :return:
  `````
- `def get_cross_project_publisher(self, publisher_params: PublisherParams) -> AbstractPublisher`
  - **Docstring:**
  `````
  跨不同的项目，发布消息。例如proj1中定义有fun1消费函数，但proj2无法直接到proj1的函数，无法直接 fun1.push 来发布消息
  可以使用这个方法，获取一个publisher。
  
  publisher = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='proj1_queue', broker_kind=publisher_params.broker_kind))
  publisher.publish({'x': aaa})
  `````
- `def push(self, queue_name, *args, **kwargs)`
  - *push发布消息到消息队列 ;*
- `def publish(self, queue_name, msg)`
  - *publish发布消息到消息队列;*
- `def consume_queues(self, *queue_names)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费,多个函数队列在当前同一个进程内启动消费.
  这种方式节约总的内存,但无法利用多核cpu
  `````
- `def consume_all_queues(self, block = True)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需一个一个函数亲自 funxx.consume()来启动,多个函数队列在当前同一个进程内启动消费.
  这种方式节约总的内存,但无法利用多核cpu
  `````
- `def multi_process_consume_queues(self, **queue_name__process_num)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费,传递队列名和进程数,每个队列启动n个单独的消费进程;
  这种方式总的内存使用高,但充分利用多核cpu
  例如 multi_process_consume_queues(queue1=2,queue2=3) 表示启动2个进程消费queue1,启动3个进程消费queue2
  `````
- `def consume_group(self, booster_group: str, block = False)`
  - *根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;*
- `def multi_process_consume_group(self, booster_group: str, process_num = 1)`
  - *根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;*
- `def multi_process_consume_all_queues(self, process_num = 1)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需指定队列名,每个队列启动n个单独的消费进程;
  这种方式总的内存使用高,但充分利用多核cpu
  `````

**Class Variables (6):**
- `_lock = threading.Lock()`
- `consume = consume_queues`
- `consume_all = consume_all_queues`
- `mp_consume = multi_process_consume_queues`
- `mp_consume_group = multi_process_consume_group`
- `mp_consume_all = multi_process_consume_all_queues`

#### 🔧 Public Functions (1)

- `def gen_pid_queue_name_key(queue_name: str) -> typing.Tuple[int, str]`
  - *Line: 268*


---

`````python
from __future__ import annotations
import copy
import inspect
from multiprocessing import Process
import os
import sys
import types
import typing
import threading
from funboost.concurrent_pool import FlexibleThreadPool
from funboost.concurrent_pool.async_helper import simple_run_in_executor
from funboost.constant import FunctionKind, StrConst
from funboost.utils.class_utils import ClsHelper

from funboost.utils.ctrl_c_end import ctrl_c_recv
from funboost.utils.decorators import flyweight
from funboost.core.loggers import flogger, develop_logger, logger_prompt

from functools import wraps

from funboost.core.exceptions import BoostDecoParamsIsOldVersion
from funboost.core.func_params_model import (
    BoosterParams,
    FunctionResultStatusPersistanceConfig,
    TaskOptions,
    PublisherParams,
)

from funboost.factories.consumer_factory import get_consumer, ConsumerCacheProxy
from funboost.factories.publisher_factotry import get_publisher, PublisherCacheProxy

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.publishers.base_publisher import AbstractPublisher


from funboost.core.msg_result_getter import AsyncResult, AioAsyncResult


class Booster:
    """
    funboost极其重视代码能在pycharm下自动补全。元编程经常造成在pycharm下代码无法自动补全提示，主要是实现代码补全难。
    这种__call__写法在pycahrm下 不仅能补全消费函数的 push consume等方法，也能补全函数本身的入参，一举两得。代码能自动补全很重要。
    一个函数fun被 boost装饰器装饰后， isinstance(fun,Booster) 为True.

    pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

    Booster 是把Consumer 和 Publisher的方法集为一体。
    """


    def __init__(
        self,
        queue_name: typing.Union[BoosterParams, str] = None,
        *,
        boost_params: BoosterParams = None,
        **kwargs,
    ):
        """
        @boost 这是funboost框架最重要的一个函数，必须看懂BoosterParams里面的入参有哪些。
        建议永远使用 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) 这种传参方式。


        pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.
        (高版本的pycharm pydantic是内置支持代码补全的,由此可见,pydantic太好了,pycharm官方都来支持)

        强烈建议所有入参放在 BoosterParams() 中,不要直接在BoosterParams之外传参.现在是兼容老的直接在@boost中传参方式.
        建议不要给第一个入参queue_name传递字符串，而是永远传递BoosterParams类型， 例如 @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))


        ```python
        # @boost('queue_test_f01', qps=0.2, ) # 老的入参方式
        @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, )) # 新的入参方式,所有入参放在 最流行的三方包 pydantic model BoosterParams 里面.
        def f(a, b):
            print(a + b)

        for i in range(10, 20):
            f.pub(dict(a=i, b=i * 2))
            f.push(i, i * 2)
        f.consume()
        # f.multi_process_conusme(8)             # # 这个是新加的方法，细粒度 线程 协程并发 同时叠加8个进程，速度炸裂。
        ```


        @boost('queue_test_f01', qps=0.2, )
        @boost(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
        @Booster(BoosterParams(queue_name='queue_test_f01', qps=0.2, ))
        @BoosterParams(queue_name='queue_test_f01', qps=0.2, )
        以上4种写法等效。
        """

        # 以下代码很复杂，主要是兼容老的在@boost直接传参的方式,强烈建议使用新的入参方式,所有入参放在一个 BoosterParams 中，那就不需要理会下面这段逻辑.
        if isinstance(queue_name, str):
            if boost_params is None:
                boost_params = BoosterParams(queue_name=queue_name)
        elif queue_name is None and boost_params is None:
            raise ValueError("boost 入参错误")
        elif isinstance(queue_name, BoosterParams):
            boost_params = queue_name
        if isinstance(queue_name, str) or kwargs:
            flogger.warning(
                f"""你的 {queue_name} 队列， funboost 40.0版本以后： {BoostDecoParamsIsOldVersion.default_message}"""
            )
        boost_params_merge = boost_params.copy()
        boost_params_merge.update_from_dict(kwargs)
        self.boost_params: BoosterParams = boost_params_merge
        self.queue_name = boost_params_merge.queue_name

    def __str__(self):
        return f"{type(self)}  队列为 {self.queue_name} 函数为 {self.consuming_function} 的 booster"

    def __get__(self, instance, cls):
        """https://python3-cookbook.readthedocs.io/zh_CN/latest/c09/p09_define_decorators_as_classes.html"""
        if instance is None:
            return self
        else:
            return types.MethodType(self, instance)

    def __call__(self, *args, **kwargs) -> Booster:
        """
        # 第一次调用__call__，是装饰函数,返回了Booster对象,从此之后,被消费函数就变成了Booster类型对象.
        # Booster类型对象,怎么支持函数原来本身的直接运行功能? 那就是要让他走到 else 分支,直接用 self.consuming_function 函数本身去运行入参
        # 这里非常巧妙
        # 如果用户之后不打算使用funboost 的分布式函数调度功能,那么直接运行函数和原来一模一样,用户不需要删除 @boost装饰器 也能直接运行函数本身
        """
        if (
            len(kwargs) == 0
            and len(args) == 1
            and isinstance(args[0], typing.Callable)
            and not isinstance(args[0], Booster)
        ):
            consuming_function = args[0]
            self.boost_params.consuming_function = consuming_function
            self.boost_params.consuming_function_raw = consuming_function
            self.boost_params.consuming_function_name = consuming_function.__name__
            # print(consuming_function)
            # print(ClsHelper.get_method_kind(consuming_function))
            # print(inspect.getsourcelines(consuming_function))
            if self.boost_params.consuming_function_kind is None:
                self.boost_params.consuming_function_kind = ClsHelper.get_method_kind(
                    consuming_function
                )
            # if self.boost_params.consuming_function_kind in [FunctionKind.CLASS_METHOD,FunctionKind.INSTANCE_METHOD]:
            #     if self.boost_params.consuming_function_class_module is None:
            #         self.boost_params.consuming_function_class_module = consuming_function.__module__
            #     if self.boost_params.consuming_function_class_name is None:
            #         self.boost_params.consuming_function_class_name = consuming_function.__qualname__.split('.')[0]
            logger_prompt.debug(
                f""" {self.boost_params.queue_name} booster 配置是 {self.boost_params.json_str_value()}"""
            )
            self.consuming_function = consuming_function
            self.is_decorated_as_consume_function = True

            consumer: AbstractConsumer = ConsumerCacheProxy(
                self.boost_params
            ).consumer
            self.consumer = consumer

            self.publisher: AbstractPublisher = consumer.publisher_of_same_queue
            # self.publish = self.pub = self.apply_async = consumer.publisher_of_same_queue.publish
            # self.push = self.delay = consumer.publisher_of_same_queue.push
            self.publish = self.pub = self.apply_async = self.publisher.publish
            self.aio_publish = self.publisher.aio_publish
            self.push = self.delay = self.publisher.push
            self.aio_push = self.publisher.aio_push

            self.clear = self.clear_queue = consumer.publisher_of_same_queue.clear
            self.get_message_count = consumer.publisher_of_same_queue.get_message_count

            self.start_consuming_message = self.consume = self.start = (
                consumer.start_consuming_message
            )
            self.clear_filter_tasks = consumer.clear_filter_tasks
            self.wait_for_possible_has_finish_all_tasks = (
                consumer.wait_for_possible_has_finish_all_tasks
            )

            self.pause = self.pause_consume = consumer.pause_consume
            self.continue_consume = consumer.continue_consume

            wraps(consuming_function)(self)
            # BoostersManager.regist_booster(self)  # 这一句是登记
            BoosterRegistry(self.boost_params.booster_registry_name).regist_booster(self)
            
            return self
        else:
            return self.consuming_function(*args, **kwargs)

    # noinspection PyMethodMayBeStatic
    def multi_process_consume(self, process_num=1):
        """超高速多进程消费"""
        from funboost.core.muliti_process_enhance import run_consumer_with_multi_process

        run_consumer_with_multi_process(self, process_num)

    multi_process_start = multi_process_consume
    mp_consume = multi_process_consume

    # noinspection PyMethodMayBeStatic
    def multi_process_pub_params_list(self, params_list, process_num=16):
        """超高速多进程发布，例如先快速发布1000万个任务到中间件，以后慢慢消费"""
        """
        用法例如，快速20进程发布1000万任务，充分利用多核加大cpu使用率。
        @boost('test_queue66c', qps=1/30,broker_kind=BrokerEnum.KAFKA_CONFLUENT)
        def f(x, y):
            print(f'函数开始执行时间 {time.strftime("%H:%M:%S")}')
        if __name__ == '__main__':
            f.multi_process_pub_params_list([{'x':i,'y':i*3}  for i in range(10000000)],process_num=20)
            f.consume()
        """
        from funboost.core.muliti_process_enhance import multi_process_pub_params_list

        multi_process_pub_params_list(self, params_list, process_num)

    # noinspection PyDefaultArgument
    # noinspection PyMethodMayBeStatic
    def fabric_deploy(
        self,
        host,
        port,
        user,
        password,
        path_pattern_exluded_tuple=("/.git/", "/.idea/", "/dist/", "/build/"),
        file_suffix_tuple_exluded=(".pyc", ".log", ".gz"),
        only_upload_within_the_last_modify_time=3650 * 24 * 60 * 60,
        file_volume_limit=1000 * 1000,
        sftp_log_level=20,
        extra_shell_str="",
        invoke_runner_kwargs={"hide": None, "pty": True, "warn": False},
        python_interpreter="python3",
        process_num=1,
        pkey_file_path=None,
    ):
        """
        入参见 fabric_deploy 函数。这里重复入参是为了代码在pycharm补全提示。
        """
        params = copy.copy(locals())
        params.pop("self")
        from funboost.core.fabric_deploy_helper import fabric_deploy

        fabric_deploy(self, **params)

    def __getstate__(self):
        state = {}
        state["queue_name"] = self.boost_params.queue_name
        state["booster_registry_name"] = self.booster_registry_name
        return state

    def __setstate__(self, state):
        """非常高级的骚操作,支持booster对象pickle序列化和反序列化,设计非常巧妙，堪称神来之笔
        这样当使用redis作为apscheduler的 jobstores时候,aps_obj.add_job(booster.push,...) 可以正常工作,
        使不报错 booster对象无法pickle序列化.

        这个反序列化,没有执着于对 socket threding.Lock 怎么反序列化,而是偷换概念，绕过难题,基于标识的代理反序列化
        """
        cur_boosters_manager = BoosterRegistry(
            state["booster_registry_name"]
        )
        _booster = cur_boosters_manager.get_or_create_booster_by_queue_name(
            state["queue_name"]
        )
        self.__dict__.update(_booster.__dict__)


boost = Booster  # @boost 后消费函数.  不能自动补全方法就用 Booster就可以。 2024版本的 pycharm抽风了，@boost的消费函数不能自动补全提示 .consume  .push 这些方法。
task_deco = boost  # 两个装饰器名字都可以。task_deco是原来名字，兼容一下。


def gen_pid_queue_name_key(queue_name: str,) -> typing.Tuple[int, str]:
    pid = os.getpid()
    return (pid,  queue_name)

@flyweight  # flyweight是享元模式，有限的多例模式，每个 booster_registry_name 对应一个对象
class BoosterRegistry:
    """
    管理boosters，可以一键启动多个消费函数或者启动一组消费函数。

    BoosterRegistry 是后加的， 原来的 BoostersManager 类是一个包含多个classmethod的类，和现在的方法名和入参一样。
    为了兼容老的 BoostersManager 这个用法，现在的 BoostersManager 是 BoosterRegistry 其中一个实例。

    """

    _lock = threading.Lock()


    def __init__(self,booster_registry_name):
        self.booster_registry_name = booster_registry_name
        
        # pid_queue_name__booster_map字典存放 {(进程id,queue_name):Booster对象}
        self.pid_queue_name__booster_map: typing.Dict[
            typing.Tuple[int, str], Booster
        ] = {}

        # queue_name__boost_params_consuming_function_map 字典存放  {queue_name,(@boost的入参字典,@boost装饰的消费函数)}
        self.queue_name__boost_params_map: typing.Dict[str, BoosterParams] = {}

        self.pid_queue_name__has_start_consume_set = set()
      

    def regist_booster(self, booster: Booster):
        """这个是框架在@boost时候自动调用的,无需用户亲自调用"""
        # if booster.boost_params.is_fake_booster is True:
        #     return
        self.pid_queue_name__booster_map[
            gen_pid_queue_name_key(booster.boost_params.queue_name)
        ] = booster
        self.queue_name__boost_params_map[booster.boost_params.queue_name] = (
            booster.boost_params
        )

    def show_all_boosters(self):
        queues = []
        for pid_queue_name, booster in self.pid_queue_name__booster_map.items():
            queues.append(pid_queue_name[1])
            flogger.debug(f"booster: {pid_queue_name[1]}  {booster}")

    def get_all_queues(self) -> list:
        return list(self.queue_name__boost_params_map.keys())

    def get_all_queue_name__boost_params_unstrict_dict(self):
        """
        主要用来给前端或可视化观看的。

        返回一个字典,键是队列名,值是@boost的 BoosterParams 入参字典,
        因为 BoosterParams 有的入参是复杂对象类型,不能json序列化
        """
        return {
            k: v.get_str_dict() for k, v in self.queue_name__boost_params_map.items()
        }

    def get_booster(self, queue_name: str) -> Booster:
        """
        当前进程获得booster对象。注意和下面的get_or_create_booster_by_queue_name方法的区别,主要是开了多进程时候有区别.
        :param queue_name:
        :return:
        """

        key = gen_pid_queue_name_key(queue_name)
        if key in self.pid_queue_name__booster_map:
            return self.pid_queue_name__booster_map[key]
        else:
            err_msg = f"进程 {os.getpid()} ，没有 {queue_name} 对应的 booster   , pid_queue_name__booster_map: {self.pid_queue_name__booster_map}"
            raise ValueError(err_msg)

    def get_or_create_booster_by_queue_name(
        self,
        queue_name,
    ) -> Booster:
        """
        当前进程获得booster对象，如果是多进程,会在新的进程内部创建一个新的booster对象,因为多进程操作有些中间件的同一个conn不行.
        :param queue_name: 就是 @boost的入参。
        :return:
        """

        key = gen_pid_queue_name_key(queue_name)
        if key in self.pid_queue_name__booster_map:
            return self.pid_queue_name__booster_map[key]
        else:
            with self._lock:
                if key not in self.pid_queue_name__booster_map:
                    boost_params = self.get_boost_params(queue_name)
                    booster = Booster(boost_params)(boost_params.consuming_function)
                    self.pid_queue_name__booster_map[key] = booster
                return booster

    def get_boost_params(self, queue_name: str) -> (dict, typing.Callable):
        """
        这个函数是为了在别的进程实例化 booster，consumer和publisher,获取queue_name队列对应的booster的当时的入参。
        有些中间件python包的对中间件连接对象不是多进程安全的，不要在进程2中去操作进程1中生成的booster consumer publisher等对象。
        """
        return self.queue_name__boost_params_map[queue_name]

    def build_booster(self, boost_params: BoosterParams) -> Booster:
        """
        当前进程获得或者创建booster对象。方便有的人需要在函数内部临时动态根据队列名创建booster,不会无数次临时生成消费者、生产者、创建消息队列连接。
        :param boost_params: 就是 @boost的入参。
        :param consuming_function: 消费函数
        :return:
        """

        key = gen_pid_queue_name_key(boost_params.queue_name)
        if key in self.pid_queue_name__booster_map:
            booster = self.pid_queue_name__booster_map[key]
        else:
            if boost_params.consuming_function is None:
                raise ValueError(
                    f" build_booster 方法的 consuming_function 字段不能为None,必须指定一个函数"
                )
            flogger.info(
                f"创建booster {boost_params} {boost_params.consuming_function}"
            )
            booster = Booster(boost_params)(boost_params.consuming_function)
        return booster

    # queue_name__cross_project_publisher_map = {}

    def get_cross_project_publisher(
        self, publisher_params: PublisherParams
    ) -> AbstractPublisher:
        """
        跨不同的项目，发布消息。例如proj1中定义有fun1消费函数，但proj2无法直接到proj1的函数，无法直接 fun1.push 来发布消息
        可以使用这个方法，获取一个publisher。

        publisher = BoostersManager.get_cross_project_publisher(PublisherParams(queue_name='proj1_queue', broker_kind=publisher_params.broker_kind))
        publisher.publish({'x': aaa})
        """
        # 确保使用当前 registry 的命名空间，实现隔离
        if publisher_params.booster_registry_name != self.booster_registry_name:
            raise ValueError(f"publisher_params.booster_registry_name != self.booster_registry_name, {publisher_params.booster_registry_name} != {self.booster_registry_name}")
            
        return PublisherCacheProxy(publisher_params).publisher

    def push(self, queue_name, *args, **kwargs):
        """push发布消息到消息队列 ;"""
        self.get_or_create_booster_by_queue_name(queue_name).push(*args, **kwargs)

    def publish(self, queue_name, msg):
        """publish发布消息到消息队列;"""
        self.get_or_create_booster_by_queue_name(queue_name).publish(msg)

    def consume_queues(self, *queue_names):
        """
        启动多个消息队列名的消费,多个函数队列在当前同一个进程内启动消费.
        这种方式节约总的内存,但无法利用多核cpu
        """
        for queue_name in queue_names:
            self.get_booster(queue_name).consume()
        ctrl_c_recv()

    consume = consume_queues

    def consume_all_queues(self, block=True):
        """
        启动所有消息队列名的消费,无需一个一个函数亲自 funxx.consume()来启动,多个函数队列在当前同一个进程内启动消费.
        这种方式节约总的内存,但无法利用多核cpu
        """
        for queue_name in self.get_all_queues():
            self.get_booster(queue_name).consume()
        if block:
            ctrl_c_recv()

    consume_all = consume_all_queues

    def multi_process_consume_queues(self, **queue_name__process_num):
        """
        启动多个消息队列名的消费,传递队列名和进程数,每个队列启动n个单独的消费进程;
        这种方式总的内存使用高,但充分利用多核cpu
        例如 multi_process_consume_queues(queue1=2,queue2=3) 表示启动2个进程消费queue1,启动3个进程消费queue2
        """
        for queue_name, process_num in queue_name__process_num.items():
            self.get_booster(queue_name).multi_process_consume(process_num)
        ctrl_c_recv()

    mp_consume = multi_process_consume_queues

    def consume_group(self, booster_group: str, block=False):
        """
        根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;
        """
        if booster_group is None:
            raise ValueError("booster_group 不能为None")
        need_consume_queue_names = []
        for queue_name in self.get_all_queues():
            booster = self.get_or_create_booster_by_queue_name(queue_name)
            if booster.boost_params.booster_group == booster_group:
                need_consume_queue_names.append(queue_name)
        flogger.info(
            f"according to booster_group:{booster_group} ,start consume queues: {need_consume_queue_names}"
        )
        for queue_name in need_consume_queue_names:
            self.get_or_create_booster_by_queue_name(queue_name).consume()
        if block:
            ctrl_c_recv()

    def multi_process_consume_group(self, booster_group: str, process_num=1):
        """
        根据@boost装饰器的 booster_group消费分组名字,启动多个消费函数;
        """
        for _ in range(process_num):
            Process(target=self.consume_group, args=(booster_group, True)).start()

    mp_consume_group = multi_process_consume_group

    def multi_process_consume_all_queues(self, process_num=1):
        """
        启动所有消息队列名的消费,无需指定队列名,每个队列启动n个单独的消费进程;
        这种方式总的内存使用高,但充分利用多核cpu
        """
        for queue_name in self.get_all_queues():
            self.get_booster(queue_name).multi_process_consume(process_num)
        ctrl_c_recv()

    mp_consume_all = multi_process_consume_all_queues


booster_registry_default = BoosterRegistry(
    booster_registry_name=StrConst.BOOSTER_REGISTRY_NAME_DEFAULT,
)
# 这个 BoostersManager 是兼容原来名字,老的BoostersManager原来是一个包含一组classmethod方法的类，
# 现在 BoostersManager 是 BoosterRegistry 的一个实例，是一个对象。
# 因为引入了 booster_registry_name 概念，为了多实例隔离更方便，开发成带实例方法的类，老的 BoostersManager 则全是calssmethod方法。
BoostersManager = booster_registry_default

`````

--- **end of file: funboost/core/booster.py** (project: funboost) --- 

---


--- **start of file: funboost/core/broker_kind__exclusive_config_default_define.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/broker_kind__exclusive_config_default_define.py`

#### 📝 Module Docstring

`````
这个文件决定了，每种broker对应的能额外传递哪些独特特殊的中间件配置，
从BoosterParams 的 broker_exclusive_config 入参中传递一个字典
`````

#### 📦 Imports

- `from logging import Logger`
- `from funboost.constant import BrokerEnum`

#### 🔧 Public Functions (2)

- `def register_broker_exclusive_config_default(broker_kind: str, broker_exclusive_config_default: dict)`
  - *Line: 14*

- `def generate_broker_exclusive_config(broker_kind: str, user_broker_exclusive_config: dict, logger: Logger)`
  - *Line: 21*


---

`````python

"""
这个文件决定了，每种broker对应的能额外传递哪些独特特殊的中间件配置，
从BoosterParams 的 broker_exclusive_config 入参中传递一个字典
"""

from logging import Logger
from funboost.constant import BrokerEnum


broker_kind__exclusive_config_default_map: dict = {}


def register_broker_exclusive_config_default(
    broker_kind: str, broker_exclusive_config_default: dict
):
    broker_kind__exclusive_config_default_map[broker_kind] = broker_exclusive_config_default



def generate_broker_exclusive_config(
    broker_kind: str,
    user_broker_exclusive_config: dict,
    logger: Logger,
):
    broker_exclusive_config_default = broker_kind__exclusive_config_default_map.get(
        broker_kind, {}
    )
    broker_exclusive_config_keys = broker_exclusive_config_default.keys()
    if user_broker_exclusive_config:
        if set(user_broker_exclusive_config).issubset(broker_exclusive_config_keys):
            logger.info(
                f"当前消息队列中间件能支持特殊独有配置 {broker_exclusive_config_default.keys()}"
            )
        else:
            logger.warning(f"""当前消息队列中间件含有不支持的特殊配置 {user_broker_exclusive_config.keys()} ,
            能支持的特殊独有配置包括 {broker_exclusive_config_keys}""")
    broker_exclusive_config_merge = dict()
    broker_exclusive_config_merge.update(broker_exclusive_config_default)
    broker_exclusive_config_merge.update(user_broker_exclusive_config)
    return broker_exclusive_config_merge


# celery的可以配置项大全  https://docs.celeryq.dev/en/stable/userguide/configuration.html#new-lowercase-settings
# celery @app.task() 所有可以配置项可以看  D:\ProgramData\Miniconda3\Lib\site-packages\celery\app\task.py
register_broker_exclusive_config_default(BrokerEnum.CELERY, {"celery_task_config": {}})


# dramatiq_actor_options 的值可以是：
# {'max_age', 'throws', 'pipe_target', 'pipe_ignore', 'on_success', 'retry_when', 'time_limit', 'min_backoff', 'max_retries', 'max_backoff', 'notify_shutdown', 'on_failure'}
register_broker_exclusive_config_default(
    BrokerEnum.DRAMATIQ, {"dramatiq_actor_options": {}}
)


register_broker_exclusive_config_default(
    BrokerEnum.GRPC,
    {
        "host": "127.0.0.1",
        "port": None,
    },
)

register_broker_exclusive_config_default(
    BrokerEnum.HTTP,
    {
        "host": "127.0.0.1",
        "port": None,
    },
)


"""
retries=0, retry_delay=0, priority=None, context=False,
name=None, expires=None, **kwargs
"""
register_broker_exclusive_config_default(BrokerEnum.HUEY, {"huey_task_kwargs": {}})


"""
auto_offset_reset 介绍

auto_offset_reset (str): A policy for resetting offsets on
OffsetOutOfRange errors: 'earliest' will move to the oldest
available message, 'latest' will move to the most recent. Any
other value will raise the exception. Default: 'latest'.
"""
register_broker_exclusive_config_default(
    BrokerEnum.KAFKA,
    {
        "group_id": "funboost_kafka",
        "auto_offset_reset": "earliest",
        "num_partitions": 10,
        "replication_factor": 1,
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.KAFKA_CONFLUENT,
    {
        "group_id": "funboost_kafka",
        "auto_offset_reset": "earliest",
        "num_partitions": 10,
        "replication_factor": 1,
    },
)


""" 
# prefetch_count 是预获取消息数量
transport_options是kombu的transport_options 。 
例如使用kombu使用redis作为中间件时候，可以设置 visibility_timeout 来决定消息取出多久没有ack，就自动重回队列。
kombu的每个中间件能设置什么 transport_options 可以看 kombu的源码中的 transport_options 参数说明。
"""
register_broker_exclusive_config_default(
    BrokerEnum.KOMBU,
    {
        "kombu_url": None,  # 如果这里也配置了kombu_url,则优先使用跟着你的kombu_url，否则使用funboost_config. KOMBU_URL
        "transport_options": {},  # transport_options是kombu的transport_options 。
        "prefetch_count": 500,
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.MYSQL_CDC, {"BinLogStreamReaderConfig": {}}
)  # 入参是 BinLogStreamReader 的入参BinLogStreamReader


"""
consumer_type Members:
Exclusive  Shared Failover KeyShared
"""
register_broker_exclusive_config_default(
    BrokerEnum.PULSAR,
    {
        "subscription_name": "funboost_group",
        "replicate_subscription_state_enabled": True,
        "consumer_type": "Shared",
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.RABBITMQ_AMQPSTORM,
    {
        "queue_durable": True,
        "x-max-priority": None,  # x-max-priority 是 rabbitmq的优先级队列配置，必须为整数，强烈建议要小于5。为None就代表队列不支持优先级。
        "no_ack": False,
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.RABBITMQ_COMPLEX_ROUTING,
    {
        "queue_durable": True,
        "x-max-priority": None,  # x-max-priority 是 rabbitmq的优先级队列配置，必须为整数，强烈建议要小于5。为None就代表队列不支持优先级。
        "no_ack": False,
        "exchange_name": "",
        "exchange_type": "direct",
        "routing_key_for_bind": None,  # 绑定交换机和队列时使用的key。None表示使用queue_name作为绑定键；""(空字符串)也表示使用queue_name。对于fanout和headers交换机，此值会被忽略。对于topic交换机，可以使用通配符*和#。
        "routing_key_for_publish": None,
        # for headers exchange
        "headers_for_bind": {},
        "x_match_for_bind": "all",  # all or any
        "exchange_declare_durable": True,
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.REDIS,
    {
        "redis_bulk_push": 1,
        "pull_msg_batch_size": 100,
    },
)  # redis_bulk_push 是否redis批量推送


register_broker_exclusive_config_default(
    BrokerEnum.REDIS_ACK_ABLE, {"pull_msg_batch_size": 100}
)

# RedisConsumerAckUsingTimeout的ack timeot 是代表消息取出后过了多少秒还未ack，就自动重回队列。这个配置一定要大于函数消耗时间，否则不停的重回队列。
"""
用法，如何设置ack_timeout，是使用 broker_exclusive_config 中传递，就能覆盖这里的3600，用户不用改BROKER_EXCLUSIVE_CONFIG_DEFAULT的源码。
@boost(BoosterParams(queue_name='test_redis_ack__use_timeout', broker_kind=BrokerEnum.REIDS_ACK_USING_TIMEOUT,
                        concurrent_num=5, log_level=20, broker_exclusive_config={'ack_timeout': 30}))
"""
register_broker_exclusive_config_default(
    BrokerEnum.REIDS_ACK_USING_TIMEOUT, {"ack_timeout": 3600}
)


register_broker_exclusive_config_default(
    BrokerEnum.REDIS_PRIORITY, {"x-max-priority": None}
)  # x-max-priority 是 rabbitmq的优先级队列配置，必须为整数，强烈建议要小于5。为None就代表队列不支持优先级。


register_broker_exclusive_config_default(
    BrokerEnum.REDIS_STREAM,
    {
        "group": "funboost_group",
        "pull_msg_batch_size": 100,
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.TCP,
    {
        "host": "127.0.0.1",
        "port": None,
        "bufsize": 10240,
    },
)


register_broker_exclusive_config_default(
    BrokerEnum.UDP,
    {
        "host": "127.0.0.1",
        "port": None,
        "bufsize": 10240,
    },
)

register_broker_exclusive_config_default(BrokerEnum.ZEROMQ, {"port": None})

`````

--- **end of file: funboost/core/broker_kind__exclusive_config_default_define.py** (project: funboost) --- 

---


--- **start of file: funboost/core/consuming_func_iniput_params_check.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/consuming_func_iniput_params_check.py`

#### 📦 Imports

- `import typing`
- `import inspect`
- `import copy`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.constant import ConsumingFuncInputParamsCheckerField`
- `from funboost.core.exceptions import FuncParamsError`

#### 🏛️ Classes (2)

##### 📌 `class ConsumingFuncInputParamsChecker(FunboostFileLoggerMixin)`
*Line: 10*

**Docstring:**
`````
发布的任务的函数参数检查，使发布的任务在消费时候不会出现低级错误。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, final_func_input_params_list_info: typing.Dict)`
  - **Parameters:**
    - `self`
    - `final_func_input_params_list_info: typing.Dict`

**Public Methods (4):**
- `def update_check_params(self, final_func_input_params_list_info)`
  - **Docstring:**
  `````
  这个是供动态热更新校验参数，funboost.faas 不重启就能动态变更函数修改后的校验规则
        因为 funboost.faas 完全不需要依赖真正的消费函数对象，
        是把保存到redis元数据的booster_params的 auto_generate_info.final_func_input_params_info 更新到ConsumingFuncInputParamsChecker实例中
        
        redis中的 auto_generate_info 例子如下
        "auto_generate_info": {
    "where_to_instantiate": "D:\codes\funboost\examples\example_faas\task_funs_dir\sub.py:5",
    "final_func_input_params_info": {
      "func_name": "sub",
      "func_position": "<function sub at 0x00000272649BBA60>",
      "is_manual_func_input_params": false,
      "all_arg_name_list": [
        "a",
        "b"
      ],
      "must_arg_name_list": [
        "a",
        "b"
      ],
      "optional_arg_name_list": []
    }
  }
        
  `````
- `def gen_func_params_info_by_func(func: typing.Callable)` `staticmethod`
- `def check_func_msg_dict(self, publish_params: dict)`
- `def gen_final_func_input_params_info(cls, consumer_or_publisher_params: typing.Union[BoosterParams, PublisherParams])` `classmethod`
  - *生成最终的函数参数信息，包括手动输入的参数和默认参数。*

##### 📌 `class FakeFunGenerator`
*Line: 117*

**Docstring:**
`````
动态函数生成器：根据参数元数据生成具有正确签名的伪函数
用途：funboost.faas 可以从 redis 元数据动态生成函数对象，无需真正的函数定义
`````

**Public Methods (3):**
- `def gen_fake_fun_by_params(final_func_input_params_info: dict)` `staticmethod`
  - **Docstring:**
  `````
  根据必需参数和可选参数列表动态生成函数
  你可以理解是为了欺骗 inspect 模块，让 inspect 模块返回的函数参数信息和实际的函数参数信息一致。
  函数名、参数列表、默认值和原函数一模一样
  `````
- `def gen_fake_fun()` `staticmethod`
  - *随便生成的假的函数，这种需要 update_check_params去更新*
- `def is_fake_fun(func)` `staticmethod`


---

`````python
import typing
import inspect
import copy
from funboost.core.func_params_model import BoosterParams,PublisherParams
from funboost.core.loggers import FunboostFileLoggerMixin
from funboost.constant import ConsumingFuncInputParamsCheckerField
from funboost.core.exceptions import FuncParamsError


class ConsumingFuncInputParamsChecker(FunboostFileLoggerMixin):
    """
    发布的任务的函数参数检查，使发布的任务在消费时候不会出现低级错误。
    """

    def __init__(self, final_func_input_params_list_info: typing.Dict):
        self.update_check_params(final_func_input_params_list_info)

    def update_check_params(self,final_func_input_params_list_info): 
        """这个是供动态热更新校验参数，funboost.faas 不重启就能动态变更函数修改后的校验规则
        因为 funboost.faas 完全不需要依赖真正的消费函数对象，
        是把保存到redis元数据的booster_params的 auto_generate_info.final_func_input_params_info 更新到ConsumingFuncInputParamsChecker实例中
        
        redis中的 auto_generate_info 例子如下
        "auto_generate_info": {
    "where_to_instantiate": "D:\\codes\\funboost\\examples\\example_faas\\task_funs_dir\\sub.py:5",
    "final_func_input_params_info": {
      "func_name": "sub",
      "func_position": "<function sub at 0x00000272649BBA60>",
      "is_manual_func_input_params": false,
      "all_arg_name_list": [
        "a",
        "b"
      ],
      "must_arg_name_list": [
        "a",
        "b"
      ],
      "optional_arg_name_list": []
    }
  }
        """
        self.consuming_func_input_params_list_info = final_func_input_params_list_info
        self.all_arg_name_list = final_func_input_params_list_info[ConsumingFuncInputParamsCheckerField.all_arg_name_list]
        self.all_arg_name_set = set(self.all_arg_name_list)
        self.position_arg_name_set = set(final_func_input_params_list_info[ConsumingFuncInputParamsCheckerField.must_arg_name_list])
        self.optional_arg_name_set = set(final_func_input_params_list_info[ConsumingFuncInputParamsCheckerField.optional_arg_name_list])


    @staticmethod
    def gen_func_params_info_by_func(func: typing.Callable):
        spec = inspect.getfullargspec(func)
        all_arg_name_list = list(spec.args)
        all_arg_name_set = set(spec.args)
        # print(spec.args)
        if spec.defaults:
            len_deafult_args = len(spec.defaults)
            position_arg_name_list = spec.args[0: -len_deafult_args]
            position_arg_name_set = set(position_arg_name_list)
            keyword_arg_name_list = spec.args[-len_deafult_args:]
            keyword_arg_name_set = set(keyword_arg_name_list)
        else:
            position_arg_name_list = spec.args
            position_arg_name_set = set(position_arg_name_list)
            keyword_arg_name_list = []
            keyword_arg_name_set = set()
        # print(func.__name__,str(func),func)
        consuming_func_input_params_list_info = {
            ConsumingFuncInputParamsCheckerField.func_name: func.__name__,
            ConsumingFuncInputParamsCheckerField.func_position: str(func),
            ConsumingFuncInputParamsCheckerField.is_manual_func_input_params: False,
            ConsumingFuncInputParamsCheckerField.all_arg_name_list: all_arg_name_list,
            ConsumingFuncInputParamsCheckerField.must_arg_name_list: position_arg_name_list,
            ConsumingFuncInputParamsCheckerField.optional_arg_name_list: keyword_arg_name_list,
        }
        return consuming_func_input_params_list_info

    def check_func_msg_dict(self, publish_params: dict):
        publish_params_keys_set = set(publish_params.keys())
        if publish_params_keys_set.issubset(self.all_arg_name_set) and publish_params_keys_set.issuperset(self.position_arg_name_set):
            return True
        else:
            error_data = {
            'your_now_publish_params_keys_list':list(publish_params_keys_set),
            'right_func_input_params_list_info':self.consuming_func_input_params_list_info,
            }
            raise FuncParamsError('Invalid parameters for consuming function',error_data=error_data)


    @classmethod
    def gen_final_func_input_params_info(cls,consumer_or_publisher_params:typing.Union[BoosterParams,PublisherParams]):
        """
        生成最终的函数参数信息，包括手动输入的参数和默认参数。
        """
        if consumer_or_publisher_params.consuming_function is None:
            return
        auto_generate_info = consumer_or_publisher_params.auto_generate_info
        if 'final_func_input_params_info' in auto_generate_info:
            return
        else:
            auto_generate_info['final_func_input_params_info'] = {}
        if consumer_or_publisher_params.manual_func_input_params['is_manual_func_input_params'] is False :
            consuming_func_input_params_list_info =  cls.gen_func_params_info_by_func(consumer_or_publisher_params.consuming_function)
            auto_generate_info['final_func_input_params_info'].update(consuming_func_input_params_list_info)
        if  consumer_or_publisher_params.manual_func_input_params['is_manual_func_input_params'] is True:
            manual_func_input_params_new = copy.deepcopy(consumer_or_publisher_params.manual_func_input_params)
            manual_func_input_params_new[ConsumingFuncInputParamsCheckerField.is_manual_func_input_params] = True
            manual_func_input_params_new[ConsumingFuncInputParamsCheckerField.all_arg_name_list] = manual_func_input_params_new[ConsumingFuncInputParamsCheckerField.must_arg_name_list] + manual_func_input_params_new[ConsumingFuncInputParamsCheckerField.optional_arg_name_list]
            manual_func_input_params_new['func_name'] = getattr(consumer_or_publisher_params.consuming_function,'__name__',None)
            # print(consumer_or_publisher_params.consuming_function,str(consumer_or_publisher_params.consuming_function))
            manual_func_input_params_new['func_position'] = str(consumer_or_publisher_params.consuming_function)
            auto_generate_info['final_func_input_params_info'].update(manual_func_input_params_new)





class FakeFunGenerator:
    """
    动态函数生成器：根据参数元数据生成具有正确签名的伪函数
    用途：funboost.faas 可以从 redis 元数据动态生成函数对象，无需真正的函数定义
    """
    
    @staticmethod
    def gen_fake_fun_by_params(final_func_input_params_info:dict):
        """
        根据必需参数和可选参数列表动态生成函数
        你可以理解是为了欺骗 inspect 模块，让 inspect 模块返回的函数参数信息和实际的函数参数信息一致。
        函数名、参数列表、默认值和原函数一模一样
        """

        must_arg_name_list = final_func_input_params_info[ConsumingFuncInputParamsCheckerField.must_arg_name_list]
        optional_arg_name_list = final_func_input_params_info[ConsumingFuncInputParamsCheckerField.optional_arg_name_list]
        func_name = final_func_input_params_info[ConsumingFuncInputParamsCheckerField.func_name]
        
        
        # 构建参数字符串
        must_params = ', '.join(must_arg_name_list)
        optional_params = ', '.join([f'{arg}=None' for arg in optional_arg_name_list])
        
        # 组合所有参数
        if must_params and optional_params:
            all_params = f'{must_params}, {optional_params}'
        elif must_params:
            all_params = must_params
        elif optional_params:
            all_params = optional_params
        else:
            all_params = ''
        
        # 动态生成函数代码
        func_code = f'''
def {func_name}({all_params}):
    """
    Dynamically generated function with signature:
    - Required params: {must_arg_name_list}
    - Optional params: {optional_arg_name_list}
    """
    return locals()
'''
        
        # 执行代码生成函数
        local_namespace = {}
        exec(func_code, {}, local_namespace)
        fake_fun = local_namespace[func_name]
        setattr(fake_fun,'is_fake_fun',True)
        return fake_fun
    
    @staticmethod
    def gen_fake_fun():
        """随便生成的假的函数，这种需要 update_check_params去更新"""
        def fake_fun():
            pass
        setattr(fake_fun,'is_fake_fun',True)
        return fake_fun
    

    @staticmethod
    def is_fake_fun(func):
        return getattr(func,'is_fake_fun',False)
`````

--- **end of file: funboost/core/consuming_func_iniput_params_check.py** (project: funboost) --- 

---


--- **start of file: funboost/core/current_task.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/current_task.py`

#### 📝 Module Docstring

`````
fct 是 funboost current task 的简写，就是当前任务的意思。能同时兼容threading和asyncio隔离。

fct用法例子 
'''
from funboost import fct 

在消费函数内部能知道自己的takid，queue_name 等等。
print(fct.function_result_status.get_status_dict())
print(fct.function_result_status.task_id)
print(fct.run_times)
print(fct.full_msg)
'''
`````

#### 📦 Imports

- `import typing`
- `import contextvars`
- `from dataclasses import dataclass`
- `import logging`
- `import threading`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`

#### 🏛️ Classes (3)

##### 📌 `class FctContext`
*Line: 28*

**Docstring:**
`````
fct 是 funboost current task 的简写
`````

**Class Variables (2):**
- `function_result_status: FunctionResultStatus`
- `logger: logging.Logger`

##### 📌 `class _FctProxy`
*Line: 50*

**Docstring:**
`````
fct 代理类，通过 contextvars 自动获取当前线程/协程的上下文。
可以直接导入这个 fct，不需要手动写 fct = funboost_current_task() 了。
直接 from funboost import fct 就完了。
funboost 的 fct 相当于 flask 的 request 那种对象，自动线程/协程级别隔离，多个线程不会互相干扰。


fct 比直接 get_fct_context 好用一点点，fct相当于把FctContext对象的一级属性的function_result_status中的很多最重要二级属性直接提升作为一级属性了。
`````

**Properties (7):**
- `@property fct_context -> FctContext`
- `@property logger -> logging.Logger`
- `@property function_params -> dict`
- `@property full_msg -> dict`
- `@property function_result_status -> FunctionResultStatus`
- `@property task_id -> str`
- `@property queue_name -> str`

##### 📌 `class FctContextThread(threading.Thread)`
*Line: 118*

**Docstring:**
`````
这个类自动把当前线程的 funboost 上下文自动传递给新开的线程。
由于 contextvars 不会自动跨线程传递，只能跨协程自动传递，如果想跨线程自动传递，需要手动复制上下文。


如果没有这个基类，那么需要 手动复制上下文，然后让线程运行 ctx.run(worker) 而不是直接运行 worker： 
# 1. 显式捕获当前上下文
ctx = contextvars.copy_context()
# 2. 让线程运行 ctx.run(worker) 而不是直接运行 worker
# 这样 worker 就会在 ctx 的上下文中执行
t = threading.Thread(target=ctx.run, args=(worker,)) # 这是正解，传递上下文

# t = threading.Thread(target=worker,args=(,)) # 这是错误写法，不能自动传递上下文给子线程，
# 例如funboost的超时 kill功能，都是在另外单独的子线程去运行消费函数的，所以有时候需要传递给子线程。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, group = None, target = None, name = None, args = (), kwargs = None)`
  - **Parameters:**
    - `self`
    - `group = None`
    - `target = None`
    - `name = None`
    - `args = ()`
    - `kwargs = None`

**Public Methods (1):**
- `def run(self)`

#### 🔧 Public Functions (4)

- `def set_fct_context(fct_context: typing.Optional[FctContext])`
  - *Line: 40*
  - *设置当前线程/协程的 FctContext*

- `def get_fct_context() -> FctContext`
  - *Line: 45*
  - *获取当前线程/协程的 FctContext*

- `def funboost_current_task() -> _FctProxy`
  - *Line: 97*
  - **Docstring:**
  `````
  这个是兼容老的funboost_current_task() 函数，现在直接用 fct 就行了。
  
  获取当前任务上下文代理对象。
  由于 contextvars 同时支持多线程和异步协程，这里直接返回 fct 代理对象即可。
  `````

- `def get_current_taskid() -> str`
  - *Line: 107*
  - *获取当前任务的 task_id*


---

`````python
""" 
fct 是 funboost current task 的简写，就是当前任务的意思。能同时兼容threading和asyncio隔离。

fct用法例子 
'''
from funboost import fct 

在消费函数内部能知道自己的takid，queue_name 等等。
print(fct.function_result_status.get_status_dict())
print(fct.function_result_status.task_id)
print(fct.run_times)
print(fct.full_msg)
'''


"""

import typing
import contextvars
from dataclasses import dataclass
import logging
import threading


from funboost.core.function_result_status_saver import FunctionResultStatus

@dataclass
class FctContext:
    """
    fct 是 funboost current task 的简写
    """
    function_result_status: FunctionResultStatus
    logger: logging.Logger
    # asyncio_use_thread_concurrent_mode: bool = False # 这个属性已经废弃了，现在不管什么并发模式，都使用contextvars

# 使用 contextvars 统一管理上下文，contextvars 同时支持多线程和异步协程场景
_fct_context_var: contextvars.ContextVar[typing.Optional[FctContext]] = contextvars.ContextVar('fct_context', default=None)


def set_fct_context(fct_context: typing.Optional[FctContext]):
    """设置当前线程/协程的 FctContext"""
    _fct_context_var.set(fct_context)


def get_fct_context() -> FctContext:
    """获取当前线程/协程的 FctContext"""
    return _fct_context_var.get()


class _FctProxy:
    """
    fct 代理类，通过 contextvars 自动获取当前线程/协程的上下文。
    可以直接导入这个 fct，不需要手动写 fct = funboost_current_task() 了。
    直接 from funboost import fct 就完了。
    funboost 的 fct 相当于 flask 的 request 那种对象，自动线程/协程级别隔离，多个线程不会互相干扰。


    fct 比直接 get_fct_context 好用一点点，fct相当于把FctContext对象的一级属性的function_result_status中的很多最重要二级属性直接提升作为一级属性了。
    """

    @property
    def fct_context(self) -> FctContext:
        return get_fct_context()

    @property
    def logger(self) -> logging.Logger:
        return self.fct_context.logger

    # 下面这些属性都是 function_result_status 的二级属性，为了方便使用，把常用的二级属性直接提升作为一级属性了。
    # 你仍然可以 通过 fct.function_result_status 来访问更多的其他属性
    @property
    def function_params(self) -> dict:
        return self.fct_context.function_result_status.params

    @property
    def full_msg(self) -> dict:
        return self.fct_context.function_result_status.msg_dict

    @property
    def function_result_status(self) -> FunctionResultStatus:
        return self.fct_context.function_result_status

    @property
    def task_id(self) -> str:
        return self.fct_context.function_result_status.task_id
    @property
    def queue_name(self) -> str:
        return self.fct_context.function_result_status.queue_name

    def __str__(self):
        return f'<{self.__class__.__name__} [{self.function_result_status.get_status_dict()}]>'


fct = _FctProxy() # 推荐使用这个 fct 对象。fct 是funboost_current_task 的简写，就是当前消息任务的意思。


def funboost_current_task() -> _FctProxy:
    """
    这个是兼容老的funboost_current_task() 函数，现在直接用 fct 就行了。

    获取当前任务上下文代理对象。
    由于 contextvars 同时支持多线程和异步协程，这里直接返回 fct 代理对象即可。
    """
    return fct


def get_current_taskid() -> str:
    """获取当前任务的 task_id"""
    try:
        ctx = get_fct_context()
        if ctx is None:
            return 'no_task_id'
        return ctx.function_result_status.task_id
    except (AttributeError, LookupError):
        return 'no_task_id'


class FctContextThread(threading.Thread):
    """
    这个类自动把当前线程的 funboost 上下文自动传递给新开的线程。
    由于 contextvars 不会自动跨线程传递，只能跨协程自动传递，如果想跨线程自动传递，需要手动复制上下文。


    如果没有这个基类，那么需要 手动复制上下文，然后让线程运行 ctx.run(worker) 而不是直接运行 worker： 
    # 1. 显式捕获当前上下文
    ctx = contextvars.copy_context()
    # 2. 让线程运行 ctx.run(worker) 而不是直接运行 worker
    # 这样 worker 就会在 ctx 的上下文中执行
    t = threading.Thread(target=ctx.run, args=(worker,)) # 这是正解，传递上下文

    # t = threading.Thread(target=worker,args=(,)) # 这是错误写法，不能自动传递上下文给子线程，
    # 例如funboost的超时 kill功能，都是在另外单独的子线程去运行消费函数的，所以有时候需要传递给子线程。

    """

    def __init__(self, group=None, target=None, name=None,
                 args=(), kwargs=None, *, daemon=None):
        super().__init__(group=group, target=target, name=name,
                         args=args, kwargs=kwargs, daemon=daemon)
        # self._fct_context = get_fct_context() # 这只针对ct

        # 1. 核心修改：捕获当前所有的 contextvars 上下文快照，
        # 这更通用，不仅针对 fct_context，还可以针对所有其他 contextvars 上下文，例如opentelemetry 的
        self._ctx = contextvars.copy_context()

    def run(self):
        # set_fct_context(self._fct_context) # 这是仅针对fct_context的上下文，其他contextvars上下文不会传递。
        # super().run()

        # 2. 核心修改：在捕获的上下文中运行 super().run()
        # 这更通用，这样 run 方法内部的所有代码都能访问到父线程的 OTel TraceID 和 fct
        return self._ctx.run(super().run)



if __name__ == '__main__':
    print(get_current_taskid())

`````

--- **end of file: funboost/core/current_task.py** (project: funboost) --- 

---


--- **start of file: funboost/core/exceptions.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/exceptions.py`

#### 📦 Imports

- `import uuid`
- `import datetime`
- `import time`
- `import json`
- `from fastapi.responses import JSONResponse`

#### 🏛️ Classes (10)

##### 📌 `class FunboostException(Exception)`
*Line: 8*

**Docstring:**
`````
企业级通用异常基类。
支持子类默认 message / code / error_data。
自动生成 trace_id（可用于分布式日志）。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, message = None, code = None, error_data: dict = None, trace_id = None)`
  - **Parameters:**
    - `self`
    - `message = None`
    - `code = None`
    - `error_data: dict = None`
    - `trace_id = None`

**Public Methods (3):**
- `def to_dict(self)`
- `def to_json(self, pretty = False)`
- `def to_fastapi_response(self, http_status = 200)`
  - **Docstring:**
  `````
  返回fastapi的JSONResponse,让异常和fastapi的接口model保持一致，复用
  
  
  pydantic model建议明确这样写：（或者allow_extra）
  
  ```pyhton
  T = typing.TypeVar('T')
  
  class BaseResponse(BaseModel, typing.Generic[T]):
      '''
      统一的泛型响应模型
      
      字段说明:
          succ: 请求是否成功，True表示成功，False表示失败
          msg: 消息描述
          data: 返回的数据，使用泛型T
          code: 业务状态码，200表示成功，其他表示各种错误
          error: 错误类型名称（可选），如 "QueueNameNotExists", "ValueError"
          traceback: 异常堆栈信息（可选），仅在出错时返回
          trace_id: 追踪ID（可选），用于分布式追踪
      '''
      succ: bool
      msg: str
      data: typing.Optional[T] = None
      error_data: typing.Optional[typing.Dict] = None
      code: typing.Optional[int] = 200
      error: typing.Optional[str] = None
      traceback: typing.Optional[str] = None
      trace_id: typing.Optional[str] = None
  ```
  
  
  可以参考  funboost/faas/fastapi_adapter.py 的 
  register_funboost_exception_handlers 和 handle_funboost_exceptions 进行自动捕获转化。
  `````

**Class Variables (4):**
- `default_message = 'An error occurred'`
- `default_code = None`
- `default_error_data = None`
- `enable_trace_id = False`

##### 📌 `class ExceptionForRetry(FunboostException)`
*Line: 140*

**Docstring:**
`````
为了重试的，抛出错误。只是定义了一个子类，用不用都可以，函数出任何类型错误了框架都会自动重试
`````

##### 📌 `class ExceptionForRequeue(FunboostException)`
*Line: 144*

**Docstring:**
`````
框架检测到此错误，重新放回当前队列中
`````

##### 📌 `class FunboostWaitRpcResultTimeout(FunboostException)`
*Line: 147*

**Docstring:**
`````
等待rpc结果超过了指定时间
`````

##### 📌 `class FunboostRpcResultError(FunboostException)`
*Line: 150*

**Docstring:**
`````
rpc结果是错误状态
`````

##### 📌 `class HasNotAsyncResult(FunboostException)`
*Line: 153*

##### 📌 `class ExceptionForPushToDlxqueue(FunboostException)`
*Line: 156*

**Docstring:**
`````
框架检测到ExceptionForPushToDlxqueue错误，发布到死信队列
`````

##### 📌 `class BoostDecoParamsIsOldVersion(FunboostException)`
*Line: 160*

**Class Variables (1):**
- `default_message = "\n你的@boost入参是老的方式,建议用新的入参方式,老入参方式不再支持函数入参代码自动补全了。\n\n老版本的@boost装饰器方式是:\n@boost('queue_name_xx',qps=3)\ndef f(x):\n    pass\n    \n\n用户需要做的改变如下:\n@boost(BoosterParams(queue_name='queue_name_xx',qps=3))\ndef f(x):\n    pass\n\n就是把原来函数入参的加个 BoosterParams 就可以了.\n\n@boost这个最重要的funboost核心方法作出改变的原因是:\n1/由于开发框架时候,Booster和Consumer多处需要重复声明入参,\n2/入参个数较多,需要locals转化,麻烦\n    "`

##### 📌 `class QueueNameNotExists(FunboostException)`
*Line: 183*

**Class Variables (2):**
- `default_message = 'queue name not exists'`
- `default_code = 4001`

##### 📌 `class FuncParamsError(FunboostException)`
*Line: 187*

**Class Variables (2):**
- `default_message = 'consuming function input params error'`
- `default_code = 5001`


---

`````python


import uuid
import datetime
import time
import json

class FunboostException(Exception):
    """
    企业级通用异常基类。
    支持子类默认 message / code / error_data。
    自动生成 trace_id（可用于分布式日志）。
    """

    # 子类可覆盖以下默认项
    default_message = "An error occurred"
    default_code = None
    default_error_data = None
    enable_trace_id = False

    def __init__(self, message=None, code=None, error_data:dict=None, trace_id=None):
        # 允许实例覆盖默认字段
        self.message = message or self.default_message
        self.code = code if code is not None else self.default_code
        self.error_data = error_data if error_data is not None else self.default_error_data

        # 自动生成 trace_id
        if trace_id:
            self.trace_id = trace_id
        elif self.enable_trace_id:
            self.trace_id = str(uuid.uuid4())
        else:
            self.trace_id = None

        # super().__init__(self.message)
        super().__init__(message,code, error_data,trace_id)

    # 优雅的字符串表现形式
    def __str__(self):
        parts = [f"{self.__class__.__name__}"]  # 显示异常类型

        if self.code is not None:
            parts.append(f"[{self.code}]")

        parts.append(self.message)

        if self.error_data:
            parts.append(f"error_data={self.error_data}")

        if self.trace_id:
            parts.append(f"trace_id={self.trace_id}")

        return " | ".join(parts)

    # REPL / 日志建议信息
    def __repr__(self):
        parts = [self.__class__.__name__]

        if self.code is not None:
            parts.append(f"code={self.code}")

        parts.append(f"message={self.message!r}")

        if self.trace_id:
            parts.append(f"trace_id={self.trace_id}")

        return f"<{' '.join(parts)}>"

    # JSON 序列化
    def to_dict(self):
        # 获取当前 UTC 时间，带时区
        utc_dt = datetime.datetime.now(datetime.timezone.utc)
        utc_str = utc_dt.isoformat()  # 2025-12-10T08:30:00+00:00

        # 获取当前本地时间，带本地时区
        local_dt = utc_dt.astimezone()  # 转成本地时区
        local_str = local_dt.isoformat()  # 2025-12-10T16:30:00+08:00

        return {
            "error": self.__class__.__name__,
            "message": self.message,
            "code": self.code,
            "error_data": self.error_data,
            "trace_id": getattr(self, "trace_id", None),
            "ts": time.time(),
            "utc_time": utc_str,
            "local_time": local_str 
        }

    def to_json(self,pretty=False):
        return json.dumps(self.to_dict(),indent=4 if pretty else None,ensure_ascii=False)

    def to_fastapi_response(self, http_status=200):
        """返回fastapi的JSONResponse,让异常和fastapi的接口model保持一致，复用
        
        
        pydantic model建议明确这样写：（或者allow_extra）

        ```pyhton
        T = typing.TypeVar('T')

        class BaseResponse(BaseModel, typing.Generic[T]):
            '''
            统一的泛型响应模型
            
            字段说明:
                succ: 请求是否成功，True表示成功，False表示失败
                msg: 消息描述
                data: 返回的数据，使用泛型T
                code: 业务状态码，200表示成功，其他表示各种错误
                error: 错误类型名称（可选），如 "QueueNameNotExists", "ValueError"
                traceback: 异常堆栈信息（可选），仅在出错时返回
                trace_id: 追踪ID（可选），用于分布式追踪
            '''
            succ: bool
            msg: str
            data: typing.Optional[T] = None
            error_data: typing.Optional[typing.Dict] = None
            code: typing.Optional[int] = 200
            error: typing.Optional[str] = None
            traceback: typing.Optional[str] = None
            trace_id: typing.Optional[str] = None
        ```


        可以参考  funboost/faas/fastapi_adapter.py 的 
        register_funboost_exception_handlers 和 handle_funboost_exceptions 进行自动捕获转化。
        """


        from fastapi.responses import JSONResponse
        return JSONResponse(
            status_code=http_status,
            content=self.to_dict()
        )
        # return FuncParamsError().to_fastapi_response()



class ExceptionForRetry(FunboostException):
    """为了重试的，抛出错误。只是定义了一个子类，用不用都可以，函数出任何类型错误了框架都会自动重试"""


class ExceptionForRequeue(FunboostException):
    """框架检测到此错误，重新放回当前队列中"""

class FunboostWaitRpcResultTimeout(FunboostException):
    """等待rpc结果超过了指定时间"""

class FunboostRpcResultError(FunboostException):
    """rpc结果是错误状态"""

class HasNotAsyncResult(FunboostException):
    pass

class ExceptionForPushToDlxqueue(FunboostException):
    """框架检测到ExceptionForPushToDlxqueue错误，发布到死信队列"""


class BoostDecoParamsIsOldVersion(FunboostException):
    default_message = """
你的@boost入参是老的方式,建议用新的入参方式,老入参方式不再支持函数入参代码自动补全了。

老版本的@boost装饰器方式是:
@boost('queue_name_xx',qps=3)
def f(x):
    pass
    

用户需要做的改变如下:
@boost(BoosterParams(queue_name='queue_name_xx',qps=3))
def f(x):
    pass

就是把原来函数入参的加个 BoosterParams 就可以了.

@boost这个最重要的funboost核心方法作出改变的原因是:
1/由于开发框架时候,Booster和Consumer多处需要重复声明入参,
2/入参个数较多,需要locals转化,麻烦
    """


class QueueNameNotExists(FunboostException):
    default_message = "queue name not exists"
    default_code = 4001

class FuncParamsError(FunboostException):
    default_message = "consuming function input params error"
    default_code = 5001



if __name__ == '__main__':
    try:
        raise FuncParamsError(
            'testmsg error',
            error_data={'k':'v'},
            trace_id='1234567890',
            
        )
    except FunboostException as e:
        print(e)
        print(str(e))
        print(e.to_json(pretty=True))

`````

--- **end of file: funboost/core/exceptions.py** (project: funboost) --- 

---


--- **start of file: funboost/core/fabric_deploy_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/fabric_deploy_helper.py`

#### 📦 Imports

- `import sys`
- `import threading`
- `import time`
- `from pathlib import Path`
- `from fabric2 import Connection`
- `from nb_libs.path_helper import PathHelper`
- `from funboost.utils.paramiko_util import ParamikoFolderUploader`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.core.booster import Booster`

#### 🔧 Public Functions (2)

- `def fabric_deploy(booster: Booster, host, port, user, password, path_pattern_exluded_tuple = ('/.git/', '/.idea/', '/dist/', '/build/'), file_suffix_tuple_exluded = ('.pyc', '.log', '.gz'), only_upload_within_the_last_modify_time = 3650 * 24 * 60 * 60, file_volume_limit = 1000 * 1000, sftp_log_level = 20, extra_shell_str = '', invoke_runner_kwargs = {'hide': None, 'pty': True, 'warn': False}, python_interpreter = 'python3', process_num = 1, pkey_file_path = None)`
  - *Line: 17*
  - **Docstring:**
  `````
  不依赖阿里云codepipeline 和任何运维发布管理工具，只需要在python代码层面就能实现多机器远程部署。
  这实现了函数级别的精确部署，而非是部署一个 .py的代码，远程部署一个函数实现难度比远程部署一个脚本更高一点，部署更灵活。
  
  之前有人问怎么方便的部署在多台机器，一般用阿里云codepipeline  k8s自动部署。被部署的远程机器必须是linux，不能是windwos。
  但是有的人是直接操作多台物理机，有些不方便，现在直接加一个利用python代码本身实现的跨机器自动部署并运行函数任务。
  
  自动根据任务函数所在文件，转化成python模块路径，实现函数级别的精确部署，比脚本级别的部署更精确到函数。
  例如 test_frame/test_fabric_deploy/test_deploy1.py的fun2函数 自动转化成 from test_frame.test_fabric_deploy.test_deploy1 import f2
  从而自动生成部署语句
  export PYTHONPATH=/home/ydf/codes/distributed_framework:$PYTHONPATH ;cd /home/ydf/codes/distributed_framework;
  python3 -c "from test_frame.test_fabric_deploy.test_deploy1 import f2;f2.multi_process_consume(2)"  -funboostmark funboost_fabric_mark_queue_test30
  
  这个是可以直接在远程机器上运行函数任务。无需用户亲自部署代码和启动代码。自动上传代码，自动设置环境变量，自动导入函数，自动运行。
  这个原理是使用python -c 实现的精确到函数级别的部署，不是python脚本级别的部署。
  可以很灵活的指定在哪台机器运行什么函数，开几个进程。这个比celery更为强大，celery需要登录到每台机器，手动下载代码并部署在多台机器，celery不支持代码自动运行在别的机器上
  
  
  :param booster:被@boost 装饰的函数
  :param host: 需要部署的远程linux机器的 ip
  :param port:需要部署的远程linux机器的 port
  :param user: 需要部署的远程linux机器的用户名
  :param password:需要部署的远程linux机器的密码
  :param path_pattern_exluded_tuple:排除的文件夹或文件路径
  :param file_suffix_tuple_exluded:排除的后缀
  :param only_upload_within_the_last_modify_time:只上传多少秒以内的文件，如果完整运行上传过一次后，之后可以把值改小，避免每次全量上传。
  :param file_volume_limit:大于这个体积的不上传，因为python代码文件很少超过1M
  :param sftp_log_level: 文件上传日志级别  10为logging.DEBUG 20为logging.INFO  30 为logging.WARNING
  :param extra_shell_str :自动部署前额外执行的命令，例如可以设置环境变量什么的
  :param python_interpreter: python解释器路径，如果linux安装了多个python环境可以指定绝对路径。
  :param invoke_runner_kwargs : invoke包的runner.py 模块的 run()方法的所有一切入参,例子只写了几个入参，实际可以传入十几个入参，大家可以自己琢磨fabric包的run方法，按需传入。
                               hide 是否隐藏远程机器的输出，值可以为 False不隐藏远程主机的输出  “out”为只隐藏远程机器的正常输出，“err”为只隐藏远程机器的错误输出，True，隐藏远程主机的一切输出
                               pty 的意思是，远程机器的部署的代码进程是否随着当前脚本的结束而结束。如果为True，本机代码结束远程进程就会结束。如果为False，即使本机代码被关闭结束，远程机器还在运行代码。
                               warn 的意思是如果远程机器控制台返回了异常码本机代码是否立即退出。warn为True这只是警告一下，warn为False,远程机器返回异常code码则本机代码直接终止退出。
  :param process_num:启动几个进程，要达到最大cpu性能就开启cpu核数个进程就可以了。每个进程内部都有任务函数本身指定的并发方式和并发数量，所以是多进程+线程/协程。
  :param pkey_file_path: 私钥文件路径，如果设置了这个参数，则使用ssh私钥登录远程机器，如果没设置，则使用密码登录。
  :return:
  
  
  task_fun.fabric_deploy('192.168.6.133', 22, 'ydf', '123456', process_num=2) 只需要这样就可以自动部署在远程机器运行，无需任何额外操作。
  `````

- `def kill_all_remote_tasks(host, port, user, password)`
  - *Line: 123*
  - *这个要小心用，杀死所有的远程部署的任务,一般不需要使用到*


---

`````python
# noinspection PyDefaultArgument
import sys
import threading
import time
from pathlib import Path
from fabric2 import Connection
from nb_libs.path_helper import PathHelper
from funboost.utils.paramiko_util import ParamikoFolderUploader

from funboost.core.loggers import get_funboost_file_logger
from funboost.core.booster import Booster

logger = get_funboost_file_logger(__name__)


# noinspection PyDefaultArgument
def fabric_deploy(booster: Booster, host, port, user, password,
                  path_pattern_exluded_tuple=('/.git/', '/.idea/', '/dist/', '/build/'),
                  file_suffix_tuple_exluded=('.pyc', '.log', '.gz'),
                  only_upload_within_the_last_modify_time=3650 * 24 * 60 * 60,
                  file_volume_limit=1000 * 1000, sftp_log_level=20, extra_shell_str='',
                  invoke_runner_kwargs={'hide': None, 'pty': True, 'warn': False},
                  python_interpreter='python3',
                  process_num=1,
                  pkey_file_path=None,
                  ):
    """
    不依赖阿里云codepipeline 和任何运维发布管理工具，只需要在python代码层面就能实现多机器远程部署。
    这实现了函数级别的精确部署，而非是部署一个 .py的代码，远程部署一个函数实现难度比远程部署一个脚本更高一点，部署更灵活。

    之前有人问怎么方便的部署在多台机器，一般用阿里云codepipeline  k8s自动部署。被部署的远程机器必须是linux，不能是windwos。
    但是有的人是直接操作多台物理机，有些不方便，现在直接加一个利用python代码本身实现的跨机器自动部署并运行函数任务。

    自动根据任务函数所在文件，转化成python模块路径，实现函数级别的精确部署，比脚本级别的部署更精确到函数。
    例如 test_frame/test_fabric_deploy/test_deploy1.py的fun2函数 自动转化成 from test_frame.test_fabric_deploy.test_deploy1 import f2
    从而自动生成部署语句
    export PYTHONPATH=/home/ydf/codes/distributed_framework:$PYTHONPATH ;cd /home/ydf/codes/distributed_framework;
    python3 -c "from test_frame.test_fabric_deploy.test_deploy1 import f2;f2.multi_process_consume(2)"  -funboostmark funboost_fabric_mark_queue_test30

    这个是可以直接在远程机器上运行函数任务。无需用户亲自部署代码和启动代码。自动上传代码，自动设置环境变量，自动导入函数，自动运行。
    这个原理是使用python -c 实现的精确到函数级别的部署，不是python脚本级别的部署。
    可以很灵活的指定在哪台机器运行什么函数，开几个进程。这个比celery更为强大，celery需要登录到每台机器，手动下载代码并部署在多台机器，celery不支持代码自动运行在别的机器上


    :param booster:被@boost 装饰的函数
    :param host: 需要部署的远程linux机器的 ip
    :param port:需要部署的远程linux机器的 port
    :param user: 需要部署的远程linux机器的用户名
    :param password:需要部署的远程linux机器的密码
    :param path_pattern_exluded_tuple:排除的文件夹或文件路径
    :param file_suffix_tuple_exluded:排除的后缀
    :param only_upload_within_the_last_modify_time:只上传多少秒以内的文件，如果完整运行上传过一次后，之后可以把值改小，避免每次全量上传。
    :param file_volume_limit:大于这个体积的不上传，因为python代码文件很少超过1M
    :param sftp_log_level: 文件上传日志级别  10为logging.DEBUG 20为logging.INFO  30 为logging.WARNING
    :param extra_shell_str :自动部署前额外执行的命令，例如可以设置环境变量什么的
    :param python_interpreter: python解释器路径，如果linux安装了多个python环境可以指定绝对路径。
    :param invoke_runner_kwargs : invoke包的runner.py 模块的 run()方法的所有一切入参,例子只写了几个入参，实际可以传入十几个入参，大家可以自己琢磨fabric包的run方法，按需传入。
                                 hide 是否隐藏远程机器的输出，值可以为 False不隐藏远程主机的输出  “out”为只隐藏远程机器的正常输出，“err”为只隐藏远程机器的错误输出，True，隐藏远程主机的一切输出
                                 pty 的意思是，远程机器的部署的代码进程是否随着当前脚本的结束而结束。如果为True，本机代码结束远程进程就会结束。如果为False，即使本机代码被关闭结束，远程机器还在运行代码。
                                 warn 的意思是如果远程机器控制台返回了异常码本机代码是否立即退出。warn为True这只是警告一下，warn为False,远程机器返回异常code码则本机代码直接终止退出。
    :param process_num:启动几个进程，要达到最大cpu性能就开启cpu核数个进程就可以了。每个进程内部都有任务函数本身指定的并发方式和并发数量，所以是多进程+线程/协程。
    :param pkey_file_path: 私钥文件路径，如果设置了这个参数，则使用ssh私钥登录远程机器，如果没设置，则使用密码登录。
    :return:


    task_fun.fabric_deploy('192.168.6.133', 22, 'ydf', '123456', process_num=2) 只需要这样就可以自动部署在远程机器运行，无需任何额外操作。
    """
    # print(locals())
    python_proj_dir = Path(sys.path[1]).resolve().as_posix() + '/'
    python_proj_dir_short = python_proj_dir.split('/')[-2]
    # 获取被调用函数所在模块文件名
    file_name = Path(sys._getframe(2).f_code.co_filename).resolve().as_posix() # noqa
    relative_file_name = Path(file_name).relative_to(Path(python_proj_dir)).as_posix()
    relative_module = relative_file_name.replace('/', '.')[:-3]  # -3是去掉.py
    func_name = booster.consuming_function.__name__

    """以下这种是为了兼容 函数没有@boost,而是使用 boosterxx = BoostersManager.build_booster() 来创建的booster. 下面的 python_exec_str 中需要用到 func_name 
    也可以远程时候使用 BoostersManager.get_booster(queue_name),然后启动消费.  因为import模块后,就注册booster信息到BoostersManager,所以能启动了.
    """
    module_obj = PathHelper(sys._getframe(2).f_code.co_filename).import_as_module()  # noqa
    for var_name,var_value in module_obj.__dict__.items():
        if isinstance(var_value,Booster) and var_value.queue_name == booster.queue_name:
            func_name = var_name

    logger.debug([file_name, python_proj_dir, python_proj_dir_short,relative_module, func_name])
    # print(relative_module)
    if user == 'root':  # 文件夹会被自动创建，无需用户创建。
        remote_dir = f'/codes/{python_proj_dir_short}'
    else:
        remote_dir = f'/home/{user}/codes/{python_proj_dir_short}'

    def _inner():
        logger.warning(f'将本地文件夹代码 {python_proj_dir}  上传到远程 {host} 的 {remote_dir} 文件夹。')
        t_start = time.perf_counter()
        uploader = ParamikoFolderUploader(host, port, user, password, python_proj_dir, remote_dir,
                                          path_pattern_exluded_tuple, file_suffix_tuple_exluded,
                                          only_upload_within_the_last_modify_time, file_volume_limit, sftp_log_level, pkey_file_path)
        uploader.upload()
        logger.info(f'上传 本地文件夹代码 {python_proj_dir}  上传到远程 {host} 的 {remote_dir} 文件夹耗时 {round(time.perf_counter() - t_start, 3)} 秒')
        # conn.run(f'''export PYTHONPATH={remote_dir}:$PYTHONPATH''')

        queue_name = booster.consumer.queue_name
        process_mark = f'funboost_fabric_mark__{queue_name}__{func_name}'
        conn = Connection(host, port=port, user=user, connect_kwargs={"password": password}, )
        kill_shell = f'''ps -aux|grep {process_mark}|grep -v grep|awk '{{print $2}}' |xargs kill -9'''
        logger.warning(f'使用linux命令 {kill_shell} 命令杀死 {process_mark} 标识的进程')
        # uploader.ssh.exec_command(kill_shell)
        conn.run(kill_shell, encoding='utf-8', warn=True)  # 不想提示，免得烦扰用户以为有什么异常了。所以用上面的paramiko包的ssh.exec_command

        python_exec_str = f'''export is_funboost_remote_run=1;export PYTHONPATH={remote_dir}:$PYTHONPATH ;{python_interpreter} -c "from {relative_module} import {func_name};{func_name}.multi_process_consume({process_num})"  -funboostmark {process_mark} '''
        shell_str = f'''cd {remote_dir}; {python_exec_str}'''
        extra_shell_str2 = extra_shell_str  # 内部函数对外部变量不能直接改。
        if not extra_shell_str2.endswith(';') and extra_shell_str != '':
            extra_shell_str2 += ';'
        shell_str = extra_shell_str2 + shell_str
        logger.warning(f'使用linux命令 {shell_str} 在远程机器 {host} 上启动任务消费')
        conn.run(shell_str, encoding='utf-8', **invoke_runner_kwargs)
        # uploader.ssh.exec_command(shell_str)

    threading.Thread(target=_inner).start()


def kill_all_remote_tasks(host, port, user, password):
    """ 这个要小心用，杀死所有的远程部署的任务,一般不需要使用到"""
    uploader = ParamikoFolderUploader(host, port, user, password, '', '')
    funboost_fabric_mark_all = 'funboost_fabric_mark__'
    kill_shell = f'''ps -aux|grep {funboost_fabric_mark_all}|grep -v grep|awk '{{print $2}}' |xargs kill -9'''
    logger.warning(f'使用linux命令 {kill_shell} 命令杀死 {funboost_fabric_mark_all} 标识的进程')
    uploader.ssh.exec_command(kill_shell)
    logger.warning(f'杀死 {host}  机器所有的 {funboost_fabric_mark_all} 标识的进程')

`````

--- **end of file: funboost/core/fabric_deploy_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/core/funboost_config_getter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/funboost_config_getter.py`

#### 📦 Imports

- `import funboost_config`


---

`````python
def _try_get_user_funboost_common_config(funboost_common_conf_field:str):
    try:
        import funboost_config  # 第一次启动funboost前还没这个文件,或者还没有初始化配置之前,就要使用使用配置.
        return getattr(funboost_config.FunboostCommonConfig,funboost_common_conf_field)
    except Exception as e:
        # print(e)
        return None
`````

--- **end of file: funboost/core/funboost_config_getter.py** (project: funboost) --- 

---


--- **start of file: funboost/core/funboost_time.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/funboost_time.py`

#### 📦 Imports

- `import pytz`
- `import time`
- `import sys`
- `import datetime`
- `import typing`
- `import threading`
- `from nb_time import NbTime`
- `from nb_time import NowTimeStrCache`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`

#### 🏛️ Classes (1)

##### 📌 `class FunboostTime(NbTime)`
*Line: 12*

**Public Methods (3):**
- `def get_time_zone_str(self, time_zone: typing.Union[str, datetime.tzinfo, None] = None)`
- `def get_str(self, formatter = None)`
- `def get_str_fast(self)`

**Class Variables (1):**
- `default_formatter = NbTime.FORMATTER_DATETIME_NO_ZONE`

#### 🔧 Public Functions (1)

- `def fast_get_now_time_str() -> str`
  - *Line: 32*


---

`````python
import pytz
import time
import sys
import datetime

import typing
import threading
from nb_time import NbTime,NowTimeStrCache
from funboost.funboost_config_deafult import FunboostCommonConfig


class FunboostTime(NbTime):
    default_formatter = NbTime.FORMATTER_DATETIME_NO_ZONE

    def get_time_zone_str(self, time_zone: typing.Union[str, datetime.tzinfo, None] = None):
        return time_zone or self.default_time_zone or FunboostCommonConfig.TIMEZONE or self.get_localzone_name()

    @staticmethod
    def _get_tow_digist(num: int) -> str:
        if len(str(num)) == 1:
            return f'0{num}'
        return str(num)

    def get_str(self, formatter=None):
        return self.datetime_obj.strftime(formatter or self.datetime_formatter)

    def get_str_fast(self):
        t_str = f'{self.datetime_obj.year}-{self._get_tow_digist(self.datetime_obj.month)}-{self._get_tow_digist(self.datetime_obj.day)} {self._get_tow_digist(self.datetime_obj.hour)}:{self._get_tow_digist(self.datetime_obj.minute)}:{self._get_tow_digist(self.datetime_obj.second)}'
        return t_str


def fast_get_now_time_str() -> str:
    return NowTimeStrCache.fast_get_now_time_str(FunboostCommonConfig.TIMEZONE)


if __name__ == '__main__':
    print(FunboostTime().get_str())
    tz = pytz.timezone(FunboostCommonConfig.TIMEZONE)
    for i in range(1000000):
        pass
        # FunboostTime()#.get_str_fast()

        # datetime.datetime.now().strftime(NbTime.FORMATTER_DATETIME_NO_ZONE)
        tz = pytz.timezone(FunboostCommonConfig.TIMEZONE)
        datetime.datetime.now(tz=tz)
        # datetime.datetime.now(tz=pytz.timezone(FunboostCommonConfig.TIMEZONE))#.strftime(NbTime.FORMATTER_DATETIME_NO_ZONE)
        # datetime.datetime.now(tz=pytz.timezone(FunboostCommonConfig.TIMEZONE)).timestamp()

        # time.strftime(NbTime.FORMATTER_DATETIME_NO_ZONE)
        # time.time()
    print(NbTime())

`````

--- **end of file: funboost/core/funboost_time.py** (project: funboost) --- 

---


--- **start of file: funboost/core/function_result_status_saver.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/function_result_status_saver.py`

#### 📦 Imports

- `import copy`
- `import datetime`
- `import json`
- `import os`
- `import socket`
- `import threading`
- `import time`
- `import uuid`
- `import pymongo`
- `import pymongo.errors`
- `import sys`
- `from pymongo import IndexModel`
- `from pymongo import ReplaceOne`
- `from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig`
- `from funboost.core.helper_funs import get_publish_time`
- `from funboost.core.helper_funs import delete_keys_and_return_new_dict`
- `from funboost.core.helper_funs import get_publish_time_format`
- `from funboost.core.serialization import Serialization`
- `from funboost.utils import time_util`
- `from funboost.utils import decorators`
- `from funboost.utils.mongo_util import MongoMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.constant import MongoDbName`

#### 🏛️ Classes (3)

##### 📌 `class RunStatus`
*Line: 24*

**Class Variables (2):**
- `running = 'running'`
- `finish = 'finish'`

##### 📌 `class FunctionResultStatus`
*Line: 28*

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: str, fucntion_name: str, msg_dict: dict)`
  - **Parameters:**
    - `self`
    - `queue_name: str`
    - `fucntion_name: str`
    - `msg_dict: dict`

**Public Methods (3):**
- `def parse_status_and_result_to_obj(cls, status_dict: dict)` `classmethod`
- `def get_status_dict(self, without_datetime_obj = False)`
- `def to_pretty_json_str(self)`

**Class Variables (4):**
- `host_name = socket.gethostname()`
- `script_name_long = sys.argv[0]`
- `script_name = script_name_long.split('/')[-1].split('\\')[-1]`
- `FUNC_RUN_ERROR = 'FUNC_RUN_ERROR'`

##### 📌 `class ResultPersistenceHelper(MongoMixin, FunboostFileLoggerMixin)`
*Line: 125*

**🔧 Constructor (`__init__`):**
- `def __init__(self, function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig, queue_name)`
  - **Parameters:**
    - `self`
    - `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig`
    - `queue_name`

**Public Methods (1):**
- `def save_function_result_to_mongo(self, function_result_status: FunctionResultStatus)`


---

`````python
import copy
import datetime
import json
import os
import socket
import threading
import time
import uuid

import pymongo
import pymongo.errors
import sys

from pymongo import IndexModel, ReplaceOne

from funboost.core.func_params_model import FunctionResultStatusPersistanceConfig
from funboost.core.helper_funs import get_publish_time, delete_keys_and_return_new_dict, get_publish_time_format
from funboost.core.serialization import Serialization
from funboost.utils import time_util, decorators
from funboost.utils.mongo_util import MongoMixin
# from nb_log import LoggerMixin
from funboost.core.loggers import FunboostFileLoggerMixin
from funboost.constant import MongoDbName
class RunStatus:
    running = 'running'
    finish = 'finish'

class FunctionResultStatus():
    host_name = socket.gethostname()

    script_name_long = sys.argv[0]
    script_name = script_name_long.split('/')[-1].split('\\')[-1]

    FUNC_RUN_ERROR = 'FUNC_RUN_ERROR'

    def __init__(self, queue_name: str, fucntion_name: str, msg_dict: dict):
        # print(params)
        self.host_process = f'{self.host_name} - {os.getpid()}'
        self.queue_name = queue_name
        self.function = fucntion_name
        self.msg_dict = msg_dict
        self.task_id = self.msg_dict.get('extra', {}).get('task_id', '')
        self.process_id = os.getpid()
        self.thread_id = threading.get_ident()
        self.publish_time  = get_publish_time(msg_dict)
        self.publish_time_format = get_publish_time_format(msg_dict)
        # print(self.publish_time_format)
        function_params = delete_keys_and_return_new_dict(msg_dict, )
        self.params = function_params
        self.params_str = Serialization.to_json_str(function_params)
        self.result = None
        self.run_times = 0
        self.exception = None
        self.exception_type = None
        self.exception_msg = None
        self.rpc_chain_error_msg_dict:dict  = None
        self.time_start = time.time()
        self.time_cost = None
        self.time_end = None
        self.success = False
        self.run_status = ''
        self.total_thread = threading.active_count()
        self._has_requeue = False
        self._has_to_dlx_queue = False
        self._has_kill_task = False
        self.rpc_result_expire_seconds = None
        
         # 额外的方便用户扩展，如果用户想自己放点其他的其他特殊奇葩信息，可以放在这里。而不必来这里改源码加字段。
         # 用户可以在同一个线程或者协程中通过 fct.function_result_status.user_context 获取。
        self.user_context:dict = {} 
      

       
    @classmethod
    def parse_status_and_result_to_obj(cls,status_dict:dict):
        obj = cls(status_dict['queue_name'],status_dict['function'],status_dict['msg_dict'])
        for k,v in status_dict.items():
            # if k.startswith('_'):
            #     continue
            setattr(obj,k,v)
        return obj

    def get_status_dict(self, without_datetime_obj=False):
        self.time_end = time.time()
        if self.run_status == RunStatus.running:
            self.time_cost = None
        else:
            self.time_cost = round(self.time_end - self.time_start, 3)
        item = {}
        for k, v in self.__dict__.items():
            if not k.startswith('_'):
                item[k] = v
        item['host_name'] = self.host_name
        item['host_process'] = self.host_process
        item['script_name'] = self.script_name
        item['script_name_long'] = self.script_name_long
        # item.pop('time_start')
        datetime_str = time_util.DatetimeConverter().datetime_str
        try:
            Serialization.to_json_str(item['result'])
            # json.dumps(item['result'])  # 不希望存不可json序列化的复杂类型。麻烦。存这种类型的结果是伪需求。
        except TypeError:
            item['result'] = str(item['result'])[:1000]
        item.update({'insert_time_str': datetime_str,
                     'insert_minutes': datetime_str[:-3],
                     })
        if not without_datetime_obj:
            item.update({'insert_time': time_util.DatetimeConverter().datetime_obj,
                         'utime': datetime.datetime.now(datetime.timezone.utc),
                         })
        else:
            item = delete_keys_and_return_new_dict(item, ['insert_time', 'utime'])

        item['_id'] = self.task_id
   
        return item

    def __str__(self):
        return f'''{self.__class__}   {Serialization.to_json_str(self.get_status_dict())}'''

    def to_pretty_json_str(self):
        return json.dumps(self.get_status_dict(),indent=4,ensure_ascii=False)


class ResultPersistenceHelper(MongoMixin, FunboostFileLoggerMixin):
 

    def __init__(self, function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig, queue_name):
        self.function_result_status_persistance_conf = function_result_status_persistance_conf
        self._bulk_list = []
        self._bulk_list_lock = threading.Lock()
        self._last_bulk_insert_time = 0
        self._has_start_bulk_insert_thread = False
        self._queue_name = queue_name
        self._table_name = self.function_result_status_persistance_conf.table_name
        if self.function_result_status_persistance_conf.is_save_status:
            self._create_indexes()
            # self._mongo_bulk_write_helper = MongoBulkWriteHelper(task_status_col, 100, 2)
            self.logger.debug(f"函数运行状态结果将保存至mongo的 {MongoDbName.TASK_STATUS_DB} 库的 {queue_name} 集合中，请确认 funboost.py文件中配置的 MONGO_CONNECT_URL")

    def _create_indexes(self):
        task_status_col = self.get_mongo_collection(MongoDbName.TASK_STATUS_DB, self._table_name)
        try:
            has_creat_index = False
            index_dict = task_status_col.index_information()
            if 'insert_time_str_-1' in index_dict:
                has_creat_index = True
            old_expire_after_seconds = None
            for index_name, v in index_dict.items():
                if index_name == 'utime_1':
                    old_expire_after_seconds = v['expireAfterSeconds']
            if has_creat_index is False:
                # params_str 如果很长，必须使用TEXt或HASHED索引。
                task_status_col.create_indexes([
                    IndexModel([("queue_name", 1)]),
                    IndexModel([("insert_time_str", -1)]), IndexModel([("insert_time", -1)]),
                                                IndexModel([("params_str", pymongo.TEXT)]), IndexModel([("success", 1)]),
                                                IndexModel([("time_cost", -1)]),  # 用于按耗时查询
                                                ], )
                task_status_col.create_index([("utime", 1)],  # 这个是过期时间索引。
                                             expireAfterSeconds=self.function_result_status_persistance_conf.expire_seconds)  # 只保留7天(用户自定义的)。
            else:
                if old_expire_after_seconds != self.function_result_status_persistance_conf.expire_seconds:
                    self.logger.warning(f'过期时间从 {old_expire_after_seconds} 修改为 {self.function_result_status_persistance_conf.expire_seconds} 。。。')
                    task_status_col.drop_index('utime_1', ),  # 这个不能也设置为True，导致修改过期时间不成功。
                    task_status_col.create_index([("utime", 1)],
                                                 expireAfterSeconds=self.function_result_status_persistance_conf.expire_seconds, background=True)  # 只保留7天(用户自定义的)。
        except pymongo.errors.PyMongoError as e:
            self.logger.warning(e)

    def save_function_result_to_mongo(self, function_result_status: FunctionResultStatus):
        if self.function_result_status_persistance_conf.is_save_status:
            task_status_col = self.get_mongo_collection(MongoDbName.TASK_STATUS_DB, self._table_name)  # type: pymongo.collection.Collection
            item = function_result_status.get_status_dict()
            item2 = copy.copy(item)
            if not self.function_result_status_persistance_conf.is_save_result:
                item2['result'] = '不保存结果'
            if item2['result'] is None:
                item2['result'] = ''
            if item2['exception'] is None:
                item2['exception'] = ''
            if self.function_result_status_persistance_conf.is_use_bulk_insert:
                # self._mongo_bulk_write_helper.add_task(InsertOne(item2))  # 自动离散批量聚合方式。
                with self._bulk_list_lock:
                    self._bulk_list.append(ReplaceOne({'_id': item2['_id']}, item2, upsert=True))
                    # if time.time() - self._last_bulk_insert_time > 0.5:
                    #     self.task_status_col.bulk_write(self._bulk_list, ordered=False)
                    #     self._bulk_list.clear()
                    #     self._last_bulk_insert_time = time.time()
                    if not self._has_start_bulk_insert_thread:
                        self._has_start_bulk_insert_thread = True
                        decorators.keep_circulating(time_sleep=0.2, is_display_detail_exception=True, block=False,
                                                    daemon=False)(self._bulk_insert)()
                        self.logger.warning(f'启动批量保存函数消费状态 结果到mongo的 线程')
            else:
                task_status_col.replace_one({'_id': item2['_id']}, item2, upsert=True)  # 立即实时插入。

    def _bulk_insert(self):
        with self._bulk_list_lock:
            if time.time() - self._last_bulk_insert_time > 0.5 and self._bulk_list:
                task_status_col = self.get_mongo_collection(MongoDbName.TASK_STATUS_DB, self._table_name)
                task_status_col.bulk_write(self._bulk_list, ordered=False)
                self._bulk_list.clear()
                self._last_bulk_insert_time = time.time()

`````

--- **end of file: funboost/core/function_result_status_saver.py** (project: funboost) --- 

---


--- **start of file: funboost/core/func_params_model.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/func_params_model.py`

#### 📝 Module Docstring

`````
pydantic 模型定义， funboost 使用pydantic 作为重要函数的入参，
方便函数入参太多在层层传递时候的麻烦，例如 BoosterParams 经常新增字段，如果funboost直接入参一大堆，需要每一层都去新增入参很麻烦

BoosterParams 是 funboost 最核心的入参模型，掌握了 BoosterParams 就是掌握了 funboost 的90% 用法。
`````

#### 📦 Imports

- `import functools`
- `import typing`
- `import asyncio`
- `import logging`
- `import datetime`
- `from pydantic.fields import Field`
- `from typing_extensions import Literal`
- `from funboost.concurrent_pool.pool_commons import ConcurrentPoolBuilder`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`
- `from funboost.core.pydantic_compatible_base import compatible_root_validator`
- `from funboost.core.pydantic_compatible_base import BaseJsonAbleModel`
- `from funboost.constant import BrokerEnum`
- `from funboost.constant import ConcurrentModeEnum`
- `from funboost.constant import StrConst`
- `from funboost.concurrent_pool import FunboostBaseConcurrentPool`
- `from funboost.concurrent_pool import FlexibleThreadPool`

#### 🏛️ Classes (5)

##### 📌 `class FunctionResultStatusPersistanceConfig(BaseJsonAbleModel)`
*Line: 27*

**Public Methods (1):**
- `def check_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (5):**
- `is_save_status: bool`
- `is_save_result: bool`
- `expire_seconds: int = 7 * 24 * 3600`
- `is_use_bulk_insert: bool = False`
- `table_name: typing.Optional[str] = None`

##### 📌 `class BoosterParams(BaseJsonAbleModel)`
*Line: 43*

**Docstring:**
`````
pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

@boost的传参必须是此类或者继承此类,如果你不想每个装饰器入参都很多,你可以写一个子类继承BoosterParams, 传参这个子类,例如下面的 BoosterParamsComplete
`````

**Public Methods (1):**
- `def check_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (52):**
- `queue_name: str`
- `broker_kind: str = BrokerEnum.SQLITE_QUEUE`
- `project_name: typing.Optional[str] = None`
- `concurrent_mode: str = ConcurrentModeEnum.THREADING`
- `concurrent_num: int = 50`
- `specify_concurrent_pool: typing.Optional[FunboostBaseConcurrentPool] = None`
- `specify_async_loop: typing.Optional[asyncio.AbstractEventLoop] = None`
- `is_auto_start_specify_async_loop_in_child_thread: bool = True`
- `qps: typing.Union[float, int, None] = None`
- `is_using_distributed_frequency_control: bool = False`
- `is_send_consumer_heartbeat_to_redis: bool = False`
- `max_retry_times: int = 3`
- `retry_interval: typing.Union[float, int] = 0`
- `is_push_to_dlx_queue_when_retry_max_times: bool = False`
- `consuming_function_decorator: typing.Optional[typing.Callable] = None`
- `function_timeout: typing.Union[int, float, None] = None`
- `is_support_remote_kill_task: bool = False`
- `log_level: int = logging.DEBUG`
- `logger_prefix: str = ''`
- `create_logger_file: bool = True`
- `logger_name: typing.Union[str, None] = ''`
- `log_filename: typing.Union[str, None] = None`
- `is_show_message_get_from_broker: bool = False`
- `is_print_detail_exception: bool = True`
- `publish_msg_log_use_full_msg: bool = False`
- `msg_expire_seconds: typing.Union[float, int, None] = None`
- `do_task_filtering: bool = False`
- `task_filtering_expire_seconds: int = 0`
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=False, is_save_status=False, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)`
- `user_custom_record_process_info_func: typing.Optional[typing.Callable] = None`
- `is_using_rpc_mode: bool = False`
- `rpc_result_expire_seconds: int = 1800`
- `rpc_timeout: int = 1800`
- `delay_task_apscheduler_jobstores_kind: Literal['redis', 'memory'] = 'redis'`
- `is_do_not_run_by_specify_time_effect: bool = False`
- `do_not_run_by_specify_time: list = ['10:00:00', '22:00:00']`
- `schedule_tasks_on_main_thread: bool = False`
- `is_auto_start_consuming_message: bool = False`
- `booster_group: typing.Union[str, None] = None`
- `consuming_function: typing.Optional[typing.Callable] = None`
- `consuming_function_raw: typing.Optional[typing.Callable] = None`
- `consuming_function_name: str = ''`
- `broker_exclusive_config: dict = {}`
- `should_check_publish_func_params: bool = True`
- `manual_func_input_params: dict = {'is_manual_func_input_params': False, 'must_arg_name_list': [], 'optional_arg_name_list': []}`
- `consumer_override_cls: typing.Optional[typing.Type] = None`
- `publisher_override_cls: typing.Optional[typing.Type] = None`
- `consuming_function_kind: typing.Optional[str] = None`
- `user_options: dict = {}`
- `auto_generate_info: dict = {}`
- `is_fake_booster: bool = False`
- `booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT`

##### 📌 `class BoosterParamsComplete(BoosterParams)`
*Line: 259*

**Docstring:**
`````
例如一个子类,这个BoosterParams的子类可以作为@booot的传参,每个@boost可以少写一些这些重复的入参字段.

function_result_status_persistance_conf 永远支持函数消费状态 结果状态持久化
is_send_consumer_heartbeat_to_redis 永远支持发送消费者的心跳到redis,便于统计分布式环境的活跃消费者
is_using_rpc_mode  永远支持rpc模式
broker_kind 永远是使用 amqpstorm包 操作 rabbbitmq作为消息队列.
specify_concurrent_pool 同一个进程的不同booster函数,共用一个线程池,线程资源利用更高.
`````

**Class Variables (6):**
- `function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=True)`
- `is_send_consumer_heartbeat_to_redis: bool = True`
- `is_using_rpc_mode: bool = True`
- `rpc_result_expire_seconds: int = 3600`
- `broker_kind: str = BrokerEnum.RABBITMQ_AMQPSTORM`
- `specify_concurrent_pool: FunboostBaseConcurrentPool = Field(default_factory=functools.partial(ConcurrentPoolBuilder.get_pool, FlexibleThreadPool, 500))`

##### 📌 `class TaskOptions(BaseJsonAbleModel)`
*Line: 279*

**Docstring:**
`````
这个是 publish 支持的额外参数，和函数参数一起发布到中间件。
可能有少数时候有这种需求。如果需要发布额外字段到消息队列，必须使用publish方法，push方法是类似celery的dalay只能发布函数入参自身。
这里面的字段值如果非None，会放到消息队列的消息里面的 extra 字段中。
`````

**Public Methods (1):**
- `def cehck_values(self)` `compatible_root_validator(skip_on_failure=True)`

**Class Variables (16):**
- `task_id: str = None`
- `publish_time: float = None`
- `publish_time_format: str = None`
- `function_timeout: typing.Union[float, int, None] = None`
- `max_retry_times: typing.Union[int, None] = None`
- `is_print_detail_exception: typing.Union[bool, None] = None`
- `msg_expire_seconds: typing.Union[float, int, None] = None`
- `is_using_rpc_mode: typing.Union[bool, None] = None`
- `countdown: typing.Union[float, int, None] = None`
- `eta: typing.Union[datetime.datetime, str, None] = None`
- `misfire_grace_time: typing.Union[int, None] = None`
- `user_extra_info: typing.Optional[dict] = None`
- `other_extra_params: typing.Optional[dict] = None`
- `filter_str: typing.Optional[str] = None`
- `can_not_json_serializable_keys: typing.List[str] = None`
- `otel_context: typing.Optional[dict] = None`

##### 📌 `class PublisherParams(BaseJsonAbleModel)`
*Line: 332*

**Class Variables (21):**
- `queue_name: str`
- `broker_kind: typing.Optional[str] = None`
- `project_name: typing.Optional[str] = None`
- `log_level: int = logging.DEBUG`
- `logger_prefix: str = ''`
- `create_logger_file: bool = True`
- `logger_name: str = ''`
- `log_filename: typing.Optional[str] = None`
- `clear_queue_within_init: bool = False`
- `consuming_function: typing.Optional[typing.Callable] = None`
- `broker_exclusive_config: dict = {}`
- `should_check_publish_func_params: bool = True`
- `manual_func_input_params: dict = {'is_manual_func_input_params': False, 'must_arg_name_list': [], 'optional_arg_name_list': []}`
- `publisher_override_cls: typing.Optional[typing.Type] = None`
- `publish_msg_log_use_full_msg: bool = False`
- `consuming_function_kind: typing.Optional[str] = None`
- `rpc_timeout: int = 1800`
- `user_options: dict = {}`
- `auto_generate_info: dict = {}`
- `is_fake_booster: bool = False`
- `booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT`


---

`````python
"""
pydantic 模型定义， funboost 使用pydantic 作为重要函数的入参，
方便函数入参太多在层层传递时候的麻烦，例如 BoosterParams 经常新增字段，如果funboost直接入参一大堆，需要每一层都去新增入参很麻烦

BoosterParams 是 funboost 最核心的入参模型，掌握了 BoosterParams 就是掌握了 funboost 的90% 用法。

"""

import functools
import typing
import asyncio
import logging
import datetime
from pydantic.fields import Field
from typing_extensions import Literal

from funboost.concurrent_pool.pool_commons import ConcurrentPoolBuilder
from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPool
from funboost.core.lazy_impoter import funboost_lazy_impoter
from funboost.core.pydantic_compatible_base import compatible_root_validator
from funboost.core.pydantic_compatible_base import BaseJsonAbleModel
from funboost.constant import BrokerEnum, ConcurrentModeEnum, StrConst


from funboost.concurrent_pool import FunboostBaseConcurrentPool

class FunctionResultStatusPersistanceConfig(BaseJsonAbleModel):
    is_save_status: bool  # 是否保存函数的运行状态信息
    is_save_result: bool  # 是否保存函数的运行结果
    expire_seconds: int = 7 * 24 * 3600  # mongo中的函数运行状态保存多久时间,自动过期
    is_use_bulk_insert: bool = False  # 是否使用批量插入来保存结果，批量插入是每隔0.5秒钟保存一次最近0.5秒内的所有的函数消费状态结果，始终会出现最后0.5秒内的执行结果没及时插入mongo。为False则，每完成一次函数就实时写入一次到mongo。
    table_name:typing.Optional[str] = None # 表名，用于指定保存函数运行状态和结果的表名，默认使用队列名作为表名。   

    @compatible_root_validator(skip_on_failure=True)
    def check_values(self, ):
        expire_seconds = self.expire_seconds
        if expire_seconds > 10 * 24 * 3600:
            funboost_lazy_impoter.flogger.warning(f'你设置的过期时间为 {expire_seconds} 秒 ,设置的时间过长。 ')
        if not self.is_save_status and self.is_save_result:
            raise ValueError(f'你设置的是不保存函数运行状态但保存函数运行结果。不允许你这么设置')
        return self

class BoosterParams(BaseJsonAbleModel):
    """
    pydatinc pycharm编程代码补全,请安装 pydantic插件, 在pycharm的  file -> settings -> Plugins -> 输入 pydantic 搜索,点击安装 pydantic 插件.

    @boost的传参必须是此类或者继承此类,如果你不想每个装饰器入参都很多,你可以写一个子类继承BoosterParams, 传参这个子类,例如下面的 BoosterParamsComplete
    """

    queue_name: str  # 队列名字,必传项,每个函数要使用不同的队列名字.
    broker_kind: str = BrokerEnum.SQLITE_QUEUE  # 中间件选型见3.1章节 https://funboost.readthedocs.io/zh-cn/latest/articles/c3.html

    """ project_name是项目名，属于管理层面的标签, 默认为None, 给booster设置所属项目名, 用于对于在redis保存的funboost信息中，根据项目名字查看相关队列。
    # 如果不设置很难从redis保存的funboost信息中，区分哪些队列名属于哪个项目。 主要是给web接口查看用。
    # 一个项目的队列名字有哪些，是保存在redis的set中，key为 f'funboost.project_name:{project_name}'
    # 通常配合 CareProjectNameEnv.set($project_name) 使用 ，它可以让你在监控和管理时“只看自己的一亩三分地“，避免被其他人的队列刷屏干扰。"""
    project_name: typing.Optional[str] = None

    """如果设置了qps，并且cocurrent_num是默认的50，会自动开了500并发，由于是采用的智能线程池任务少时候不会真开那么多线程而且会自动缩小线程数量。
    具体看ThreadPoolExecutorShrinkAble的说明
    由于有很好用的qps控制运行频率和智能扩大缩小的线程池，此框架建议不需要理会和设置并发数量只需要关心qps就行了，框架的并发是自适应并发数量，这一点很强很好用。"""
    concurrent_mode: str = ConcurrentModeEnum.THREADING  # 并发模式,支持THREADING,GEVENT,EVENTLET,ASYNC,SINGLE_THREAD并发,multi_process_consume 支持协程/线程 叠加多进程并发,性能炸裂.
    concurrent_num: int = 50  # 并发数量，并发种类由concurrent_mode决定
    specify_concurrent_pool: typing.Optional[FunboostBaseConcurrentPool] = None  # 使用指定的线程池/携程池，可以多个消费者共使用一个线程池,节约线程.不为None时候。threads_num失效
    
    specify_async_loop: typing.Optional[asyncio.AbstractEventLoop] = None  # 指定的async的loop循环，设置并发模式为async才能起作用。 有些包例如aiohttp,发送请求和httpclient的实例化不能处在两个不同的loop中,可以传过来.
    is_auto_start_specify_async_loop_in_child_thread: bool = True  # 是否自动在funboost asyncio并发池的子线程中自动启动指定的async的loop循环，设置并发模式为async才能起作用。如果是False,用户自己在自己的代码中去手动启动自己的loop.run_forever() 
    
    """qps:
    强悍的控制功能,指定1秒内的函数执行次数，例如可以是小数0.01代表每100秒执行一次，也可以是50代表1秒执行50次.为None则不控频。 
    设置qps时候,不需要指定并发数量,funboost的能够自适应智能动态调节并发池大小."""
    qps: typing.Union[float, int, None] = None
    """is_using_distributed_frequency_control:
    是否使用分布式空频（依赖redis统计消费者数量，然后频率平分），默认只对当前实例化的消费者空频有效。
    假如实例化了2个qps为10的使用同一队列名的消费者，并且都启动，则每秒运行次数会达到20。
    如果使用分布式空频则所有消费者加起来的总运行次数是10。"""
    is_using_distributed_frequency_control: bool = False

    is_send_consumer_heartbeat_to_redis: bool = False  # 是否将发布者的心跳发送到redis，有些功能的实现需要统计活跃消费者。因为有的中间件不是真mq。这个功能,需要安装redis.

    """max_retry_times:
    最大自动重试次数，当函数发生错误，立即自动重试运行n次，对一些特殊不稳定情况会有效果。
    可以在函数中主动抛出重试的异常ExceptionForRetry，框架也会立即自动重试。
    主动抛出ExceptionForRequeue异常，则当前 消息会重返中间件，
    主动抛出 ExceptionForPushToDlxqueue  异常，可以使消息发送到单独的死信队列中，死信队列的名字是 队列名字 + _dlx。"""
    max_retry_times: int = 3
    retry_interval: typing.Union[float, int] = 0  # 函数出错后间隔多少秒再重试.
    is_push_to_dlx_queue_when_retry_max_times: bool = False  # 函数达到最大重试次数仍然没成功，是否发送到死信队列,死信队列的名字是 队列名字 + _dlx。


    consuming_function_decorator: typing.Optional[typing.Callable] = None  # 函数的装饰器。因为此框架做参数自动转指点，需要获取精准的入参名称，不支持在消费函数上叠加 @ *args  **kwargs的装饰器，如果想用装饰器可以这里指定。
    
    
    """
    function_timeout: 
    超时秒数，函数运行超过这个时间，则自动杀死函数。为0是不限制。 
    用户应该尽量使用各种三方包例如 aiohttp pymysql 自己的 socket timeout 设置来控制超时，而不是无脑使用funboost的function_timeout参数。
    谨慎使用,非必要别去设置超时时间,设置后性能会降低(因为需要把用户函数包装到另一个线单独的程中去运行),而且突然强制超时杀死运行中函数,可能会造成死锁.
    (例如用户函数在获得线程锁后突然杀死函数,别的线程再也无法获得锁了)
    """
    function_timeout: typing.Union[int, float,None] = None 
    """
    is_support_remote_kill_task:
    是否支持远程任务杀死功能，如果任务数量少，单个任务耗时长，确实需要远程发送命令来杀死正在运行的函数，才设置为true，否则不建议开启此功能。
    (是把函数放在单独的线程中实现的,随时准备线程被远程命令杀死,所以性能会降低)
    """
    is_support_remote_kill_task: bool = False  
   
    """
    log_level:
        logger_name 对应的 日志级别
        消费者和发布者的日志级别,建议设置DEBUG级别,不然无法知道正在运行什么消息.
        这个是funboost每个队列的单独命名空间的日志级别,丝毫不会影响改变用户其他日志以及root命名空间的日志级别,所以DEBUG级别就好,
        用户不要压根不懂什么是python logger 的name,还去手痒调高级别. 
        不懂python日志命名空间的小白去看nb_log文档,或者直接问 ai大模型 python logger name的作用是什么.
    """
    log_level: int = logging.DEBUG # 不需要改这个级别,请看上面原因
    logger_prefix: str = ''  # 日志名字前缀,可以设置前缀
    create_logger_file: bool = True  # 发布者和消费者是否创建文件文件日志,为False则只打印控制台不写文件.
    logger_name: typing.Union[str, None] = ''  # 队列消费者发布者的日志命名空间.
    log_filename: typing.Union[str, None] = None  # 消费者发布者的文件日志名字.如果为None,则自动使用 funboost.队列 名字作为文件日志名字.  日志文件夹是在nb_log_config.py的 LOG_PATH中决定的.
    is_show_message_get_from_broker: bool = False  # 运行时候,是否记录从消息队列获取出来的消息内容
    is_print_detail_exception: bool = True  # 消费函数出错时候,是否打印详细的报错堆栈,为False则只打印简略的报错信息不包含堆栈.
    publish_msg_log_use_full_msg: bool = False # 发布到消息队列的消息内容的日志，是否显示消息的完整体，还是只显示函数入参。

    msg_expire_seconds: typing.Union[float, int,None] = None  # 消息过期时间,可以设置消息是多久之前发布的就丢弃这条消息,不运行. 为None则永不丢弃

    do_task_filtering: bool = False  # 是否对函数入参进行过滤去重.
    task_filtering_expire_seconds: int = 0  # 任务过滤的失效期，为0则永久性过滤任务。例如设置过滤过期时间是1800秒 ， 30分钟前发布过1 + 2 的任务，现在仍然执行，如果是30分钟以内执行过这个任务，则不执行1 + 2

    function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(
        is_save_result=False, is_save_status=False, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=False)  # 是否保存函数的入参，运行结果和运行状态到mongodb。这一步用于后续的参数追溯，任务统计和web展示，需要安装mongo。

    user_custom_record_process_info_func: typing.Optional[typing.Callable] = None  # 提供一个用户自定义的保存消息处理记录到某个地方例如mysql数据库的函数，函数仅仅接受一个入参，入参类型是 FunctionResultStatus，用户可以打印参数

    is_using_rpc_mode: bool = False  # 是否使用rpc模式，可以在发布端获取消费端的结果回调，但消耗一定性能，使用async_result.result时候会等待阻塞住当前线程。
    rpc_result_expire_seconds: int = 1800  # redis保存rpc结果的过期时间.
    rpc_timeout:int = 1800 # rpc模式下，等待rpc结果返回的超时时间

    delay_task_apscheduler_jobstores_kind :Literal[ 'redis', 'memory'] = 'redis'  # 延时任务的aspcheduler对象使用哪种jobstores ，可以为 redis memory 两种作为jobstore

    
    is_do_not_run_by_specify_time_effect: bool = False  # 是否使不运行的时间段生效
    do_not_run_by_specify_time: list = ['10:00:00', '22:00:00']  # 不运行的时间段,在这个时间段自动不运行函数.

    schedule_tasks_on_main_thread: bool = False  # 直接在主线程调度任务，意味着不能直接在当前主线程同时开启两个消费者。

    is_auto_start_consuming_message: bool = False  # 是否在定义后就自动启动消费，无需用户手动写 .consume() 来启动消息消费。
    
    # booster_group :消费分组名字， BoostersManager.consume_group 时候根据 booster_group 启动多个消费函数,减少需要写 f1.consume() f2.consume() ...这种。
    # 不像BoostersManager.consume_all() 会启动所有不相关消费函数,也不像  f1.consume() f2.consume() 这样需要逐个启动消费函数。
    # 可以根据业务逻辑创建不同的分组，实现灵活的消费启动策略。
    # 用法见文档 4.2d.3 章节.   使用 BoostersManager ,通过 consume_group 启动一组消费函数
    booster_group:typing.Union[str, None] = None

    consuming_function: typing.Optional[typing.Callable] = None  # 消费函数,在@boost时候不用指定,因为装饰器知道下面的函数.
    consuming_function_raw: typing.Optional[typing.Callable] = None  # 不需要传递，自动生成
    consuming_function_name: str = '' # 不需要传递，自动生成

    
    """
    # 加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，
    # 例如kafka支持消费者组，rabbitmq也支持各种独特概念例如各种ack机制 复杂路由机制，有的中间件原生能支持消息优先级有的中间件不支持,
    # 每一种消息队列都有独特的配置参数意义，可以通过这里传递。
    # 每种中间件能传递的键值对可以看 funboost/core/broker_kind__exclusive_config_default.py 的 BROKER_EXCLUSIVE_CONFIG_DEFAULT 属性。
    """
    broker_exclusive_config: dict = {} 
    


    should_check_publish_func_params: bool = True  # 消息发布时候是否校验消息发布内容,比如有的人发布消息,函数只接受a,b两个入参,他去传2个入参,或者传参不存在的参数名字; 如果消费函数加了装饰器 ，你非要写*args,**kwargs,那就需要关掉发布消息时候的函数入参检查
    manual_func_input_params :dict= {'is_manual_func_input_params': False,'must_arg_name_list':[],'optional_arg_name_list':[]} # 也可以手动指定函数入参字段，默认是根据消费函数def定义的入参来生成这个。


    consumer_override_cls: typing.Optional[typing.Type] = None  # 使用 consumer_override_cls 和 publisher_override_cls 来自定义重写或新增消费者 发布者,见文档4.21b介绍，
    publisher_override_cls: typing.Optional[typing.Type] = None

    # func_params_is_pydantic_model: bool = False  # funboost 兼容支持 函数娼还是 pydantic model类型，funboost在发布之前和取出来时候自己转化。

    consuming_function_kind: typing.Optional[str] = None  # 自动生成的信息,不需要用户主动传参,如果自动判断失误就传递。是判断消费函数是函数还是实例方法还是类方法。如果传递了，就不自动获取函数类型。
    """ consuming_function_kind 可以为以下类型，
    class FunctionKind:
        CLASS_METHOD = 'CLASS_METHOD'
        INSTANCE_METHOD = 'INSTANCE_METHOD'
        STATIC_METHOD = 'STATIC_METHOD'
        COMMON_FUNCTION = 'COMMON_FUNCTION'
    """

    """
    user_options:
    用户额外自定义的配置,高级用户或者奇葩需求可以用得到,用户可以自由发挥,存放任何设置.
    user_options 提供了一个统一的、用户自定义的命名空间，让用户可以为自己的“奇葩需求”或“高级定制”传递配置，而无需等待框架开发者添加官方支持。
    funboost 是自由框架不是奴役框架,不仅消费函数逻辑自由,目录层级结构自由,自定义奇葩扩展也要追求自由,用户不用改funboost BoosterParams 源码来加装饰器参数
    
    使用场景见文档 4b.6 章节.
    """
    user_options: dict = {} # 用户自定义的配置,高级用户或者奇葩需求可以用得到,用户可以自由发挥,存放任何设置,例如配合 consumer_override_cls中读取 或 register_custom_broker 使用
    
    
    auto_generate_info: dict = {}  # 自动生成的信息,不需要用户主动传参.例如包含 final_func_input_params_info 和 where_to_instantiate 等。
    
    """# is_fake_booster：是否是伪造的booster,
    # 用于faas模式下，因为跨项目的faas管理只拿到了redis的一些基本元数据，没有booster的函数逻辑，
    # 例如ApsJobAdder管理定时任务，需要booster，但没有真实的函数逻辑，
    # 你可以看 SingleQueueConusmerParamsGetter.gen_booster_for_faas 的用法，目前主要是控制不要执行 BoostersManager.regist_booster
    # 普通用户完全不用改这个参数。
    """
    is_fake_booster: bool = False
    booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT  # 普通用户不用管不用改，用于隔离boosters注册。例如faas的是虚假的跨服务跨项目的booster，没有具体函数逻辑，不可污染真正的注册。
    

    @compatible_root_validator(skip_on_failure=True, )
    def check_values(self):
       
        # 如果设置了qps，并且cocurrent_num是默认的50，会自动开了500并发，由于是采用的智能线程池任务少时候不会真开那么多线程而且会自动缩小线程数量。具体看ThreadPoolExecutorShrinkAble的说明
        # 由于有很好用的qps控制运行频率和智能扩大缩小的线程池，此框架建议不需要理会和设置并发数量只需要关心qps就行了，框架的并发是自适应并发数量，这一点很强很好用。
        if self.qps and self.concurrent_num == 50:
            self.concurrent_num = 500
        if self.concurrent_mode == ConcurrentModeEnum.SINGLE_THREAD:
            self.concurrent_num = 1

        self.is_send_consumer_heartbeat_to_redis = self.is_send_consumer_heartbeat_to_redis or self.is_using_distributed_frequency_control

        if self.concurrent_mode not in ConcurrentModeEnum.__dict__.values():
            raise ValueError('设置的并发模式不正确')
        if self.broker_kind in [BrokerEnum.REDIS_ACK_ABLE, BrokerEnum.REDIS_STREAM, BrokerEnum.REDIS_PRIORITY, 
                                     BrokerEnum.RedisBrpopLpush,BrokerEnum.REDIS,BrokerEnum.REDIS_PUBSUB]:
            self.is_send_consumer_heartbeat_to_redis = True  # 需要心跳进程来辅助判断消息是否属于掉线或关闭的进程，需要重回队列
       
        if self.function_result_status_persistance_conf.table_name is None:
            self.function_result_status_persistance_conf.table_name = self.queue_name
        
        # 禁止子类添加 BoosterParams 中不存在的字段，主要是担心用户继承的子类中拼写错误，本以为自己是覆盖父类字段默认值，实际却变成了新增了字段。
        # 兼容 Pydantic v1 和 v2 获取所有字段
        self_fields = self.model_fields.keys() if hasattr(self, 'model_fields') else self.__fields__.keys()
        parent_fields = BoosterParams.model_fields.keys() if hasattr(BoosterParams, 'model_fields') else BoosterParams.__fields__.keys()
        for k in self_fields:
            if k not in parent_fields:
                raise ValueError(f'{self.__class__.__name__} 的字段新增了父类 BoosterParams 不存在的字段 "{k}"')  # 使 BoosterParams的子类,不能增加字段,只能覆盖字段.
        
        return self

    def __call__(self, func):
        """
        新增加一种语法,
        一般是使用@boost(BoosterParams(queue_name='q1',qps=2))，你如果图方便可以使用 @BoosterParams(queue_name='q1',qps=2)这样的写法。

        @BoosterParams(queue_name='q1',qps=2) 这个和 @boost(BoosterParams(queue_name='q1',qps=2)) 写法等效,

        @BoosterParams(queue_name='q1',qps=2)
        def f(a,b):
            print(a,b)
        :param func:
        :return:
        """
        return funboost_lazy_impoter.boost(self)(func)


class BoosterParamsComplete(BoosterParams):
    """
    例如一个子类,这个BoosterParams的子类可以作为@booot的传参,每个@boost可以少写一些这些重复的入参字段.

    function_result_status_persistance_conf 永远支持函数消费状态 结果状态持久化
    is_send_consumer_heartbeat_to_redis 永远支持发送消费者的心跳到redis,便于统计分布式环境的活跃消费者
    is_using_rpc_mode  永远支持rpc模式
    broker_kind 永远是使用 amqpstorm包 操作 rabbbitmq作为消息队列.
    specify_concurrent_pool 同一个进程的不同booster函数,共用一个线程池,线程资源利用更高.
    """

    function_result_status_persistance_conf: FunctionResultStatusPersistanceConfig = FunctionResultStatusPersistanceConfig(
        is_save_result=True, is_save_status=True, expire_seconds=7 * 24 * 3600, is_use_bulk_insert=True)  # 开启函数消费状态 结果持久化到 mongo,为True用户必须要安装mongo和多浪费一丝丝性能.
    is_send_consumer_heartbeat_to_redis: bool = True  # 消费者心跳发到redis,为True那么用户必须安装reids
    is_using_rpc_mode: bool = True  # 固定支持rpc模式,不用每次指定 (不需要使用rpc模式的同学,就不要指定为True,必须安装redis和浪费一点性能)
    rpc_result_expire_seconds: int = 3600
    broker_kind: str = BrokerEnum.RABBITMQ_AMQPSTORM  # 固定使用rabbitmq,不用每次指定
    specify_concurrent_pool: FunboostBaseConcurrentPool = Field(default_factory=functools.partial(ConcurrentPoolBuilder.get_pool, FlexibleThreadPool, 500))  # 多个消费函数共享线程池


class TaskOptions(BaseJsonAbleModel):
    """
    这个是 publish 支持的额外参数，和函数参数一起发布到中间件。
    可能有少数时候有这种需求。如果需要发布额外字段到消息队列，必须使用publish方法，push方法是类似celery的dalay只能发布函数入参自身。
    这里面的字段值如果非None，会放到消息队列的消息里面的 extra 字段中。
    """
    # task_id 和 publish_time 和 publish_time_format 这三个可以指定，如果不指定就自动生成
    task_id: str = None
    publish_time: float = None
    publish_time_format: str = None
    
    # function_timeout，max_retry_times，is_print_detail_exception，msg_expire_seconds，is_using_rpc_mode 这几个是 消费函数执行时候的控制参数，
    # 这个优先级比BoosterParams更高，例如 BoosterParams 设置重试3次，你可以通过 TaskOptions 设置重试10次，那么最终消费函数执行时候，会按照 TaskOptions 中的设置来执行。
    # task_options 中的设置，优先级 高于 @boost(BoosterParams(...)) 中的设置。
    function_timeout: typing.Union[float, int,None] = None
    max_retry_times: typing.Union[int,None] = None
    is_print_detail_exception: typing.Union[bool,None] = None
    msg_expire_seconds: typing.Union[float, int,None] = None
    is_using_rpc_mode: typing.Union[bool,None] = None

    # countdown，eta，misfire_grace_time 这三个是 发布延时任务
    countdown: typing.Union[float, int,None] = None
    eta: typing.Union[datetime.datetime, str,None] = None  # 时间对象， 或 %Y-%m-%d %H:%M:%S 字符串。
    misfire_grace_time: typing.Union[int, None] = None
    
    user_extra_info: typing.Optional[dict] = None # 用户自定义的额外信息，用户随意存放任何信息，但要保证可以json序列化。可以在消费端通过 fct.full_msg 获取。

    other_extra_params: typing.Optional[dict] = None  # 其他参数，某些中间件独有的, 例如消息优先级 , task_options=TaskOptions(other_extra_params={'priroty': priorityxx})，
    
    """filter_str:
    用户指定过滤字符串， 例如函数入参是 def fun(userid,username,sex，user_description),
    默认是所有入参一起组成json来过滤，但其实只把userid的值来过滤就好了。所以如果需要精准的按照什么过滤，用户来灵活指定一个字符串就好了
    
    用法见文档4.35 
    f3.publish(msg={'a':i,'b':i*2},task_options=TaskOptions(filter_str=str(i)))
    """
    filter_str :typing.Optional[str] = None 

    can_not_json_serializable_keys: typing.List[str] = None # 不能json序列化的入参名字，反序列化时候需要使用pickle来反序列化这些字段(这个是自动生成的，用户不需要手动指定此入参。)
    
    otel_context :typing.Optional[dict] = None # opentelemetry 的上下文，用于链路追踪

    @compatible_root_validator(skip_on_failure=True)
    def cehck_values(self):
        if self.countdown and self.eta:
            raise ValueError('不能同时设置eta和countdown')
        if self.misfire_grace_time is not None and self.misfire_grace_time < 1:
            raise ValueError(f'misfire_grace_time 的值要么是大于1的整数， 要么等于None')
        return self


# PriorityConsumingControlConfig = TaskOptions # 兼容老名字

class PublisherParams(BaseJsonAbleModel):
    queue_name: str
    broker_kind: typing.Optional[str] = None

    # 项目名, 默认为None, 给booster设置所属项目名, 用于在redis保存的funboost信息中，根据项目名字查看相关队列。
    # 如果不设置很难从redis保存的funboost信息中，区分哪些队列名属于哪个项目。 主要是给web接口查看用。
    project_name: typing.Optional[str] = None # 推荐去设置

    log_level: int = logging.DEBUG
    logger_prefix: str = ''
    create_logger_file: bool = True
    logger_name: str = ''  # 队列消费者发布者的日志命名空间.
    log_filename: typing.Optional[str] = None
    clear_queue_within_init: bool = False  # with 语法发布时候,先清空消息队列
    consuming_function: typing.Optional[typing.Callable] = None  # consuming_function 作用是 inspect 模块获取函数的入参信息

    broker_exclusive_config: dict = {}
    
    should_check_publish_func_params: bool = True  # 消息发布时候是否校验消息发布内容,比如有的人发布消息,函数只接受a,b两个入参,他去传2个入参,或者传参不存在的参数名字,  如果消费函数你非要写*args,**kwargs,那就需要关掉发布消息时候的函数入参检查
    manual_func_input_params :dict= {'is_manual_func_input_params': False,'must_arg_name_list':[],'optional_arg_name_list':[]}

    publisher_override_cls: typing.Optional[typing.Type] = None
    # func_params_is_pydantic_model: bool = False  # funboost 兼容支持 函数娼还是 pydantic model类型，funboost在发布之前和取出来时候自己转化。
    publish_msg_log_use_full_msg: bool = False # 发布到消息队列的消息内容的日志，是否显示消息的完整体，还是只显示函数入参。
    consuming_function_kind: typing.Optional[str] = None  # 自动生成的信息,不需要用户主动传参.
    rpc_timeout: int = 1800 # rpc模式下，等待rpc结果返回的超时时间
    user_options: dict = {}  # 用户自定义的配置,高级用户或者奇葩需求可以用得到,用户可以自由发挥,存放任何设置.
    auto_generate_info: dict = {}
    is_fake_booster: bool = False # 是否是伪造的booster, 不注册到BoostersManager
    booster_registry_name: str = StrConst.BOOSTER_REGISTRY_NAME_DEFAULT  # 普通用户不用管不用改，用于隔离boosters注册。例如faas的是虚假的跨服务跨项目的booster，没有具体函数逻辑，不可污染真正的注册。
    
    


if __name__ == '__main__':
    from funboost.concurrent_pool import FlexibleThreadPool

    pass
    # print(FunctionResultStatusPersistanceConfig(is_save_result=True, is_save_status=True, expire_seconds=70 * 24 * 3600).update_from_kwargs(expire_seconds=100).get_str_dict())
    #
    # print(TaskOptions().get_str_dict())

    print(BoosterParams(queue_name='3213', specify_concurrent_pool=FlexibleThreadPool(100)).json_pre())
    # print(PublisherParams.schema_json())  # 注释掉，因为 PublisherParams 包含 Callable 类型字段，无法生成 JSON Schema

`````

--- **end of file: funboost/core/func_params_model.py** (project: funboost) --- 

---


--- **start of file: funboost/core/helper_funs.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/helper_funs.py`

#### 📦 Imports

- `import copy`
- `import pytz`
- `import time`
- `import uuid`
- `from funboost.utils.uuid7 import uuid7`
- `import datetime`
- `from funboost.core.funboost_time import FunboostTime`
- `from funboost.core.funboost_time import fast_get_now_time_str`
- `from funboost import FunboostCommonConfig`

#### 🏛️ Classes (1)

##### 📌 `class MsgGenerater`
*Line: 52*

**Public Methods (4):**
- `def generate_task_id(queue_name: str) -> str` `staticmethod`
  - **Docstring:**
  `````
  UUIDv7 是 时间有序（time-ordered） 的 UUID，新一代 UUID 规范（RFC 9562，已标准化），
  专门为数据库/分布式系统设计。一句话总结：
  UUIDv7 = “像 UUID 一样全局唯一 + 像雪花 ID 一样按时间递增”
  `````
- `def generate_publish_time() -> float` `staticmethod`
- `def generate_publish_time_format() -> str` `staticmethod`
- `def generate_pulish_time_and_task_id(cls, queue_name: str, task_id = None)` `classmethod`

#### 🔧 Public Functions (4)

- `def get_publish_time(paramsx: dict)`
  - *Line: 10*
  - **Docstring:**
  `````
  :param paramsx:
  :return:
  `````

- `def get_publish_time_format(paramsx: dict)`
  - *Line: 18*
  - **Docstring:**
  `````
  :param paramsx:
  :return:
  `````

- `def delete_keys_and_return_new_dict(dictx: dict, keys: list = None)`
  - *Line: 26*

- `def block_python_main_thread_exit()`
  - *Line: 37*
  - **Docstring:**
  `````
  https://funboost.readthedocs.io/zh-cn/latest/articles/c10.html#runtimeerror-cannot-schedule-new-futures-after-interpreter-shutdown
  
  主要是用于 python3.9以上 定时任务报错，  定时任务报错 RuntimeError: cannot schedule new futures after interpreter shutdown
  如果主线程结束了，apscheduler就会报这个错，加上这个while 1 ： time.sleep(100) 目的就是阻止主线程退出。
  `````


---

`````python
import copy
import pytz
import time
import uuid
from funboost.utils.uuid7 import uuid7
import datetime
from funboost.core.funboost_time import FunboostTime, fast_get_now_time_str


def get_publish_time(paramsx: dict):
    """
    :param paramsx:
    :return:
    """
    return paramsx.get('extra', {}).get('publish_time', None)


def get_publish_time_format(paramsx: dict):
    """
    :param paramsx:
    :return:
    """
    return paramsx.get('extra', {}).get('publish_time_format', None)


def delete_keys_and_return_new_dict(dictx: dict, keys: list = None):
    dict_new = copy.deepcopy(dictx)  # 主要是去掉一级键 publish_time，浅拷贝即可。新的消息已经不是这样了。
    keys = ['publish_time', 'publish_time_format', 'extra'] if keys is None else keys
    for dict_key in keys:
        try:
            dict_new.pop(dict_key)
        except KeyError:
            pass
    return dict_new


def block_python_main_thread_exit():
    """

    https://funboost.readthedocs.io/zh-cn/latest/articles/c10.html#runtimeerror-cannot-schedule-new-futures-after-interpreter-shutdown

    主要是用于 python3.9以上 定时任务报错，  定时任务报错 RuntimeError: cannot schedule new futures after interpreter shutdown
    如果主线程结束了，apscheduler就会报这个错，加上这个while 1 ： time.sleep(100) 目的就是阻止主线程退出。
    """
    while 1:
        time.sleep(100)


run_forever = block_python_main_thread_exit


class MsgGenerater:
    @staticmethod
    def generate_task_id(queue_name:str) -> str:
        """
        UUIDv7 是 时间有序（time-ordered） 的 UUID，新一代 UUID 规范（RFC 9562，已标准化），
        专门为数据库/分布式系统设计。一句话总结：
        UUIDv7 = “像 UUID 一样全局唯一 + 像雪花 ID 一样按时间递增”
        """
        # return f'{queue_name}_result:{uuid.uuid4()}'
        uuid7_obj =  uuid7()
        return str(uuid7_obj) # uuid7 对数据库顺序更友好


    @staticmethod
    def generate_publish_time() -> float:
        return round(time.time(),4)


    @staticmethod
    def generate_publish_time_format() -> str:
        # return FunboostTime().get_str()  # 性能不好
        # return get_now_time_str_by_tz()  # 2秒100万次
        return fast_get_now_time_str() # 0.4秒100万次


    @classmethod
    def generate_pulish_time_and_task_id(cls,queue_name:str,task_id=None):
        extra_params = {'task_id': task_id or cls.generate_task_id(queue_name), 
                        'publish_time': cls.generate_publish_time(),  # 时间戳秒
                        'publish_time_format': cls.generate_publish_time_format() # 时间字符串 例如 2025-12-25 10:00:00
                        
                        }
        return extra_params



if __name__ == '__main__':

    from funboost import FunboostCommonConfig

    print(FunboostTime())
    for i in range(1000000):
        # time.time()
        MsgGenerater.generate_publish_time_format()
        # FunboostTime().get_str()

        # datetime.datetime.now(tz=pytz.timezone(FunboostCommonConfig.TIMEZONE)).strftime(FunboostTime.FORMATTER_DATETIME_NO_ZONE)

    print(FunboostTime())
`````

--- **end of file: funboost/core/helper_funs.py** (project: funboost) --- 

---


--- **start of file: funboost/core/kill_remote_task.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/kill_remote_task.py`

#### 📦 Imports

- `import ctypes`
- `import threading`
- `import time`
- `from funboost.utils.time_util import DatetimeConverter`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.current_task import FctContextThread`

#### 🏛️ Classes (4)

##### 📌 `class ThreadKillAble(FctContextThread)`
*Line: 11*

**Class Variables (3):**
- `task_id = None`
- `killed = False`
- `event_kill = threading.Event()`

##### 📌 `class TaskHasKilledError(Exception)`
*Line: 21*

##### 📌 `class RemoteTaskKillerZset(RedisMixin, FunboostFileLoggerMixin)`
*Line: 67*

**Docstring:**
`````
zset实现的，需要zrank 多次。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name, task_id)`
  - **Parameters:**
    - `self`
    - `queue_name`
    - `task_id`

**Public Methods (4):**
- `def send_remote_task_comd(self)`
- `def judge_need_revoke_run(self)`
- `def kill_local_task(self)`
- `def start_cycle_kill_task(self)`

##### 📌 `class RemoteTaskKiller(RedisMixin, FunboostFileLoggerMixin)`
*Line: 111*

**Docstring:**
`````
hash实现的，只需要 hmget 一次
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name, task_id)`
  - **Parameters:**
    - `self`
    - `queue_name`
    - `task_id`

**Public Methods (4):**
- `def send_kill_remote_task_comd(self)`
- `def judge_need_revoke_run(self)`
- `def kill_local_task(self)`
- `def start_cycle_kill_task(self)`

#### 🔧 Public Functions (5)

- `def kill_thread(thread_id)`
  - *Line: 17*

- `def kill_fun_deco(task_id)`
  - *Line: 25*

- `def kill_thread_by_task_id(task_id)`
  - *Line: 54*

- `def my_fun(x)`
  - *Line: 174*
  - *使用lock.acquire(),强行杀死会一直无法释放锁*

- `def my_fun2(x)`
  - *Line: 189*
  - *使用with lock,强行杀死会不会出现一直无法释放锁*


---

`````python
import ctypes
import threading
import time
from funboost.utils.time_util import DatetimeConverter
from funboost.utils.redis_manager import RedisMixin
# import nb_log
from funboost.core.loggers import FunboostFileLoggerMixin
from funboost.core.current_task import FctContextThread


class ThreadKillAble(FctContextThread):
    task_id = None
    killed = False
    event_kill = threading.Event()


def kill_thread(thread_id):
    ctypes.pythonapi.PyThreadState_SetAsyncExc(ctypes.c_long(thread_id), ctypes.py_object(SystemExit))


class TaskHasKilledError(Exception):
    pass


def kill_fun_deco(task_id):
    def _inner(f):
        def __inner(*args, **kwargs):
            def _new_func(oldfunc, result, oldfunc_args, oldfunc_kwargs):
                result.append(oldfunc(*oldfunc_args, **oldfunc_kwargs))
                threading.current_thread().event_kill.set()  # noqa

            result = []
            new_kwargs = {
                'oldfunc': f,
                'result': result,
                'oldfunc_args': args,
                'oldfunc_kwargs': kwargs
            }

            thd = ThreadKillAble(target=_new_func, args=(), kwargs=new_kwargs)
            thd.task_id = task_id
            thd.event_kill = threading.Event()
            thd.start()
            thd.event_kill.wait()
            if not result and thd.killed is True:
                raise TaskHasKilledError(f'{DatetimeConverter()} 线程已被杀死 {thd.task_id}')
            return result[0]

        return __inner

    return _inner


def kill_thread_by_task_id(task_id):
    for t in threading.enumerate():
        if isinstance(t, ThreadKillAble):
            thread_task_id = getattr(t, 'task_id', None)
            if thread_task_id == task_id:
                t.killed = True
                t.event_kill.set()
                kill_thread(t.ident)


kill_task = kill_thread_by_task_id


class RemoteTaskKillerZset(RedisMixin, FunboostFileLoggerMixin):
    """
    zset实现的，需要zrank 多次。
    """

    def __init__(self, queue_name, task_id):
        self.queue_name = queue_name
        self.task_id = task_id
        self._redis_zset_key = f'funboost_kill_task:{queue_name}'
        self._lsat_kill_task_ts = time.time()

    def send_remote_task_comd(self):
        self.redis_db_frame.zadd(self._redis_zset_key, {self.task_id: time.time()})

    def judge_need_revoke_run(self):
        if self.redis_db_frame.zrank(self._redis_zset_key, self.task_id) is not None:
            self.redis_db_frame.zrem(self._redis_zset_key, self.task_id)
            return True
        return False

    def kill_local_task(self):
        kill_task(self.task_id)

    def start_cycle_kill_task(self):
        def _start_cycle_kill_task():
            while 1:
                for t in threading.enumerate():
                    if isinstance(t, ThreadKillAble):
                        thread_task_id = getattr(t, 'task_id', None)
                        if self.redis_db_frame.zrank(self._redis_zset_key, thread_task_id) is not None:
                            self.redis_db_frame.zrem(self._redis_zset_key, thread_task_id)
                            t.killed = True
                            t.event_kill.set()
                            kill_thread(t.ident)
                            self._lsat_kill_task_ts = time.time()
                            self.logger.warning(f'队列 {self.queue_name} 的 任务 {thread_task_id} 被杀死')
                if time.time() - self._lsat_kill_task_ts < 2:
                    time.sleep(0.001)
                else:
                    time.sleep(5)

        threading.Thread(target=_start_cycle_kill_task).start()


class RemoteTaskKiller(RedisMixin, FunboostFileLoggerMixin):
    """
    hash实现的，只需要 hmget 一次
    """

    def __init__(self, queue_name, task_id):
        self.queue_name = queue_name
        self.task_id = task_id
        # self.redis_zset_key = f'funboost_kill_task:{queue_name}'
        self._redis_hash_key = f'funboost_kill_task_hash:{queue_name}'
        # self._lsat_kill_task_ts = 0  # time.time()
        self._recent_scan_need_kill_task = False

    def send_kill_remote_task_comd(self):
        # self.redis_db_frame.zadd(self.redis_zset_key, {self.task_id: time.time()})
        self.redis_db_frame.hset(self._redis_hash_key, key=self.task_id, value=time.time())

    def judge_need_revoke_run(self):
        if self.redis_db_frame.hexists(self._redis_hash_key, self.task_id):
            self.redis_db_frame.hdel(self._redis_hash_key, self.task_id)
            return True
        return False

    def kill_local_task(self):
        kill_task(self.task_id)

    def start_cycle_kill_task(self):
        def _start_cycle_kill_task():
            while 1:
                if self._recent_scan_need_kill_task:
                    # print(0.0001)
                    time.sleep(0.01)
                else:
                    # print(555)
                    time.sleep(5)
                self._recent_scan_need_kill_task = False
                thread_task_id_list = []
                task_id__thread_map = {}
                for t in threading.enumerate():
                    if isinstance(t, ThreadKillAble):
                        thread_task_id = getattr(t, 'task_id', None)
                        thread_task_id_list.append(thread_task_id)
                        task_id__thread_map[thread_task_id] = t
                if thread_task_id_list:
                    values = self.redis_db_frame.hmget(self._redis_hash_key, keys=thread_task_id_list)
                    for idx, thread_task_id in enumerate(thread_task_id_list):
                        if values[idx] is not None:
                            self.redis_db_frame.hdel(self._redis_hash_key, thread_task_id)
                            t = task_id__thread_map[thread_task_id]
                            t.killed = True
                            t.event_kill.set()
                            kill_thread(t.ident)
                            self._recent_scan_need_kill_task = True
                            self.logger.warning(f'队列 {self.queue_name} 的 任务 {thread_task_id} 被杀死')

        threading.Thread(target=_start_cycle_kill_task).start()


if __name__ == '__main__':

    test_lock = threading.Lock()


    def my_fun(x):
        """
        使用lock.acquire(),强行杀死会一直无法释放锁
        """
        test_lock.acquire()
        print(f'start {x}')
        # resp = requests.get('http://127.0.0.1:5000')  # flask接口里面sleep30秒，
        # print(resp.text)
        for i in range(10):
            time.sleep(2)
        test_lock.release()
        print(f'over {x}')
        return 666


    def my_fun2(x):
        """
        使用with lock,强行杀死会不会出现一直无法释放锁
        """
        with test_lock:
            print(f'start {x}')
            # resp = requests.get('http://127.0.0.1:5000')  # flask接口里面sleep30秒，
            # print(resp.text)
            for i in range(10):
                time.sleep(2)
            print(f'over {x}')
            return 666


    threading.Thread(target=kill_fun_deco(task_id='task1234')(my_fun2), args=(777,)).start()
    threading.Thread(target=kill_fun_deco(task_id='task5678')(my_fun2), args=(888,)).start()
    time.sleep(5)
    # kill_thread_by_task_id('task1234')

    k = RemoteTaskKiller('test_kill_queue', 'task1234')
    k.start_cycle_kill_task()
    k.send_kill_remote_task_comd()

    """
    第一种代码：
    test_lock.acquire()
    执行io耗时代码
    test_lock.release()
    如果使用lock.acquire()获得锁以后，执行耗时代码时候，还没有执行lock.release() 强行杀死线程，会导致锁一直不能释放
    
    第二种代码
    with test_lock:
        执行io耗时代码
    使用with lock 获得锁以后，执行耗时代码时候，强行杀死线程，则不会导致锁一直不能释放
    
    """

`````

--- **end of file: funboost/core/kill_remote_task.py** (project: funboost) --- 

---


--- **start of file: funboost/core/lazy_impoter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/lazy_impoter.py`

#### 📦 Imports

- `import abc`
- `from funboost.utils.decorators import cached_method_result`
- `from funboost.utils.decorators import singleton`
- `from funboost.utils.decorators import SingletonBaseNew`
- `from funboost.utils.decorators import SingletonBaseCustomInit`
- `from funboost.utils.decorators import singleton_no_lock`
- `from funboost.core import booster`
- `from funboost.core import booster`
- `from funboost.core import booster`
- `from funboost.core.loggers import flogger`
- `import gevent`
- `from gevent import pool as gevent_pool`
- `from gevent import monkey`
- `from gevent.queue import JoinableQueue`
- `from eventlet import greenpool`
- `from eventlet import monkey_patch`
- `from eventlet import patcher`
- `from eventlet import Timeout`
- `from peewee import ModelSelect`
- `from peewee import Model`
- `from peewee import BigAutoField`
- `from peewee import CharField`
- `from peewee import DateTimeField`
- `from peewee import MySQLDatabase`
- `from playhouse.shortcuts import model_to_dict`
- `from playhouse.shortcuts import dict_to_model`
- `from aiohttp import web`
- `from aiohttp.web_request import Request`
- `from pynats import NATSClient`
- `from pynats import NATSMessage`
- `from gnsq import Consumer`
- `from gnsq import Message`
- `from gnsq import Producer`
- `from gnsq import NsqdHTTPClient`
- `from gnsq.errors import NSQHttpError`
- `from elasticsearch import helpers`
- `import psutil`
- `import paho.mqtt.client as mqtt`
- `import zmq`
- `from kafka import KafkaConsumer as OfficialKafkaConsumer`
- `from kafka import KafkaProducer`
- `from kafka import KafkaAdminClient`
- `from kafka.admin import NewTopic`
- `from kafka.errors import TopicAlreadyExistsError`

#### 🏛️ Classes (12)

##### 📌 `class FunboostLazyImpoter(SingletonBaseNew)`
*Line: 11*

**Docstring:**
`````
延迟导入,避免需要互相导入.
`````

**Properties (4):**
- `@property BoostersManager`
- `@property boost`
- `@property Booster`
- `@property flogger`

##### 📌 `class GeventImporter`
*Line: 54*

**Docstring:**
`````
避免提前导入
import gevent
from gevent import pool as gevent_pool
from gevent import monkey
from gevent.queue import JoinableQueue
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Parameters:**
    - `self`

##### 📌 `class EventletImporter`
*Line: 76*

**Docstring:**
`````
避免提前导入
from eventlet import greenpool, monkey_patch, patcher, Timeout
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Parameters:**
    - `self`

##### 📌 `class PeeweeImporter`
*Line: 92*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install peewee == 3.17
  `````
  - **Parameters:**
    - `self`

##### 📌 `class AioHttpImporter`
*Line: 108*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install aiohttp==3.8.3
  `````
  - **Parameters:**
    - `self`

##### 📌 `class NatsImporter`
*Line: 119*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install nats-python 
  `````
  - **Parameters:**
    - `self`

##### 📌 `class GnsqImporter`
*Line: 128*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install  gnsq==1.0.1
  `````
  - **Parameters:**
    - `self`

##### 📌 `class ElasticsearchImporter`
*Line: 142*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install elasticsearch 
  `````
  - **Parameters:**
    - `self`

##### 📌 `class PsutilImporter`
*Line: 150*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install  psutil
  `````
  - **Parameters:**
    - `self`

##### 📌 `class PahoMqttImporter`
*Line: 158*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install paho-mqtt
  `````
  - **Parameters:**
    - `self`

##### 📌 `class ZmqImporter`
*Line: 166*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install zmq pyzmq
  `````
  - **Parameters:**
    - `self`

##### 📌 `class KafkaPythonImporter`
*Line: 174*

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Docstring:**
  `````
  pip install kafka-python==2.0.2
  `````
  - **Parameters:**
    - `self`


---

`````python
import abc

from funboost.utils.decorators import cached_method_result, singleton, SingletonBaseNew, SingletonBaseCustomInit, singleton_no_lock

"""
延迟导入
或者使用时候再pip安装
"""


class FunboostLazyImpoter(SingletonBaseNew):
    """
    延迟导入,避免需要互相导入.
    """

    @property
    @cached_method_result
    def BoostersManager(self):
        from funboost.core import booster
        return booster.BoostersManager

    @property
    @cached_method_result
    def boost(self):
        from funboost.core import  booster
        return booster.boost

    @property
    @cached_method_result
    def Booster(self):
        from funboost.core import booster
        return booster.Booster

    @property
    @cached_method_result
    def flogger(self):
        from funboost.core.loggers import flogger
        return flogger



    # @property
    # @cached_method_result
    # def get_current_taskid(self):
    #     from funboost.core.current_task import get_current_taskid
    #     return get_current_taskid


funboost_lazy_impoter = FunboostLazyImpoter()


# noinspection SpellCheckingInspection
@singleton
class GeventImporter:
    """
    避免提前导入
    import gevent
    from gevent import pool as gevent_pool
    from gevent import monkey
    from gevent.queue import JoinableQueue
    """

    def __init__(self):
        import gevent
        print('导入gevent')
        from gevent import pool as gevent_pool
        from gevent import monkey
        from gevent.queue import JoinableQueue
        self.gevent = gevent
        self.gevent_pool = gevent_pool
        self.monkey = monkey
        self.JoinableQueue = JoinableQueue


@singleton_no_lock
class EventletImporter:
    """
    避免提前导入
    from eventlet import greenpool, monkey_patch, patcher, Timeout
    """

    def __init__(self):
        from eventlet import greenpool, monkey_patch, patcher, Timeout
        print('导入eventlet')
        self.greenpool = greenpool
        self.monkey_patch = monkey_patch
        self.patcher = patcher
        self.Timeout = Timeout


@singleton_no_lock
class PeeweeImporter:
    def __init__(self):
        """pip install peewee == 3.17"""
        from peewee import ModelSelect, Model, BigAutoField, CharField, DateTimeField, MySQLDatabase
        from playhouse.shortcuts import model_to_dict, dict_to_model
        self.ModelSelect = ModelSelect
        self.Model = Model
        self.BigAutoField = BigAutoField
        self.CharField = CharField
        self.DateTimeField = DateTimeField
        self.MySQLDatabase = MySQLDatabase
        self.model_to_dict = model_to_dict
        self.dict_to_model = dict_to_model


@singleton_no_lock
class AioHttpImporter:

    def __init__(self):
        """pip install aiohttp==3.8.3"""
        from aiohttp import web
        from aiohttp.web_request import Request
        self.web = web
        self.Request = Request


@singleton_no_lock
class NatsImporter:
    def __init__(self):
        """pip install nats-python """
        from pynats import NATSClient, NATSMessage
        self.NATSClient = NATSClient
        self.NATSMessage = NATSMessage


@singleton_no_lock
class GnsqImporter:
    def __init__(self):
        """pip install  gnsq==1.0.1"""
        from gnsq import Consumer, Message
        from gnsq import Producer, NsqdHTTPClient
        from gnsq.errors import NSQHttpError
        self.Consumer = Consumer
        self.Message = Message
        self.Producer = Producer
        self.NsqdHTTPClient = NsqdHTTPClient
        self.NSQHttpError = NSQHttpError


@singleton_no_lock
class ElasticsearchImporter:
    def __init__(self):
        """pip install elasticsearch """
        from elasticsearch import helpers
        self.helpers = helpers


@singleton_no_lock
class PsutilImporter:
    def __init__(self):
        """pip install  psutil"""
        import psutil
        self.psutil = psutil


@singleton_no_lock
class PahoMqttImporter:
    def __init__(self):
        """pip install paho-mqtt"""
        import paho.mqtt.client as mqtt
        self.mqtt = mqtt


@singleton_no_lock
class ZmqImporter:
    def __init__(self):
        """pip install zmq pyzmq"""
        import zmq
        self.zmq = zmq


@singleton_no_lock
class KafkaPythonImporter:
    def __init__(self):
        """pip install kafka-python==2.0.2"""

        from kafka import KafkaConsumer as OfficialKafkaConsumer, KafkaProducer, KafkaAdminClient
        from kafka.admin import NewTopic
        from kafka.errors import TopicAlreadyExistsError

        self.OfficialKafkaConsumer = OfficialKafkaConsumer
        self.KafkaProducer = KafkaProducer
        self.KafkaAdminClient = KafkaAdminClient
        self.NewTopic = NewTopic
        self.TopicAlreadyExistsError = TopicAlreadyExistsError


if __name__ == '__main__':
    print()
    for i in range(1000000):
        # funboost_lazy_impoter.BoostersManager
        # EventletImporter().greenpool
        # GeventImporter().JoinableQueue
        ZmqImporter().zmq
    print()

`````

--- **end of file: funboost/core/lazy_impoter.py** (project: funboost) --- 

---


--- **start of file: funboost/core/loggers.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/loggers.py`

#### 📦 Imports

- `import nb_log`
- `from funboost.core.funboost_config_getter import _try_get_user_funboost_common_config`
- `from nb_log import get_logger`
- `from nb_log import LoggerLevelSetterMixin`
- `from nb_log import nb_log_config_default`
- `import logging`

#### 🏛️ Classes (2)

##### 📌 `class FunboostFileLoggerMixin(nb_log.LoggerMixin)`
*Line: 18*

**Docstring:**
`````
给对象添加一个logger树形命名空间是类本身,写入funboost.log
`````

**Properties (1):**
- `@property logger -> logging.Logger`

**Class Variables (1):**
- `subclass_logger_dict = {}`

##### 📌 `class FunboostMetaTypeFileLogger(type)`
*Line: 33*

**Docstring:**
`````
给类添加一个属性.名空间是类本身,写入funboost.log
`````

**🔧 Constructor (`__init__`):**
- `def __init__(cls, name, bases, attrs)`
  - **Parameters:**
    - `cls`
    - `name`
    - `bases`
    - `attrs`

#### 🔧 Public Functions (1)

- `def get_funboost_file_logger(name, **kwargs) -> logging.Logger`
  - *Line: 11*
  - *日志自动写入 funboost.log文件中,不需要亲自指定文件名*


---

`````python
import nb_log
from funboost.core.funboost_config_getter import _try_get_user_funboost_common_config

# noinspection PyUnresolvedReferences
from nb_log import get_logger, LoggerLevelSetterMixin, nb_log_config_default
import logging

LOG_FILE_NAME = 'funboost.log'


def get_funboost_file_logger(name, *, log_level_int: int = None, **kwargs) -> logging.Logger:
    """日志自动写入 funboost.log文件中,不需要亲自指定文件名"""
    kwargs['log_filename'] = LOG_FILE_NAME
    kwargs['error_log_filename'] = nb_log.generate_error_file_name(log_filename=LOG_FILE_NAME)
    return nb_log.get_logger(name, log_level_int=log_level_int, **kwargs, )


class FunboostFileLoggerMixin(nb_log.LoggerMixin):
    """给对象添加一个logger树形命名空间是类本身,写入funboost.log"""
    subclass_logger_dict = {}

    @property
    def logger(self) -> logging.Logger:
        logger_name_key = self.logger_full_name + '3'
        if logger_name_key not in self.subclass_logger_dict:
            logger_var = get_funboost_file_logger(self.logger_full_name)
            self.subclass_logger_dict[logger_name_key] = logger_var
            return logger_var
        else:
            return self.subclass_logger_dict[logger_name_key]


class FunboostMetaTypeFileLogger(type):
    """
    给类添加一个属性.名空间是类本身,写入funboost.log
    """

    def __init__(cls, name, bases, attrs):
        super().__init__(name, bases, attrs)
        cls.logger: logging.Logger = get_funboost_file_logger(name)


nb_log.LogManager('_KeepAliveTimeThread').preset_log_level(_try_get_user_funboost_common_config('KEEPALIVETIMETHREAD_LOG_LEVEL') or logging.DEBUG)

flogger = get_funboost_file_logger('funboost', )
# print(_try_get_user_funboost_common_config('FUNBOOST_PROMPT_LOG_LEVEL'))
logger_prompt = get_funboost_file_logger('funboost.prompt', log_level_int=_try_get_user_funboost_common_config('FUNBOOST_PROMPT_LOG_LEVEL') or logging.DEBUG)

# 开发时候的调试日志，比print方便通过级别一键屏蔽。
develop_logger = get_logger('funboost_develop', log_level_int=logging.WARNING, log_filename='funboost_develop.log')

if __name__ == '__main__':
    logger1 = get_funboost_file_logger('name1')
    logger1.info('啦啦啦啦啦啦啦')
    logger1.error('错错错')
    
`````

--- **end of file: funboost/core/loggers.py** (project: funboost) --- 

---


--- **start of file: funboost/core/msg_result_getter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/msg_result_getter.py`

#### 📦 Imports

- `import asyncio`
- `import threading`
- `import time`
- `import typing`
- `import json`
- `from funboost.constant import MongoDbName`
- `from funboost.core.exceptions import FunboostWaitRpcResultTimeout`
- `from funboost.core.exceptions import FunboostRpcResultError`
- `from funboost.core.exceptions import HasNotAsyncResult`
- `from funboost.utils.mongo_util import MongoMixin`
- `from funboost.concurrent_pool import CustomThreadPoolExecutor`
- `from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPoolMinWorkers0`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.redis_manager import AioRedisMixin`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`

#### 🏛️ Classes (4)

##### 📌 `class AsyncResult(RedisMixin)`
*Line: 41*

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id, timeout = 1800)`
  - **Parameters:**
    - `self`
    - `task_id`
    - `timeout = 1800`

**Public Methods (8):**
- `def callback_run_executor(self, thread_pool_executor)` `callback_run_executor.setter`
  - **Docstring:**
  `````
  用户可以 async_result.callback_run_executor = 你自己的线程池
  thread_pool_executor 用户可以传递 FlexibleThreadPool或者 ThreadPoolExecutorShrinkAble 或者官方的 concurrent.futures.ThreadPoolExecutor 类型的对象都可以，任意线程池只要实现了submit方法即可。
  :param thread_pool_executor:
  :return:
  `````
- `def set_timeout(self, timeout = 1800)`
- `def is_pending(self)`
- `def get(self)`
- `def is_success(self)`
- `def set_callback(self, callback_func: typing.Callable)`
  - **Docstring:**
  `````
  :param callback_func: 函数结果回调函数，使回调函数自动在线程池中并发运行。
  :return:
  `````
- `def wait_rpc_data_or_raise(self, raise_exception: bool = True) -> FunctionResultStatus`
- `def batch_wait_rpc_data_or_raise(cls, r_list: typing.List['AsyncResult'], raise_exception: bool = True) -> typing.List[FunctionResultStatus]` `classmethod`

**Properties (4):**
- `@property callback_run_executor`
- `@property status_and_result`
- `@property status_and_result_obj -> FunctionResultStatus`
- `@property result`

**Class Variables (2):**
- `default_callback_run_executor = FlexibleThreadPoolMinWorkers0(200, work_queue_maxsize=50)`
- `rpc_data = status_and_result_obj`

##### 📌 `class AioAsyncResult(AioRedisMixin)`
*Line: 144*

**Docstring:**
`````
这个是可以用于asyncio的语法环境中。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id, timeout = 1800)`
  - **Parameters:**
    - `self`
    - `task_id`
    - `timeout = 1800`

**Public Methods (7):**
- `def set_timeout(self, timeout = 1800)`
- `async def is_pending(self)`
- `async def get(self)`
- `async def is_success(self)`
- `async def set_callback(self, aio_callback_func: typing.Callable)`
- `async def wait_rpc_data_or_raise(self, raise_exception: bool = True) -> FunctionResultStatus`
- `async def batch_wait_rpc_data_or_raise(cls, r_list: typing.List['AioAsyncResult'], raise_exception: bool = True) -> typing.List[FunctionResultStatus]` `classmethod`

**Properties (3):**
- `@property status_and_result`
- `@property status_and_result_obj -> FunctionResultStatus`
- `@property result`

**Class Variables (1):**
- `rpc_data = status_and_result_obj`

##### 📌 `class ResultFromMongo(MongoMixin)`
*Line: 249*

**Docstring:**
`````
以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果

async_result = add.push(i, i * 2)
task_id=async_result.task_id
print(ResultFromMongo(task_id).get_status_and_result())


print(ResultFromMongo('test_queue77h6_result:764a1ba2-14eb-49e2-9209-ac83fc5db1e8').get_status_and_result())
print(ResultFromMongo('test_queue77h6_result:5cdb4386-44cc-452f-97f4-9e5d2882a7c1').get_result())
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, task_id: str)`
  - **Parameters:**
    - `self`
    - `task_id: str`

**Public Methods (3):**
- `def query_result(self)`
- `def get_status_and_result(self)`
- `def get_result(self)`
  - *以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果*

##### 📌 `class FutureStatusResult`
*Line: 283*

**Docstring:**
`````
用于sync_call模式的结果等待和通知
使用threading.Event实现同步等待
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, call_type: str)`
  - **Parameters:**
    - `self`
    - `call_type: str`

**Public Methods (4):**
- `def set_finish(self)`
  - *标记任务完成*
- `def wait_finish(self, rpc_timeout)`
  - *等待任务完成，带超时*
- `def set_staus_result_obj(self, staus_result_obj: FunctionResultStatus)`
  - *设置任务执行结果*
- `def get_staus_result_obj(self)`
  - *获取任务执行结果*


---

`````python
import asyncio
import threading
import time

import typing
import json

from funboost.constant import MongoDbName
from funboost.core.exceptions import FunboostWaitRpcResultTimeout, FunboostRpcResultError, HasNotAsyncResult
from funboost.utils.mongo_util import MongoMixin

from funboost.concurrent_pool import CustomThreadPoolExecutor
from funboost.concurrent_pool.flexible_thread_pool import FlexibleThreadPoolMinWorkers0
from funboost.utils.redis_manager import RedisMixin
from funboost.utils.redis_manager import AioRedisMixin
from funboost.core.serialization import Serialization

from funboost.core.function_result_status_saver import FunctionResultStatus




NO_RESULT = 'no_result'

def _judge_rpc_function_result_status_obj(status_and_result_obj:FunctionResultStatus,raise_exception:bool):
    if status_and_result_obj is None:
        raise FunboostWaitRpcResultTimeout(f'wait rpc data timeout for task_id:{status_and_result_obj.task_id}')
    if status_and_result_obj.success is True:
        return status_and_result_obj
    else:
        raw_erorr = status_and_result_obj.exception
        if status_and_result_obj.exception_type == 'FunboostRpcResultError':
            raw_erorr = json.loads(status_and_result_obj.exception_msg) # 使canvas链式报错json显示更美观
        error_msg_dict = {'task_id':status_and_result_obj.task_id,'raw_error':raw_erorr}
        if raise_exception:
            raise FunboostRpcResultError(json.dumps(error_msg_dict,indent=4,ensure_ascii=False))
        else:
            status_and_result_obj.rpc_chain_error_msg_dict = error_msg_dict
            return status_and_result_obj

class AsyncResult(RedisMixin):
    default_callback_run_executor = FlexibleThreadPoolMinWorkers0(200,work_queue_maxsize=50)

    @property
    def callback_run_executor(self, ):
        return self._callback_run_executor or self.default_callback_run_executor
    @callback_run_executor.setter
    def callback_run_executor(self,thread_pool_executor):
        """
        用户可以 async_result.callback_run_executor = 你自己的线程池
        thread_pool_executor 用户可以传递 FlexibleThreadPool或者 ThreadPoolExecutorShrinkAble 或者官方的 concurrent.futures.ThreadPoolExecutor 类型的对象都可以，任意线程池只要实现了submit方法即可。
        :param thread_pool_executor:
        :return:
        """
        self._callback_run_executor = thread_pool_executor

    def __init__(self, task_id, timeout=1800):
        self.task_id = task_id
        self.timeout = timeout
        self._has_pop = False
        self._status_and_result = None
        self._callback_run_executor = None

    def set_timeout(self, timeout=1800):
        self.timeout = timeout
        return self

    def is_pending(self):
        return not self.redis_db_filter_and_rpc_result.exists(self.task_id)

    @property
    def status_and_result(self):
        if not self._has_pop:
            # print(f'{self.task_id} 正在等待结果')
            redis_value = self.redis_db_filter_and_rpc_result.blpop(self.task_id, self.timeout)
            self._has_pop = True
            if redis_value is not None:
                status_and_result_str = redis_value[1]
                self._status_and_result = Serialization.to_dict(status_and_result_str)
                self.redis_db_filter_and_rpc_result.lpush(self.task_id, status_and_result_str)
                self.redis_db_filter_and_rpc_result.expire(self.task_id, self._status_and_result['rpc_result_expire_seconds'])
                return self._status_and_result
            return None
        return self._status_and_result
    
    @property
    def status_and_result_obj(self) -> FunctionResultStatus:
        """这个是为了比字典有更好的ide代码补全效果"""
        if self.status_and_result is not None:
            return FunctionResultStatus.parse_status_and_result_to_obj(self.status_and_result)
    
    rpc_data =status_and_result_obj

    def get(self):
        # print(self.status_and_result)
        if self.status_and_result is not None:
            return self.status_and_result['result']
        else:
            raise HasNotAsyncResult

    @property
    def result(self):
        return self.get()

    def is_success(self):
        if self.status_and_result is not None:
            return self.status_and_result['success']
        else:
            raise HasNotAsyncResult

    def _run_callback_func(self, callback_func):
        callback_func(self.status_and_result)

    def set_callback(self, callback_func: typing.Callable):
        """
        :param callback_func: 函数结果回调函数，使回调函数自动在线程池中并发运行。
        :return:
        """

        ''' 用法例如
        from test_frame.test_rpc.test_consume import add
        def show_result(status_and_result: dict):
            """
            :param status_and_result: 一个字典包括了函数入参、函数结果、函数是否运行成功、函数运行异常类型
            """
            print(status_and_result)

        for i in range(100):
            async_result = add.push(i, i * 2)
            # print(async_result.result)   # 执行 .result是获取函数的运行结果，会阻塞当前发布消息的线程直到函数运行完成。
            async_result.set_callback(show_result) # 使用回调函数在线程池中并发的运行函数结果
        '''
        self.callback_run_executor.submit(self._run_callback_func, callback_func)
    
    def wait_rpc_data_or_raise(self,raise_exception:bool=True)->FunctionResultStatus:
        return _judge_rpc_function_result_status_obj(self.status_and_result_obj,raise_exception)
    
    @classmethod
    def batch_wait_rpc_data_or_raise(cls,r_list:typing.List['AsyncResult'],raise_exception:bool=True)->typing.List[FunctionResultStatus]:
        return [ _judge_rpc_function_result_status_obj(r.status_and_result_obj,raise_exception) 
                for r in r_list]


class AioAsyncResult(AioRedisMixin):
    """ 这个是可以用于asyncio的语法环境中。"""
    '''
    用法例子
import asyncio

from funboost import AioAsyncResult
from test_frame.test_rpc.test_consume import add


async def process_result(status_and_result: dict):
    """
    :param status_and_result: 一个字典包括了函数入参、函数结果、函数是否运行成功、函数运行异常类型
    """
    await asyncio.sleep(1)
    print(status_and_result)


async def test_get_result(i):
    async_result = add.push(i, i * 2)
    aio_async_result = AioAsyncResult(task_id=async_result.task_id) # 这里要使用asyncio语法的类，更方便的配合asyncio异步编程生态
    print(await aio_async_result.result) # 注意这里有个await，如果不await就是打印一个协程对象，不会得到结果。这是asyncio的基本语法，需要用户精通asyncio。
    print(await aio_async_result.status_and_result)
    await aio_async_result.set_callback(process_result)  #  你也可以编排任务到loop中


if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    for j in range(100):
        loop.create_task(test_get_result(j))
    loop.run_forever()

    '''

    def __init__(self, task_id, timeout=1800):
        self.task_id = task_id
        self.timeout = timeout
        self._has_pop = False
        self._status_and_result = None

    def set_timeout(self, timeout=1800):
        self.timeout = timeout
        return self

    async def is_pending(self):
        is_exists = await self.aioredis_db_filter_and_rpc_result.exists(self.task_id)
        return not is_exists

    @property
    async def status_and_result(self):
        if not self._has_pop:
            t1 = time.time()
            redis_value = await self.aioredis_db_filter_and_rpc_result.blpop(self.task_id, self.timeout)
            self._has_pop = True
            if redis_value is not None:
                status_and_result_str = redis_value[1]
                self._status_and_result = Serialization.to_dict(status_and_result_str)
                await self.aioredis_db_filter_and_rpc_result.lpush(self.task_id, status_and_result_str)
                await self.aioredis_db_filter_and_rpc_result.expire(self.task_id, self._status_and_result['rpc_result_expire_seconds'])
                return self._status_and_result
            return None
        return self._status_and_result

    @property
    async def status_and_result_obj(self) -> FunctionResultStatus:
        """这个是为了比字典有更好的ide代码补全效果"""
        sr = await self.status_and_result
        if sr is not None:
            return FunctionResultStatus.parse_status_and_result_to_obj(sr)

    rpc_data =status_and_result_obj
    async def get(self):
        # print(self.status_and_result)
        if (await self.status_and_result) is not None:
            return (await self.status_and_result)['result']
        else:
            raise HasNotAsyncResult

    @property
    async def result(self):
        return await self.get()

    async def is_success(self):
        if (await self.status_and_result) is not None:
            return (await self.status_and_result)['success']
        else:
            raise HasNotAsyncResult

    async def _run_callback_func(self, callback_func):
        await callback_func(await self.status_and_result)

    async def set_callback(self, aio_callback_func: typing.Callable):
        asyncio.create_task(self._run_callback_func(callback_func=aio_callback_func))

    async def wait_rpc_data_or_raise(self,raise_exception:bool=True)->FunctionResultStatus:
        return _judge_rpc_function_result_status_obj(await self.status_and_result_obj,raise_exception)

    @classmethod
    async def batch_wait_rpc_data_or_raise(cls,r_list:typing.List['AioAsyncResult'],raise_exception:bool=True)->typing.List[FunctionResultStatus]:
        return [ _judge_rpc_function_result_status_obj(await r.status_and_result_obj,raise_exception) 
                for r in r_list]
    



class ResultFromMongo(MongoMixin):
    """
    以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果

    async_result = add.push(i, i * 2)
    task_id=async_result.task_id
    print(ResultFromMongo(task_id).get_status_and_result())


    print(ResultFromMongo('test_queue77h6_result:764a1ba2-14eb-49e2-9209-ac83fc5db1e8').get_status_and_result())
    print(ResultFromMongo('test_queue77h6_result:5cdb4386-44cc-452f-97f4-9e5d2882a7c1').get_result())
    """

    def __init__(self, task_id: str, ):
        self.task_id = task_id
        self.col_name = task_id.split('_result:')[0]
        self.mongo_row = None
        self._has_query = False

    def query_result(self):
        col = self.get_mongo_collection(MongoDbName.TASK_STATUS_DB, self.col_name)
        self.mongo_row = col.find_one({'_id': self.task_id})
        self._has_query = True

    def get_status_and_result(self):
        self.query_result()
        return self.mongo_row or NO_RESULT

    def get_result(self):
        """以非阻塞等待的方式从funboost的状态结果持久化的mongodb数据库根据taskid获取结果"""
        self.query_result()
        return (self.mongo_row or {}).get('result', NO_RESULT)


class FutureStatusResult:
    """
    用于sync_call模式的结果等待和通知
    使用threading.Event实现同步等待
    """
    def __init__(self, call_type: str):
        self.execute_finish_event = threading.Event()
        self.staus_result_obj: FunctionResultStatus = None
        self.call_type = call_type  # sync_call or publish

    def set_finish(self):
        """标记任务完成"""
        self.execute_finish_event.set()

    def wait_finish(self, rpc_timeout):
        """等待任务完成，带超时"""
        return self.execute_finish_event.wait(rpc_timeout)

    def set_staus_result_obj(self, staus_result_obj: FunctionResultStatus):
        """设置任务执行结果"""
        self.staus_result_obj = staus_result_obj

    def get_staus_result_obj(self):
        """获取任务执行结果"""
        return self.staus_result_obj

if __name__ == '__main__':
    print(ResultFromMongo('test_queue77h6_result:764a1ba2-14eb-49e2-9209-ac83fc5db1e8').get_status_and_result())
    print(ResultFromMongo('test_queue77h6_result:5cdb4386-44cc-452f-97f4-9e5d2882a7c1').get_result())

`````

--- **end of file: funboost/core/msg_result_getter.py** (project: funboost) --- 

---


--- **start of file: funboost/core/muliti_process_enhance.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/muliti_process_enhance.py`

#### 📦 Imports

- `import os`
- `import signal`
- `from multiprocessing import Process`
- `import time`
- `from typing import List`
- `from concurrent.futures import ProcessPoolExecutor`
- `from funboost.core.booster import Booster`
- `from funboost.core.helper_funs import run_forever`
- `from funboost.core.loggers import flogger`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`

#### 🔧 Public Functions (2)

- `def run_consumer_with_multi_process(booster: Booster, process_num = 1)`
  - *Line: 21*
  - **Docstring:**
  `````
  :param booster:被 boost 装饰器装饰的消费函数
  :param process_num:开启多个进程。  主要是 多进程并发  + 4种细粒度并发(threading gevent eventlet asyncio)。叠加并发。
  这种是多进程方式，一次编写能够兼容win和linux的运行。一次性启动6个进程 叠加 多线程 并发。
  `````

- `def multi_process_pub_params_list(booster: Booster, params_list, process_num = 16)`
  - *Line: 59*
  - *超高速多进程发布任务，充分利用多核*


---

`````python
import os
import signal
from multiprocessing import Process
import time
from typing import List
from concurrent.futures import ProcessPoolExecutor
from funboost.core.booster import Booster
from funboost.core.helper_funs import run_forever
from funboost.core.loggers import flogger
from funboost.core.lazy_impoter import funboost_lazy_impoter


def _run_consumer_in_new_process(queue_name, ):
    booster_current_pid = funboost_lazy_impoter.BoostersManager.get_or_create_booster_by_queue_name(queue_name)
    # booster_current_pid = boost(**boost_params)(consuming_function)
    booster_current_pid.consume()
    # ConsumersManager.join_all_consumer_dispatch_task_thread()
    run_forever()


def run_consumer_with_multi_process(booster: Booster, process_num=1):
    """
    :param booster:被 boost 装饰器装饰的消费函数
    :param process_num:开启多个进程。  主要是 多进程并发  + 4种细粒度并发(threading gevent eventlet asyncio)。叠加并发。
    这种是多进程方式，一次编写能够兼容win和linux的运行。一次性启动6个进程 叠加 多线程 并发。
    """
    '''
       from funboost import boost, BrokerEnum, ConcurrentModeEnum, run_consumer_with_multi_process
       import os

       @boost('test_multi_process_queue',broker_kind=BrokerEnum.REDIS_ACK_ABLE,concurrent_mode=ConcurrentModeEnum.THREADING,)
       def fff(x):
           print(x * 10,os.getpid())

       if __name__ == '__main__':
           # fff.consume()
           run_consumer_with_multi_process(fff,6) # 一次性启动6个进程 叠加 多线程 并发。
           fff.multi_process_conusme(6)    # 这也是一次性启动6个进程 叠加 多线程 并发。
    '''
    if not isinstance(booster, Booster):
        raise ValueError(f'{booster} 参数必须是一个被 boost 装饰的函数')
    if process_num == 1 and False:
        booster.consume()
    else:
        for i in range(process_num):
            # print(i)
            Process(target=_run_consumer_in_new_process,
                    args=(booster.queue_name,)).start()


def _multi_process_pub_params_list_in_new_process(queue_name, msgs: List[dict]):
    booster_current_pid = funboost_lazy_impoter.BoostersManager.get_or_create_booster_by_queue_name(queue_name)
    publisher = booster_current_pid.publisher
    publisher.set_log_level(20)  # 超高速发布，如果打印详细debug日志会卡死屏幕和严重降低代码速度。
    for msg in msgs:
        publisher.publish(msg)


def multi_process_pub_params_list(booster: Booster, params_list, process_num=16):
    """超高速多进程发布任务，充分利用多核"""
    if not isinstance(booster, Booster):
        raise ValueError(f'{booster} 参数必须是一个被 boost 装饰的函数')
    params_list_len = len(params_list)
    if params_list_len < 1000 * 100:
        raise ValueError(f'要要发布的任务数量是 {params_list_len} 个,要求必须至少发布10万任务才使用此方法')
    ava_len = params_list_len // process_num + 1
    with ProcessPoolExecutor(process_num) as pool:
        t0 = time.time()
        for i in range(process_num):
            msgs = params_list[i * ava_len: (i + 1) * ava_len]
            # print(msgs)
            pool.submit(_multi_process_pub_params_list_in_new_process, booster.queue_name,
                        msgs)
    flogger.info(f'\n 通过 multi_process_pub_params_list 多进程子进程的发布方式，发布了 {params_list_len} 个任务。耗时 {time.time() - t0} 秒')

`````

--- **end of file: funboost/core/muliti_process_enhance.py** (project: funboost) --- 

---


--- **start of file: funboost/core/pydantic_compatible_base.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/pydantic_compatible_base.py`

#### 📝 Module Docstring

`````
这个pydantic 基类能兼容pydantic v1 和 v2 和v3
使v2中不再警告用户使用过气的方法，使未来的v3中不报错v1的老方法不存在。
`````

#### 📦 Imports

- `import datetime`
- `import functools`
- `import json`
- `import typing`
- `from collections import OrderedDict`
- `from pydantic import BaseModel`
- `import pydantic`
- `from concurrent.futures import ThreadPoolExecutor`
- `from asyncio import AbstractEventLoop`
- `from pydantic import ConfigDict`
- `from pydantic import root_validator`
- `from pydantic import model_validator`

#### 🏛️ Classes (4)

##### 📌 `class BaseJsonAbleModel(CompatibleModel)`
*Line: 160*

**Docstring:**
`````
因为model字段包括了 函数和自定义类型的对象,无法直接json序列化,需要自定义json序列化
`````

**Public Methods (7):**
- `def get_str_dict(self)`
- `def json_str_value(self)`
- `def json_pre(self)`
- `def update_from_dict(self, dictx: dict)`
- `def update_from_kwargs(self, **kwargs)`
- `def update_from_model(self, modelx: BaseModel)`
- `def init_by_another_model(model_type: typing.Type[BaseModel], modelx: BaseModel)` `staticmethod`

##### 📌 `class CompatibleModel(BaseModel)`
*Line: 42*

**Public Methods (2):**
- `def to_json(self, **kwargs)`
- `def to_dict(self)`

##### 📌 `class CompatibleModel(BaseModel)`
*Line: 60*

**Public Methods (2):**
- `def to_json(self, **kwargs)`
- `def to_dict(self)`

**Class Variables (1):**
- `model_config = ConfigDict(arbitrary_types_allowed=True, extra='forbid')`

##### 📌 `class _ValuesNamespace`
*Line: 99*

**🔧 Constructor (`__init__`):**
- `def __init__(self, d: dict)`
  - **Parameters:**
    - `self`
    - `d: dict`

**Public Methods (1):**
- `def keys(self)`

**Properties (2):**
- `@property model_fields`
- `@property __class__`

**Class Variables (2):**
- `_model_cls = cls`
- `_field_keys = set(values.keys())`

#### 🔧 Public Functions (5)

- `def get_pydantic_major_version() -> int`
  - *Line: 33*

- `def compatible_root_validator()`
  - *Line: 76*
  - **Docstring:**
  `````
  统一 pydantic v1 和 v2 的校验器写法，让用户可以统一用 self.xxx 的方式访问和修改字段。
  
  v1: root_validator(skip_on_failure=skip_on_failure) - 原本签名是 (cls, values: dict)
  v2: model_validator(mode=mode) - 签名是 (self)
  
  用法:
      @compatible_root_validator(skip_on_failure=True)
      def check_values(self):
          if self.qps and self.concurrent_num == 50:
              self.concurrent_num = 500
          return self
  `````

- `def decorator(func)`
  - *Line: 91*

- `def v1_wrapper(cls, values: dict)`
  - *Line: 96*

- `def v2_wrapper(self)` `functools.wraps(func)`
  - *Line: 152*


---

`````python

"""
这个pydantic 基类能兼容pydantic v1 和 v2 和v3
使v2中不再警告用户使用过气的方法，使未来的v3中不报错v1的老方法不存在。
"""
import datetime
import functools
import json
import typing
from collections import OrderedDict
from pydantic import BaseModel
import pydantic


def _patch_for_pydantic_field_deepcopy():
    from concurrent.futures import ThreadPoolExecutor
    from asyncio import AbstractEventLoop

    # noinspection PyUnusedLocal,PyDefaultArgument
    def __deepcopy__(self, memodict={}):
        """
        pydantic 的默认值，需要deepcopy
        """
        return self

    # pydantic 的类型需要用到
    ThreadPoolExecutor.__deepcopy__ = __deepcopy__
    AbstractEventLoop.__deepcopy__ = __deepcopy__
    # BaseEventLoop.__deepcopy__ = __deepcopy__

_patch_for_pydantic_field_deepcopy

def get_pydantic_major_version() -> int:
    version = pydantic.VERSION
    try:
        return int(version.split(".", 1)[0])
    except Exception:
        return -1

if get_pydantic_major_version() == 1:

    class CompatibleModel(BaseModel):
        class Config:
            arbitrary_types_allowed = True
            # allow_mutation = False
            extra = "forbid"
            json_encoders = {
                datetime.datetime: lambda v: v.strftime("%Y-%m-%d %H:%M:%S")
            }

        def to_json(self, **kwargs):
            return self.json(**kwargs)

        def to_dict(self):
            return self.dict()

elif get_pydantic_major_version() >= 2:
    from pydantic import ConfigDict

    class CompatibleModel(BaseModel):
        model_config = ConfigDict(
            arbitrary_types_allowed=True,
            extra="forbid",
        )

        # pydantic v2 默认就能正确序列化 datetime，无需额外配置

        def to_json(self, **kwargs):
            return self.model_dump_json(**kwargs)

        def to_dict(self):
            return self.model_dump()


# 统一兼容 root_validator / model_validator 的装饰器
def compatible_root_validator(*, skip_on_failure=True, mode="after"):
    """
    统一 pydantic v1 和 v2 的校验器写法，让用户可以统一用 self.xxx 的方式访问和修改字段。

    v1: root_validator(skip_on_failure=skip_on_failure) - 原本签名是 (cls, values: dict)
    v2: model_validator(mode=mode) - 签名是 (self)

    用法:
        @compatible_root_validator(skip_on_failure=True)
        def check_values(self):
            if self.qps and self.concurrent_num == 50:
                self.concurrent_num = 500
            return self
    """

    def decorator(func):
        if get_pydantic_major_version() == 1:
            from pydantic import root_validator

            # 注意：不能使用 @functools.wraps(func)，否则 pydantic v1 会检查到原函数签名 (self) 而报错
            def v1_wrapper(cls, values: dict):
                # 创建一个命名空间对象，让用户可以用 self.xxx 的方式访问字段
                # 同时代理访问原始模型类的元信息（如 __fields__, model_fields）
                class _ValuesNamespace:
                    # 类属性：存储原始模型类的引用
                    _model_cls = cls
                    _field_keys = set(values.keys())

                    def __init__(self, d: dict):
                        # 将字段值存入实例
                        for k, v in d.items():
                            object.__setattr__(self, k, v)

                    def __setattr__(self, name, value):
                        object.__setattr__(self, name, value)

                    def keys(self):
                        return self._field_keys

                    @property
                    def model_fields(self):
                        # 代理访问类的字段定义（兼容 v2 风格）
                        # 在 v1 中返回 __fields__
                        return self._model_cls.__fields__

                    def __getattr__(self, name):
                        # 处理 __fields__ 等特殊属性的访问
                        if name == "__fields__":
                            return self._model_cls.__fields__
                        raise AttributeError(
                            f"'{self._model_cls.__name__}' object has no attribute '{name}'"
                        )

                    @property
                    def __class__(self):
                        # 让 self.__class__.__name__ 返回正确的类名
                        return self._model_cls

                ns = _ValuesNamespace(values)
                result = func(ns)
                # 把修改后的值同步回 values 字典
                for k in values:
                    if hasattr(result, k):
                        values[k] = getattr(result, k)
                return values

            v1_wrapper.__name__ = func.__name__  # 手动设置函数名，用于调试
            v1_wrapper.__doc__ = func.__doc__
            return root_validator(skip_on_failure=skip_on_failure, allow_reuse=True)(
                v1_wrapper
            )
        else:
            from pydantic import model_validator

            # v2 的 model_validator(mode='after') 直接接收 self
            @functools.wraps(func)
            def v2_wrapper(self):
                return func(self)

            return model_validator(mode=mode)(v2_wrapper)

    return decorator


class BaseJsonAbleModel(CompatibleModel):
    """
    因为model字段包括了 函数和自定义类型的对象,无法直接json序列化,需要自定义json序列化
    """

    def get_str_dict(self):
        model_dict: dict = self.to_dict()  # noqa
        model_dict_copy = OrderedDict()
        for k, v in model_dict.items():
            if isinstance(v, typing.Callable):
                model_dict_copy[k] = str(v)
            # elif k in ['specify_concurrent_pool', 'specify_async_loop'] and v is not None:
            elif (
                type(v).__module__ != "builtins"
            ):  # 自定义类型的对象,json不可序列化,需要转化下.
                model_dict_copy[k] = str(v)
            else:
                model_dict_copy[k] = v
        return model_dict_copy

    def json_str_value(self):
        try:
            return json.dumps(
                dict(self.get_str_dict()),
                ensure_ascii=False,
            )
        except TypeError as e:
            return str(self.get_str_dict())

    def json_pre(self):
        try:
            return json.dumps(self.get_str_dict(), ensure_ascii=False, indent=4)
        except TypeError as e:
            return str(self.get_str_dict())

    def update_from_dict(self, dictx: dict):
        for k, v in dictx.items():
            setattr(self, k, v)
        return self

    def update_from_kwargs(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)
        return self

    def update_from_model(self, modelx: BaseModel):
        for k, v in modelx.to_dict().items():
            setattr(self, k, v)
        return self

    @staticmethod
    def init_by_another_model(model_type: typing.Type[BaseModel], modelx: BaseModel):
        init_dict = {}
        for k, v in modelx.to_dict().items():
            if k in model_type.__fields__.keys():
                init_dict[k] = v
        return model_type(**init_dict)

`````

--- **end of file: funboost/core/pydantic_compatible_base.py** (project: funboost) --- 

---


--- **start of file: funboost/core/serialization.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/serialization.py`

#### 📦 Imports

- `import typing`
- `import json`
- `import orjson`
- `import pickle`
- `import ast`

#### 🏛️ Classes (2)

##### 📌 `class Serialization`
*Line: 7*

**Public Methods (3):**
- `def to_json_str(dic: typing.Union[dict, str])` `staticmethod`
- `def to_dict(strx: typing.Union[str, dict])` `staticmethod`
- `def find_can_not_json_serializable_keys(dic: dict) -> typing.List[str]` `staticmethod`

##### 📌 `class PickleHelper`
*Line: 34*

**Public Methods (2):**
- `def to_str(obj_x: typing.Any)` `staticmethod`
- `def to_obj(str_x: str)` `staticmethod`


---

`````python
import typing
import json
import orjson
import pickle
import ast

class Serialization:
    @staticmethod
    def to_json_str(dic:typing.Union[dict,str]):
        if isinstance(dic,str):
            return dic
        str1 =orjson.dumps(dic)
        return str1.decode('utf8')

    @staticmethod
    def to_dict(strx:typing.Union[str,dict]):
        if isinstance(strx,dict):
            return strx
        return orjson.loads(strx)
    
    @staticmethod
    def find_can_not_json_serializable_keys(dic:dict)->typing.List[str]:
        can_not_json_serializable_keys = []
        dic = Serialization.to_dict(dic)
        for k,v in dic.items():
            if not isinstance(v,str):
                try:
                    json.dumps(v)
                except:
                    can_not_json_serializable_keys.append(k)
        return can_not_json_serializable_keys
    

class PickleHelper:
    @staticmethod
    def to_str(obj_x:typing.Any):
        return str(pickle.dumps(obj_x)) # 对象pickle,转成字符串
    
    @staticmethod
    def to_obj(str_x:str):
        return pickle.loads(ast.literal_eval(str_x)) # 不是从字节转成对象,是从字符串转,所以需要这样.
    


`````

--- **end of file: funboost/core/serialization.py** (project: funboost) --- 

---


--- **start of file: funboost/core/task_id_logger.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/task_id_logger.py`

#### 📦 Imports

- `import functools`
- `from nb_log import CompatibleLogger`
- `from funboost.core.current_task import get_current_taskid`

#### 🏛️ Classes (1)

##### 📌 `class TaskIdLogger(CompatibleLogger)`
*Line: 7*

**Docstring:**
`````
如果你要使用带taskid的日志模板,一定要使用
 LogManager('namexx',logger_cls=TaskIdLogger).get_logger_and_add_handlers(....)
 的方式来创建logger, 就是需要指定logger_cls=TaskIdLogger ,否则的话你需要在打印日志时候 手动传递extra logger.info(msg,extra={'task_id':task_idxxx})
 
`````


---

`````python
import functools

from nb_log import CompatibleLogger
from funboost.core.current_task import get_current_taskid


class TaskIdLogger(CompatibleLogger):
    """
    如果你要使用带taskid的日志模板,一定要使用
     LogManager('namexx',logger_cls=TaskIdLogger).get_logger_and_add_handlers(....)
     的方式来创建logger, 就是需要指定logger_cls=TaskIdLogger ,否则的话你需要在打印日志时候 手动传递extra logger.info(msg,extra={'task_id':task_idxxx})
     """
    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):
        extra = extra or {}
        if 'task_id' not in extra:
            extra['task_id'] = get_current_taskid()
        if 'sys_getframe_n' not in extra:
            extra['sys_getframe_n'] = 3
        super()._log(level, msg, args, exc_info, extra, stack_info)

`````

--- **end of file: funboost/core/task_id_logger.py** (project: funboost) --- 

---


--- **start of file: funboost/core/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/__init__.py`


---

`````python

`````

--- **end of file: funboost/core/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/core/cli/discovery_boosters.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/cli/discovery_boosters.py`

#### 📝 Module Docstring

`````
【⚠️ 安全警示 & 最佳实践】

1. 关于 BoosterDiscovery 自动扫描的风险提示
-------------------------------------------------------
BoosterDiscovery(....).auto_discovery() 请务必谨慎使用，强烈建议实例化时传入精确的过滤参数。

原因：
    部分开发者的编程习惯可能不严谨，对于包含执行动作的脚本，未添加 `if __name__ == '__main__':` 保护，
    或者不理解 `__main__` 的作用。Python 的 import 机制意味着“导入即执行模块顶层代码”。

危险场景假设：
    假设项目中存在一个临时的脏数据清理脚本 `my_temp_dangerous_delete_mysql_script.py`：

    ```python
    # ❌ 危险写法：写在模块顶层，不在函数内，也无 main 保护
    import db_client
    db_client.execute("DROP TABLE users") 
    ```

后果：
    如果你使用了无限制的 `auto_discovery()`，即使项目上线2年后，一旦扫描并 import 到这个脚本，
    数据库表会在瞬间被删除。这绝对是生产事故级别的灾难。

✅ 正确用法（精确传参）：
    BoosterDiscovery(
        project_root_path='/path/to/your_project', 
        booster_dirs=['your_booster_dir'],
        max_depth=1,
        py_file_re_str='tasks'  # 强烈建议：只扫描包含 'tasks' 的文件，避开临时脚本
    ).auto_discovery()


2. 为什么推荐“显式 Import”而非“自动扫描”？BoosterDiscovery不是funboost的必需品！
-------------------------------------------------------
其实不建议过度依赖 `auto_discovery()`，更推荐的最佳实践是：
👉 手动明确 import 包含 @boost 的模块。需要用到哪些消费函数，就导入哪些模块。

Funboost vs Celery 的架构差异：
    * Funboost：
      没有中央 `app` 实例，不需要像 Celery 那样有一个单独的 `celery_app.py` 模块。
      架构上天然不存在“互相依赖导入”的死结。因此，要用什么消费函数，直接导入即可，简单直观。

    * Celery：
      必须手写 `includes` 配置或调用 `autodiscover_tasks()`。
      根本原因是：Celery 的 `xx_tasks.py` 需要导入 `celery_app.py` 中的 `app` 对象；
      而 `celery worker` 启动 `app` 时又需要导入 `xx_tasks.py` 来注册任务。
      这种设计导致双方陷入“循环导入”的死结，迫使 Celery 发明了一套复杂的导入机制，
      也让新手在规划目录结构时小心翼翼、非常纠结。
`````

#### 📦 Imports

- `import re`
- `import sys`
- `import typing`
- `from os import PathLike`
- `from pathlib import Path`
- `import importlib.util`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.utils.decorators import flyweight`
- `from funboost.core.lazy_impoter import funboost_lazy_impoter`

#### 🏛️ Classes (1)

##### 📌 `class BoosterDiscovery(FunboostFileLoggerMixin)`
*Line: 64*

**🔧 Constructor (`__init__`):**
- `def __init__(self, project_root_path: typing.Union[PathLike, str], booster_dirs: typing.List[typing.Union[PathLike, str]], max_depth = 1, py_file_re_str: str = None)`
  - **Docstring:**
  `````
  :param project_root_path 项目根目录
  :param booster_dirs: @boost装饰器函数所在的模块的文件夹,不用包含项目根目录长路径
  :param max_depth: 查找多少深层级子目录
  :param py_file_re_str: 文件名匹配过滤. 例如你所有的消费函数都在xxx_task.py yyy_task.py这样的,  你可以传参 task.py , 避免自动import了不需要导入的模块
  
  BoosterDiscovery(....).auto_discovery() 需要谨慎使用，谨慎传参，原因见上面模块注释。
  `````
  - **Parameters:**
    - `self`
    - `project_root_path: typing.Union[PathLike, str]`
    - `booster_dirs: typing.List[typing.Union[PathLike, str]]`
    - `max_depth = 1`
    - `py_file_re_str: str = None`

**Public Methods (2):**
- `def get_py_files_recursively(self, current_folder_path: Path, current_depth = 0)`
  - *先找到所有py文件*
- `def auto_discovery(self)`
  - **Docstring:**
  `````
  把所有py文件自动执行import,主要是把 所有的@boost函数装饰器注册到 pid_queue_name__booster_map 中
  这个auto_discovery方法最好放到main里面,如果要扫描自身文件夹,没写正则排除文件本身,会无限懵逼死循环导入,无无限懵逼死循环导入
  `````


---

`````python
"""
【⚠️ 安全警示 & 最佳实践】

1. 关于 BoosterDiscovery 自动扫描的风险提示
-------------------------------------------------------
BoosterDiscovery(....).auto_discovery() 请务必谨慎使用，强烈建议实例化时传入精确的过滤参数。

原因：
    部分开发者的编程习惯可能不严谨，对于包含执行动作的脚本，未添加 `if __name__ == '__main__':` 保护，
    或者不理解 `__main__` 的作用。Python 的 import 机制意味着“导入即执行模块顶层代码”。

危险场景假设：
    假设项目中存在一个临时的脏数据清理脚本 `my_temp_dangerous_delete_mysql_script.py`：

    ```python
    # ❌ 危险写法：写在模块顶层，不在函数内，也无 main 保护
    import db_client
    db_client.execute("DROP TABLE users") 
    ```

后果：
    如果你使用了无限制的 `auto_discovery()`，即使项目上线2年后，一旦扫描并 import 到这个脚本，
    数据库表会在瞬间被删除。这绝对是生产事故级别的灾难。

✅ 正确用法（精确传参）：
    BoosterDiscovery(
        project_root_path='/path/to/your_project', 
        booster_dirs=['your_booster_dir'],
        max_depth=1,
        py_file_re_str='tasks'  # 强烈建议：只扫描包含 'tasks' 的文件，避开临时脚本
    ).auto_discovery()


2. 为什么推荐“显式 Import”而非“自动扫描”？BoosterDiscovery不是funboost的必需品！
-------------------------------------------------------
其实不建议过度依赖 `auto_discovery()`，更推荐的最佳实践是：
👉 手动明确 import 包含 @boost 的模块。需要用到哪些消费函数，就导入哪些模块。

Funboost vs Celery 的架构差异：
    * Funboost：
      没有中央 `app` 实例，不需要像 Celery 那样有一个单独的 `celery_app.py` 模块。
      架构上天然不存在“互相依赖导入”的死结。因此，要用什么消费函数，直接导入即可，简单直观。

    * Celery：
      必须手写 `includes` 配置或调用 `autodiscover_tasks()`。
      根本原因是：Celery 的 `xx_tasks.py` 需要导入 `celery_app.py` 中的 `app` 对象；
      而 `celery worker` 启动 `app` 时又需要导入 `xx_tasks.py` 来注册任务。
      这种设计导致双方陷入“循环导入”的死结，迫使 Celery 发明了一套复杂的导入机制，
      也让新手在规划目录结构时小心翼翼、非常纠结。
""" 

import re
import sys
import typing
from os import PathLike
from pathlib import Path
import importlib.util
# import nb_log
from funboost.core.loggers import FunboostFileLoggerMixin
from funboost.utils.decorators import flyweight
from funboost.core.lazy_impoter import funboost_lazy_impoter

@flyweight
class BoosterDiscovery(FunboostFileLoggerMixin):
    def __init__(self, project_root_path: typing.Union[PathLike, str],
                 booster_dirs: typing.List[typing.Union[PathLike, str]],
                 max_depth=1, py_file_re_str: str = None):
        """
        :param project_root_path 项目根目录
        :param booster_dirs: @boost装饰器函数所在的模块的文件夹,不用包含项目根目录长路径
        :param max_depth: 查找多少深层级子目录
        :param py_file_re_str: 文件名匹配过滤. 例如你所有的消费函数都在xxx_task.py yyy_task.py这样的,  你可以传参 task.py , 避免自动import了不需要导入的模块
        
        BoosterDiscovery(....).auto_discovery() 需要谨慎使用，谨慎传参，原因见上面模块注释。
        
        """
        self.project_root_path = project_root_path
        self.booster__full_path_dirs = [Path(project_root_path) / Path(boost_dir) for boost_dir in booster_dirs]
        self.max_depth = max_depth
        self.py_file_re_str = py_file_re_str

        self.py_files = []
        self._has_discovery_import = False

    def get_py_files_recursively(self, current_folder_path: Path, current_depth=0, ):
        """先找到所有py文件"""
        if current_depth > self.max_depth:
            return
        for item in current_folder_path.iterdir():
            if item.is_dir():
                self.get_py_files_recursively(item, current_depth + 1)
            elif item.suffix == '.py':
                if self.py_file_re_str:
                    if re.search(self.py_file_re_str, str(item), ):
                        self.py_files.append(str(item))
                else:
                    self.py_files.append(str(item))
        self.py_files = list(set(self.py_files))

    def auto_discovery(self, ):
        """把所有py文件自动执行import,主要是把 所有的@boost函数装饰器注册到 pid_queue_name__booster_map 中
        这个auto_discovery方法最好放到main里面,如果要扫描自身文件夹,没写正则排除文件本身,会无限懵逼死循环导入,无无限懵逼死循环导入
        """
        if self._has_discovery_import is False:
            self._has_discovery_import = True
        else:
            pass
            return  # 这一个判断是避免用户执行BoosterDiscovery.auto_discovery没有放到 if __name__ == '__main__'中,导致无限懵逼死循环.
        self.logger.info(self.booster__full_path_dirs)
        for dir in self.booster__full_path_dirs:
            if not Path(dir).exists():
                raise Exception(f'没有这个文件夹 ->  {dir}')

            self.get_py_files_recursively(Path(dir))
            for file_path in self.py_files:
                self.logger.debug(f'导入模块 {file_path}')
                if Path(file_path) == Path(sys._getframe(1).f_code.co_filename):
                    self.logger.warning(f'排除导入调用auto_discovery的模块自身 {file_path}')  # 否则下面的import这个文件,会造成无限懵逼死循环
                    continue

                # module_name = Path(file_path).as_posix().replace('/', '.') + '.' + Path(file_path).stem
                module_name = Path(file_path).relative_to(Path(self.project_root_path)).with_suffix('').as_posix().replace('/', '.').replace('\\', '.')
                # print(module_name, file_path)
                spec = importlib.util.spec_from_file_location(module_name, file_path)
                module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(module)
        funboost_lazy_impoter.BoostersManager.show_all_boosters()


if __name__ == '__main__':
    # 指定文件夹路径
    BoosterDiscovery(project_root_path='/codes/funboost',
                     booster_dirs=['test_frame/test_funboost_cli/test_find_boosters'],
                     max_depth=2, py_file_re_str='task').auto_discovery()

`````

--- **end of file: funboost/core/cli/discovery_boosters.py** (project: funboost) --- 

---


--- **start of file: funboost/core/cli/funboost_cli_user_templ.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/cli/funboost_cli_user_templ.py`

#### 📝 Module Docstring

`````
funboost现在 新增 命令行启动消费 发布  和清空消息
`````

#### 📦 Imports

- `import sys`
- `from pathlib import Path`
- `import fire`
- `from funboost.core.cli.funboost_fire import BoosterFire`
- `from funboost.core.cli.funboost_fire import env_dict`
- `from funboost.core.cli.discovery_boosters import BoosterDiscovery`


---

`````python
"""
funboost现在 新增 命令行启动消费 发布  和清空消息


"""
import sys
from pathlib import Path
import fire

project_root_path = Path(__file__).absolute().parent
print(f'project_root_path is : {project_root_path}  ,请确认是否正确')
sys.path.insert(1, str(project_root_path))  # 这个是为了方便命令行不用用户手动先 export PYTHONPATTH=项目根目录

# $$$$$$$$$$$$
# 以上的sys.path代码需要放在最上面,先设置好pythonpath再导入funboost相关的模块
# $$$$$$$$$$$$


from funboost.core.cli.funboost_fire import BoosterFire, env_dict
from funboost.core.cli.discovery_boosters import BoosterDiscovery

# 需要启动的函数,那么该模块或函数建议建议要被import到这来, 否则需要要在 --import_modules_str 或 booster_dirs 中指定用户项目中有哪些模块包括了booster
'''
有4种方式,自动找到有@boost装饰器,注册booster

1. 用户亲自把要启动的消费函数所在模块或函数 手动 import 一下到此模块来
2. 用户在使用命令行时候 --import_modules_str 指定导入哪些模块路径,就能启动那些队列名来消费和发布了.
3. 用户使用BoosterDiscovery.auto_discovery_boosters  自动 import 指定文件夹下的 .py 文件来实现.
4  用户在使用命令行时候传参 project_root_path booster_dirs ,自动扫描模块,自动import
'''
env_dict['project_root_path'] = project_root_path

if __name__ == '__main__':
    # booster_dirs 用户可以自己增加扫描的文件夹,这样可以命令行少传了 --booster_dirs_str
    # BoosterDiscovery 可以多次调用
    BoosterDiscovery(project_root_path, booster_dirs=[], max_depth=1, py_file_re_str=None).auto_discovery()  # 这个最好放到main里面,如果要扫描自身文件夹,没写正则排除文件本身,会无限懵逼死循环导入
    fire.Fire(BoosterFire, )

'''

python /codes/funboost/funboost_cli_user.py   --booster_dirs_str=test_frame/test_funboost_cli/test_find_boosters --max_depth=2  push test_find_queue1 --x=1 --y=2

python /codes/funboost/funboost_cli_user.py   --booster_dirs_str=test_frame/test_funboost_cli/test_find_boosters --max_depth=2  consume test_find_queue1 

'''

`````

--- **end of file: funboost/core/cli/funboost_cli_user_templ.py** (project: funboost) --- 

---


--- **start of file: funboost/core/cli/funboost_fire.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/cli/funboost_fire.py`

#### 📦 Imports

- `import copy`
- `import importlib`
- `import sys`
- `import typing`
- `from os import PathLike`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.cli.discovery_boosters import BoosterDiscovery`
- `from funboost.utils.ctrl_c_end import ctrl_c_recv`
- `from funboost.funboost_web_manager.app import start_funboost_web_manager`

#### 🏛️ Classes (1)

##### 📌 `class BoosterFire(object)`
*Line: 15*

**🔧 Constructor (`__init__`):**
- `def __init__(self, import_modules_str: str = None, booster_dirs_str: str = None, max_depth = 1, py_file_re_str: str = None, project_root_path = None)`
  - **Docstring:**
  `````
  :param project_root_path : 用户项目根目录
  :param import_modules_str:
  :param booster_dirs_str: 扫描@boost函数所在的目录，如果多个目录用,隔开
  :param max_depth: 扫描目录代码层级
  :param py_file_re_str: python文件的正则， 例如  tasks.py那么就不自动import其他名字的python模块
  `````
  - **Parameters:**
    - `self`
    - `import_modules_str: str = None`
    - `booster_dirs_str: str = None`
    - `max_depth = 1`
    - `py_file_re_str: str = None`
    - `project_root_path = None`

**Public Methods (11):**
- `def show_all_queues(self)`
  - *显示扫描到的所有queue name*
- `def clear(self, *queue_names: str)`
  - *清空多个queue ; 例子: clear test_cli1_queue1  test_cli1_queue2   # 清空2个消息队列消息队列*
- `def push(self, queue_name, *args, **kwargs)`
  - **Docstring:**
  `````
  push发布消息到消息队列 ;
  例子: 假设函数是 def  add(x,y)  队列名是 add_queue , 发布 1 + 2求和;
  push add_queue 1 2;
  或者 push add_queue --x=1 --y=2;
  或者 push add_queue -x 1 -y 2;
  `````
- `def publish(self, queue_name, msg)`
  - **Docstring:**
  `````
  publish发布消息到消息队列;
  假设函数是 def  add(x,y)  队列名是 add_queue , 发布 1 + 2求和;
  publish add_queue "{'x':1,'y':2}"
  `````
- `def consume_queues(self, *queue_names: str)`
  - **Docstring:**
  `````
  启动多个消息队列名的消费;
  例子: consume queue1 queue2
  `````
- `def consume_all_queues(self)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需指定队列名;
  例子: consume_all_queues
  `````
- `def multi_process_consume_queues(self, **queue_name__process_num)`
  - **Docstring:**
  `````
  使用多进程启动消费,每个队列开启多个单独的进程消费;
  例子:  mp_consume --queue1=2 --queue2=3    # queue1启动两个单独进程消费  queue2 启动3个单独进程消费
  `````
- `def multi_process_consume_all_queues(self, process_num = 1)`
  - **Docstring:**
  `````
  启动所有消息队列名的消费,无需指定队列名,每个队列启动n个单独的消费进程;
  例子: multi_process_consume_all_queues 2
  `````
- `def pause(self, *queue_names: str)`
  - **Docstring:**
  `````
  暂停多个消息队列名的消费;
  例子: pause queue1 queue2
  `````
- `def continue_consume(self, *queue_names: str)`
  - **Docstring:**
  `````
  继续多个消息队列名的消费;
  例子: continue_consume queue1 queue2
  `````
- `def start_funboost_web_manager(self)`
  - **Docstring:**
  `````
  启动funboost web管理器;
  例子: start_funboost_web_manager
  `````

**Class Variables (5):**
- `consume = consume_queues`
- `consume_all = consume_all_queues`
- `mp_consume = multi_process_consume_queues`
- `mp_consume_all = multi_process_consume_all_queues`
- `start_web = start_funboost_web_manager`


---

`````python
import copy
import importlib
import sys
import typing
from os import PathLike

from funboost.core.booster import BoostersManager
from funboost.core.cli.discovery_boosters import BoosterDiscovery
from funboost.utils.ctrl_c_end import ctrl_c_recv

env_dict = {'project_root_path': None}


# noinspection PyMethodMayBeStatic
class BoosterFire(object):
    def __init__(self, import_modules_str: str = None,
                 booster_dirs_str: str = None, max_depth=1, py_file_re_str: str = None, project_root_path=None):
        """
        :param project_root_path : 用户项目根目录
        :param import_modules_str:
        :param booster_dirs_str: 扫描@boost函数所在的目录，如果多个目录用,隔开
        :param max_depth: 扫描目录代码层级
        :param py_file_re_str: python文件的正则， 例如  tasks.py那么就不自动import其他名字的python模块
        """
        project_root_path = env_dict['project_root_path'] or project_root_path
        print(f'project_root_path is :{project_root_path} ,请确认')
        if project_root_path is None:
            raise Exception('project_root_path is none')
        loc = copy.copy(locals())
        for k, v in loc.items():
            print(f'{k} : {v}')
        sys.path.insert(1, str(project_root_path))
        self.import_modules_str = import_modules_str
        if import_modules_str:
            for m in self.import_modules_str.split(','):
                importlib.import_module(m)  # 发现@boost函数
        if booster_dirs_str and project_root_path:
            boost_dirs = booster_dirs_str.split(',')
            BoosterDiscovery(project_root_path=str(project_root_path), booster_dirs=boost_dirs,
                             max_depth=max_depth, py_file_re_str=py_file_re_str).auto_discovery()  # 发现@boost函数

    def show_all_queues(self):
        """显示扫描到的所有queue name"""
        print(f'get_all_queues: {BoostersManager.get_all_queues()}')
        return self

    def clear(self, *queue_names: str):
        """
        清空多个queue ; 例子: clear test_cli1_queue1  test_cli1_queue2   # 清空2个消息队列消息队列
        """

        for queue_name in queue_names:
            BoostersManager.get_booster(queue_name).clear()
        return self

    def push(self, queue_name, *args, **kwargs):
        """push发布消息到消息队列 ;
        例子: 假设函数是 def  add(x,y)  队列名是 add_queue , 发布 1 + 2求和;
        push add_queue 1 2;
        或者 push add_queue --x=1 --y=2;
        或者 push add_queue -x 1 -y 2;
        """
        BoostersManager.push(queue_name,*args, **kwargs)
        return self

    def __str__(self):
        # print('over')  # 这行重要,否则命令行链式调用无法自动结束
        return ''

    def publish(self, queue_name, msg):
        """publish发布消息到消息队列;
           假设函数是 def  add(x,y)  队列名是 add_queue , 发布 1 + 2求和;
           publish add_queue "{'x':1,'y':2}"
        """

        BoostersManager.publish(queue_name,msg)
        return self

    def consume_queues(self, *queue_names: str):
        """
        启动多个消息队列名的消费;
        例子: consume queue1 queue2
        """
        BoostersManager.consume_queues(*queue_names)

    consume = consume_queues

    def consume_all_queues(self, ):
        """
        启动所有消息队列名的消费,无需指定队列名;
        例子: consume_all_queues
        """
        BoostersManager.consume_all_queues()

    consume_all = consume_all_queues

    def multi_process_consume_queues(self, **queue_name__process_num):
        """
        使用多进程启动消费,每个队列开启多个单独的进程消费;
        例子:  mp_consume --queue1=2 --queue2=3    # queue1启动两个单独进程消费  queue2 启动3个单独进程消费
        """
        BoostersManager.multi_process_consume_queues(**queue_name__process_num)

    mp_consume = multi_process_consume_queues

    def multi_process_consume_all_queues(self, process_num=1):
        """
        启动所有消息队列名的消费,无需指定队列名,每个队列启动n个单独的消费进程;
        例子: multi_process_consume_all_queues 2
        """
        BoostersManager.multi_process_consume_all_queues(process_num)

    mp_consume_all = multi_process_consume_all_queues

    def pause(self, *queue_names: str):
        """
        暂停多个消息队列名的消费;
        例子: pause queue1 queue2
        """
        for queue_name in queue_names:
            BoostersManager.get_booster(queue_name).pause()

    def continue_consume(self, *queue_names: str):
        """
        继续多个消息队列名的消费;
        例子: continue_consume queue1 queue2
        """
        for queue_name in queue_names:
            BoostersManager.get_booster(queue_name).continue_consume()
    
    def start_funboost_web_manager(self):
        """
        启动funboost web管理器;
        例子: start_funboost_web_manager
        """
        from funboost.funboost_web_manager.app import start_funboost_web_manager
        start_funboost_web_manager()

    start_web = start_funboost_web_manager

`````

--- **end of file: funboost/core/cli/funboost_fire.py** (project: funboost) --- 

---


--- **start of file: funboost/core/cli/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/core/cli/__init__.py`


---

`````python

`````

--- **end of file: funboost/core/cli/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/faas/django_adapter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/faas/django_adapter.py`

#### 📝 Module Docstring

`````
django 开箱即用， 用户使用




使用说明：
Django-Ninja 开箱即用 Router
要求: 
1. pip install django-ninja
2. Django >= 3.1 (支持 async)

使用方法:
在你的 Django 项目的 api.py (或 urls.py) 中:

from ninja import NinjaAPI

api = NinjaAPI()
api.add_router("/funboost", django_router)

urlpatterns = [
    path('admin/', admin.site.urls),
    # 挂载 NinjaAPI
    path("api/", api.urls),
]
`````

#### 📦 Imports

- `import traceback`
- `import typing`
- `from ninja import Router`
- `from ninja import Schema`
- `from pydantic import Field`
- `from funboost import AioAsyncResult`
- `from funboost import TaskOptions`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🏛️ Classes (8)

##### 📌 `class MsgItemSchema(Schema)`
*Line: 49*

**Class Variables (4):**
- `queue_name: str = Field(..., description='目标队列名称')`
- `msg_body: dict = Field(..., description='任务参数字典')`
- `need_result: bool = Field(False, description='是否需要等待并返回结果(RPC模式)')`
- `timeout: int = Field(60, description='RPC模式下的等待超时时间(秒)')`

##### 📌 `class PublishData(Schema)`
*Line: 57*

**Class Variables (2):**
- `task_id: typing.Optional[str] = None`
- `status_and_result: typing.Optional[dict] = None`

##### 📌 `class CountData(Schema)`
*Line: 62*

**Class Variables (2):**
- `queue_name: str`
- `count: int = -1`

##### 📌 `class AllQueuesData(Schema)`
*Line: 67*

**Class Variables (2):**
- `queues: typing.List[str] = []`
- `count: int = 0`

##### 📌 `class BaseResponse(Schema)`
*Line: 73*

**Class Variables (2):**
- `succ: bool`
- `msg: str`

##### 📌 `class PublishResponse(BaseResponse)`
*Line: 78*

**Class Variables (1):**
- `data: typing.Optional[PublishData] = None`

##### 📌 `class CountResponse(BaseResponse)`
*Line: 82*

**Class Variables (1):**
- `data: typing.Optional[CountData] = None`

##### 📌 `class AllQueuesResponse(BaseResponse)`
*Line: 86*

**Class Variables (1):**
- `data: typing.Optional[AllQueuesData] = None`

#### 🔧 Public Functions (4)

- `async def publish_msg(request, payload: MsgItemSchema)` `django_router.post('/publish', response=PublishResponse, summary='发布消息')`
  - *Line: 93*
  - **Docstring:**
  `````
  发布消息到 Funboost 队列。
  如果 need_result=True，将挂起等待任务执行完成并返回结果。
  `````

- `async def get_result(request, task_id: str, timeout: int = 5)` `django_router.get('/get_result', response=PublishResponse, summary='获取任务结果')`
  - *Line: 147*
  - *根据 Task ID 主动轮询获取任务执行结果*

- `def get_msg_count(request, queue_name: str)` `django_router.get('/get_msg_count', response=CountResponse, summary='获取队列堆积数量')`
  - *Line: 185*
  - *获取指定队列当前堆积的消息数量 (同步接口)*

- `def get_all_queues(request)` `django_router.get('/get_all_queues', response=AllQueuesResponse, summary='获取所有队列名称')`
  - *Line: 214*
  - **Docstring:**
  `````
  获取所有已注册的队列名称
  
  返回所有通过 @boost 装饰器注册的队列名称列表
  `````


---

`````python
"""
django 开箱即用， 用户使用




使用说明：
Django-Ninja 开箱即用 Router
要求: 
1. pip install django-ninja
2. Django >= 3.1 (支持 async)

使用方法:
在你的 Django 项目的 api.py (或 urls.py) 中:

from ninja import NinjaAPI

api = NinjaAPI()
api.add_router("/funboost", django_router)

urlpatterns = [
    path('admin/', admin.site.urls),
    # 挂载 NinjaAPI
    path("api/", api.urls),
]



"""

# -*- coding: utf-8 -*-
import traceback
import typing
from ninja import Router, Schema
from pydantic import Field
from funboost import AioAsyncResult, TaskOptions
from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter, QueuesConusmerParamsGetter
from funboost.core.loggers import get_funboost_file_logger


logger = get_funboost_file_logger(__name__)


# 创建 Router 实例
django_router = Router(tags=["Funboost 分布式任务"])

# --- Schemas (数据模型) ---

class MsgItemSchema(Schema):
    queue_name: str = Field(..., description="目标队列名称")
    msg_body: dict = Field(..., description="任务参数字典")
    need_result: bool = Field(False, description="是否需要等待并返回结果(RPC模式)")
    timeout: int = Field(60, description="RPC模式下的等待超时时间(秒)")


# 统一响应格式的数据结构
class PublishData(Schema):
    task_id: typing.Optional[str] = None
    status_and_result: typing.Optional[dict] = None


class CountData(Schema):
    queue_name: str
    count: int = -1


class AllQueuesData(Schema):
    queues: typing.List[str] = []
    count: int = 0


# 统一响应模型
class BaseResponse(Schema):
    succ: bool
    msg: str


class PublishResponse(BaseResponse):
    data: typing.Optional[PublishData] = None


class CountResponse(BaseResponse):
    data: typing.Optional[CountData] = None


class AllQueuesResponse(BaseResponse):
    data: typing.Optional[AllQueuesData] = None


# --- Endpoints ---

@django_router.post("/publish", response=PublishResponse, summary="发布消息")
async def publish_msg(request, payload: MsgItemSchema):
    """
    发布消息到 Funboost 队列。
    如果 need_result=True，将挂起等待任务执行完成并返回结果。
    """
    status_and_result = None
    task_id = None
    
    try:
        # 核心：通过redis中的配置动态获取或创建 Publisher 对象
        publisher = SingleQueueConusmerParamsGetter(payload.queue_name).gen_publisher_for_faas()
        booster_params_by_redis = SingleQueueConusmerParamsGetter(payload.queue_name).get_one_queue_params_use_cache()

        if payload.need_result:
            # 检查是否开启了 RPC 模式
            if booster_params_by_redis['is_using_rpc_mode'] is False:
                raise ValueError(f'need_result为True, 但队列 {payload.queue_name} 未开启 is_using_rpc_mode')
            
            # 异步发布消息 (带 RPC 配置)
            async_result = await publisher.aio_publish(
                payload.msg_body,
                task_options=TaskOptions(is_using_rpc_mode=True)
            )
            task_id = async_result.task_id
            
            # 异步等待结果 (AioAsyncResult 是非阻塞的)
            status_and_result = await AioAsyncResult(task_id, timeout=payload.timeout).status_and_result
        else:
            # 普通异步发布 (Fire and forget)
            async_result = await publisher.aio_publish(payload.msg_body)
            task_id = async_result.task_id

        return {
            "succ": True,
            "msg": f"{payload.queue_name} 队列消息发布成功",
            "data": {
                "task_id": task_id,
                "status_and_result": status_and_result
            }
        }

    except Exception as e:
        # 捕获所有异常，返回 200 状态码但在 body 中标记失败（也可以选择返回 500）
        return {
            "succ": False,
            "msg": f"发布失败: {str(e)} - {traceback.format_exc()}",
            "data": {
                "task_id": task_id,
                "status_and_result": None
            }
        }


@django_router.get("/get_result", response=PublishResponse, summary="获取任务结果")
async def get_result(request, task_id: str, timeout: int = 5):
    """
    根据 Task ID 主动轮询获取任务执行结果
    """
    try:
        status_and_result = await AioAsyncResult(task_id, timeout=timeout).status_and_result

        if status_and_result:
            return {
                "succ": True,
                "msg": "获取成功",
                "data": {
                    "task_id": task_id,
                    "status_and_result": status_and_result
                }
            }
        else:
            return {
                "succ": False,
                "msg": "未获取到结果(可能运行中、已过期或超时)",
                "data": {
                    "task_id": task_id,
                    "status_and_result": None
                }
            }
            
    except Exception as e:
        return {
            "succ": False,
            "msg": f"获取出错: {str(e)}",
            "data": {
                "task_id": task_id,
                "status_and_result": None
            }
        }


@django_router.get("/get_msg_count", response=CountResponse, summary="获取队列堆积数量")
def get_msg_count(request, queue_name: str):
    """
    获取指定队列当前堆积的消息数量 (同步接口)
    """
    try:

        publisher = SingleQueueConusmerParamsGetter(queue_name).gen_publisher_for_faas()
        # 获取数量通常很快，不需要 async
        count = publisher.get_message_count()
        return {
            "succ": True,
            "msg": "获取成功",
            "data": {
                "queue_name": queue_name,
                "count": count
            }
        }
    except Exception as e:
        return {
            "succ": False,
            "msg": f"获取失败: {str(e)}",
            "data": {
                "queue_name": queue_name,
                "count": -1
            }
        }


@django_router.get("/get_all_queues", response=AllQueuesResponse, summary="获取所有队列名称")
def get_all_queues(request):
    """
    获取所有已注册的队列名称
    
    返回所有通过 @boost 装饰器注册的队列名称列表
    """
    try:
        # 获取所有队列名称
        all_queues = QueuesConusmerParamsGetter().get_all_queue_names()
        
        return {
            "succ": True,
            "msg": "获取成功",
            "data": {
                "queues": all_queues,
                "count": len(all_queues)
            }
        }
    except Exception as e:
        return {
            "succ": False,
            "msg": f"获取所有队列失败: {str(e)}",
            "data": {
                "queues": [],
                "count": 0
            }
        }
`````

--- **end of file: funboost/faas/django_adapter.py** (project: funboost) --- 

---


--- **start of file: funboost/faas/faas_util.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/faas/faas_util.py`

#### 📦 Imports

- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`

#### 🔧 Public Functions (1)

- `def gen_aps_job_adder(queue_name, job_store_kind)`
  - *Line: 7*


---

`````python

from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter

IS_AUTO_START_APSCHEDULER = True # 必须启动，不启动获取和添加不了定时任务.这个不要改成False。
IS_AUTO_PAUSED_APSCHEDULER = True # 你可以暂停定时器，网页端用于专门执行定时任务的增删改查，但不触发发送定时任务到消息队列。 在消费脚本部署booster启动消费和启动定时器并且不暂停。

def gen_aps_job_adder(queue_name, job_store_kind):
    return SingleQueueConusmerParamsGetter(queue_name).generate_aps_job_adder(
        job_store_kind=job_store_kind, is_auto_start=IS_AUTO_START_APSCHEDULER, is_auto_paused=IS_AUTO_PAUSED_APSCHEDULER)
`````

--- **end of file: funboost/faas/faas_util.py** (project: funboost) --- 

---


--- **start of file: funboost/faas/fastapi_adapter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/faas/fastapi_adapter.py`

#### 📝 Module Docstring

`````
fastapi 开箱即用，只需要用户的 app.include_router(fastapi_router) ,即可自动给用户的fastapi添加常用路由，实现faas




使用说明:
    在用户自己的 FastAPI 项目中
       app.include_router(fastapi_router)
    


如果fastapi_router集成到你自己的fastapi app时候，你觉得需要加上权限鉴权，可以这样： 
app.include_router(
    fastapi_router,
    dependencies=[
        Depends(your_authenticate),
    ]
)
`````

#### 📦 Imports

- `import traceback`
- `import typing`
- `import asyncio`
- `from funboost import AioAsyncResult`
- `from funboost import AsyncResult`
- `from funboost import TaskOptions`
- `from funboost import BoosterParams`
- `from funboost import Booster`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import CareProjectNameEnv`
- `from funboost.core.exceptions import FunboostException`
- `from fastapi import FastAPI`
- `from fastapi import APIRouter`
- `from fastapi import Query`
- `from fastapi import Request`
- `from fastapi.responses import JSONResponse`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.constant import RedisKeys`
- `from funboost.faas.faas_util import gen_aps_job_adder`
- `from pydantic import BaseModel`
- `from pydantic import ConfigDict`
- `import functools`
- `import uvicorn`
- `from pydantic import BaseModel`

#### 🏛️ Classes (26)

##### 📌 `class BaseAllowExtraModel(BaseModel)`
*Line: 216*

##### 📌 `class BaseResponse(BaseModel, typing.Generic[T])`
*Line: 232*

**Docstring:**
`````
统一的泛型响应模型

字段说明:
    succ: 请求是否成功，True表示成功，False表示失败
    msg: 消息描述
    data: 返回的数据，使用泛型T
    code: 业务状态码，200表示成功，其他表示各种错误
    error: 错误类型名称（可选），如 "QueueNameNotExists", "ValueError"
    traceback: 异常堆栈信息（可选），仅在出错时返回
    trace_id: 追踪ID（可选），用于分布式追踪
`````

**Class Variables (8):**
- `succ: bool`
- `msg: str`
- `data: typing.Optional[T] = None`
- `error_data: typing.Optional[typing.Dict] = None`
- `code: typing.Optional[int] = 200`
- `error: typing.Optional[str] = None`
- `traceback: typing.Optional[str] = None`
- `trace_id: typing.Optional[str] = None`

##### 📌 `class MsgItem(BaseModel)`
*Line: 255*

**Class Variables (5):**
- `queue_name: str`
- `msg_body: dict`
- `need_result: bool = False`
- `timeout: int = 60`
- `task_id: str = None`

##### 📌 `class FunctionResultStatusModel(BaseModel)`
*Line: 266*

**Docstring:**
`````
函数执行结果状态模型
对应 FunctionResultStatus.get_status_dict() 的返回值结构
`````

**Class Variables (31):**
- `host_process: str`
- `queue_name: str`
- `function: str`
- `msg_dict: dict`
- `task_id: str`
- `process_id: int`
- `thread_id: int`
- `total_thread: int`
- `publish_time: float`
- `publish_time_format: str`
- `time_start: float`
- `time_cost: typing.Optional[float]`
- `time_end: float`
- `insert_time_str: str`
- `insert_minutes: str`
- `params: dict`
- `params_str: str`
- `result: typing.Any`
- `run_times: int`
- `success: bool`
- `run_status: str`
- `exception: typing.Optional[str]`
- `exception_type: typing.Optional[str]`
- `exception_msg: typing.Optional[str]`
- `rpc_chain_error_msg_dict: typing.Optional[dict]`
- `rpc_result_expire_seconds: typing.Optional[int]`
- `host_name: str`
- `script_name: str`
- `script_name_long: str`
- `user_context: typing.Optional[dict] = {}`
- `_id: str`

##### 📌 `class RpcRespData(BaseAllowExtraModel)`
*Line: 328*

**Class Variables (2):**
- `task_id: typing.Optional[str] = None`
- `status_and_result: typing.Optional[FunctionResultStatusModel] = None`

##### 📌 `class CountData(BaseModel)`
*Line: 333*

**Class Variables (2):**
- `queue_name: str`
- `count: int = -1`

##### 📌 `class AllQueuesData(BaseModel)`
*Line: 338*

**Class Variables (2):**
- `queues: typing.List[str] = []`
- `count: int = 0`

##### 📌 `class DeprecateQueueRequest(BaseModel)`
*Line: 343*

**Docstring:**
`````
废弃队列请求模型
`````

**Class Variables (1):**
- `queue_name: str`

##### 📌 `class DeprecateQueueData(BaseModel)`
*Line: 348*

**Docstring:**
`````
废弃队列响应数据模型
`````

**Class Variables (2):**
- `queue_name: str`
- `removed: bool`

##### 📌 `class QueueNameRequest(BaseModel)`
*Line: 454*

**Docstring:**
`````
队列名称请求模型
`````

**Class Variables (1):**
- `queue_name: str`

##### 📌 `class QueueControlData(BaseModel)`
*Line: 459*

**Docstring:**
`````
队列控制操作的响应数据
`````

**Class Variables (2):**
- `queue_name: str`
- `success: bool`

##### 📌 `class ClearQueueData(BaseModel)`
*Line: 573*

**Docstring:**
`````
清空队列响应数据
`````

**Class Variables (2):**
- `queue_name: str`
- `success: bool`

##### 📌 `class QueueParams(BaseAllowExtraModel)`
*Line: 660*

**Docstring:**
`````
队列的完整配置参数，
和BoosterParams不同的是，这里是完全版可json序列化的
这里的数据是从redis获取的，redis只能存json序列化的数据。
`````

**Class Variables (50):**
- `queue_name: str`
- `broker_kind: str`
- `project_name: typing.Optional[str] = None`
- `concurrent_mode: str`
- `concurrent_num: int`
- `specify_concurrent_pool: typing.Optional[typing.Any]`
- `specify_async_loop: typing.Optional[typing.Any]`
- `is_auto_start_specify_async_loop_in_child_thread: bool`
- `qps: typing.Optional[float]`
- `is_using_distributed_frequency_control: bool`
- `is_send_consumer_heartbeat_to_redis: bool`
- `max_retry_times: int`
- `retry_interval: typing.Union[float, int]`
- `is_push_to_dlx_queue_when_retry_max_times: bool`
- `consuming_function_decorator: typing.Optional[typing.Any]`
- `function_timeout: typing.Optional[float]`
- `is_support_remote_kill_task: bool`
- `log_level: int`
- `logger_prefix: str`
- `create_logger_file: bool`
- `logger_name: str`
- `log_filename: typing.Optional[str]`
- `is_show_message_get_from_broker: bool`
- `is_print_detail_exception: bool`
- `publish_msg_log_use_full_msg: bool`
- `msg_expire_seconds: typing.Optional[float]`
- `do_task_filtering: bool`
- `task_filtering_expire_seconds: int`
- `function_result_status_persistance_conf: typing.Dict[str, typing.Any]`
- `user_custom_record_process_info_func: typing.Optional[typing.Any]`
- `is_using_rpc_mode: bool`
- `rpc_result_expire_seconds: int`
- `rpc_timeout: int`
- `delay_task_apscheduler_jobstores_kind: str`
- `is_do_not_run_by_specify_time_effect: bool`
- `do_not_run_by_specify_time: typing.Tuple[str, str]`
- `schedule_tasks_on_main_thread: bool`
- `is_auto_start_consuming_message: bool`
- `booster_group: typing.Optional[str]`
- `consuming_function: typing.Any`
- `consuming_function_raw: typing.Any`
- `consuming_function_name: str`
- `broker_exclusive_config: typing.Dict[str, typing.Any]`
- `should_check_publish_func_params: bool`
- `manual_func_input_params: typing.Optional[typing.Dict[str, typing.Any]] = None`
- `consumer_override_cls: typing.Optional[typing.Any]`
- `publisher_override_cls: typing.Optional[typing.Any]`
- `consuming_function_kind: typing.Optional[str]`
- `user_options: typing.Dict[str, typing.Any]`
- `auto_generate_info: typing.Dict[str, typing.Any]`

##### 📌 `class ActiveConsumerRunInfo(BaseAllowExtraModel)`
*Line: 764*

**Docstring:**
`````
单个活跃消费者的详细信息
这些数据是从redis中的心跳信息获取的
`````

**Class Variables (25):**
- `queue_name: str`
- `computer_name: str`
- `computer_ip: str`
- `process_id: int`
- `consumer_id: int`
- `consumer_uuid: str`
- `start_datetime_str: str`
- `start_timestamp: float`
- `hearbeat_datetime_str: str`
- `hearbeat_timestamp: float`
- `consuming_function: str`
- `code_filename: str`
- `unit_time_for_count: int`
- `last_x_s_execute_count: int`
- `last_x_s_execute_count_fail: int`
- `last_execute_task_time: float`
- `last_x_s_avarage_function_spend_time: typing.Optional[float]`
- `last_x_s_total_cost_time: typing.Optional[float]`
- `msg_num_in_broker: int`
- `current_time_for_execute_task_times_every_unit_time: float`
- `last_timestamp_when_has_task_in_queue: float`
- `total_consume_count_from_start: int`
- `total_consume_count_from_start_fail: int`
- `total_cost_time_from_start: float`
- `avarage_function_spend_time_from_start: typing.Optional[float]`

##### 📌 `class QueueParamsAndActiveConsumersData(BaseModel)`
*Line: 810*

**Docstring:**
`````
队列参数和活跃消费者数据
`````

**Class Variables (13):**
- `queue_params: QueueParams`
- `active_consumers: typing.List[ActiveConsumerRunInfo]`
- `pause_flag: int`
- `msg_num_in_broker: int`
- `history_run_count: typing.Optional[int]`
- `history_run_fail_count: typing.Optional[int]`
- `all_consumers_last_x_s_execute_count: int`
- `all_consumers_last_x_s_execute_count_fail: int`
- `all_consumers_last_x_s_avarage_function_spend_time: typing.Optional[float]`
- `all_consumers_avarage_function_spend_time_from_start: typing.Optional[float]`
- `all_consumers_total_consume_count_from_start: int`
- `all_consumers_total_consume_count_from_start_fail: int`
- `all_consumers_last_execute_task_time: typing.Optional[float]`

##### 📌 `class QueueConfigData(BaseModel)`
*Line: 827*

**Docstring:**
`````
队列配置数据
`````

**Class Variables (2):**
- `queues_config: typing.Dict[str, QueueParams] = {}`
- `count: int = 0`

##### 📌 `class AllQueuesRunInfoData(BaseModel)`
*Line: 937*

**Docstring:**
`````
所有队列的运行信息
`````

**Class Variables (2):**
- `queues: typing.Dict[str, QueueParamsAndActiveConsumersData]`
- `total_count: int`

##### 📌 `class TimingJobRequest(BaseModel)`
*Line: 989*

**Docstring:**
`````
添加定时任务请求
`````

**Class Variables (21):**
- `queue_name: str`
- `trigger: str`
- `job_id: typing.Optional[str] = None`
- `job_store_kind: str = 'redis'`
- `replace_existing: bool = False`
- `args: typing.Optional[typing.List] = None`
- `kwargs: typing.Optional[typing.Dict] = None`
- `run_date: typing.Optional[str] = None`
- `weeks: typing.Optional[int] = None`
- `days: typing.Optional[int] = None`
- `hours: typing.Optional[int] = None`
- `minutes: typing.Optional[int] = None`
- `seconds: typing.Optional[int] = None`
- `year: typing.Optional[str] = None`
- `month: typing.Optional[str] = None`
- `day: typing.Optional[str] = None`
- `week: typing.Optional[str] = None`
- `day_of_week: typing.Optional[str] = None`
- `hour: typing.Optional[str] = None`
- `minute: typing.Optional[str] = None`
- `second: typing.Optional[str] = None`

##### 📌 `class TimingJobData(BaseModel)`
*Line: 1022*

**Docstring:**
`````
定时任务数据
`````

**Class Variables (6):**
- `job_id: str`
- `queue_name: typing.Optional[str] = None`
- `trigger: typing.Optional[str] = None`
- `next_run_time: typing.Optional[str] = None`
- `status: typing.Optional[str] = None`
- `kwargs: typing.Optional[typing.Dict] = None`

##### 📌 `class TimingJobListData(BaseModel)`
*Line: 1032*

**Docstring:**
`````
定时任务列表数据
`````

**Class Variables (2):**
- `jobs_by_queue: typing.Dict[str, typing.List[TimingJobData]] = {}`
- `total_count: int = 0`

##### 📌 `class DeleteAllJobsData(BaseModel)`
*Line: 1305*

**Docstring:**
`````
删除所有任务的结果数据
`````

**Class Variables (2):**
- `deleted_count: int = 0`
- `failed_jobs: typing.List[str] = []`

##### 📌 `class SchedulerStatusData(BaseModel)`
*Line: 1493*

**Class Variables (3):**
- `queue_name: str`
- `status_code: int`
- `status_str: str`

##### 📌 `class SchedulerControlData(BaseModel)`
*Line: 1498*

**Class Variables (2):**
- `queue_name: str`
- `status_str: str`

##### 📌 `class CareProjectNameData(BaseModel)`
*Line: 1575*

**Docstring:**
`````
care_project_name 响应数据
`````

**Class Variables (1):**
- `care_project_name: typing.Optional[str] = None`

##### 📌 `class SetCareProjectNameRequest(BaseModel)`
*Line: 1580*

**Docstring:**
`````
设置 care_project_name 请求模型
`````

**Class Variables (1):**
- `care_project_name: str = ''`

##### 📌 `class AllProjectNamesData(BaseModel)`
*Line: 1585*

**Docstring:**
`````
所有项目名称响应数据
`````

**Class Variables (2):**
- `project_names: typing.List[str] = []`
- `count: int = 0`

#### 🔧 Public Functions (31)

- `async def funboost_exception_handler(request: Request, exc: FunboostException) -> JSONResponse`
  - *Line: 65*
  - **Docstring:**
  `````
  统一处理 FunboostException 类型的异常
  自动提取异常的 code、message、data 等信息返回给前端
  `````

- `async def general_exception_handler(request: Request, exc: Exception) -> JSONResponse`
  - *Line: 87*
  - **Docstring:**
  `````
  统一处理所有其他异常
  返回固定code 5555,并包含完整的异常堆栈信息
  `````

- `def register_funboost_exception_handlers(app: FastAPI)`
  - *Line: 108*
  - **Docstring:**
  `````
  注册 Funboost 的全局异常处理器到 FastAPI app
  
  使用示例:
      from funboost.faas.fastapi_adapter import fastapi_router, register_funboost_exception_handlers
      
      app = FastAPI()
      app.include_router(fastapi_router)
      register_funboost_exception_handlers(app)  # 注册全局异常处理
  `````

- `def handle_funboost_exceptions(func)`
  - *Line: 128*
  - **Docstring:**
  `````
  装饰器：统一处理 funboost router 接口的异常
  只在 funboost 的接口中使用，不会影响用户自己的 FastAPI app
  
  使用方法:
      @fastapi_router.get("/some_endpoint")
      @handle_funboost_exceptions
      async def some_endpoint():
          # 直接写业务逻辑，不需要 try-except
          return BaseResponse(...)
  
  异常处理规则:
      - FunboostException: 返回异常的 code、message、data、trace_id
      - 其他异常: 返回 code 5555，包含完整堆栈信息
  `````

- `async def publish_msg(msg_item: MsgItem)` `fastapi_router.post('/publish', response_model=BaseResponse[RpcRespData])`
  - *Line: 355*
  - **Docstring:**
  `````
  发布消息接口，支持RPC模式。
  支持queue_name是否存在的校验，支持校验消息内容是否正确。所以不用担心跨部门用户使用了错误的queue_name，或者消息内容不正确。
  
  用户可以先通过 /get_queues_config 接口获取所有队列的配置信息，就知道有哪些队列，以及每个队列支持的消费函数的消息内容需要包括哪些入参字段了。
  # 发布消息时候会立即校验入参是否正确，使用了redis中的 booster配置的 auto_generate_info.final_func_input_params_info 信息来校验入参名字和个数是否正确
  `````

- `async def get_result(task_id: str, timeout: int = 5)` `fastapi_router.get('/get_result', response_model=BaseResponse[RpcRespData])`
  - *Line: 411*
  - *根据 task_id 获取任务执行结果*

- `def pause_consume(request: QueueNameRequest)` `fastapi_router.post('/pause_consume', response_model=BaseResponse[QueueControlData])`
  - *Line: 466*
  - **Docstring:**
  `````
  暂停队列消费
  
  请求体:
      {
          "queue_name": "队列名称"
      }
  
  返回:
      暂停操作的结果
      
  说明:
      此接口会在 Redis 中设置暂停标志为 '1'，消费者会定期检查此标志并暂停消费。
      暂停不会立即生效，需要等待消费者检查标志的时间间隔。
  `````

- `def resume_consume(request: QueueNameRequest)` `fastapi_router.post('/resume_consume', response_model=BaseResponse[QueueControlData])`
  - *Line: 508*
  - **Docstring:**
  `````
  恢复队列消费
  
  请求体:
      {
          "queue_name": "队列名称"
      }
  
  返回:
      恢复操作的结果
      
  说明:
      此接口会在 Redis 中设置暂停标志为 '0'，消费者会定期检查此标志并恢复消费。
      恢复不会立即生效，需要等待消费者检查标志的时间间隔。
  `````

- `def get_msg_count(queue_name: str)` `fastapi_router.get('/get_msg_count', response_model=BaseResponse[CountData])` `handle_funboost_exceptions`
  - *Line: 552*
  - **Docstring:**
  `````
  根据 queue_name 获取消息数量
  
  注意：此接口使用了 @handle_funboost_exceptions 装饰器
  所以不需要写 try-except，异常会自动被捕获并返回统一格式
  `````

- `def clear_queue(request: QueueNameRequest)` `fastapi_router.post('/clear_queue', response_model=BaseResponse[ClearQueueData])`
  - *Line: 580*
  - **Docstring:**
  `````
  清空队列中的所有消息
  
  请求体:
      {
          "queue_name": "队列名称"
      }
  
  返回:
      清空操作的结果
      
  说明:
      此接口会清空指定队列中的所有待消费消息。
      ⚠️ 此操作不可逆，请谨慎使用！
      
  注意:
      broker_kind 会自动从已注册的 booster 中获取，无需手动指定。
  `````

- `def get_all_queues()` `fastapi_router.get('/get_all_queues', response_model=BaseResponse[AllQueuesData])`
  - *Line: 627*
  - **Docstring:**
  `````
  获取所有已注册的队列名称
  
  返回所有通过 @boost 装饰器注册的队列名称列表
  `````

- `def get_queues_config()` `fastapi_router.get('/get_queues_config', response_model=BaseResponse[QueueConfigData])`
  - *Line: 834*
  - **Docstring:**
  `````
  获取所有队列的配置信息
  
  返回所有已注册队列的详细配置参数，包括：
  - 队列名称
  - broker 类型
  - 并发数量
  - QPS 限制
  - 是否启用 RPC 模式
  - ！！！重要，消费函数的入参名字列表在 auto_generate_info.final_func_input_params_info 中 ，用于发布消息时校验入参是否正确，不正确的消息格式立刻从接口返回报错消息内容不正确。
    前端或跨部门可以先获取所有队列名字以及队列对应的配置，就知道rpc publish发布接口可以传哪些queue_name以及对应的消息应该包含哪些字段。
    auto_generate_info.final_func_input_params_info ，相当于是funboost能自动根据消费函数的def定义，对外提供消费函数的接口文档字段，就类似fastapi自动对接口函数入参生成了文档，避免需要重复手动一个个的编辑接口文档字段。
  - 等等其他 @boost 装饰器的所有参数
  
  主要用于前端可视化展示和管理
  `````

- `def get_one_queue_config(queue_name: str)` `fastapi_router.get('/get_one_queue_config', response_model=BaseResponse[QueueParams])` `handle_funboost_exceptions`
  - *Line: 876*
  - **Docstring:**
  `````
  获取单个队列的配置信息
  
  参数:
      queue_name: 队列名称（必填）
  
  返回:
      队列的配置信息，包括函数入参信息 (auto_generate_info.final_func_input_params_info)
  `````

- `def get_queue_run_info(queue_name: str)` `fastapi_router.get('/get_queue_run_info', response_model=BaseResponse[QueueParamsAndActiveConsumersData])`
  - *Line: 894*
  - **Docstring:**
  `````
  获取单个队列的运行信息
  
  参数:
      queue_name: 队列名称（必填）
  
  返回:
      队列的详细运行信息，包括：
      - queue_params: 队列配置参数
      - active_consumers: 活跃的消费者列表
      - pause_flag: 暂停标志（-1,0表示未暂停，1表示已暂停）
      - msg_num_in_broker: broker中的消息数量（实时）
      - history_run_count: 历史运行总次数
      - history_run_fail_count: 历史失败总次数
      - all_consumers_last_x_s_execute_count: 所有消费进程，最近X秒所有消费者的执行次数
      - all_consumers_last_x_s_execute_count_fail: 所有消费进程，最近X秒所有消费者的失败次数
      - all_consumers_last_x_s_avarage_function_spend_time: 所有消费进程，最近X秒的平均函数耗时
      - all_consumers_avarage_function_spend_time_from_start: 所有消费进程，从启动开始的平均函数耗时
      - all_consumers_total_consume_count_from_start: 所有消费进程，从启动开始的总消费次数
      - all_consumers_total_consume_count_from_start_fail: 所有消费进程，从启动开始的总失败次数
      - all_consumers_last_execute_task_time: 所有消费进程中，最后一次执行任务的时间戳
  `````

- `def get_all_queue_run_info()` `fastapi_router.get('/get_all_queue_run_info', response_model=BaseResponse[AllQueuesRunInfoData])`
  - *Line: 944*
  - **Docstring:**
  `````
  获取所有队列的运行信息
  
  返回:
      所有队列的详细运行信息，包括每个队列的：
      - queue_params: 队列配置参数
      - active_consumers: 活跃的消费者列表
      - pause_flag: 暂停标志
      - msg_num_in_broker: broker中的消息数量
      - history_run_count: 历史运行总次数
      - history_run_fail_count: 历史失败总次数
      - 以及各种统计信息
  `````

- `def add_timing_job(job_request: TimingJobRequest)` `fastapi_router.post('/add_timing_job', response_model=BaseResponse[TimingJobData])`
  - *Line: 1042*
  - **Docstring:**
  `````
  添加定时任务
  
  支持三种触发方式:
  1. date: 在指定日期时间执行一次
     - 需要提供: run_date
     - 示例: {"trigger": "date", "run_date": "2025-12-03 15:00:00"}
  
  2. interval: 按固定时间间隔执行
     - 需要提供: weeks, days, hours, minutes, seconds 中的至少一个
     - 示例: {"trigger": "interval", "seconds": 10}
  
  3. cron: 按cron表达式执行
     - 需要提供: year, month, day, week, day_of_week, hour, minute, second 中的至少一个
     - 示例: {"trigger": "cron", "hour": "*/2", "minute": "30"}
  `````

- `def get_timing_jobs(queue_name: typing.Optional[str] = None, job_store_kind: str = 'redis')` `fastapi_router.get('/get_timing_jobs', response_model=BaseResponse[TimingJobListData])`
  - *Line: 1133*
  - **Docstring:**
  `````
  获取定时任务列表
  
  参数:
      queue_name: 队列名称（可选，如果不提供则获取所有队列的任务）
      job_store_kind: 任务存储方式，'redis' 或 'memory'
  
  返回格式:
      jobs_by_queue: {queue_name: [jobs]}，按队列分组的任务
      total_count: 总任务数
  `````

- `def get_timing_job(job_id: str, queue_name: str, job_store_kind: str = 'redis')` `fastapi_router.get('/get_timing_job', response_model=BaseResponse[TimingJobData])`
  - *Line: 1219*
  - **Docstring:**
  `````
  获取单个定时任务的详细信息
  
  参数:
      job_id: 任务ID（必填）
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'
  
  返回:
      任务的详细信息，包括任务ID、队列名、触发器类型、下次运行时间等
  `````

- `def delete_timing_job(job_id: str, queue_name: str, job_store_kind: str = 'redis')` `fastapi_router.delete('/delete_timing_job', response_model=BaseResponse)`
  - *Line: 1273*
  - **Docstring:**
  `````
  删除定时任务
  
  参数:
      job_id: 任务ID
      queue_name: 队列名称
      job_store_kind: 任务存储方式，'redis' 或 'memory'
  `````

- `def delete_all_timing_jobs(queue_name: typing.Optional[str] = None, job_store_kind: str = 'redis')` `fastapi_router.delete('/delete_all_timing_jobs', response_model=BaseResponse[DeleteAllJobsData])`
  - *Line: 1312*
  - **Docstring:**
  `````
  删除所有定时任务
  
  参数:
      queue_name: 队列名称（可选，如果不提供则删除所有队列的所有任务）
      job_store_kind: 任务存储方式，'redis' 或 'memory'
  
  返回:
      deleted_count: 成功删除的任务数量
      failed_jobs: 删除失败的任务ID列表
  `````

- `def pause_timing_job(job_id: str, queue_name: str, job_store_kind: str = 'redis')` `fastapi_router.post('/pause_timing_job', response_model=BaseResponse)`
  - *Line: 1395*
  - **Docstring:**
  `````
  暂停定时任务
  
  参数:
      job_id: 任务ID
      queue_name: 队列名称
      job_store_kind: 任务存储方式，'redis' 或 'memory'
  `````

- `def resume_timing_job(job_id: str, queue_name: str, job_store_kind: str = 'redis')` `fastapi_router.post('/resume_timing_job', response_model=BaseResponse)`
  - *Line: 1428*
  - **Docstring:**
  `````
  恢复定时任务
  
  参数:
      job_id: 任务ID
      queue_name: 队列名称
      job_store_kind: 任务存储方式，'redis' 或 'memory'
  `````

- `async def deprecate_queue(request: DeprecateQueueRequest)` `fastapi_router.delete('/deprecate_queue', response_model=BaseResponse[DeprecateQueueData])` `handle_funboost_exceptions`
  - *Line: 1462*
  - **Docstring:**
  `````
  废弃队列 - 从 Redis 的 funboost_all_queue_names set 中移除队列名
  
  Args:
      request: 包含要废弃的队列名称
      
  Returns:
      BaseResponse[DeprecateQueueData]: 包含废弃结果
      
  使用场景:
      当队列改名或不再使用时，可以调用此接口将其从队列列表中移除
  `````

- `def get_scheduler_status(queue_name: str = Query(..., description='队列名称'), job_store_kind: str = Query('redis', description="任务存储方式，'redis' 或 'memory'，默认 'redis'"))` `fastapi_router.get('/get_scheduler_status', response_model=BaseResponse[SchedulerStatusData])` `handle_funboost_exceptions`
  - *Line: 1504*
  - *获取定时器调度器状态*

- `def pause_scheduler(queue_name: str = Query(..., description='队列名称'), job_store_kind: str = Query('redis', description="任务存储方式，'redis' 或 'memory'，默认 'redis'"))` `fastapi_router.post('/pause_scheduler', response_model=BaseResponse[SchedulerControlData])` `handle_funboost_exceptions`
  - *Line: 1530*
  - **Docstring:**
  `````
  暂停定时器调度器
  注意：这只会暂停当前进程中的调度器实例。如果部署了多实例，可能需要单独控制。
  `````

- `def resume_scheduler(queue_name: str = Query(..., description='队列名称'), job_store_kind: str = Query('redis', description="任务存储方式，'redis' 或 'memory'，默认 'redis'"))` `fastapi_router.post('/resume_scheduler', response_model=BaseResponse[SchedulerControlData])` `handle_funboost_exceptions`
  - *Line: 1553*
  - *恢复运行定时器调度器*

- `def get_care_project_name()` `fastapi_router.get('/get_care_project_name', response_model=BaseResponse[CareProjectNameData])` `handle_funboost_exceptions`
  - *Line: 1593*
  - **Docstring:**
  `````
  获取当前的 care_project_name 设置
  
  返回:
      care_project_name: 当前设置的项目名称，None 表示不限制（显示全部）
  `````

- `def set_care_project_name(request: SetCareProjectNameRequest)` `fastapi_router.post('/set_care_project_name', response_model=BaseResponse[CareProjectNameData])` `handle_funboost_exceptions`
  - *Line: 1613*
  - **Docstring:**
  `````
  设置 care_project_name
  
  请求体:
      care_project_name: 项目名称，空字符串表示不限制（显示全部项目）
  
  说明:
      设置后会影响本次会话的所有页面（队列操作、消费者信息等）
  `````

- `def get_all_project_names()` `fastapi_router.get('/get_all_project_names', response_model=BaseResponse[AllProjectNamesData])` `handle_funboost_exceptions`
  - *Line: 1643*
  - **Docstring:**
  `````
  获取所有已注册的项目名称列表
  
  返回:
      project_names: 项目名称列表（按字母排序）
      count: 项目数量
  `````

- `async def async_wrapper(*args, **kwargs)` `functools.wraps(func)`
  - *Line: 147*

- `def sync_wrapper(*args, **kwargs)` `functools.wraps(func)`
  - *Line: 180*


---

`````python

"""
fastapi 开箱即用，只需要用户的 app.include_router(fastapi_router) ,即可自动给用户的fastapi添加常用路由，实现faas




使用说明:
    在用户自己的 FastAPI 项目中
       app.include_router(fastapi_router)
    


如果fastapi_router集成到你自己的fastapi app时候，你觉得需要加上权限鉴权，可以这样： 
app.include_router(
    fastapi_router,
    dependencies=[
        Depends(your_authenticate),
    ]
)

"""

import traceback
import typing
import asyncio

from funboost import AioAsyncResult, AsyncResult, TaskOptions, BoosterParams, Booster

from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter, QueuesConusmerParamsGetter,CareProjectNameEnv
from funboost.core.exceptions import FunboostException
from fastapi import FastAPI, APIRouter, Query, Request
from fastapi.responses import JSONResponse


try:
    from pydantic import BaseModel, ConfigDict  # v2
    pydantic_version = 'v2'
except ImportError:
    from pydantic import BaseModel              # v1
    ConfigDict = None
    pydantic_version = 'v1'
from funboost.core.loggers import get_funboost_file_logger
from funboost.utils.redis_manager import RedisMixin
from funboost.constant import RedisKeys
from funboost.faas.faas_util import gen_aps_job_adder

logger = get_funboost_file_logger(__name__)





# 创建 Router 实例，方便用户 include 到自己的 app 中
# 用户可以使用 app.include_router(fastapi_router)
fastapi_router = APIRouter(prefix='/funboost', tags=['funboost'])





# ==================== fastapi app 处理装饰器 ====================
# 会影响用户自己的 app，看用户自己喜好了，因为有的用户的response是自定义的，不是funboost fatapi_router的BaseResponse。

async def funboost_exception_handler(request: Request, exc: FunboostException) -> JSONResponse:
    """
    统一处理 FunboostException 类型的异常
    自动提取异常的 code、message、data 等信息返回给前端
    """
    # 注意：这里不能直接返回 BaseResponse，因为FastAPI的异常处理器需要返回Response对象
    # 但我们可以使用BaseResponse的结构来保持格式一致
    response_data = {
        "succ": False,
        "msg": exc.message,
        "code": exc.code or 5000,
        "error_data": exc.error_data,
        "error": exc.__class__.__name__,
        "traceback": None,  # FunboostException不返回traceback
        "trace_id": getattr(exc, "trace_id", None)
    }
    return JSONResponse(
        status_code=200,  # HTTP状态码仍然返回200,业务错误通过code区分
        content=response_data
    )


async def general_exception_handler(request: Request, exc: Exception) -> JSONResponse:
    """
    统一处理所有其他异常
    返回固定code 5555,并包含完整的异常堆栈信息
    """
    logger.exception(f'未预期的异常: {str(exc)}')
    response_data = {
        "succ": False,
        "msg": f"系统错误: {type(exc).__name__}: {str(exc)}",
        "code": 5555,
        "error_data": None,
        "error": type(exc).__name__,
        "traceback": traceback.format_exc(),
        "trace_id": None
    }
    return JSONResponse(
        status_code=200,  # HTTP状态码仍然返回200,业务错误通过code区分
        content=response_data
    )


def register_funboost_exception_handlers(app: FastAPI):
    """
    注册 Funboost 的全局异常处理器到 FastAPI app
    
    使用示例:
        from funboost.faas.fastapi_adapter import fastapi_router, register_funboost_exception_handlers
        
        app = FastAPI()
        app.include_router(fastapi_router)
        register_funboost_exception_handlers(app)  # 注册全局异常处理
    """
    app.add_exception_handler(FunboostException, funboost_exception_handler)
    app.add_exception_handler(Exception, general_exception_handler)




# ==================== Funboost Router 异常处理装饰器 ====================
# 只针对 funboost router 的接口，不影响用户自己的 app

def handle_funboost_exceptions(func):
    """
    装饰器：统一处理 funboost router 接口的异常
    只在 funboost 的接口中使用，不会影响用户自己的 FastAPI app
    
    使用方法:
        @fastapi_router.get("/some_endpoint")
        @handle_funboost_exceptions
        async def some_endpoint():
            # 直接写业务逻辑，不需要 try-except
            return BaseResponse(...)
    
    异常处理规则:
        - FunboostException: 返回异常的 code、message、data、trace_id
        - 其他异常: 返回 code 5555，包含完整堆栈信息
    """
    import functools
    
    @functools.wraps(func)
    async def async_wrapper(*args, **kwargs):
        try:
            # 如果是异步函数
            if asyncio.iscoroutinefunction(func):
                return await func(*args, **kwargs)
            else:
                return func(*args, **kwargs)
        except FunboostException as e:
            # 处理 FunboostException
            # print(4444,e.to_dict())
            return BaseResponse(
                succ=False,
                msg=e.message,
                code=e.code or 5000,
                error_data=e.error_data,
                error=e.__class__.__name__,
                traceback=traceback.format_exc(),  
                trace_id=getattr(e, "trace_id", None)
            )
        except Exception as e:
            # 处理其他异常
            logger.exception(f'未预期的异常: {str(e)}')
            return BaseResponse(
                succ=False,
                msg=f"系统错误: {type(e).__name__}: {str(e)}",
                code=5555,
                error_data=None,
                error=type(e).__name__,
                traceback=traceback.format_exc(),
                trace_id=None
            )
    
    @functools.wraps(func)
    def sync_wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except FunboostException as e:
            # 处理 FunboostException
            # print(4444,e.to_dict())
            return BaseResponse(
                succ=False,
                msg=e.message,
                code=e.code or 5000,
                error_data=e.error_data,
                error=e.__class__.__name__,
                traceback=traceback.format_exc(),  
                trace_id=getattr(e, "trace_id", None)
            )
        except Exception as e:
            # 处理其他异常
            logger.exception(f'未预期的异常: {str(e)}')
            return BaseResponse(
                succ=False,
                msg=f"系统错误: {type(e).__name__}: {str(e)}",
                code=5555,
                error_data=None,
                error=type(e).__name__,
                traceback=traceback.format_exc(),
                trace_id=None
            )
    
    # 根据函数类型返回对应的包装器
    if asyncio.iscoroutinefunction(func):
        return async_wrapper
    else:
        return sync_wrapper



class BaseAllowExtraModel(BaseModel):
    
    if pydantic_version == 'v2':
        # Pydantic v2 使用
        model_config = ConfigDict(extra="allow")

    elif pydantic_version == 'v1':
        # Pydantic v1 使用
        class Config:
            extra = "allow"



# 统一响应模型（泛型）
T = typing.TypeVar('T')

class BaseResponse(BaseModel, typing.Generic[T]):
    """
    统一的泛型响应模型
    
    字段说明:
        succ: 请求是否成功，True表示成功，False表示失败
        msg: 消息描述
        data: 返回的数据，使用泛型T
        code: 业务状态码，200表示成功，其他表示各种错误
        error: 错误类型名称（可选），如 "QueueNameNotExists", "ValueError"
        traceback: 异常堆栈信息（可选），仅在出错时返回
        trace_id: 追踪ID（可选），用于分布式追踪
    """
    succ: bool
    msg: str
    data: typing.Optional[T] = None
    error_data: typing.Optional[typing.Dict] = None
    code: typing.Optional[int] = 200
    error: typing.Optional[str] = None
    traceback: typing.Optional[str] = None
    trace_id: typing.Optional[str] = None


class MsgItem(BaseModel):
    queue_name: str  # 队列名
    msg_body: dict  # 消息体,就是boost函数的入参字典,例如 {"x":1,"y":2}
    need_result: bool = False  # 发布消息后,是否需要返回结果
    timeout: int = 60  # 等待结果返回的最大等待时间.
    task_id: str = None  # 可选：指定 task_id


# 统一响应格式的数据结构

# 函数执行结果状态的详细模型（参考 FunctionResultStatus）
class FunctionResultStatusModel(BaseModel):
    """
    函数执行结果状态模型
    对应 FunctionResultStatus.get_status_dict() 的返回值结构
    """
    # 基本信息
    host_process: str  # 主机名-进程ID，例如 "LAPTOP-7V78BBO2 - 34572"
    queue_name: str  # 队列名称
    function: str  # 函数名称
    
    # 消息信息
    msg_dict: dict  # 原始消息字典
    task_id: str  # 任务ID
    
    # 进程和线程信息
    process_id: int  # 进程ID
    thread_id: int  # 线程ID
    total_thread: int  # 活跃线程总数
    
    # 时间信息
    publish_time: float  # 发布时间（时间戳）
    publish_time_format: str  # 发布时间格式化字符串，例如 "2025-12-05 13:28:12"
    time_start: float  # 开始执行时间（时间戳）
    time_cost: typing.Optional[float]  # 执行耗时（秒）
    time_end: float  # 结束时间（时间戳）
    insert_time_str: str  # 插入时间字符串，例如 "2025-12-05 13:28:13"
    insert_minutes: str  # 插入时间精确到分钟，例如 "2025-12-05 13:28"
    
    # 参数信息
    params: dict  # 函数参数（字典形式）
    params_str: str  # 函数参数（JSON字符串形式）
    
    # 执行结果信息
    result: typing.Any  # 函数执行结果
    run_times: int  # 运行次数
    success: bool  # 是否成功
    run_status: str  # 运行状态：'running' 或 'finish'
    
    # 异常信息（可选）
    exception: typing.Optional[str]  # 异常详情
    exception_type: typing.Optional[str]  # 异常类型
    exception_msg: typing.Optional[str]  # 异常消息
    rpc_chain_error_msg_dict: typing.Optional[dict]  # RPC链式调用错误信息
    
    # RPC配置
    rpc_result_expire_seconds: typing.Optional[int]  # RPC结果过期时间（秒）
    
    # 主机信息
    host_name: str  # 主机名，例如 "LAPTOP-7V78BBO2"
    script_name: str  # 脚本名称（短），例如 "example_fastapi_router.py"
    script_name_long: str  # 脚本名称（完整路径）

    user_context: typing.Optional[dict] = {}  # 用户自定义的额外信息，用户随意存放任何信息。
    
    # MongoDB文档ID
    _id: str  # MongoDB 文档ID，通常等于 task_id
    
    class Config:
        # 允许字段别名（如 _id）
        populate_by_name = True


class RpcRespData(BaseAllowExtraModel):
    task_id: typing.Optional[str] = None
    status_and_result: typing.Optional[FunctionResultStatusModel] = None  # 消费函数的消费状态和结果


class CountData(BaseModel):
    queue_name: str
    count: int = -1


class AllQueuesData(BaseModel):
    queues: typing.List[str] = []
    count: int = 0


class DeprecateQueueRequest(BaseModel):
    """废弃队列请求模型"""
    queue_name: str  # 要废弃的队列名称


class DeprecateQueueData(BaseModel):
    """废弃队列响应数据模型"""
    queue_name: str
    removed: bool  # 是否成功移除


@fastapi_router.post("/publish", response_model=BaseResponse[RpcRespData])
async def publish_msg(msg_item: MsgItem):
    """
    发布消息接口，支持RPC模式。
    支持queue_name是否存在的校验，支持校验消息内容是否正确。所以不用担心跨部门用户使用了错误的queue_name，或者消息内容不正确。

    用户可以先通过 /get_queues_config 接口获取所有队列的配置信息，就知道有哪些队列，以及每个队列支持的消费函数的消息内容需要包括哪些入参字段了。
    # 发布消息时候会立即校验入参是否正确，使用了redis中的 booster配置的 auto_generate_info.final_func_input_params_info 信息来校验入参名字和个数是否正确
    """
    status_and_result = None
    task_id = None
    try:
        # SingleQueueConusmerParamsGetter(msg_item.queue_name).gen_publisher_for_faas() 从 funboost 的reids配置中生成 publisher
        # 不需要用户亲自判断queue_name，然后精确使用某个非常具体的消费函数，


        publisher = SingleQueueConusmerParamsGetter(msg_item.queue_name).gen_publisher_for_faas()
        booster_params_by_redis = SingleQueueConusmerParamsGetter(msg_item.queue_name).get_one_queue_params_use_cache()
        
        # 检查是否需要 RPC 模式
        if msg_item.need_result:
          
            # 开启 RPC 模式发布
            async_result = await publisher.aio_publish(
                msg_item.msg_body,
                task_id=msg_item.task_id,  # 可选：指定 task_id（用于重试失败任务）
                task_options=TaskOptions(is_using_rpc_mode=True)
            )
            task_id = async_result.task_id
            # 等待结果
            status_and_result = await AioAsyncResult(async_result.task_id, timeout=msg_item.timeout).status_and_result
        else:
            # 普通发布，可以指定 task_id
            async_result = await publisher.aio_publish(msg_item.msg_body, task_id=msg_item.task_id)
            task_id = async_result.task_id

        return BaseResponse[RpcRespData](
            succ=True,
            msg=f'{msg_item.queue_name} 队列,消息发布成功',
            data=RpcRespData(
                task_id=task_id,
                status_and_result=status_and_result
            )
        )
    except Exception as e:
        logger.exception(f'发布消息失败: {str(e)}')
        return BaseResponse[RpcRespData](
            succ=False,
            msg=f'{msg_item.queue_name} 队列,消息发布失败 {type(e)} {e} {traceback.format_exc()}',
            data=RpcRespData(
                task_id=task_id,
                status_and_result=status_and_result
            )
        )


@fastapi_router.get("/get_result", response_model=BaseResponse[RpcRespData])
async def get_result(task_id: str, timeout: int = 5,):
    """
    根据 task_id 获取任务执行结果
    """
    try:
        # 尝试获取结果，默认给个短的 timeout 防止一直阻塞，或者复用 AioAsyncResult 的逻辑
        # 注意：如果任务还在运行，AioAsyncResult 会阻塞直到 timeout
        # 如果任务早已完成并过期，这里可能返回 None
        status_and_result = await AioAsyncResult(task_id, timeout=timeout).status_and_result
        
        if status_and_result:
            return BaseResponse[RpcRespData](
                succ=True,
                msg="获取成功",
                data=RpcRespData(
                    task_id=task_id,
                    status_and_result=status_and_result
                )
            )
        else:
            return BaseResponse[RpcRespData](
                succ=False,
                msg="未获取到结果(可能已过期或未开始执行或超时或压根没启动消费)",
                data=RpcRespData(
                    task_id=task_id,
                    status_and_result=None
                )
            )
            
    except Exception as e:
        logger.exception(f'获取结果失败: {str(e)}')
        return BaseResponse[RpcRespData](
            succ=False,
            msg=f"获取结果出错: {str(e)}",
            data=RpcRespData(
                task_id=task_id,
                status_and_result=None
            )
        )


# 队列控制接口（暂停/恢复）

class QueueNameRequest(BaseModel):
    """队列名称请求模型"""
    queue_name: str


class QueueControlData(BaseModel):
    """队列控制操作的响应数据"""
    queue_name: str
    success: bool


@fastapi_router.post("/pause_consume", response_model=BaseResponse[QueueControlData])
def pause_consume(request: QueueNameRequest):
    """
    暂停队列消费
    
    请求体:
        {
            "queue_name": "队列名称"
        }
    
    返回:
        暂停操作的结果
        
    说明:
        此接口会在 Redis 中设置暂停标志为 '1'，消费者会定期检查此标志并暂停消费。
        暂停不会立即生效，需要等待消费者检查标志的时间间隔。
    """
    try:
        
        
        RedisMixin().redis_db_frame.hset(RedisKeys.REDIS_KEY_PAUSE_FLAG, request.queue_name, '1')
        
        return BaseResponse[QueueControlData](
            succ=True,
            msg=f"队列 {request.queue_name} 暂停成功",
            data=QueueControlData(
                queue_name=request.queue_name,
                success=True
            )
        )
    except Exception as e:
        logger.exception(f'暂停队列消费失败: {str(e)}')
        return BaseResponse[QueueControlData](
            succ=False,
            msg=f"暂停队列 {request.queue_name} 失败: {str(e)}",
            data=QueueControlData(
                queue_name=request.queue_name,
                success=False
            )
        )


@fastapi_router.post("/resume_consume", response_model=BaseResponse[QueueControlData])
def resume_consume(request: QueueNameRequest):
    """
    恢复队列消费
    
    请求体:
        {
            "queue_name": "队列名称"
        }
    
    返回:
        恢复操作的结果
        
    说明:
        此接口会在 Redis 中设置暂停标志为 '0'，消费者会定期检查此标志并恢复消费。
        恢复不会立即生效，需要等待消费者检查标志的时间间隔。
    """
    try:
        
        
        RedisMixin().redis_db_frame.hset(RedisKeys.REDIS_KEY_PAUSE_FLAG, request.queue_name, '0')
        
        return BaseResponse[QueueControlData](
            succ=True,
            msg=f"队列 {request.queue_name} 恢复成功",
            data=QueueControlData(
                queue_name=request.queue_name,
                success=True
            )
        )
    except Exception as e:
        logger.exception(f'恢复队列消费失败: {str(e)}')
        return BaseResponse[QueueControlData](
            succ=False,
            msg=f"恢复队列 {request.queue_name} 失败: {str(e)}",
            data=QueueControlData(
                queue_name=request.queue_name,
                success=False
            )
        )



@fastapi_router.get("/get_msg_count", response_model=BaseResponse[CountData])
@handle_funboost_exceptions  # 使用装饰器统一处理异常，不影响用户的app
def get_msg_count(queue_name: str):
    """
    根据 queue_name 获取消息数量
    
    注意：此接口使用了 @handle_funboost_exceptions 装饰器
    所以不需要写 try-except，异常会自动被捕获并返回统一格式
    """
    # 直接写业务逻辑，不需要 try-except
    publisher = SingleQueueConusmerParamsGetter(queue_name).gen_publisher_for_faas()
    # 获取消息数量（注意：某些中间件可能不支持准确计数，返回-1）
    count = publisher.get_message_count()
    return BaseResponse[CountData](
        succ=True,
        msg="获取成功",
        data=CountData(
            queue_name=queue_name,
            count=count
        )
    )
# 队列清空接口

class ClearQueueData(BaseModel):
    """清空队列响应数据"""
    queue_name: str
    success: bool


@fastapi_router.post("/clear_queue", response_model=BaseResponse[ClearQueueData])
def clear_queue(request: QueueNameRequest):
    """
    清空队列中的所有消息
    
    请求体:
        {
            "queue_name": "队列名称"
        }
    
    返回:
        清空操作的结果
        
    说明:
        此接口会清空指定队列中的所有待消费消息。
        ⚠️ 此操作不可逆，请谨慎使用！
        
    注意:
        broker_kind 会自动从已注册的 booster 中获取，无需手动指定。
    """
    try:
        # 通过 queue_name 自动获取对应的 booster
        publisher = SingleQueueConusmerParamsGetter(request.queue_name).gen_publisher_for_faas()
        publisher.clear()
        
        return BaseResponse[ClearQueueData](
            succ=True,
            msg=f"队列 {request.queue_name} 清空成功",
            data=ClearQueueData(
                queue_name=request.queue_name,
                success=True
            )
        )
    except Exception as e:
        logger.exception(f'清空队列失败: {str(e)}')
        return BaseResponse[ClearQueueData](
            succ=False,
            msg=f"清空队列 {request.queue_name} 失败: {str(e)}",
            data=ClearQueueData(
                queue_name=request.queue_name,
                success=False
            )
        )




@fastapi_router.get("/get_all_queues", response_model=BaseResponse[AllQueuesData])
def get_all_queues():
    """
    获取所有已注册的队列名称
    
    返回所有通过 @boost 装饰器注册的队列名称列表
    """
    try:
        # 获取所有队列名称
        all_queues = QueuesConusmerParamsGetter().get_all_queue_names()
        
        return BaseResponse[AllQueuesData](
            succ=True,
            msg="获取成功",
            data=AllQueuesData(
                queues=all_queues,
                count=len(all_queues)
            )
        )
    except Exception as e:
        logger.exception(f'获取所有队列失败: {str(e)}')
        return BaseResponse[AllQueuesData](
            succ=False,
            msg=f"获取所有队列失败: {str(e)}",
            data=AllQueuesData(
                queues=[],
                count=0
            )
        )




# 队列配置参数详细模型（参考 BoosterParams）
class QueueParams(BaseAllowExtraModel):
    """
    队列的完整配置参数，
    和BoosterParams不同的是，这里是完全版可json序列化的
    这里的数据是从redis获取的，redis只能存json序列化的数据。
    
    """
    # 基础配置
    queue_name: str  # 队列名字
    broker_kind: str  # 中间件类型，如 REDIS, RABBITMQ 等
    project_name: typing.Optional[str] = None # 项目名
    
    # 并发配置
    concurrent_mode: str  # 并发模式：threading/gevent/eventlet/async/single_thread
    concurrent_num: int  # 并发数量
    specify_concurrent_pool: typing.Optional[typing.Any]  # 指定的线程池/协程池
    specify_async_loop: typing.Optional[typing.Any]   # 指定的async loop
    is_auto_start_specify_async_loop_in_child_thread: bool  # 是否自动在子线程启动async loop
    
    # 频率控制
    qps: typing.Optional[float]  # QPS限制（每秒执行次数）
    is_using_distributed_frequency_control: bool  # 是否使用分布式频控
    
    # 心跳与监控
    is_send_consumer_heartbeat_to_redis: bool  # 是否发送消费者心跳到redis
    
    # 重试配置
    max_retry_times: int  # 最大自动重试次数
    retry_interval: typing.Union[float, int]  # 重试间隔（秒）
    is_push_to_dlx_queue_when_retry_max_times: bool  # 达到最大重试次数后是否推送到死信队列
    
    # 函数装饰与超时
    consuming_function_decorator: typing.Optional[typing.Any]    # 函数装饰器
    function_timeout: typing.Optional[float]  # 函数超时时间（秒）
    is_support_remote_kill_task: bool  # 是否支持远程杀死任务
    
    # 日志配置
    log_level: int  # 日志级别
    logger_prefix: str  # 日志名字前缀
    create_logger_file: bool  # 是否创建文件日志
    logger_name: str  # 日志命名空间
    log_filename: typing.Optional[str]  # 日志文件名
    is_show_message_get_from_broker: bool  # 是否显示从broker获取的消息
    is_print_detail_exception: bool  # 是否打印详细异常堆栈
    publish_msg_log_use_full_msg: bool  # 发布消息日志是否显示完整消息
    
    # 消息过期与过滤
    msg_expire_seconds: typing.Optional[float]  # 消息过期时间（秒）
    do_task_filtering: bool  # 是否对函数入参进行过滤去重
    task_filtering_expire_seconds: int  # 任务过滤的失效期
    
    # 函数结果持久化
    function_result_status_persistance_conf: typing.Dict[str, typing.Any]  # 函数结果状态持久化配置
    
    # 用户自定义
    user_custom_record_process_info_func: typing.Optional[typing.Any]  # 用户自定义的保存消息处理记录函数
    
    # RPC模式
    is_using_rpc_mode: bool  # 是否使用RPC模式
    rpc_result_expire_seconds: int  # RPC结果过期时间（秒）
    rpc_timeout: int  # RPC超时时间（秒）
    
    # 延时任务
    delay_task_apscheduler_jobstores_kind: str  # 延时任务的jobstore类型：redis/memory
    
    # 定时运行控制
    is_do_not_run_by_specify_time_effect: bool  # 是否使不运行的时间段生效
    do_not_run_by_specify_time: typing.Tuple[str, str]  # 不运行的时间段
    
    # 启动控制
    schedule_tasks_on_main_thread: bool  # 是否在主线程调度任务
    is_auto_start_consuming_message: bool  # 是否自动启动消费
    
    # 分组管理
    booster_group: typing.Optional[str]  # 消费分组名字
    
    # 消费函数信息
    consuming_function: typing.Any  # 消费函数
    consuming_function_raw: typing.Any  # 原始消费函数
    consuming_function_name: str  # 消费函数名称
    
    # 中间件专属配置
    broker_exclusive_config: typing.Dict[str, typing.Any]  # 不同中间件的专属配置
    
    # 参数校验
    should_check_publish_func_params: bool  # 是否校验发布时的函数参数
    manual_func_input_params :typing.Optional[typing.Dict[str, typing.Any]] = None # 手动指定函数入参字段，默认是根据消费函数def定义的入参来生成这个。
    
    # 自定义覆盖类
    consumer_override_cls: typing.Optional[typing.Any]   # 自定义消费者类
    publisher_override_cls: typing.Optional[typing.Any]   # 自定义发布者类
    
    # 函数类型
    consuming_function_kind: typing.Optional[str]  # 函数类型：CLASS_METHOD/INSTANCE_METHOD/STATIC_METHOD/COMMON_FUNCTION
    
    # 用户自定义配置
    user_options: typing.Dict[str, typing.Any]  # 用户额外自定义的配置
    
    # 自动生成信息
    auto_generate_info: typing.Dict[str, typing.Any]  # 自动生成的信息,里面有个 final_func_input_params_info 存储了函数入参信息，用户也可以把这当做微服务的接口文档协议，让用户清楚知道消息需要传递哪些入参。

    

# 活跃消费者详细模型
class ActiveConsumerRunInfo(BaseAllowExtraModel):
    """
    单个活跃消费者的详细信息
    这些数据是从redis中的心跳信息获取的
    """
    # 基本信息
    queue_name: str  # 队列名
    computer_name: str  # 计算机名
    computer_ip: str  # 计算机IP地址
    process_id: int  # 进程ID
    consumer_id: int  # 消费者ID
    consumer_uuid: str  # 消费者UUID
    
    # 启动和心跳时间
    start_datetime_str: str  # 启动时间字符串，格式：YYYY-MM-DD HH:MM:SS
    start_timestamp: float  # 启动时间戳
    hearbeat_datetime_str: str  # 最近心跳时间字符串
    hearbeat_timestamp: float  # 最近心跳时间戳
    
    # 消费函数信息
    consuming_function: str  # 消费函数名
    code_filename: str  # 代码文件路径
    
    # 时间单位配置
    unit_time_for_count: int  # 统计的时间单位（秒）
    
    # 最近X秒执行统计
    last_x_s_execute_count: int  # 最近X秒执行次数
    last_x_s_execute_count_fail: int  # 最近X秒失败次数
    last_execute_task_time: float  # 最后一次执行任务的时间戳
    last_x_s_avarage_function_spend_time: typing.Optional[float]   # 最近X秒平均耗时（秒）
    last_x_s_total_cost_time: typing.Optional[float]  # 最近X秒总耗时（秒）
    
    # 消息队列状态
    msg_num_in_broker: int  # broker中的消息数量
    current_time_for_execute_task_times_every_unit_time: float  # 当前统计周期的开始时间戳
    last_timestamp_when_has_task_in_queue: float  # 最后一次队列有任务的时间戳
    
    # 从启动开始的统计
    total_consume_count_from_start: int  # 从启动开始的总执行次数
    total_consume_count_from_start_fail: int  # 从启动开始的总失败次数
    total_cost_time_from_start: float  # 从启动开始的总耗时（秒）
    avarage_function_spend_time_from_start: typing.Optional[float]  # 从启动开始的平均耗时（秒）


# 队列运行信息数据模型
class QueueParamsAndActiveConsumersData(BaseModel):
    """队列参数和活跃消费者数据"""
    queue_params: QueueParams  # 队列的booster入参大全
    active_consumers: typing.List[ActiveConsumerRunInfo]   # 队列对应的所有活跃消费者列表
    pause_flag: int  # 暂停标志
    msg_num_in_broker: int   # broker中的消息数量
    history_run_count: typing.Optional[int]   # 历史运行次数
    history_run_fail_count: typing.Optional[int]   # 历史失败次数
    all_consumers_last_x_s_execute_count: int   # 所有消费进程最近X秒所有消费者执行次数
    all_consumers_last_x_s_execute_count_fail: int   # 所有消费进程最近X秒所有消费者失败次数
    all_consumers_last_x_s_avarage_function_spend_time: typing.Optional[float]   # 所有消费进程最近X秒平均耗时
    all_consumers_avarage_function_spend_time_from_start: typing.Optional[float]   # 所有消费进程从启动开始的平均耗时
    all_consumers_total_consume_count_from_start: int   # 所有消费进程从启动开始总消费次数
    all_consumers_total_consume_count_from_start_fail: int   # 所有消费进程从启动开始总失败次数
    all_consumers_last_execute_task_time: typing.Optional[float]   # 所有消费进程中最后一次执行任务的时间戳


class QueueConfigData(BaseModel):
    """队列配置数据"""
    queues_config: typing.Dict[str, QueueParams] = {}
    count: int = 0


@fastapi_router.get("/get_queues_config", response_model=BaseResponse[QueueConfigData])
def get_queues_config():
    """
    获取所有队列的配置信息
    
    返回所有已注册队列的详细配置参数，包括：
    - 队列名称
    - broker 类型
    - 并发数量
    - QPS 限制
    - 是否启用 RPC 模式
    - ！！！重要，消费函数的入参名字列表在 auto_generate_info.final_func_input_params_info 中 ，用于发布消息时校验入参是否正确，不正确的消息格式立刻从接口返回报错消息内容不正确。
      前端或跨部门可以先获取所有队列名字以及队列对应的配置，就知道rpc publish发布接口可以传哪些queue_name以及对应的消息应该包含哪些字段。
      auto_generate_info.final_func_input_params_info ，相当于是funboost能自动根据消费函数的def定义，对外提供消费函数的接口文档字段，就类似fastapi自动对接口函数入参生成了文档，避免需要重复手动一个个的编辑接口文档字段。
    - 等等其他 @boost 装饰器的所有参数
    
    主要用于前端可视化展示和管理
    """
    try:
        queues_config = QueuesConusmerParamsGetter().get_queues_params()
        
        return BaseResponse[QueueConfigData](
            succ=True,
            msg="获取成功",
            data=QueueConfigData(
                queues_config=queues_config,
                count=len(queues_config)
            )
        )
    except Exception as e:
        logger.exception(f'获取队列配置失败: {str(e)}')
        return BaseResponse[QueueConfigData](
            succ=False,
            msg=f"获取队列配置失败: {str(e)}",
            data=QueueConfigData(
                queues_config={},
                count=0
            )
        )


@fastapi_router.get("/get_one_queue_config", response_model=BaseResponse[QueueParams])
@handle_funboost_exceptions
def get_one_queue_config(queue_name: str):
    """
    获取单个队列的配置信息
    
    参数:
        queue_name: 队列名称（必填）
    
    返回:
        队列的配置信息，包括函数入参信息 (auto_generate_info.final_func_input_params_info)
    """
    queue_params = SingleQueueConusmerParamsGetter(queue_name).get_one_queue_params()
    
    return BaseResponse[QueueParams](
        succ=True,
        msg="获取成功",
        data=queue_params
    )
@fastapi_router.get("/get_queue_run_info", response_model=BaseResponse[QueueParamsAndActiveConsumersData])
def get_queue_run_info(queue_name: str):
    """
    获取单个队列的运行信息
    
    参数:
        queue_name: 队列名称（必填）
    
    返回:
        队列的详细运行信息，包括：
        - queue_params: 队列配置参数
        - active_consumers: 活跃的消费者列表
        - pause_flag: 暂停标志（-1,0表示未暂停，1表示已暂停）
        - msg_num_in_broker: broker中的消息数量（实时）
        - history_run_count: 历史运行总次数
        - history_run_fail_count: 历史失败总次数
        - all_consumers_last_x_s_execute_count: 所有消费进程，最近X秒所有消费者的执行次数
        - all_consumers_last_x_s_execute_count_fail: 所有消费进程，最近X秒所有消费者的失败次数
        - all_consumers_last_x_s_avarage_function_spend_time: 所有消费进程，最近X秒的平均函数耗时
        - all_consumers_avarage_function_spend_time_from_start: 所有消费进程，从启动开始的平均函数耗时
        - all_consumers_total_consume_count_from_start: 所有消费进程，从启动开始的总消费次数
        - all_consumers_total_consume_count_from_start_fail: 所有消费进程，从启动开始的总失败次数
        - all_consumers_last_execute_task_time: 所有消费进程中，最后一次执行任务的时间戳
    """
    try:
        # 获取单个队列的运行信息
        queue_info = SingleQueueConusmerParamsGetter(queue_name).get_one_queue_params_and_active_consumers()
        
        return BaseResponse[QueueParamsAndActiveConsumersData](
            succ=True,
            msg="获取成功",
            data=QueueParamsAndActiveConsumersData(**queue_info)
        )
        
    except Exception as e:
        logger.exception(f'获取队列运行信息失败: {str(e)}')
        return BaseResponse[QueueParamsAndActiveConsumersData](
            succ=False,
            msg=f"获取队列运行信息失败: {str(e)}",
            data=None
        )


# 所有队列运行信息数据模型
class AllQueuesRunInfoData(BaseModel):
    """所有队列的运行信息"""
    queues: typing.Dict[str, QueueParamsAndActiveConsumersData]  # 队列名到队列运行信息的映射
    total_count: int  # 队列总数


@fastapi_router.get("/get_all_queue_run_info", response_model=BaseResponse[AllQueuesRunInfoData])
def get_all_queue_run_info():
    """
    获取所有队列的运行信息
    
    返回:
        所有队列的详细运行信息，包括每个队列的：
        - queue_params: 队列配置参数
        - active_consumers: 活跃的消费者列表
        - pause_flag: 暂停标志
        - msg_num_in_broker: broker中的消息数量
        - history_run_count: 历史运行总次数
        - history_run_fail_count: 历史失败总次数
        - 以及各种统计信息
    """
    try:
        # 获取所有队列的运行信息
        all_queues_info = QueuesConusmerParamsGetter().get_queues_params_and_active_consumers()
        print(all_queues_info)
        
        # 转换为 Pydantic 模型
        queues_data = {}
        for queue_name, queue_info in all_queues_info.items():
            queues_data[queue_name] = QueueParamsAndActiveConsumersData(**queue_info)
        
        return BaseResponse[AllQueuesRunInfoData](
            succ=True,
            msg="获取成功",
            data=AllQueuesRunInfoData(
                queues=queues_data,
                total_count=len(queues_data)
            )
        )
        
    except Exception as e:
        logger.exception(f'获取所有队列运行信息失败: {str(e)}')
        return BaseResponse[AllQueuesRunInfoData](
            succ=False,
            msg=f"获取所有队列运行信息失败: {str(e)}",
            data=None
        )

# ==================== 定时任务管理接口 ====================


# 定时任务相关数据模型
class TimingJobRequest(BaseModel):
    """添加定时任务请求"""
    queue_name: str  # 队列名称
    trigger: str  # 触发器类型: 'date', 'interval', 'cron'
    job_id: typing.Optional[str] = None  # 任务ID，如果不提供则自动生成
    job_store_kind: str = 'redis'  # 任务存储方式: 'redis' 或 'memory'
    replace_existing: bool = False  # 是否替换已存在的任务
    
    # 任务参数
    args: typing.Optional[typing.List] = None  # 位置参数
    kwargs: typing.Optional[typing.Dict] = None  # 关键字参数
    
    # date 触发器参数
    run_date: typing.Optional[str] = None  # 运行时间，格式: 'YYYY-MM-DD HH:MM:SS'
    
    # interval 触发器参数
    weeks: typing.Optional[int] = None
    days: typing.Optional[int] = None
    hours: typing.Optional[int] = None
    minutes: typing.Optional[int] = None
    seconds: typing.Optional[int] = None
    
    # cron 触发器参数
    year: typing.Optional[str] = None
    month: typing.Optional[str] = None
    day: typing.Optional[str] = None
    week: typing.Optional[str] = None
    day_of_week: typing.Optional[str] = None
    hour: typing.Optional[str] = None
    minute: typing.Optional[str] = None
    second: typing.Optional[str] = None


class TimingJobData(BaseModel):
    """定时任务数据"""
    job_id: str
    queue_name: typing.Optional[str] = None
    trigger: typing.Optional[str] = None
    next_run_time: typing.Optional[str] = None
    status: typing.Optional[str] = None  # "running" 或 "paused"
    kwargs: typing.Optional[typing.Dict] = None  # 任务的 kwargs 参数


class TimingJobListData(BaseModel):
    """定时任务列表数据"""
    jobs_by_queue: typing.Dict[str, typing.List[TimingJobData]] = {}  # 按队列分组的任务
    total_count: int = 0





@fastapi_router.post("/add_timing_job", response_model=BaseResponse[TimingJobData])
def add_timing_job(job_request: TimingJobRequest):
    """
    添加定时任务
    
    支持三种触发方式:
    1. date: 在指定日期时间执行一次
       - 需要提供: run_date
       - 示例: {"trigger": "date", "run_date": "2025-12-03 15:00:00"}
    
    2. interval: 按固定时间间隔执行
       - 需要提供: weeks, days, hours, minutes, seconds 中的至少一个
       - 示例: {"trigger": "interval", "seconds": 10}
    
    3. cron: 按cron表达式执行
       - 需要提供: year, month, day, week, day_of_week, hour, minute, second 中的至少一个
       - 示例: {"trigger": "cron", "hour": "*/2", "minute": "30"}
    """
    try:
        # 获取 job_adder
        job_adder = gen_aps_job_adder(job_request.queue_name, job_request.job_store_kind)

        # 构建触发器参数
        trigger_args = {}
        
        if job_request.trigger == 'date':
            if job_request.run_date:
                trigger_args['run_date'] = job_request.run_date
        
        elif job_request.trigger == 'interval':
            if job_request.weeks is not None:
                trigger_args['weeks'] = job_request.weeks
            if job_request.days is not None:
                trigger_args['days'] = job_request.days
            if job_request.hours is not None:
                trigger_args['hours'] = job_request.hours
            if job_request.minutes is not None:
                trigger_args['minutes'] = job_request.minutes
            if job_request.seconds is not None:
                trigger_args['seconds'] = job_request.seconds
        
        elif job_request.trigger == 'cron':
            if job_request.year is not None:
                trigger_args['year'] = job_request.year
            if job_request.month is not None:
                trigger_args['month'] = job_request.month
            if job_request.day is not None:
                trigger_args['day'] = job_request.day
            if job_request.week is not None:
                trigger_args['week'] = job_request.week
            if job_request.day_of_week is not None:
                trigger_args['day_of_week'] = job_request.day_of_week
            if job_request.hour is not None:
                trigger_args['hour'] = job_request.hour
            if job_request.minute is not None:
                trigger_args['minute'] = job_request.minute
            if job_request.second is not None:
                trigger_args['second'] = job_request.second
        
        # 添加任务
        job = job_adder.add_push_job(
            trigger=job_request.trigger,
            args=job_request.args,
            kwargs=job_request.kwargs,
            id=job_request.job_id,
            replace_existing=job_request.replace_existing,
            **trigger_args
        )

        return BaseResponse[TimingJobData](
            succ=True,
            msg="定时任务添加成功",
            data=TimingJobData(
                job_id=job.id,
                queue_name=job_request.queue_name,
                trigger=str(job.trigger),
                next_run_time=str(job.next_run_time) if job.next_run_time else None,
                status="running",
                kwargs=job_request.kwargs
            )
        )
        
    except Exception as e:
        logger.exception(f'添加定时任务失败: {str(e)}')
        return BaseResponse[TimingJobData](
            succ=False,
            msg=f"添加定时任务失败: {str(e)}\n{traceback.format_exc()}",
            data=None
        )


@fastapi_router.get("/get_timing_jobs", response_model=BaseResponse[TimingJobListData])
def get_timing_jobs(
    queue_name: typing.Optional[str] = None,
    job_store_kind: str = 'redis'
):
    """
    获取定时任务列表
    
    参数:
        queue_name: 队列名称（可选，如果不提供则获取所有队列的任务）
        job_store_kind: 任务存储方式，'redis' 或 'memory'
    
    返回格式:
        jobs_by_queue: {queue_name: [jobs]}，按队列分组的任务
        total_count: 总任务数
    """
    try:
        # 使用字典格式存储：{queue_name: [jobs]}
        jobs_by_queue: typing.Dict[str, typing.List[TimingJobData]] = {}
        total_count = 0
        
        if queue_name:
            # 获取指定队列的任务
            jobs_by_queue[queue_name] = []
            try:
                job_adder = gen_aps_job_adder(queue_name, job_store_kind)
                jobs = job_adder.aps_obj.get_jobs()
                
                for job in jobs:
                    status = "paused" if job.next_run_time is None else "running"
                    kwargs = job.kwargs if hasattr(job, 'kwargs') and job.kwargs else {}
                    jobs_by_queue[queue_name].append(TimingJobData(
                        job_id=job.id,
                        queue_name=queue_name,
                        trigger=str(job.trigger),
                        next_run_time=str(job.next_run_time) if job.next_run_time else None,
                        status=status,
                        kwargs=kwargs
                    ))
                    total_count += 1
            except Exception as e:
                logger.exception(f'获取定时任务列表失败: {str(e)}')
                pass  # 队列不存在或没有任务，保持空数组
        else:
            # 获取所有队列的任务
            all_queues = list(QueuesConusmerParamsGetter().get_all_queue_names())
            for q_name in all_queues:
                jobs_by_queue[q_name] = []  # 初始化为空数组
                try:
                    job_adder = gen_aps_job_adder(q_name, job_store_kind)
                    jobs = job_adder.aps_obj.get_jobs()
                    
                    for job in jobs:
                        status = "paused" if job.next_run_time is None else "running"
                        kwargs = job.kwargs if hasattr(job, 'kwargs') and job.kwargs else {}
                        jobs_by_queue[q_name].append(TimingJobData(
                            job_id=job.id,
                            queue_name=q_name,
                            trigger=str(job.trigger),
                            next_run_time=str(job.next_run_time) if job.next_run_time else None,
                            status=status,
                            kwargs=kwargs
                        ))
                        total_count += 1
                except Exception as e:
                    logger.exception(f'获取定时任务列表失败: {str(e)}')
                    pass  # 队列没有任务或出错，保持空数组
        
        return BaseResponse[TimingJobListData](
            succ=True,
            msg="获取成功",
            data=TimingJobListData(
                jobs_by_queue=jobs_by_queue,
                total_count=total_count
            )
        )
        
    except Exception as e:
        logger.exception(f'获取定时任务列表失败: {str(e)}')
        return BaseResponse[TimingJobListData](
            succ=False,
            msg=f"获取定时任务列表失败: {str(e)}",
            data=TimingJobListData(jobs_by_queue={}, total_count=0)
        )


@fastapi_router.get("/get_timing_job", response_model=BaseResponse[TimingJobData])
def get_timing_job(
    job_id: str,
    queue_name: str,
    job_store_kind: str = 'redis'
):
    """
    获取单个定时任务的详细信息
    
    参数:
        job_id: 任务ID（必填）
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'
    
    返回:
        任务的详细信息，包括任务ID、队列名、触发器类型、下次运行时间等
    """
    try:
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        
        # 获取指定的任务
        job = job_adder.aps_obj.get_job(job_id)
        
        if job:
            status = "paused" if job.next_run_time is None else "running"
            kwargs = job.kwargs if hasattr(job, 'kwargs') and job.kwargs else {}
            return BaseResponse[TimingJobData](
                succ=True,
                msg="获取成功",
                data=TimingJobData(
                    job_id=job.id,
                    queue_name=queue_name,
                    trigger=str(job.trigger),
                    next_run_time=str(job.next_run_time) if job.next_run_time else None,
                    status=status,
                    kwargs=kwargs
                )
            )
        else:
            return BaseResponse[TimingJobData](
                succ=False,
                msg=f"任务 {job_id} 不存在",
                data=None
            )
        
    except Exception as e:
        logger.exception(f'获取定时任务失败: {str(e)}')
        return BaseResponse[TimingJobData](
            succ=False,
            msg=f"获取定时任务失败: {str(e)}",
            data=None
        )


@fastapi_router.delete("/delete_timing_job", response_model=BaseResponse)
def delete_timing_job(
    job_id: str,
    queue_name: str,
    job_store_kind: str = 'redis'
):
    """
    删除定时任务
    
    参数:
        job_id: 任务ID
        queue_name: 队列名称
        job_store_kind: 任务存储方式，'redis' 或 'memory'
    """
    try:
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.remove_job(job_id)
        
        return BaseResponse(
            succ=True,
            msg=f"定时任务 {job_id} 删除成功",
            data=None
        )
        
    except Exception as e:
        logger.exception(f'删除定时任务失败: {str(e)}')
        return BaseResponse(
            succ=False,
            msg=f"删除定时任务失败: {str(e)}",
            data=None
        )


class DeleteAllJobsData(BaseModel):
    """删除所有任务的结果数据"""
    deleted_count: int = 0
    failed_jobs: typing.List[str] = []


@fastapi_router.delete("/delete_all_timing_jobs", response_model=BaseResponse[DeleteAllJobsData])
def delete_all_timing_jobs(
    queue_name: typing.Optional[str] = None,
    job_store_kind: str = 'redis'
):
    """
    删除所有定时任务
    
    参数:
        queue_name: 队列名称（可选，如果不提供则删除所有队列的所有任务）
        job_store_kind: 任务存储方式，'redis' 或 'memory'
    
    返回:
        deleted_count: 成功删除的任务数量
        failed_jobs: 删除失败的任务ID列表
    """
    try:
        deleted_count = 0
        failed_jobs = []
        
        if queue_name:
            # 删除指定队列的所有任务
            try:

                job_adder = gen_aps_job_adder(queue_name, job_store_kind)
                jobs = job_adder.aps_obj.get_jobs()
                
                for job in jobs:
                    try:
                        job_adder.aps_obj.remove_job(job.id)
                        deleted_count += 1
                    except Exception as e:
                        failed_jobs.append(f"{job.id}: {str(e)}")
            except Exception as e:
                return BaseResponse[DeleteAllJobsData](
                    succ=False,
                    msg=f"删除队列 {queue_name} 的任务失败: {str(e)}",
                    data=DeleteAllJobsData(
                        deleted_count=deleted_count,
                        failed_jobs=failed_jobs
                    )
                )
        else:
            # 删除所有队列的所有任务
            all_queues = list(QueuesConusmerParamsGetter().get_all_queue_names())
            for q_name in all_queues:
                try:

                    job_adder = gen_aps_job_adder(q_name, job_store_kind)
                    jobs = job_adder.aps_obj.get_jobs()
                    
                    for job in jobs:
                        try:
                            job_adder.aps_obj.remove_job(job.id)
                            deleted_count += 1
                        except Exception as e:
                            failed_jobs.append(f"{q_name}/{job.id}: {str(e)}")
                except Exception as e:
                    logger.exception(f'删除队列 {q_name} 的任务失败: {str(e)}')
                    # 队列没有任务或出错，继续处理下一个队列
                    pass
        
        return BaseResponse[DeleteAllJobsData](
            succ=True,
            msg=f"成功删除 {deleted_count} 个定时任务",
            data=DeleteAllJobsData(
                deleted_count=deleted_count,
                failed_jobs=failed_jobs
            )
        )
        
    except Exception as e:
        logger.exception(f'删除所有定时任务失败: {str(e)}')
        return BaseResponse[DeleteAllJobsData](
            succ=False,
            msg=f"删除所有定时任务失败: {str(e)}",
            data=DeleteAllJobsData(
                deleted_count=0,
                failed_jobs=[]
            )
        )


@fastapi_router.post("/pause_timing_job", response_model=BaseResponse)
def pause_timing_job(
    job_id: str,
    queue_name: str,
    job_store_kind: str = 'redis'
):
    """
    暂停定时任务
    
    参数:
        job_id: 任务ID
        queue_name: 队列名称
        job_store_kind: 任务存储方式，'redis' 或 'memory'
    """
    try:
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.pause_job(job_id)
        
        return BaseResponse(
            succ=True,
            msg=f"定时任务 {job_id} 已暂停",
            data=None
        )
        
    except Exception as e:
        logger.exception(f'暂停定时任务失败: {str(e)}')
        return BaseResponse(
            succ=False,
            msg=f"暂停定时任务失败: {str(e)}",
            data=None
        )


@fastapi_router.post("/resume_timing_job", response_model=BaseResponse)
def resume_timing_job(
    job_id: str,
    queue_name: str,
    job_store_kind: str = 'redis'
):
    """
    恢复定时任务
    
    参数:
        job_id: 任务ID
        queue_name: 队列名称
        job_store_kind: 任务存储方式，'redis' 或 'memory'
    """
    try:
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.resume_job(job_id)
        
        return BaseResponse(
            succ=True,
            msg=f"定时任务 {job_id} 已恢复",
            data=None
        )
        
    except Exception as e:
        logger.exception(f'恢复定时任务失败: {str(e)}')
        return BaseResponse(
            succ=False,
            msg=f"恢复定时任务失败: {str(e)}",
            data=None
        )


@fastapi_router.delete("/deprecate_queue", response_model=BaseResponse[DeprecateQueueData])
@handle_funboost_exceptions
async def deprecate_queue(request: DeprecateQueueRequest):
    """
    废弃队列 - 从 Redis 的 funboost_all_queue_names set 中移除队列名
    
    Args:
        request: 包含要废弃的队列名称
        
    Returns:
        BaseResponse[DeprecateQueueData]: 包含废弃结果
        
    使用场景:
        当队列改名或不再使用时，可以调用此接口将其从队列列表中移除
    """
    queue_name = request.queue_name
    
    # 调用 SingleQueueConusmerParamsGetter 的 deprecate_queue 方法
    SingleQueueConusmerParamsGetter(queue_name).deprecate_queue()
    
    logger.info(f'成功废弃队列: {queue_name}')
    return BaseResponse(
        succ=True,
        msg=f"成功废弃队列: {queue_name}",
        data=DeprecateQueueData(
            queue_name=queue_name,
            removed=True
        )
    )


# ==================== Scheduler Control Endpoints ====================

class SchedulerStatusData(BaseModel):
    queue_name: str
    status_code: int
    status_str: str

class SchedulerControlData(BaseModel):
    queue_name: str
    status_str: str

@fastapi_router.get("/get_scheduler_status", response_model=BaseResponse[SchedulerStatusData])
@handle_funboost_exceptions
def get_scheduler_status(
    queue_name: str = Query(..., description="队列名称"),
    job_store_kind: str = Query("redis", description="任务存储方式，'redis' 或 'memory'，默认 'redis'")
):
    """
    获取定时器调度器状态
    """
    
    job_adder = gen_aps_job_adder(queue_name, job_store_kind)
    
    state_map = {0: 'stopped', 1: 'running', 2: 'paused'}
    state = job_adder.aps_obj.state
    
    return BaseResponse(
        succ=True,
        msg="获取成功",
        data=SchedulerStatusData(
            queue_name=queue_name,
            status_code=state,
            status_str=state_map.get(state, 'unknown')
        )
    )


@fastapi_router.post("/pause_scheduler", response_model=BaseResponse[SchedulerControlData])
@handle_funboost_exceptions
def pause_scheduler(
    queue_name: str = Query(..., description="队列名称"),
    job_store_kind: str = Query("redis", description="任务存储方式，'redis' 或 'memory'，默认 'redis'")
):
    """
    暂停定时器调度器
    注意：这只会暂停当前进程中的调度器实例。如果部署了多实例，可能需要单独控制。
    """
    job_adder = gen_aps_job_adder(queue_name, job_store_kind)
    job_adder.aps_obj.pause()
    
    return BaseResponse(
        succ=True,
        msg=f"调度器已暂停 ({queue_name})",
        data=SchedulerControlData(
            queue_name=queue_name,
            status_str="paused"
        )
    )


@fastapi_router.post("/resume_scheduler", response_model=BaseResponse[SchedulerControlData])
@handle_funboost_exceptions
def resume_scheduler(
    queue_name: str = Query(..., description="队列名称"),
    job_store_kind: str = Query("redis", description="任务存储方式，'redis' 或 'memory'，默认 'redis'")
):
    """
    恢复运行定时器调度器
    """
    job_adder = gen_aps_job_adder(queue_name, job_store_kind)
    job_adder.aps_obj.resume()
    
    return BaseResponse(
        succ=True,
        msg=f"调度器已恢复运行 ({queue_name})",
        data=SchedulerControlData(
            queue_name=queue_name,
            status_str="running"
        )
    )


# ==================== care_project_name 项目筛选接口 ====================

class CareProjectNameData(BaseModel):
    """care_project_name 响应数据"""
    care_project_name: typing.Optional[str] = None


class SetCareProjectNameRequest(BaseModel):
    """设置 care_project_name 请求模型"""
    care_project_name: str = ""  # 空字符串表示不限制


class AllProjectNamesData(BaseModel):
    """所有项目名称响应数据"""
    project_names: typing.List[str] = []
    count: int = 0


@fastapi_router.get("/get_care_project_name", response_model=BaseResponse[CareProjectNameData])
@handle_funboost_exceptions
def get_care_project_name():
    """
    获取当前的 care_project_name 设置
    
    返回:
        care_project_name: 当前设置的项目名称，None 表示不限制（显示全部）
    """
    care_project_name = CareProjectNameEnv.get()
    
    return BaseResponse(
        succ=True,
        msg="获取成功",
        data=CareProjectNameData(
            care_project_name=care_project_name
        )
    )


@fastapi_router.post("/set_care_project_name", response_model=BaseResponse[CareProjectNameData])
@handle_funboost_exceptions
def set_care_project_name(request: SetCareProjectNameRequest):
    """
    设置 care_project_name
    
    请求体:
        care_project_name: 项目名称，空字符串表示不限制（显示全部项目）
    
    说明:
        设置后会影响本次会话的所有页面（队列操作、消费者信息等）
    """
    care_project_name = request.care_project_name
    
    # 空字符串表示清除限制
    CareProjectNameEnv.set(care_project_name)
    
    # 如果设置为空字符串，返回时显示为 None
    display_value = care_project_name if care_project_name else None
    
    logger.info(f'设置 care_project_name 为: {display_value}')
    return BaseResponse(
        succ=True,
        msg=f"设置成功: {display_value if display_value else '不限制（显示全部）'}",
        data=CareProjectNameData(
            care_project_name=display_value
        )
    )


@fastapi_router.get("/get_all_project_names", response_model=BaseResponse[AllProjectNamesData])
@handle_funboost_exceptions
def get_all_project_names():
    """
    获取所有已注册的项目名称列表
    
    返回:
        project_names: 项目名称列表（按字母排序）
        count: 项目数量
    """
    # 使用 QueuesConusmerParamsGetter 获取所有项目名称
    project_names = QueuesConusmerParamsGetter().get_all_project_names()
    
    return BaseResponse(
        succ=True,
        msg="获取成功",
        data=AllProjectNamesData(
            project_names=sorted(project_names) if project_names else [],
            count=len(project_names) if project_names else 0
        )
    )


# 运行应用 (仅在作为主脚本运行时创建 app)
if __name__ == "__main__":
    import uvicorn

    CareProjectNameEnv.set('test_project1')

    # 这是一个示例，展示用户如何将 funboost router 集成到自己的 app 中
    app = FastAPI()
    app.include_router(fastapi_router)
    # 注意：funboost router 的异常处理使用装饰器 @handle_funboost_exceptions，无需全局注册


    print("启动 Funboost API 服务...")
    print("接口文档: http://127.0.0.1:16666/docs")
    uvicorn.run(app, host="0.0.0.0", port=16666, )

`````

--- **end of file: funboost/faas/fastapi_adapter.py** (project: funboost) --- 

---


--- **start of file: funboost/faas/flask_adapter.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/faas/flask_adapter.py`

#### 📝 Module Docstring

`````
Flask 开箱即用，作者自带贡献，只需要用户的 app.register_blueprint(flask_blueprint)
即可自动给用户的Flask应用添加常用路由
包括发布消息， 根据task_id获取结果， 获取队列消息数量



使用说明:
    在用户自己的 Flask 项目中:
       app.register_blueprint(flask_blueprint)
    
`````

#### 📦 Imports

- `import traceback`
- `from flask import Blueprint`
- `from flask import request`
- `from flask import jsonify`
- `from funboost import AsyncResult`
- `from funboost import TaskOptions`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import CareProjectNameEnv`
- `from funboost.faas.faas_util import gen_aps_job_adder`
- `from funboost.core.loggers import get_funboost_file_logger`
- `from flask import Flask`

#### 🔧 Public Functions (23)

- `def publish_msg()` `flask_blueprint.route('/publish', methods=['POST'])`
  - *Line: 34*
  - **Docstring:**
  `````
  发布消息接口
  
  请求体示例:
  {
      "queue_name": "test_queue",
      "msg_body": {"x": 1, "y": 2},
      "need_result": true,
      "timeout": 60
  }
  `````

- `def get_result()` `flask_blueprint.route('/get_result', methods=['GET'])`
  - *Line: 133*
  - **Docstring:**
  `````
  根据 task_id 获取任务执行结果
  
  查询参数:
      task_id: str - 任务ID（必填）
      timeout: int - 超时时间，默认5秒
  `````

- `def get_msg_count()` `flask_blueprint.route('/get_msg_count', methods=['GET'])`
  - *Line: 191*
  - **Docstring:**
  `````
  根据 queue_name 获取消息数量
  
  查询参数:
      queue_name: str - 队列名称（必填）
  `````

- `def get_all_queues()` `flask_blueprint.route('/get_all_queues', methods=['GET'])`
  - *Line: 237*
  - **Docstring:**
  `````
  获取所有已注册的队列名称
  
  返回所有通过 @boost 装饰器注册的队列名称列表
  `````

- `def clear_queue()` `flask_blueprint.route('/clear_queue', methods=['POST'])`
  - *Line: 270*
  - **Docstring:**
  `````
  清空队列中的所有消息
  
  请求体 (JSON):
      {
          "queue_name": "队列名称"
      }
  
  返回:
      清空操作的结果
      
  说明:
      此接口会清空指定队列中的所有待消费消息。
      ⚠️ 此操作不可逆，请谨慎使用！
      
  注意:
      broker_kind 会自动从已注册的 booster 中获取，无需手动指定。
  `````

- `def get_one_queue_config()` `flask_blueprint.route('/get_one_queue_config', methods=['GET'])`
  - *Line: 331*
  - **Docstring:**
  `````
  获取单个队列的配置信息
  
  查询参数:
      queue_name: 队列名称（必填）
  
  返回:
      队列的配置信息，包括函数入参信息 (final_func_input_params_info)
  `````

- `def get_queues_config()` `flask_blueprint.route('/get_queues_config', methods=['GET'])`
  - *Line: 369*
  - **Docstring:**
  `````
  获取所有队列的配置信息
  
  返回所有已注册队列的详细配置参数，包括：
  - 队列名称
  - broker 类型
  - 并发数量
  - QPS 限制
  - 是否启用 RPC 模式
  - ！！！重要，消费函数的入参名字列表在 auto_generate_info.final_func_input_params_info 中
  - 等等其他 @boost 装饰器的所有参数
  
  主要用于前端可视化展示和管理
  `````

- `def get_queue_run_info()` `flask_blueprint.route('/get_queue_run_info', methods=['GET'])`
  - *Line: 408*
  - **Docstring:**
  `````
  获取单个队列的运行信息
  
  查询参数:
      queue_name: 队列名称（必填）
  
  返回:
      队列的详细运行信息，包括：
      - queue_params: 队列配置参数
      - active_consumers: 活跃的消费者列表
      - pause_flag: 暂停标志（-1,0表示未暂停，1表示已暂停）
      - msg_num_in_broker: broker中的消息数量（实时）
      - history_run_count: 历史运行总次数
      - history_run_fail_count: 历史失败总次数
      - all_consumers_last_x_s_execute_count: 所有消费进程，最近X秒所有消费者的执行次数
      - all_consumers_last_x_s_execute_count_fail: 所有消费进程，最近X秒所有消费者的失败次数
      - all_consumers_last_x_s_avarage_function_spend_time: 所有消费进程，最近X秒的平均函数耗时
      - all_consumers_avarage_function_spend_time_from_start: 所有消费进程，从启动开始的平均函数耗时
      - all_consumers_total_consume_count_from_start: 所有消费进程，从启动开始的总消费次数
      - all_consumers_total_consume_count_from_start_fail: 所有消费进程，从启动开始的总失败次数
      - all_consumers_last_execute_task_time: 所有消费进程中，最后一次执行任务的时间戳
  `````

- `def add_timing_job()` `flask_blueprint.route('/add_timing_job', methods=['POST'])`
  - *Line: 460*
  - **Docstring:**
  `````
  添加定时任务
  
  支持三种触发方式:
  1. date: 在指定日期时间执行一次
     - 需要提供: run_date
     - 示例: {"trigger": "date", "run_date": "2025-12-03 15:00:00"}
  
  2. interval: 按固定时间间隔执行
     - 需要提供: weeks, days, hours, minutes, seconds 中的至少一个
     - 示例: {"trigger": "interval", "seconds": 10}
  
  3. cron: 按cron表达式执行
     - 需要提供: year, month, day, week, day_of_week, hour, minute, second 中的至少一个
     - 示例: {"trigger": "cron", "hour": "*/2", "minute": "30"}
  
  请求体示例:
  {
      "queue_name": "test_queue",
      "trigger": "interval",
      "seconds": 10,
      "job_id": "my_job_001",
      "job_store_kind": "redis",
      "replace_existing": false
  }
  `````

- `def get_timing_jobs()` `flask_blueprint.route('/get_timing_jobs', methods=['GET'])`
  - *Line: 591*
  - **Docstring:**
  `````
  获取定时任务列表
  
  查询参数:
      queue_name: 队列名称（可选，如果不提供则获取所有队列的任务）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  
  返回格式:
      {
          "succ": True,
          "msg": "获取成功",
          "data": {
              "jobs_by_queue": {
                  "queue_name1": [job1, job2, ...],
                  "queue_name2": [job3, ...],
                  ...
              },
              "total_count": 总任务数
          }
      }
  `````

- `def get_timing_job()` `flask_blueprint.route('/get_timing_job', methods=['GET'])`
  - *Line: 694*
  - **Docstring:**
  `````
  获取单个定时任务的详细信息
  
  查询参数:
      job_id: 任务ID（必填）
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def delete_timing_job()` `flask_blueprint.route('/delete_timing_job', methods=['DELETE'])`
  - *Line: 752*
  - **Docstring:**
  `````
  删除定时任务
  
  查询参数:
      job_id: 任务ID（必填）
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def delete_all_timing_jobs()` `flask_blueprint.route('/delete_all_timing_jobs', methods=['DELETE'])`
  - *Line: 792*
  - **Docstring:**
  `````
  删除所有定时任务
  
  查询参数:
      queue_name: 队列名称（可选，如果不提供则删除所有队列的所有任务）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def pause_timing_job()` `flask_blueprint.route('/pause_timing_job', methods=['POST'])`
  - *Line: 869*
  - **Docstring:**
  `````
  暂停定时任务
  
  查询参数:
      job_id: 任务ID（必填）
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def resume_timing_job()` `flask_blueprint.route('/resume_timing_job', methods=['POST'])`
  - *Line: 909*
  - **Docstring:**
  `````
  恢复定时任务
  
  查询参数:
      job_id: 任务ID（必填）
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def get_scheduler_status()` `flask_blueprint.route('/get_scheduler_status', methods=['GET'])`
  - *Line: 964*
  - **Docstring:**
  `````
  获取定时器调度器状态
  
  查询参数:
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
      
  返回:
      status: 0(已停止), 1(运行中), 2(已暂停)
  `````

- `def pause_scheduler()` `flask_blueprint.route('/pause_scheduler', methods=['POST'])`
  - *Line: 1011*
  - **Docstring:**
  `````
  暂停定时器调度器
  注意：这只会暂停当前进程中的调度器实例。如果部署了多实例，可能需要单独控制。
  
  查询参数:
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def resume_scheduler()` `flask_blueprint.route('/resume_scheduler', methods=['POST'])`
  - *Line: 1053*
  - **Docstring:**
  `````
  恢复运行定时器调度器
  
  查询参数:
      queue_name: 队列名称（必填）
      job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
  `````

- `def deprecate_queue()` `flask_blueprint.route('/deprecate_queue', methods=['DELETE'])`
  - *Line: 1094*
  - **Docstring:**
  `````
  废弃队列 - 从 Redis 的 funboost_all_queue_names set 和 项目的队列名下 移除队列名
  
  请求体 (JSON):
      {
          "queue_name": "要废弃的队列名称"
      }
  
  返回:
      {
          "succ": True/False,
          "msg": "提示信息",
          "data": {
              "queue_name": "队列名称",
              "removed": True/False
          }
      }
  `````

- `def get_care_project_name()` `flask_blueprint.route('/get_care_project_name', methods=['GET'])`
  - *Line: 1149*
  - **Docstring:**
  `````
  获取当前的 care_project_name 设置
  
  返回:
      {
          "succ": True,
          "msg": "获取成功",
          "data": {
              "care_project_name": "项目名称或None"
          }
      }
  `````

- `def set_care_project_name()` `flask_blueprint.route('/set_care_project_name', methods=['POST'])`
  - *Line: 1183*
  - **Docstring:**
  `````
  设置 care_project_name
  
  请求体 (JSON):
      {
          "care_project_name": "项目名称" 或 "" (空字符串表示不限制)
      }
  
  返回:
      {
          "succ": True,
          "msg": "设置成功",
          "data": {
              "care_project_name": "设置后的值"
          }
      }
  `````

- `def get_all_project_names()` `flask_blueprint.route('/get_all_project_names', methods=['GET'])`
  - *Line: 1230*
  - **Docstring:**
  `````
  获取所有已注册的项目名称列表
  
  返回:
      {
          "succ": True,
          "msg": "获取成功",
          "data": {
              "project_names": ["project1", "project2", ...],
              "count": 数量
          }
      }
  `````

- `def index()` `app.route('/')`
  - *Line: 1280*


---

`````python
"""
Flask 开箱即用，作者自带贡献，只需要用户的 app.register_blueprint(flask_blueprint)
即可自动给用户的Flask应用添加常用路由
包括发布消息， 根据task_id获取结果， 获取队列消息数量



使用说明:
    在用户自己的 Flask 项目中:
       app.register_blueprint(flask_blueprint)
    


"""

import traceback
from flask import Blueprint, request, jsonify

from funboost import AsyncResult, TaskOptions
from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter, QueuesConusmerParamsGetter, CareProjectNameEnv
from funboost.faas.faas_util import gen_aps_job_adder
from funboost.core.loggers import get_funboost_file_logger



logger = get_funboost_file_logger(__name__)

# 创建 Blueprint 实例，方便用户 register 到自己的 app 中
# 用户可以使用 app.register_blueprint(flask_blueprint)
flask_blueprint = Blueprint('funboost', __name__, url_prefix='/funboost')


@flask_blueprint.route("/publish", methods=['POST'])
def publish_msg():
    """
    发布消息接口
    
    请求体示例:
    {
        "queue_name": "test_queue",
        "msg_body": {"x": 1, "y": 2},
        "need_result": true,
        "timeout": 60
    }
    """
    status_and_result = None
    task_id = None
    
    try:
        # 获取 JSON 数据
        data = request.get_json()
        if not data:
            return jsonify({
                "succ": False,
                "msg": "请求体必须是 JSON 格式",
                "data": {
                    "task_id": None,
                    "status_and_result": None
                }
            }), 400
        
        queue_name = data.get('queue_name')
        msg_body = data.get('msg_body')
        need_result = data.get('need_result', False)
        timeout = data.get('timeout', 60)
        task_id_param = data.get('task_id')  # 可选：指定 task_id
        
        # 验证必填字段
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 字段必填",
                "data": {
                    "task_id": None,
                    "status_and_result": None
                }
            }), 400
        
        if not msg_body or not isinstance(msg_body, dict):
            return jsonify({
                "succ": False,
                "msg": "msg_body 字段必填且必须是字典类型",
                "data": {
                    "task_id": None,
                    "status_and_result": None
                }
            }), 400
        
        # BoostersManager.get_or_create_booster_by_queue_name 是通过queue_name反向得到或创建booster。
        # 不需要用户亲自判断queue_name，然后精确使用某个非常具体的消费函数，
        publisher = SingleQueueConusmerParamsGetter(queue_name).gen_publisher_for_faas()
        booster_params_by_redis = SingleQueueConusmerParamsGetter(queue_name).get_one_queue_params_use_cache()

        # 检查是否需要 RPC 模式
        if need_result:
            # 开启 RPC 模式发布（同步方式）
            async_result = publisher.publish(
                msg_body,
                task_id=task_id_param,  # 可选：指定 task_id（用于重试失败任务）
                task_options=TaskOptions(is_using_rpc_mode=True)
            )
            task_id = async_result.task_id
            
            # 等待结果（同步方式）
            print(async_result.task_id,timeout)
            status_and_result = AsyncResult(async_result.task_id, timeout=timeout).status_and_result
        else:
            # 普通发布（同步方式），可以指定 task_id
            async_result = publisher.publish(msg_body, task_id=task_id_param)
            task_id = async_result.task_id

        return jsonify({
            "succ": True,
            "msg": f'{queue_name} 队列,消息发布成功',
            "data": {
                "task_id": task_id,
                "status_and_result": status_and_result
            }
        })
        
    except Exception as e:
        return jsonify({
            "succ": False,
            "msg": f'消息发布失败 {type(e)} {e} {traceback.format_exc()}',
            "data": {
                "task_id": task_id,
                "status_and_result": status_and_result
            }
        }), 500


@flask_blueprint.route("/get_result", methods=['GET'])
def get_result():
    """
    根据 task_id 获取任务执行结果
    
    查询参数:
        task_id: str - 任务ID（必填）
        timeout: int - 超时时间，默认5秒
    """
    try:
        task_id = request.args.get('task_id')
        timeout = int(request.args.get('timeout', 5))
        
        if not task_id:
            return jsonify({
                "succ": False,
                "msg": "task_id 参数必填",
                "data": {
                    "task_id": None,
                    "status_and_result": None
                }
            }), 400
        
        # 尝试获取结果，默认给个短的 timeout 防止一直阻塞
        # 注意：如果任务还在运行，AsyncResult 会阻塞直到 timeout
        # 如果任务早已完成并过期，这里可能返回 None
        status_and_result = AsyncResult(task_id, timeout=timeout).status_and_result
        
        if status_and_result is not None:
            return jsonify({
                "succ": True,
                "msg": "获取成功",
                "data": {
                    "task_id": task_id,
                    "status_and_result": status_and_result
                }
            })
        else:
            return jsonify({
                "succ": False,
                "msg": "未获取到结果(可能已过期或未开始执行或超时)",
                "data": {
                    "task_id": task_id,
                    "status_and_result": None
                }
            })
            
    except Exception as e:
        return jsonify({
            "succ": False,
            "msg": f"获取结果出错: {str(e)}",
            "data": {
                "task_id": task_id if 'task_id' in locals() else None,
                "status_and_result": None
            }
        }), 500


@flask_blueprint.route("/get_msg_count", methods=['GET'])
def get_msg_count():
    """
    根据 queue_name 获取消息数量
    
    查询参数:
        queue_name: str - 队列名称（必填）
    """
    try:
        queue_name = request.args.get('queue_name')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 参数必填",
                "data": {
                    "queue_name": None,
                    "count": -1
                }
            },), 400
        

        publisher = SingleQueueConusmerParamsGetter(queue_name).gen_publisher_for_faas()
        # 获取消息数量（注意：某些中间件可能不支持准确计数，返回-1）
        count = publisher.get_message_count()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "queue_name": queue_name,
                "count": count
            }
        })
        
    except Exception as e:
        return jsonify({
            "succ": False,
            "msg": f"获取消息数量失败: {str(e)}",
            "data": {
                "queue_name": queue_name if 'queue_name' in locals() else None,
                "count": -1
            }
        }), 500


@flask_blueprint.route("/get_all_queues", methods=['GET'])
def get_all_queues():
    """
    获取所有已注册的队列名称
    
    返回所有通过 @boost 装饰器注册的队列名称列表
    """
    try:
        # 获取所有队列名称
        all_queues = QueuesConusmerParamsGetter().get_all_queue_names()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "queues": all_queues,
                "count": len(all_queues)
            }
        })
        
    except Exception as e:
        return jsonify({
            "succ": False,
            "msg": f"获取所有队列失败: {str(e)}",
            "data": {
                "queues": [],
                "count": 0
            }
        }), 500




@flask_blueprint.route("/clear_queue", methods=['POST'])
def clear_queue():
    """
    清空队列中的所有消息
    
    请求体 (JSON):
        {
            "queue_name": "队列名称"
        }
    
    返回:
        清空操作的结果
        
    说明:
        此接口会清空指定队列中的所有待消费消息。
        ⚠️ 此操作不可逆，请谨慎使用！
        
    注意:
        broker_kind 会自动从已注册的 booster 中获取，无需手动指定。
    """
    try:
        data = request.get_json()
        queue_name = data.get('queue_name')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 字段必填",
                "data": None
            }), 400
        
        # 通过 queue_name 自动获取对应的 publisher
        publisher = SingleQueueConusmerParamsGetter(queue_name).gen_publisher_for_faas()
        publisher.clear()
        
        return jsonify({
            "succ": True,
            "msg": f"队列 {queue_name} 清空成功",
            "data": {
                "queue_name": queue_name,
                "success": True
            }
        })
        
    except Exception as e:
        logger.exception(f'清空队列失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"清空队列 {queue_name if 'queue_name' in locals() else ''} 失败: {str(e)}",
            "data": {
                "queue_name": queue_name if 'queue_name' in locals() else None,
                "success": False
            }
        }), 500



# ==================== 定时任务管理接口 ====================



@flask_blueprint.route("/get_one_queue_config", methods=['GET'])
def get_one_queue_config():
    """
    获取单个队列的配置信息
    
    查询参数:
        queue_name: 队列名称（必填）
    
    返回:
        队列的配置信息，包括函数入参信息 (final_func_input_params_info)
    """
    try:
        queue_name = request.args.get('queue_name')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 参数必填",
                "data": None
            }), 400
        
        queue_params = SingleQueueConusmerParamsGetter(queue_name).get_one_queue_params()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": queue_params
        })
        
    except Exception as e:
        logger.exception(f'获取队列配置失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取队列配置失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/get_queues_config", methods=['GET'])
def get_queues_config():
    """
    获取所有队列的配置信息
    
    返回所有已注册队列的详细配置参数，包括：
    - 队列名称
    - broker 类型
    - 并发数量
    - QPS 限制
    - 是否启用 RPC 模式
    - ！！！重要，消费函数的入参名字列表在 auto_generate_info.final_func_input_params_info 中
    - 等等其他 @boost 装饰器的所有参数
    
    主要用于前端可视化展示和管理
    """
    try:
        queues_config = QueuesConusmerParamsGetter().get_queues_params()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "queues_config": queues_config,
                "count": len(queues_config)
            }
        })
    except Exception as e:
        logger.exception(f'获取队列配置失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取队列配置失败: {str(e)}",
            "data": {
                "queues_config": {},
                "count": 0
            }
        }), 500


@flask_blueprint.route("/get_queue_run_info", methods=['GET'])
def get_queue_run_info():
    """
    获取单个队列的运行信息
    
    查询参数:
        queue_name: 队列名称（必填）
    
    返回:
        队列的详细运行信息，包括：
        - queue_params: 队列配置参数
        - active_consumers: 活跃的消费者列表
        - pause_flag: 暂停标志（-1,0表示未暂停，1表示已暂停）
        - msg_num_in_broker: broker中的消息数量（实时）
        - history_run_count: 历史运行总次数
        - history_run_fail_count: 历史失败总次数
        - all_consumers_last_x_s_execute_count: 所有消费进程，最近X秒所有消费者的执行次数
        - all_consumers_last_x_s_execute_count_fail: 所有消费进程，最近X秒所有消费者的失败次数
        - all_consumers_last_x_s_avarage_function_spend_time: 所有消费进程，最近X秒的平均函数耗时
        - all_consumers_avarage_function_spend_time_from_start: 所有消费进程，从启动开始的平均函数耗时
        - all_consumers_total_consume_count_from_start: 所有消费进程，从启动开始的总消费次数
        - all_consumers_total_consume_count_from_start_fail: 所有消费进程，从启动开始的总失败次数
        - all_consumers_last_execute_task_time: 所有消费进程中，最后一次执行任务的时间戳
    """
    try:
        queue_name = request.args.get('queue_name')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 参数必填",
                "data": None
            }), 400
        
        # 获取单个队列的运行信息
        queue_info = SingleQueueConusmerParamsGetter(queue_name).get_one_queue_params_and_active_consumers()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": queue_info
        })
        
    except Exception as e:
        logger.exception(f'获取队列运行信息失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取队列运行信息失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/add_timing_job", methods=['POST'])
def add_timing_job():
    """
    添加定时任务
    
    支持三种触发方式:
    1. date: 在指定日期时间执行一次
       - 需要提供: run_date
       - 示例: {"trigger": "date", "run_date": "2025-12-03 15:00:00"}
    
    2. interval: 按固定时间间隔执行
       - 需要提供: weeks, days, hours, minutes, seconds 中的至少一个
       - 示例: {"trigger": "interval", "seconds": 10}
    
    3. cron: 按cron表达式执行
       - 需要提供: year, month, day, week, day_of_week, hour, minute, second 中的至少一个
       - 示例: {"trigger": "cron", "hour": "*/2", "minute": "30"}
    
    请求体示例:
    {
        "queue_name": "test_queue",
        "trigger": "interval",
        "seconds": 10,
        "job_id": "my_job_001",
        "job_store_kind": "redis",
        "replace_existing": false
    }
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                "succ": False,
                "msg": "请求体必须是 JSON 格式",
                "data": None
            }), 400
        
        queue_name = data.get('queue_name')
        trigger = data.get('trigger')
        job_id = data.get('job_id')
        job_store_kind = data.get('job_store_kind', 'redis')
        replace_existing = data.get('replace_existing', False)
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 字段必填",
                "data": None
            }), 400
        
        if not trigger or trigger not in ['date', 'interval', 'cron']:
            return jsonify({
                "succ": False,
                "msg": "trigger 字段必填，且必须是 'date', 'interval', 'cron' 之一",
                "data": None
            }), 400
        
        # 获取 booster
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)

        # print(888888,job_adder.aps_obj,id(job_adder.aps_obj),job_adder.aps_obj.get_jobs())

        # 构建触发器参数
        trigger_args = {}
        
        if trigger == 'date':
            if data.get('run_date'):
                trigger_args['run_date'] = data.get('run_date')
        
        elif trigger == 'interval':
            if data.get('weeks') is not None:
                trigger_args['weeks'] = data.get('weeks')
            if data.get('days') is not None:
                trigger_args['days'] = data.get('days')
            if data.get('hours') is not None:
                trigger_args['hours'] = data.get('hours')
            if data.get('minutes') is not None:
                trigger_args['minutes'] = data.get('minutes')
            if data.get('seconds') is not None:
                trigger_args['seconds'] = data.get('seconds')
        
        elif trigger == 'cron':
            if data.get('year') is not None:
                trigger_args['year'] = data.get('year')
            if data.get('month') is not None:
                trigger_args['month'] = data.get('month')
            if data.get('day') is not None:
                trigger_args['day'] = data.get('day')
            if data.get('week') is not None:
                trigger_args['week'] = data.get('week')
            if data.get('day_of_week') is not None:
                trigger_args['day_of_week'] = data.get('day_of_week')
            if data.get('hour') is not None:
                trigger_args['hour'] = data.get('hour')
            if data.get('minute') is not None:
                trigger_args['minute'] = data.get('minute')
            if data.get('second') is not None:
                trigger_args['second'] = data.get('second')
        
        # 添加任务
        job = job_adder.add_push_job(
            trigger=trigger,
            args=data.get('args'),
            kwargs=data.get('kwargs'),
            id=job_id,
            replace_existing=replace_existing,
            **trigger_args
        )
        
        return jsonify({
            "succ": True,
            "msg": "定时任务添加成功",
            "data": {
                "job_id": job.id,
                "queue_name": queue_name,
                "trigger": str(job.trigger),
                "next_run_time": str(job.next_run_time) if job.next_run_time else None,
                "status": "running",
                "kwargs": data.get('kwargs')
            }
        })
        
    except Exception as e:
        logger.exception(f'添加定时任务失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"添加定时任务失败: {str(e)}\n{traceback.format_exc()}",
            "data": None
        }), 500


@flask_blueprint.route("/get_timing_jobs", methods=['GET'])
def get_timing_jobs():
    """
    获取定时任务列表
    
    查询参数:
        queue_name: 队列名称（可选，如果不提供则获取所有队列的任务）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    
    返回格式:
        {
            "succ": True,
            "msg": "获取成功",
            "data": {
                "jobs_by_queue": {
                    "queue_name1": [job1, job2, ...],
                    "queue_name2": [job3, ...],
                    ...
                },
                "total_count": 总任务数
            }
        }
    """
    try:
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        # 使用字典格式存储：{queue_name: [jobs]}
        jobs_by_queue = {}
        total_count = 0
        
        if queue_name:
            # 获取指定队列的任务
            jobs_by_queue[queue_name] = []
            try:
                job_adder = gen_aps_job_adder(queue_name, job_store_kind)
                jobs = job_adder.aps_obj.get_jobs()
                
                for job in jobs:
                    # 判断任务状态：next_run_time 为 None 表示任务已暂停
                    status = "paused" if job.next_run_time is None else "running"
                    # 获取任务的 kwargs 参数
                    kwargs = job.kwargs if hasattr(job, 'kwargs') and job.kwargs else {}
                    jobs_by_queue[queue_name].append({
                        "job_id": job.id,
                        "queue_name": queue_name,
                        "trigger": str(job.trigger),
                        "next_run_time": str(job.next_run_time) if job.next_run_time else None,
                        "status": status,
                        "kwargs": kwargs
                    })
                    total_count += 1
            except Exception as e:
                logger.exception(f'获取定时任务列表失败: {str(e)}')
               
        else:
            # 获取所有队列的任务
            all_queues = list(QueuesConusmerParamsGetter().get_all_queue_names())
            for q_name in all_queues:
                jobs_by_queue[q_name] = []  # 初始化为空数组
                try:
                    job_adder = gen_aps_job_adder(q_name, job_store_kind)
                    jobs = job_adder.aps_obj.get_jobs()
                    
                    for job in jobs:
                        # 判断任务状态：next_run_time 为 None 表示任务已暂停
                        status = "paused" if job.next_run_time is None else "running"
                        # 获取任务的 kwargs 参数
                        kwargs = job.kwargs if hasattr(job, 'kwargs') and job.kwargs else {}
                        jobs_by_queue[q_name].append({
                            "job_id": job.id,
                            "queue_name": q_name,
                            "trigger": str(job.trigger),
                            "next_run_time": str(job.next_run_time) if job.next_run_time else None,
                            "status": status,
                            "kwargs": kwargs
                        })
                        total_count += 1
                except Exception as e:
                    logger.exception(f'获取定时任务列表失败: {str(e)}')
                 
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "jobs_by_queue": jobs_by_queue,
                "total_count": total_count
            }
        })
        
    except Exception as e:
        logger.exception(f'获取定时任务列表失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取定时任务列表失败: {str(e)}",
            "data": {
                "jobs_by_queue": {},
                "total_count": 0
            }
        }), 500


@flask_blueprint.route("/get_timing_job", methods=['GET'])
def get_timing_job():
    """
    获取单个定时任务的详细信息
    
    查询参数:
        job_id: 任务ID（必填）
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        job_id = request.args.get('job_id')
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not job_id or not queue_name:
            return jsonify({
                "succ": False,
                "msg": "job_id 和 queue_name 参数必填",
                "data": None
            }), 400
        
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        
        # 获取指定的任务
        job = job_adder.aps_obj.get_job(job_id)
        
        if job:
            status = "paused" if job.next_run_time is None else "running"
            kwargs = job.kwargs if hasattr(job, 'kwargs') and job.kwargs else {}
            return jsonify({
                "succ": True,
                "msg": "获取成功",
                "data": {
                    "job_id": job.id,
                    "queue_name": queue_name,
                    "trigger": str(job.trigger),
                    "next_run_time": str(job.next_run_time) if job.next_run_time else None,
                    "status": status,
                    "kwargs": kwargs
                }
            })
        else:
            return jsonify({
                "succ": False,
                "msg": f"任务 {job_id} 不存在",
                "data": None
            }), 404
        
    except Exception as e:
        logger.exception(f'获取定时任务失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取定时任务失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/delete_timing_job", methods=['DELETE'])
def delete_timing_job():
    """
    删除定时任务
    
    查询参数:
        job_id: 任务ID（必填）
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        job_id = request.args.get('job_id')
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not job_id or not queue_name:
            return jsonify({
                "succ": False,
                "msg": "job_id 和 queue_name 参数必填",
                "data": None
            }), 400
        
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.remove_job(job_id)
        
        return jsonify({
            "succ": True,
            "msg": f"定时任务 {job_id} 删除成功",
            "data": None
        })
        
    except Exception as e:
        logger.exception(f'删除定时任务失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"删除定时任务失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/delete_all_timing_jobs", methods=['DELETE'])
def delete_all_timing_jobs():
    """
    删除所有定时任务
    
    查询参数:
        queue_name: 队列名称（可选，如果不提供则删除所有队列的所有任务）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        deleted_count = 0
        failed_jobs = []
        
        if queue_name:
            # 删除指定队列的所有任务
            try:
                job_adder = gen_aps_job_adder(queue_name, job_store_kind)
                jobs = job_adder.aps_obj.get_jobs()
                
                for job in jobs:
                    try:
                        job_adder.aps_obj.remove_job(job.id)
                        deleted_count += 1
                    except Exception as e:
                        failed_jobs.append(f"{job.id}: {str(e)}")
            except Exception as e:
                return jsonify({
                    "succ": False,
                    "msg": f"删除队列 {queue_name} 的任务失败: {str(e)}",
                    "data": {
                        "deleted_count": deleted_count,
                        "failed_jobs": failed_jobs
                    }
                }), 500
        else:
            # 删除所有队列的所有任务
            all_queues = list(QueuesConusmerParamsGetter().get_all_queue_names())
            for q_name in all_queues:
                try:
                    job_adder = gen_aps_job_adder(q_name, job_store_kind)
                    jobs = job_adder.aps_obj.get_jobs()
                    
                    for job in jobs:
                        try:
                            job_adder.aps_obj.remove_job(job.id)
                            deleted_count += 1
                        except Exception as e:
                            failed_jobs.append(f"{q_name}/{job.id}: {str(e)}")
                except Exception as e:
                    logger.exception(f'删除队列 {q_name} 的任务失败: {str(e)}')
                    # 队列没有任务或出错，继续处理下一个队列
                    
        
        return jsonify({
            "succ": True,
            "msg": f"成功删除 {deleted_count} 个定时任务",
            "data": {
                "deleted_count": deleted_count,
                "failed_jobs": failed_jobs
            }
        })
        
    except Exception as e:
        logger.exception(f'删除所有定时任务失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"删除所有定时任务失败: {str(e)}",
            "data": {
                "deleted_count": 0,
                "failed_jobs": []
            }
        }), 500


@flask_blueprint.route("/pause_timing_job", methods=['POST'])
def pause_timing_job():
    """
    暂停定时任务
    
    查询参数:
        job_id: 任务ID（必填）
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        job_id = request.args.get('job_id')
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not job_id or not queue_name:
            return jsonify({
                "succ": False,
                "msg": "job_id 和 queue_name 参数必填",
                "data": None
            }), 400
        
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.pause_job(job_id)
        
        return jsonify({
            "succ": True,
            "msg": f"定时任务 {job_id} 已暂停",
            "data": None
        })
        
    except Exception as e:
        logger.exception(f'暂停定时任务失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"暂停定时任务失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/resume_timing_job", methods=['POST'])
def resume_timing_job():
    """
    恢复定时任务
    
    查询参数:
        job_id: 任务ID（必填）
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        job_id = request.args.get('job_id')
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not job_id or not queue_name:
            return jsonify({
                "succ": False,
                "msg": "job_id 和 queue_name 参数必填",
                "data": None
            }), 400
        
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.resume_job(job_id)
        
        return jsonify({
            "succ": True,
            "msg": f"定时任务 {job_id} 已恢复",
            "data": None
        })
        
    except Exception as e:
        logger.exception(f'恢复定时任务失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"恢复定时任务失败: {str(e)}",
            "data": None
        }), 500

















@flask_blueprint.route("/get_scheduler_status", methods=['GET'])
def get_scheduler_status():
    """
    获取定时器调度器状态
    
    查询参数:
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
        
    返回:
        status: 0(已停止), 1(运行中), 2(已暂停)
    """
    try:
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 参数必填",
                "data": None
            }), 400
            
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        
        state_map = {0: 'stopped', 1: 'running', 2: 'paused'}
        state = job_adder.aps_obj.state
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "queue_name": queue_name,
                "status_code": state,
                "status_str": state_map.get(state, 'unknown')
            }
        })
        
    except Exception as e:
        logger.exception(f'获取调度器状态失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取调度器状态失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/pause_scheduler", methods=['POST'])
def pause_scheduler():
    """
    暂停定时器调度器
    注意：这只会暂停当前进程中的调度器实例。如果部署了多实例，可能需要单独控制。
    
    查询参数:
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 参数必填",
                "data": None
            }), 400
            
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.pause()
        
        return jsonify({
            "succ": True,
            "msg": f"调度器已暂停 ({queue_name})",
            "data": {
                "queue_name": queue_name,
                "status_str": "paused"
            }
        })
        
    except Exception as e:
        logger.exception(f'暂停调度器失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"暂停调度器失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/resume_scheduler", methods=['POST'])
def resume_scheduler():
    """
    恢复运行定时器调度器
    
    查询参数:
        queue_name: 队列名称（必填）
        job_store_kind: 任务存储方式，'redis' 或 'memory'，默认 'redis'
    """
    try:
        queue_name = request.args.get('queue_name')
        job_store_kind = request.args.get('job_store_kind', 'redis')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "queue_name 参数必填",
                "data": None
            }), 400
            
        job_adder = gen_aps_job_adder(queue_name, job_store_kind)
        job_adder.aps_obj.resume()
        
        return jsonify({
            "succ": True,
            "msg": f"调度器已恢复运行 ({queue_name})",
            "data": {
                "queue_name": queue_name,
                "status_str": "running"
            }
        })
        
    except Exception as e:
        logger.exception(f'恢复调度器失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"恢复调度器失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/deprecate_queue", methods=['DELETE'])
def deprecate_queue():
    """
    废弃队列 - 从 Redis 的 funboost_all_queue_names set 和 项目的队列名下 移除队列名
    
    请求体 (JSON):
        {
            "queue_name": "要废弃的队列名称"
        }
    
    返回:
        {
            "succ": True/False,
            "msg": "提示信息",
            "data": {
                "queue_name": "队列名称",
                "removed": True/False
            }
        }
    """
    try:
        data = request.get_json()
        queue_name = data.get('queue_name')
        
        if not queue_name:
            return jsonify({
                "succ": False,
                "msg": "缺少参数 queue_name",
                "data": None
            }), 400
        
        # 调用 SingleQueueConusmerParamsGetter 的 deprecate_queue 方法
        SingleQueueConusmerParamsGetter(queue_name).deprecate_queue()
        
        logger.info(f'成功废弃队列: {queue_name}')
        return jsonify({
            "succ": True,
            "msg": f"成功废弃队列: {queue_name}",
            "data": {
                "queue_name": queue_name,
                "removed": True
            }
        })
        
    except Exception as e:
        logger.exception(f'废弃队列失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"废弃队列失败: {str(e)}",
            "data": None
        }), 500


# ==================== care_project_name 项目筛选接口 ====================

@flask_blueprint.route("/get_care_project_name", methods=['GET'])
def get_care_project_name():
    """
    获取当前的 care_project_name 设置
    
    返回:
        {
            "succ": True,
            "msg": "获取成功",
            "data": {
                "care_project_name": "项目名称或None"
            }
        }
    """
    try:
        care_project_name = CareProjectNameEnv.get()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "care_project_name": care_project_name
            }
        })
        
    except Exception as e:
        logger.exception(f'获取 care_project_name 失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/set_care_project_name", methods=['POST'])
def set_care_project_name():
    """
    设置 care_project_name
    
    请求体 (JSON):
        {
            "care_project_name": "项目名称" 或 "" (空字符串表示不限制)
        }
    
    返回:
        {
            "succ": True,
            "msg": "设置成功",
            "data": {
                "care_project_name": "设置后的值"
            }
        }
    """
    try:
        data = request.get_json()
        care_project_name = data.get('care_project_name', '')
        
        # 空字符串表示清除限制，设置为空字符串（环境变量中）
        CareProjectNameEnv.set(care_project_name)
        
        # 如果设置为空字符串，返回时显示为 None
        display_value = care_project_name if care_project_name else None
        
        logger.info(f'设置 care_project_name 为: {display_value}')
        return jsonify({
            "succ": True,
            "msg": f"设置成功: {display_value if display_value else '不限制（显示全部）'}",
            "data": {
                "care_project_name": display_value
            }
        })
        
    except Exception as e:
        logger.exception(f'设置 care_project_name 失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"设置失败: {str(e)}",
            "data": None
        }), 500


@flask_blueprint.route("/get_all_project_names", methods=['GET'])
def get_all_project_names():
    """
    获取所有已注册的项目名称列表
    
    返回:
        {
            "succ": True,
            "msg": "获取成功",
            "data": {
                "project_names": ["project1", "project2", ...],
                "count": 数量
            }
        }
    """
    try:
        # 使用 QueuesConusmerParamsGetter 获取所有项目名称
        project_names = QueuesConusmerParamsGetter().get_all_project_names()
        
        return jsonify({
            "succ": True,
            "msg": "获取成功",
            "data": {
                "project_names": sorted(project_names) if project_names else [],
                "count": len(project_names) if project_names else 0
            }
        })
        
    except Exception as e:
        logger.exception(f'获取项目名称列表失败: {str(e)}')
        return jsonify({
            "succ": False,
            "msg": f"获取项目名称列表失败: {str(e)}",
            "data": {
                "project_names": [],
                "count": 0
            }
        }), 500


# 运行应用 (仅在作为主脚本运行时创建 app)
if __name__ == "__main__":
    from flask import Flask


    # 这是一个示例，展示用户如何将 flask_blueprint 集成到自己的 app 中
    app = Flask(__name__)
    app.config['JSON_AS_ASCII'] = False
    app.register_blueprint(flask_blueprint)

    @app.route('/')
    def index():
        return "Funboost Flask API 服务运行中！"

    print("启动 Funboost Flask API 服务...")
    print("访问地址: http://127.0.0.1:5000")

    app.run(host="0.0.0.0", port=5000, debug=True)

`````

--- **end of file: funboost/faas/flask_adapter.py** (project: funboost) --- 

---


--- **start of file: funboost/faas/README.md** (project: funboost) --- 

`````markdown
## 详细见教程4.38章节


## funboost.faas 给各种python流行web框架一键增加funboost api路由接口

`funboost.faas` 内置了对多个主流web框架的开箱即用的贡献，用户无需再亲自重复在各种python web框架中写发布消息和获取结果的的路由接口，和获取消息队列，和定时任务接口

###  funboost.faas 开箱即用  
给你自己的web服务轻松一键新增 多个 funboost 的路由接口，   

**支持的框架包括：**  
- fastapi
- flask
- django






### 使用举例
#### 举例fastapi
```
from funboost.faas import fastapi_router, CareProjectNameEnv

app = FastAPI() # app是你的fastapi app，你只需要添加这个router fastapi_router，即可一键增加多个funboost的路由接口

CareProjectNameEnv.set('test_project1') # 可选，只关注指定的test_project1项目下的队列

app.include_router(fastapi_router)
```


`````

--- **end of file: funboost/faas/README.md** (project: funboost) --- 

---


--- **start of file: funboost/faas/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/faas/__init__.py`

#### 📝 Module Docstring

`````
惰性导入机制：只在用户实际访问时才导入对应的 router
这样用户只使用 fastapi 时不会因为 flask/django 未安装而报错
`````

#### 📦 Imports

- `import typing`
- `from funboost.core.active_cousumer_info_getter import ActiveCousumerProcessInfoGetter`
- `from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import CareProjectNameEnv`
- `from fastapi_adapter import fastapi_router`
- `from flask_adapter import flask_blueprint`
- `from django_adapter import django_router`


---

`````python
# funboost/faas/__init__.py

"""
惰性导入机制：只在用户实际访问时才导入对应的 router
这样用户只使用 fastapi 时不会因为 flask/django 未安装而报错
"""

import typing


from funboost.core.active_cousumer_info_getter import (
    ActiveCousumerProcessInfoGetter,
    QueuesConusmerParamsGetter,
    SingleQueueConusmerParamsGetter,
    CareProjectNameEnv,
 )


# 动态导入配置：映射表定义了所有支持的router
_ROUTER_CONFIG = {
    'fastapi_router': {
        'module': 'fastapi_adapter',
        'attr': 'fastapi_router',
        'package': 'fastapi',
    },
    'flask_blueprint': {
        'module': 'flask_adapter',
        'attr': 'flask_blueprint',
        'package': 'flask',
    },
    'django_router': {
        'module': 'django_adapter',
        'attr': 'django_router',
        'package': 'django-ninja',
    },
}

# 动态导入的缓存
_cache = {}


def __getattr__(name: str):
    """
    惰性导入机制：只在用户实际访问时才导入对应的 router
    这样用户只使用 fastapi 时不会因为 flask/django 未安装而报错
    """
    # 检查是否是支持的router
    if name not in _ROUTER_CONFIG:
        raise AttributeError(f"module '{__name__}' has no attribute '{name}'")
    
    # 如果已缓存，直接返回
    if name in _cache:
        return _cache[name]
    
    # 获取配置信息
    config = _ROUTER_CONFIG[name]
    
    # 动态导入
    try:
        module = __import__(
            f"{__package__}.{config['module']}", 
            fromlist=[config['attr']]
        )
        router_obj = getattr(module, config['attr'])
        _cache[name] = router_obj
        return router_obj
    except ImportError as e:
        raise ImportError(
            f"无法导入 {name}，请先安装 {config['package']}: pip install {config['package']}\n"
            f"原始错误: {e}"
        )


# 定义 __all__ 以支持 from funboost.faas import *
__all__ = [
    'ActiveCousumerProcessInfoGetter',
    'QueuesConusmerParamsGetter',
    'SingleQueueConusmerParamsGetter',
    'CareProjectNameEnv',
    'fastapi_router',
    'flask_blueprint',
    'django_router',
]


# 4. 类型检查支持 (让 PyCharm/VSCode 能补全)
if typing.TYPE_CHECKING:
    # 这里只是给 IDE 看的，运行时不会执行，所以不会报错
    from .fastapi_adapter import fastapi_router 
    from .flask_adapter import flask_blueprint
    from .django_adapter import django_router
`````

--- **end of file: funboost/faas/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/factories/broker_kind__publsiher_consumer_type_map.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/factories/broker_kind__publsiher_consumer_type_map.py`

#### 📦 Imports

- `import typing`
- `from funboost.publishers.empty_publisher import EmptyPublisher`
- `from funboost.publishers.nats_publisher import NatsPublisher`
- `from funboost.publishers.peewee_publisher import PeeweePublisher`
- `from funboost.publishers.redis_publisher_lpush import RedisPublisherLpush`
- `from funboost.publishers.redis_publisher_priority import RedisPriorityPublisher`
- `from funboost.publishers.redis_pubsub_publisher import RedisPubSubPublisher`
- `from funboost.publishers.tcp_publisher import TCPPublisher`
- `from funboost.publishers.txt_file_publisher import TxtFilePublisher`
- `from funboost.publishers.udp_publisher import UDPPublisher`
- `from funboost.publishers.zeromq_publisher import ZeroMqPublisher`
- `from funboost.publishers.kafka_publisher import KafkaPublisher`
- `from funboost.publishers.local_python_queue_publisher import LocalPythonQueuePublisher`
- `from funboost.publishers.mongomq_publisher import MongoMqPublisher`
- `from funboost.publishers.persist_queue_publisher import PersistQueuePublisher`
- `from funboost.publishers.rabbitmq_pika_publisher import RabbitmqPublisher`
- `from funboost.publishers.redis_publisher import RedisPublisher`
- `from funboost.publishers.rocketmq_publisher import RocketmqPublisher`
- `from funboost.publishers.redis_stream_publisher import RedisStreamPublisher`
- `from funboost.publishers.mqtt_publisher import MqttPublisher`
- `from funboost.publishers.httpsqs_publisher import HttpsqsPublisher`
- `from funboost.consumers.empty_consumer import EmptyConsumer`
- `from funboost.consumers.redis_consumer_priority import RedisPriorityConsumer`
- `from funboost.consumers.redis_pubsub_consumer import RedisPbSubConsumer`
- `from funboost.consumers.kafka_consumer import KafkaConsumer`
- `from funboost.consumers.local_python_queue_consumer import LocalPythonQueueConsumer`
- `from funboost.consumers.mongomq_consumer import MongoMqConsumer`
- `from funboost.consumers.nats_consumer import NatsConsumer`
- `from funboost.consumers.peewee_conusmer import PeeweeConsumer`
- `from funboost.consumers.persist_queue_consumer import PersistQueueConsumer`
- `from funboost.consumers.rabbitmq_pika_consumer import RabbitmqConsumer`
- `from funboost.consumers.redis_brpoplpush_consumer import RedisBrpopLpushConsumer`
- `from funboost.consumers.redis_consumer import RedisConsumer`
- `from funboost.consumers.redis_consumer_ack_able import RedisConsumerAckAble`
- `from funboost.consumers.rocketmq_consumer import RocketmqConsumer`
- `from funboost.consumers.redis_stream_consumer import RedisStreamConsumer`
- `from funboost.consumers.tcp_consumer import TCPConsumer`
- `from funboost.consumers.txt_file_consumer import TxtFileConsumer`
- `from funboost.consumers.udp_consumer import UDPConsumer`
- `from funboost.consumers.zeromq_consumer import ZeroMqConsumer`
- `from funboost.consumers.mqtt_consumer import MqttConsumer`
- `from funboost.consumers.httpsqs_consumer import HttpsqsConsumer`
- `from funboost.consumers.redis_consumer_ack_using_timeout import RedisConsumerAckUsingTimeout`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.constant import BrokerEnum`
- `import sys`
- `from funboost.publishers.rabbitmq_amqpstorm_publisher import RabbitmqPublisherUsingAmqpStorm`
- `from funboost.consumers.rabbitmq_amqpstorm_consumer import RabbitmqConsumerAmqpStorm`
- `from funboost.publishers.rabbitmq_complex_routing_publisher import RabbitmqComplexRoutingPublisher`
- `from funboost.consumers.rabbitmq_complex_routing_consumer import RabbitmqComplexRoutingConsumer`
- `from funboost.publishers.rabbitmq_rabbitpy_publisher import RabbitmqPublisherUsingRabbitpy`
- `from funboost.consumers.rabbitmq_rabbitpy_consumer import RabbitmqConsumerRabbitpy`
- `from funboost.consumers.pulsar_consumer import PulsarConsumer`
- `from funboost.publishers.pulsar_publisher import PulsarPublisher`
- `from funboost.consumers.celery_consumer import CeleryConsumer`
- `from funboost.publishers.celery_publisher import CeleryPublisher`
- `from funboost.consumers.nameko_consumer import NamekoConsumer`
- `from funboost.publishers.nameko_publisher import NamekoPublisher`
- `from funboost.consumers.sqlachemy_consumer import SqlachemyConsumer`
- `from funboost.publishers.sqla_queue_publisher import SqlachemyQueuePublisher`
- `from funboost.consumers.dramatiq_consumer import DramatiqConsumer`
- `from funboost.publishers.dramatiq_publisher import DramatiqPublisher`
- `from funboost.consumers.huey_consumer import HueyConsumer`
- `from funboost.publishers.huey_publisher import HueyPublisher`
- `from funboost.consumers.kafka_consumer_manually_commit import KafkaConsumerManuallyCommit`
- `from funboost.publishers.confluent_kafka_publisher import ConfluentKafkaPublisher`
- `from funboost.consumers.kafka_consumer_manually_commit import SaslPlainKafkaConsumer`
- `from funboost.publishers.confluent_kafka_publisher import SaslPlainKafkaPublisher`
- `from funboost.consumers.rq_consumer import RqConsumer`
- `from funboost.publishers.rq_publisher import RqPublisher`
- `from funboost.consumers.kombu_consumer import KombuConsumer`
- `from funboost.publishers.kombu_publisher import KombuPublisher`
- `from funboost.publishers.nsq_publisher import NsqPublisher`
- `from funboost.consumers.nsq_consumer import NsqConsumer`
- `from funboost.consumers.grpc_consumer import GrpcConsumer`
- `from funboost.publishers.grpc_publisher import GrpcPublisher`
- `from funboost.consumers.mysql_cdc_consumer import MysqlCdcConsumer`
- `from funboost.publishers.mysql_cdc_publisher import MysqlCdcPublisher`
- `from funboost.consumers.http_consumer import HTTPConsumer`
- `from funboost.publishers.http_publisher import HTTPPublisher`

#### 🔧 Public Functions (2)

- `def register_custom_broker(broker_kind, publisher_class: typing.Type[AbstractPublisher], consumer_class: typing.Type[AbstractConsumer])`
  - *Line: 91*
  - **Docstring:**
  `````
  动态注册中间件到框架中， 方便的增加中间件类型或者修改是自定义消费者逻辑。
  :param broker_kind:
  :param publisher_class:
  :param consumer_class:
  :return:
  `````

- `def regist_to_funboost(broker_kind: str)`
  - *Line: 107*
  - **Docstring:**
  `````
  不直接定义在broker_kind__publsiher_consumer_type_map, 延迟导入是因为funboost没有pip自动安装这些三方包，防止一启动就报错。
  这样当用户需要使用某些三方包中间件作为消息队列时候，按照import报错信息，用户自己去pip安装好。或者 pip install funboost[all] 一次性安装所有中间件。
  建议按照 https://github.com/ydf0509/funboost/blob/master/setup.py 中的 extra_brokers 和 install_requires 里面的版本号来安装三方包版本.
  `````


---

`````python
import typing

from funboost.publishers.empty_publisher import EmptyPublisher

from funboost.publishers.nats_publisher import NatsPublisher
from funboost.publishers.peewee_publisher import PeeweePublisher
from funboost.publishers.redis_publisher_lpush import RedisPublisherLpush
from funboost.publishers.redis_publisher_priority import RedisPriorityPublisher
from funboost.publishers.redis_pubsub_publisher import RedisPubSubPublisher
from funboost.publishers.tcp_publisher import TCPPublisher
from funboost.publishers.txt_file_publisher import TxtFilePublisher
from funboost.publishers.udp_publisher import UDPPublisher
from funboost.publishers.zeromq_publisher import ZeroMqPublisher
from funboost.publishers.kafka_publisher import KafkaPublisher
from funboost.publishers.local_python_queue_publisher import LocalPythonQueuePublisher
from funboost.publishers.mongomq_publisher import MongoMqPublisher

from funboost.publishers.persist_queue_publisher import PersistQueuePublisher

from funboost.publishers.rabbitmq_pika_publisher import RabbitmqPublisher

from funboost.publishers.redis_publisher import RedisPublisher
from funboost.publishers.rocketmq_publisher import RocketmqPublisher
from funboost.publishers.redis_stream_publisher import RedisStreamPublisher
from funboost.publishers.mqtt_publisher import MqttPublisher
from funboost.publishers.httpsqs_publisher import HttpsqsPublisher

from funboost.consumers.empty_consumer import EmptyConsumer
from funboost.consumers.redis_consumer_priority import RedisPriorityConsumer
from funboost.consumers.redis_pubsub_consumer import RedisPbSubConsumer

from funboost.consumers.kafka_consumer import KafkaConsumer
from funboost.consumers.local_python_queue_consumer import LocalPythonQueueConsumer
from funboost.consumers.mongomq_consumer import MongoMqConsumer
from funboost.consumers.nats_consumer import NatsConsumer

from funboost.consumers.peewee_conusmer import PeeweeConsumer
from funboost.consumers.persist_queue_consumer import PersistQueueConsumer
from funboost.consumers.rabbitmq_pika_consumer import RabbitmqConsumer

from funboost.consumers.redis_brpoplpush_consumer import RedisBrpopLpushConsumer
from funboost.consumers.redis_consumer import RedisConsumer
from funboost.consumers.redis_consumer_ack_able import RedisConsumerAckAble
from funboost.consumers.rocketmq_consumer import RocketmqConsumer
from funboost.consumers.redis_stream_consumer import RedisStreamConsumer
from funboost.consumers.tcp_consumer import TCPConsumer
from funboost.consumers.txt_file_consumer import TxtFileConsumer
from funboost.consumers.udp_consumer import UDPConsumer
from funboost.consumers.zeromq_consumer import ZeroMqConsumer
from funboost.consumers.mqtt_consumer import MqttConsumer
from funboost.consumers.httpsqs_consumer import HttpsqsConsumer
from funboost.consumers.redis_consumer_ack_using_timeout import RedisConsumerAckUsingTimeout

from funboost.publishers.base_publisher import AbstractPublisher
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.constant import BrokerEnum

broker_kind__publsiher_consumer_type_map = {


    BrokerEnum.REDIS: (RedisPublisher, RedisConsumer),
    BrokerEnum.MEMORY_QUEUE: (LocalPythonQueuePublisher, LocalPythonQueueConsumer),
    BrokerEnum.RABBITMQ_PIKA: (RabbitmqPublisher, RabbitmqConsumer),
    BrokerEnum.MONGOMQ: (MongoMqPublisher, MongoMqConsumer),
    BrokerEnum.PERSISTQUEUE: (PersistQueuePublisher, PersistQueueConsumer),
    BrokerEnum.KAFKA: (KafkaPublisher, KafkaConsumer),
    BrokerEnum.REDIS_ACK_ABLE: (RedisPublisher, RedisConsumerAckAble),
    BrokerEnum.REDIS_PRIORITY: (RedisPriorityPublisher, RedisPriorityConsumer),
    BrokerEnum.ROCKETMQ: (RocketmqPublisher, RocketmqConsumer),
    BrokerEnum.REDIS_STREAM: (RedisStreamPublisher, RedisStreamConsumer),
    BrokerEnum.ZEROMQ: (ZeroMqPublisher, ZeroMqConsumer),
    BrokerEnum.RedisBrpopLpush: (RedisPublisherLpush, RedisBrpopLpushConsumer),
    BrokerEnum.MQTT: (MqttPublisher, MqttConsumer),
    BrokerEnum.HTTPSQS: (HttpsqsPublisher, HttpsqsConsumer),
    BrokerEnum.UDP: (UDPPublisher, UDPConsumer),
    BrokerEnum.TCP: (TCPPublisher, TCPConsumer),

    BrokerEnum.NATS: (NatsPublisher, NatsConsumer),
    BrokerEnum.TXT_FILE: (TxtFilePublisher, TxtFileConsumer),
    BrokerEnum.PEEWEE: (PeeweePublisher, PeeweeConsumer),
    BrokerEnum.REDIS_PUBSUB: (RedisPubSubPublisher, RedisPbSubConsumer),
    BrokerEnum.REIDS_ACK_USING_TIMEOUT: (RedisPublisher, RedisConsumerAckUsingTimeout),
    BrokerEnum.EMPTY:(EmptyPublisher,EmptyConsumer),

}

for broker_kindx, cls_tuple in broker_kind__publsiher_consumer_type_map.items():
    cls_tuple[1].BROKER_KIND = broker_kindx


def register_custom_broker(broker_kind, publisher_class: typing.Type[AbstractPublisher], consumer_class: typing.Type[AbstractConsumer]):
    """
    动态注册中间件到框架中， 方便的增加中间件类型或者修改是自定义消费者逻辑。
    :param broker_kind:
    :param publisher_class:
    :param consumer_class:
    :return:
    """
    if not issubclass(publisher_class, AbstractPublisher):
        raise TypeError(f'publisher_class 必须是 AbstractPublisher 的子或孙类')
    if not issubclass(consumer_class, AbstractConsumer):
        raise TypeError(f'consumer_class 必须是 AbstractConsumer 的子或孙类')
    broker_kind__publsiher_consumer_type_map[broker_kind] = (publisher_class, consumer_class)
    consumer_class.BROKER_KIND = broker_kind


def regist_to_funboost(broker_kind: str):
    """
    不直接定义在broker_kind__publsiher_consumer_type_map, 延迟导入是因为funboost没有pip自动安装这些三方包，防止一启动就报错。
    这样当用户需要使用某些三方包中间件作为消息队列时候，按照import报错信息，用户自己去pip安装好。或者 pip install funboost[all] 一次性安装所有中间件。
    建议按照 https://github.com/ydf0509/funboost/blob/master/setup.py 中的 extra_brokers 和 install_requires 里面的版本号来安装三方包版本.
    """
    if broker_kind == BrokerEnum.RABBITMQ_AMQPSTORM:
        from funboost.publishers.rabbitmq_amqpstorm_publisher import RabbitmqPublisherUsingAmqpStorm
        from funboost.consumers.rabbitmq_amqpstorm_consumer import RabbitmqConsumerAmqpStorm
        register_custom_broker(BrokerEnum.RABBITMQ_AMQPSTORM, RabbitmqPublisherUsingAmqpStorm, RabbitmqConsumerAmqpStorm)

    if broker_kind == BrokerEnum.RABBITMQ_COMPLEX_ROUTING:
        from funboost.publishers.rabbitmq_complex_routing_publisher import RabbitmqComplexRoutingPublisher
        from funboost.consumers.rabbitmq_complex_routing_consumer import RabbitmqComplexRoutingConsumer
        register_custom_broker(BrokerEnum.RABBITMQ_COMPLEX_ROUTING, RabbitmqComplexRoutingPublisher, RabbitmqComplexRoutingConsumer)

    if broker_kind == BrokerEnum.RABBITMQ_RABBITPY:
        from funboost.publishers.rabbitmq_rabbitpy_publisher import RabbitmqPublisherUsingRabbitpy
        from funboost.consumers.rabbitmq_rabbitpy_consumer import RabbitmqConsumerRabbitpy
        register_custom_broker(BrokerEnum.RABBITMQ_RABBITPY, RabbitmqPublisherUsingRabbitpy, RabbitmqConsumerRabbitpy)

    if broker_kind == BrokerEnum.PULSAR:
        from funboost.consumers.pulsar_consumer import PulsarConsumer
        from funboost.publishers.pulsar_publisher import PulsarPublisher
        register_custom_broker(BrokerEnum.PULSAR, PulsarPublisher, PulsarConsumer)

    if broker_kind == BrokerEnum.CELERY:
        from funboost.consumers.celery_consumer import CeleryConsumer
        from funboost.publishers.celery_publisher import CeleryPublisher
        register_custom_broker(BrokerEnum.CELERY, CeleryPublisher, CeleryConsumer)

    if broker_kind == BrokerEnum.NAMEKO:
        from funboost.consumers.nameko_consumer import NamekoConsumer
        from funboost.publishers.nameko_publisher import NamekoPublisher
        register_custom_broker(BrokerEnum.NAMEKO, NamekoPublisher, NamekoConsumer)

    if broker_kind == BrokerEnum.SQLACHEMY:
        from funboost.consumers.sqlachemy_consumer import SqlachemyConsumer
        from funboost.publishers.sqla_queue_publisher import SqlachemyQueuePublisher
        register_custom_broker(BrokerEnum.SQLACHEMY, SqlachemyQueuePublisher, SqlachemyConsumer)

    if broker_kind == BrokerEnum.DRAMATIQ:
        from funboost.consumers.dramatiq_consumer import DramatiqConsumer
        from funboost.publishers.dramatiq_publisher import DramatiqPublisher
        register_custom_broker(BrokerEnum.DRAMATIQ, DramatiqPublisher, DramatiqConsumer)

    if broker_kind == BrokerEnum.HUEY:
        from funboost.consumers.huey_consumer import HueyConsumer
        from funboost.publishers.huey_publisher import HueyPublisher
        register_custom_broker(BrokerEnum.HUEY, HueyPublisher, HueyConsumer)

    if broker_kind == BrokerEnum.KAFKA_CONFLUENT:
        from funboost.consumers.kafka_consumer_manually_commit import KafkaConsumerManuallyCommit
        from funboost.publishers.confluent_kafka_publisher import ConfluentKafkaPublisher
        register_custom_broker(BrokerEnum.KAFKA_CONFLUENT, ConfluentKafkaPublisher, KafkaConsumerManuallyCommit)

    if broker_kind == BrokerEnum.KAFKA_CONFLUENT_SASlPlAIN:
        from funboost.consumers.kafka_consumer_manually_commit import SaslPlainKafkaConsumer
        from funboost.publishers.confluent_kafka_publisher import SaslPlainKafkaPublisher
        register_custom_broker(broker_kind, SaslPlainKafkaPublisher, SaslPlainKafkaConsumer)

    if broker_kind == BrokerEnum.RQ:
        from funboost.consumers.rq_consumer import RqConsumer
        from funboost.publishers.rq_publisher import RqPublisher
        register_custom_broker(broker_kind, RqPublisher, RqConsumer)

    if broker_kind == BrokerEnum.KOMBU:
        from funboost.consumers.kombu_consumer import KombuConsumer
        from funboost.publishers.kombu_publisher import KombuPublisher
        register_custom_broker(broker_kind, KombuPublisher, KombuConsumer)

    if broker_kind == BrokerEnum.NSQ:
        from funboost.publishers.nsq_publisher import NsqPublisher
        from funboost.consumers.nsq_consumer import NsqConsumer
        register_custom_broker(broker_kind, NsqPublisher, NsqConsumer)

    if broker_kind == BrokerEnum.GRPC:
        from funboost.consumers.grpc_consumer import GrpcConsumer
        from funboost.publishers.grpc_publisher import GrpcPublisher
        register_custom_broker(broker_kind, GrpcPublisher, GrpcConsumer)

    if broker_kind == BrokerEnum.MYSQL_CDC:
        from funboost.consumers.mysql_cdc_consumer import MysqlCdcConsumer
        from funboost.publishers.mysql_cdc_publisher import MysqlCdcPublisher
        register_custom_broker(broker_kind, MysqlCdcPublisher, MysqlCdcConsumer)
    
    if broker_kind == BrokerEnum.HTTP:
        from funboost.consumers.http_consumer import HTTPConsumer
        from funboost.publishers.http_publisher import HTTPPublisher
        register_custom_broker(broker_kind, HTTPPublisher, HTTPConsumer)

if __name__ == '__main__':
    import sys

    print(sys.modules)

`````

--- **end of file: funboost/factories/broker_kind__publsiher_consumer_type_map.py** (project: funboost) --- 

---


--- **start of file: funboost/factories/consumer_factory.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/factories/consumer_factory.py`

#### 📦 Imports

- `import os`
- `import threading`
- `import typing`
- `from funboost.constant import BrokerEnum`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import broker_kind__publsiher_consumer_type_map`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import regist_to_funboost`

#### 🏛️ Classes (1)

##### 📌 `class ConsumerCacheProxy`
*Line: 36*

**🔧 Constructor (`__init__`):**
- `def __init__(self, boost_params: BoosterParams)`
  - **Parameters:**
    - `self`
    - `boost_params: BoosterParams`

**Properties (1):**
- `@property consumer -> AbstractConsumer`

**Class Variables (2):**
- `pid_registry_queue_name__consumer_map: typing.Dict[typing.Tuple[int, str, str], AbstractConsumer] = {}`
- `_lock = threading.Lock()`

#### 🔧 Public Functions (1)

- `def get_consumer(boost_params: BoosterParams) -> AbstractConsumer`
  - *Line: 13*
  - **Docstring:**
  `````
  :param args: 入参是AbstractConsumer的入参
  :param broker_kind:
  :param kwargs:
  :return:
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:19

import os
import threading
import typing
from funboost.constant import BrokerEnum
from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.func_params_model import BoosterParams


def get_consumer(boost_params: BoosterParams) -> AbstractConsumer:
    """
    :param args: 入参是AbstractConsumer的入参
    :param broker_kind:
    :param kwargs:
    :return:
    """
    from funboost.factories.broker_kind__publsiher_consumer_type_map import broker_kind__publsiher_consumer_type_map, regist_to_funboost
    regist_to_funboost(boost_params.broker_kind)  # 动态注册中间件到框架是为了延迟导入，用户没安装不需要的第三方包不报错。

    if boost_params.broker_kind not in broker_kind__publsiher_consumer_type_map:
        raise ValueError(f'设置的中间件种类不正确,你设置的值是 {boost_params.broker_kind} ')
    consumer_cls = broker_kind__publsiher_consumer_type_map[boost_params.broker_kind][1]
    if not boost_params.consumer_override_cls:
        return consumer_cls(boost_params)
    else:
        ConsumerClsOverride = type(f'{consumer_cls.__name__}__{boost_params.consumer_override_cls.__name__}', (boost_params.consumer_override_cls, consumer_cls, AbstractConsumer), {})
        # class ConsumerClsOverride(boost_params.consumer_override_cls, consumer_cls, AbstractConsumer):
        #     pass

        return ConsumerClsOverride(boost_params)


class ConsumerCacheProxy:
    pid_registry_queue_name__consumer_map:typing.Dict[typing.Tuple[int,str,str],AbstractConsumer] = {}
    _lock = threading.Lock()

    def __init__(self,boost_params: BoosterParams):
        self.boost_params = boost_params

    @property
    def consumer(self) ->AbstractConsumer:
        pid = os.getpid()
        # 加入 booster_registry_name 作为命名空间隔离，支持不同 registry 使用相同的 queue_name 而不冲突
        key = (pid, self.boost_params.booster_registry_name, self.boost_params.queue_name)
        if key not in self.pid_registry_queue_name__consumer_map:
            with self._lock:
                if key not in self.pid_registry_queue_name__consumer_map:
                    self.pid_registry_queue_name__consumer_map[key] = get_consumer(self.boost_params)
        return self.pid_registry_queue_name__consumer_map[key]
`````

--- **end of file: funboost/factories/consumer_factory.py** (project: funboost) --- 

---


--- **start of file: funboost/factories/publisher_factotry.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/factories/publisher_factotry.py`

#### 📦 Imports

- `import copy`
- `import os`
- `import threading`
- `import typing`
- `from typing import Callable`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import broker_kind__publsiher_consumer_type_map`
- `from funboost.factories.broker_kind__publsiher_consumer_type_map import regist_to_funboost`

#### 🏛️ Classes (1)

##### 📌 `class PublisherCacheProxy`
*Line: 47*

**🔧 Constructor (`__init__`):**
- `def __init__(self, publisher_params: PublisherParams)`
  - **Parameters:**
    - `self`
    - `publisher_params: PublisherParams`

**Properties (1):**
- `@property publisher -> AbstractPublisher`

**Class Variables (2):**
- `pid_registry_queue_name__publisher_map: typing.Dict[typing.Tuple[int, str, str], AbstractPublisher] = {}`
- `_lock = threading.Lock()`

#### 🔧 Public Functions (1)

- `def get_publisher(publisher_params: PublisherParams) -> AbstractPublisher`
  - *Line: 15*
  - **Docstring:**
  `````
  :param queue_name:
  :param log_level_int:
  :param logger_prefix:
  :param is_add_file_handler:
  :param clear_queue_within_init:
  :param is_add_publish_time:是否添加发布时间，以后废弃，都添加。
  :param consuming_function:消费函数，为了做发布时候的函数入参校验用的，如果不传则不做发布任务的校验，
             例如add 函数接收x，y入参，你推送{"x":1,"z":3}就是不正确的，函数不接受z参数。
  :param broker_kind: 中间件或使用包的种类。
  :param broker_exclusive_config 加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，
         例如kafka支持消费者组，rabbitmq也支持各种独特概念例如各种ack机制 复杂路由机制，每一种消息队列都有独特的配置参数意义，可以通过这里传递。
  
  :return:
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:16
import copy
import os
import threading
import typing
from typing import Callable
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.core.func_params_model import PublisherParams


# broker_kind__publisher_type_map

def get_publisher(publisher_params: PublisherParams) -> AbstractPublisher:
    """
    :param queue_name:
    :param log_level_int:
    :param logger_prefix:
    :param is_add_file_handler:
    :param clear_queue_within_init:
    :param is_add_publish_time:是否添加发布时间，以后废弃，都添加。
    :param consuming_function:消费函数，为了做发布时候的函数入参校验用的，如果不传则不做发布任务的校验，
               例如add 函数接收x，y入参，你推送{"x":1,"z":3}就是不正确的，函数不接受z参数。
    :param broker_kind: 中间件或使用包的种类。
    :param broker_exclusive_config 加上一个不同种类中间件非通用的配置,不同中间件自身独有的配置，不是所有中间件都兼容的配置，因为框架支持30种消息队列，消息队列不仅仅是一般的先进先出queue这么简单的概念，
           例如kafka支持消费者组，rabbitmq也支持各种独特概念例如各种ack机制 复杂路由机制，每一种消息队列都有独特的配置参数意义，可以通过这里传递。

    :return:
    """

    from funboost.factories.broker_kind__publsiher_consumer_type_map import broker_kind__publsiher_consumer_type_map, regist_to_funboost
    broker_kind = publisher_params.broker_kind
    regist_to_funboost(broker_kind)  # 动态注册中间件到框架是为了延迟导入，用户没安装不需要的第三方包不报错。
    if broker_kind not in broker_kind__publsiher_consumer_type_map:
        raise ValueError(f'设置的中间件种类不正确,你设置的值是 {broker_kind} ')
    publisher_cls = broker_kind__publsiher_consumer_type_map[broker_kind][0]
    if not publisher_params.publisher_override_cls:
        return publisher_cls(publisher_params)
    else:
        PublsiherClsOverride = type(f'{publisher_cls.__name__}__{publisher_params.publisher_override_cls.__name__}', (publisher_params.publisher_override_cls, publisher_cls, AbstractPublisher), {})
        # class PublsiherClsOverride(publisher_params.publisher_override_cls, publisher_cls, AbstractPublisher):
        #     pass

        return PublsiherClsOverride(publisher_params)

class PublisherCacheProxy:
    pid_registry_queue_name__publisher_map:typing.Dict[typing.Tuple[int,str,str],AbstractPublisher] = {}
    _lock = threading.Lock()
    def __init__(self,publisher_params: PublisherParams):
        self.publisher_params = publisher_params
      
    @property
    def publisher(self) ->AbstractPublisher:
        pid = os.getpid()
        key = (pid, self.publisher_params.booster_registry_name, self.publisher_params.queue_name)
        if key not in self.pid_registry_queue_name__publisher_map:
            with self._lock:
                if key not in self.pid_registry_queue_name__publisher_map:
                    self.pid_registry_queue_name__publisher_map[key] = get_publisher(self.publisher_params)
        return self.pid_registry_queue_name__publisher_map[key]
`````

--- **end of file: funboost/factories/publisher_factotry.py** (project: funboost) --- 

---


--- **start of file: funboost/factories/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/factories/__init__.py`

#### 📝 Module Docstring

`````
工厂模式，通过broker_kind来生成不同中间件类型的消费者和发布者。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:17

"""
工厂模式，通过broker_kind来生成不同中间件类型的消费者和发布者。
"""
`````

--- **end of file: funboost/factories/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/funboost_web_manager/app.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/funboost_web_manager/app.py`

#### 📦 Imports

- `import threading`
- `import sys`
- `import os`
- `import datetime`
- `import json`
- `import traceback`
- `import typing`
- `from funboost.core.func_params_model import TaskOptions`
- `from flask import render_template`
- `from flask import Flask`
- `from flask import request`
- `from flask import url_for`
- `from flask import jsonify`
- `from flask import flash`
- `from flask import redirect`
- `from flask_bootstrap import Bootstrap`
- `from flask_wtf import FlaskForm`
- `from wtforms import StringField`
- `from wtforms import PasswordField`
- `from wtforms import BooleanField`
- `from wtforms import SubmitField`
- `from wtforms.validators import DataRequired`
- `from wtforms.validators import Length`
- `from flask_login import login_user`
- `from flask_login import logout_user`
- `from flask_login import login_required`
- `from flask_login import LoginManager`
- `from flask_login import UserMixin`
- `import nb_log`
- `from funboost import nb_print`
- `from funboost import ActiveCousumerProcessInfoGetter`
- `from funboost.funboost_web_manager.functions import get_cols`
- `from funboost.funboost_web_manager.functions import query_result`
- `from funboost.funboost_web_manager.functions import get_speed`
- `from funboost.funboost_web_manager import functions as app_functions`
- `from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import CareProjectNameEnv`
- `from funboost.faas import flask_blueprint`
- `from funboost.funboost_web_manager.functions import get_consume_speed_curve`
- `import traceback`

#### 🏛️ Classes (2)

##### 📌 `class User(UserMixin)`
*Line: 68*

##### 📌 `class LoginForm(FlaskForm)`
*Line: 97*

**Class Variables (3):**
- `user_name = StringField('用户名', validators=[DataRequired(), Length(3, 64)])`
- `password = PasswordField('密码', validators=[DataRequired(), Length(3, 64)])`
- `remember_me = BooleanField('记住我')`

#### 🔧 Public Functions (18)

- `def query_user(user_name)`
  - *Line: 83*

- `def load_user(user_id)` `login_manager.user_loader`
  - *Line: 90*

- `def login()` `app.route('/login', methods=['GET', 'POST'])`
  - *Line: 104*

- `def logout()` `app.route('/logout')` `login_required`
  - *Line: 142*

- `def index()` `app.route('/')` `login_required`
  - *Line: 149*

- `def query_cols_view()` `app.route('/query_cols')` `login_required`
  - *Line: 156*

- `def query_result_view()` `app.route('/query_result')` `login_required`
  - *Line: 163*

- `def speed_stats()` `app.route('/speed_stats')` `login_required`
  - *Line: 169*

- `def consume_speed_curve()` `app.route('/consume_speed_curve')` `login_required`
  - *Line: 184*
  - *获取消费速率曲线数据*

- `def serve_template(template)` `app.route('/tpl/<template>')` `login_required`
  - *Line: 205*

- `def hearbeat_info_by_queue_name()` `app.route('/running_consumer/hearbeat_info_by_queue_name')`
  - *Line: 216*

- `def hearbeat_info_by_ip()` `app.route('/running_consumer/hearbeat_info_by_ip')`
  - *Line: 231*

- `def hearbeat_info_partion_by_queue_name()` `app.route('/running_consumer/hearbeat_info_partion_by_queue_name')`
  - *Line: 248*

- `def hearbeat_info_partion_by_ip()` `app.route('/running_consumer/hearbeat_info_partion_by_ip')`
  - *Line: 261*

- `def get_queues_params_and_active_consumers()` `app.route('/queue/params_and_active_consumers')`
  - *Line: 275*

- `def get_msg_num_all_queues()` `app.route('/queue/get_msg_num_all_queues', methods=['GET'])`
  - *Line: 298*
  - *这个是通过消费者周期每隔10秒上报到redis的，性能好。不需要实时获取每个消息队列，直接从redis读取所有队列的消息数量*

- `def get_time_series_data_by_queue_name(queue_name)` `app.route('/queue/get_time_series_data/<queue_name>', methods=['GET'])`
  - *Line: 305*
  - **Docstring:**
  `````
  _summary_
  
  Args:
      queue_name (_type_): _description_
  
  Returns:
      _type_: _description_
  
  返回例如  [{'report_data': {'pause_flag': -1, 'msg_num_in_broker': 936748, 'history_run_count': '150180', 'history_run_fail_count': '46511', 'all_consumers_last_x_s_execute_count': 7, 'all_consumers_last_x_s_execute_count_fail': 0, 'all_consumers_last_x_s_avarage_function_spend_time': 3.441, 'all_consumers_avarage_function_spend_time_from_start': 4.598, 'all_consumers_total_consume_count_from_start': 1296, 'all_consumers_total_consume_count_from_start_fail': 314, 'report_ts': 1749617360.597841}, 'report_ts': 1749617360.597841}, {'report_data': {'pause_flag': -1, 'msg_num_in_broker': 936748, 'history_run_count': '150184', 'history_run_fail_count': '46514', 'all_consumers_last_x_s_execute_count': 7, 'all_consumers_last_x_s_execute_count_fail': 0, 'all_consumers_last_x_s_avarage_function_spend_time': 3.441, 'all_consumers_avarage_function_spend_time_from_start': 4.599, 'all_consumers_total_consume_count_from_start': 1299, 'all_consumers_total_consume_count_from_start_fail': 316, 'report_ts': 1749617370.628166}, 'report_ts': 1749617370.628166}]
  `````

- `def start_funboost_web_manager(host = '0.0.0.0', port = 27018, block = False, debug = False, care_project_name: typing.Optional[str] = None)`
  - *Line: 346*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/9/18 0018 14:46
import threading

import sys


import os
# print("PYTHONPATH:", os.environ.get('PYTHONPATH'))


import datetime
import json
import traceback
import typing
from funboost.core.func_params_model import TaskOptions

"""
pip install Flask flask_bootstrap  flask_wtf  wtforms flask_login       
"""
from flask import render_template, Flask, request, url_for, jsonify, flash, redirect
from flask_bootstrap import Bootstrap
from flask_wtf import FlaskForm
from wtforms import StringField, PasswordField, BooleanField, SubmitField
from wtforms.validators import DataRequired, Length
from flask_login import login_user, logout_user, login_required, LoginManager, UserMixin

import nb_log
from funboost import (
    nb_print,
    ActiveCousumerProcessInfoGetter,
    # BoostersManager,  # 未使用
    # PublisherParams,  # 未使用
    # RedisMixin,  # 已废弃的 pause/resume 路由使用，现已注释
)
from funboost.funboost_web_manager.functions import (
    get_cols,
    query_result,
    get_speed,
    # Statistic,  # 已废弃，前端不再使用 speed_statistic_for_echarts 路由
)
from funboost.funboost_web_manager import functions as app_functions
from funboost.core.active_cousumer_info_getter import (
    QueuesConusmerParamsGetter,
    SingleQueueConusmerParamsGetter,
    CareProjectNameEnv,
)
# from funboost.constant import RedisKeys  # 已废弃的 pause/resume 路由使用，现已注释
from funboost.faas import flask_blueprint

app = Flask(__name__)
app.secret_key = "mtfy54321"
app.config["JSON_AS_ASCII"] = False
bootstrap = Bootstrap(app)
login_manager = LoginManager()
login_manager.login_view = "login"
login_manager.login_message_category = "info"
login_manager.login_message = "Access denied."
login_manager.init_app(app)


# 定时任务用faas这里面自带的flask蓝图，因为通用的faas接口是2025年12月才有的功能，老的flask接口是在这里单独开发的。
app.register_blueprint(flask_blueprint)  



class User(UserMixin):
    pass


users = [
    {"id": "Tom", "user_name": "Tom", "password": "111111"},
    {"id": "user", "user_name": "user", "password": "mtfy123"},
    {"id": "admin", "user_name": "admin", "password": "123456"},
]


nb_log.get_logger("flask", log_filename="flask.log")
nb_log.get_logger("werkzeug", log_filename="werkzeug.log")


def query_user(user_name):
    for user in users:
        if user_name == user["user_name"]:
            return user


@login_manager.user_loader
def load_user(user_id):
    if query_user(user_id) is not None:
        curr_user = User()
        curr_user.id = user_id
        return curr_user


class LoginForm(FlaskForm):
    user_name = StringField("用户名", validators=[DataRequired(), Length(3, 64)])
    password = PasswordField("密码", validators=[DataRequired(), Length(3, 64)])
    remember_me = BooleanField("记住我")


@app.route("/login", methods=["GET", "POST"])
def login():
    form = LoginForm()
    if request.method == "POST":
        # nb_print(form.validate())
        # nb_print(form.password.data)
        # nb_print(form.user_name.data)
        # nb_print(form.user_name.errors)
        # nb_print(form.password.errors)
        if form.validate_on_submit():
            user = query_user(form.user_name.data)
            if user is not None and request.form["password"] == user["password"]:
                curr_user = User()
                curr_user.id = form.user_name.data

                # 通过Flask-Login的login_user方法登录用户
                nb_print(form.remember_me.data)
                login_user(
                    curr_user,
                    remember=form.remember_me.data,
                    duration=datetime.timedelta(days=7),
                )

                return redirect(url_for("index"))

            flash("用户名或密码错误", category="error")

            # if form.user_name.data == 'user' and form.password.data == 'mtfy123':
            #     login_user(form.user_name.data, form.remember_me.data)
            #     return redirect(url_for('index'))
            # else:
            #     flash('账号或密码错误',category='error')
            #     return render_template('login4.html', form=form)

    return render_template("login.html", form=form)


@app.route("/logout")
@login_required
def logout():
    logout_user()
    return redirect(url_for("login"))


@app.route("/")
@login_required
def index():
    page = request.args.get("page")
    return render_template("index.html", page=page)


@app.route("/query_cols")
@login_required
def query_cols_view():
    nb_print(request.args)
    return jsonify(get_cols(request.args.get("col_name_search")))


@app.route("/query_result")
@login_required
def query_result_view():
    return jsonify(query_result(**request.values.to_dict()))


@app.route("/speed_stats")
@login_required
def speed_stats():
    return jsonify(get_speed(**request.values.to_dict()))


# 以下路由已废弃，功能已迁移到 consume_speed_curve，前端不再使用
# @app.route("/speed_statistic_for_echarts")
# @login_required
# def speed_statistic_for_echarts():
#     stat = Statistic(request.args.get("col_name"))
#     stat.build_result()
#     return jsonify(stat.result)


@app.route("/consume_speed_curve")
@login_required
def consume_speed_curve():
    """获取消费速率曲线数据"""
    from funboost.funboost_web_manager.functions import get_consume_speed_curve
    col_name = request.args.get("col_name")
    start_time = request.args.get("start_time")
    end_time = request.args.get("end_time")
    granularity = request.args.get("granularity", "auto")
    
    if not col_name or not start_time or not end_time:
        return jsonify({"error": "缺少必要参数: col_name, start_time, end_time"})
    
    try:
        result = get_consume_speed_curve(col_name, start_time, end_time, granularity)
        return jsonify(result)
    except Exception as e:
        import traceback
        return jsonify({"error": str(e), "traceback": traceback.format_exc()})


@app.route("/tpl/<template>")
@login_required
def serve_template(template):
    # 安全检查：确保只能访问templates目录下的html文件
    if not template.endswith(".html"):
        return "Invalid request", 400
    try:
        return render_template(template)
    except Exception as e:
        return f"Template not found: {template}", 404


@app.route("/running_consumer/hearbeat_info_by_queue_name")
def hearbeat_info_by_queue_name():
    queue_name = request.args.get("queue_name")
    if queue_name in ("所有", None, ""):
        info_map = ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_queue_name()
        ret_list = []
        for queue_name, dic in info_map.items():
            ret_list.extend(dic)
        return jsonify(ret_list)
    else:
        return jsonify(
            ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_by_queue_name(queue_name)
        )


@app.route("/running_consumer/hearbeat_info_by_ip")
def hearbeat_info_by_ip():
    ip = request.args.get("ip")
    if ip in ("所有", None, ""):
        info_map = (
            ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_ip()
        )
        ret_list = []
        for queue_name, dic in info_map.items():
            ret_list.extend(dic)
        return jsonify(ret_list)
    else:
        return jsonify(
            ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_by_ip(ip)
        )


@app.route("/running_consumer/hearbeat_info_partion_by_queue_name")
def hearbeat_info_partion_by_queue_name():
    info_map = ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_queue_name()
    ret_list = []
    total_count = 0
    for k, v in info_map.items():
        ret_list.append({"collection_name": k, "count": len(v)})
        total_count += len(v)
    ret_list = sorted(ret_list, key=lambda x: x["collection_name"])
    ret_list.insert(0, {"collection_name": "所有", "count": total_count})
    return jsonify(ret_list)


@app.route("/running_consumer/hearbeat_info_partion_by_ip")
def hearbeat_info_partion_by_ip():
    info_map = ActiveCousumerProcessInfoGetter().get_all_hearbeat_info_partition_by_ip()
    ret_list = []
    total_count = 0
    for k, v in info_map.items():
        ret_list.append({"collection_name": k, "count": len(v)})
        total_count += len(v)
    ret_list = sorted(ret_list, key=lambda x: x["collection_name"])
    ret_list.insert(0, {"collection_name": "所有", "count": total_count})
    print(ret_list)
    return jsonify(ret_list)


@app.route("/queue/params_and_active_consumers")
def get_queues_params_and_active_consumers():
    return jsonify(
        QueuesConusmerParamsGetter().get_queues_params_and_active_consumers()
    )





# 以下两个路由已废弃，前端没有使用（暂停/恢复消费功能可能在其他地方实现）
# @app.route("/queue/pause/<queue_name>", methods=["POST"])
# def pause_cousume(queue_name):
#     RedisMixin().redis_db_frame.hset(RedisKeys.REDIS_KEY_PAUSE_FLAG, queue_name, "1")
#     return jsonify({"success": True})


# @app.route("/queue/resume/<queue_name>", methods=["POST"])
# def resume_consume(queue_name):
#     RedisMixin().redis_db_frame.hset(RedisKeys.REDIS_KEY_PAUSE_FLAG, queue_name, "0")
#     return jsonify({"success": True})


@app.route("/queue/get_msg_num_all_queues", methods=["GET"])
def get_msg_num_all_queues():
    """这个是通过消费者周期每隔10秒上报到redis的，性能好。不需要实时获取每个消息队列，直接从redis读取所有队列的消息数量"""
    return jsonify(QueuesConusmerParamsGetter().get_msg_num(ignore_report_ts=True))



@app.route("/queue/get_time_series_data/<queue_name>", methods=["GET"])
def get_time_series_data_by_queue_name(
    queue_name,
):
    """_summary_

    Args:
        queue_name (_type_): _description_

    Returns:
        _type_: _description_

    返回例如  [{'report_data': {'pause_flag': -1, 'msg_num_in_broker': 936748, 'history_run_count': '150180', 'history_run_fail_count': '46511', 'all_consumers_last_x_s_execute_count': 7, 'all_consumers_last_x_s_execute_count_fail': 0, 'all_consumers_last_x_s_avarage_function_spend_time': 3.441, 'all_consumers_avarage_function_spend_time_from_start': 4.598, 'all_consumers_total_consume_count_from_start': 1296, 'all_consumers_total_consume_count_from_start_fail': 314, 'report_ts': 1749617360.597841}, 'report_ts': 1749617360.597841}, {'report_data': {'pause_flag': -1, 'msg_num_in_broker': 936748, 'history_run_count': '150184', 'history_run_fail_count': '46514', 'all_consumers_last_x_s_execute_count': 7, 'all_consumers_last_x_s_execute_count_fail': 0, 'all_consumers_last_x_s_avarage_function_spend_time': 3.441, 'all_consumers_avarage_function_spend_time_from_start': 4.599, 'all_consumers_total_consume_count_from_start': 1299, 'all_consumers_total_consume_count_from_start_fail': 316, 'report_ts': 1749617370.628166}, 'report_ts': 1749617370.628166}]
    """
    # 获取前端传递的参数
    start_ts = request.args.get("start_ts")
    end_ts = request.args.get("end_ts")
    curve_samples_count = request.args.get("curve_samples_count")

    # 如果前端指定了采样点数，使用前端的值
    if curve_samples_count:
        try:
            curve_samples_count = int(curve_samples_count)
            # 验证值是否在允许的范围内
            allowed_values = [60, 120, 180, 360, 720, 1440, 8640]
            if curve_samples_count not in allowed_values:
                curve_samples_count = 360  # 默认值
        except (ValueError, TypeError):
            curve_samples_count = 360  # 默认值
    else:
        # 如果前端没有指定，使用默认值
        curve_samples_count = 360

    return jsonify(
        SingleQueueConusmerParamsGetter(queue_name).get_one_queue_time_series_data(
            start_ts, end_ts, curve_samples_count
        )
    )




def start_funboost_web_manager(
    host="0.0.0.0",
    port=27018,
    block=False,
    debug=False,
    care_project_name: typing.Optional[str] = None,
):
    
    if care_project_name is not None:
       CareProjectNameEnv.set(care_project_name)
    print("start_funboost_web_manager , sys.path :", sys.path)

    def _start_funboost_web_manager():
        app.run(debug=debug, threaded=True, host=host, port=port)

    QueuesConusmerParamsGetter().cycle_get_queues_params_and_active_consumers_and_report()
    if block is True:
        _start_funboost_web_manager()
    else:
        threading.Thread(target=_start_funboost_web_manager).start()


if __name__ == "__main__":
    # app.jinja_env.auto_reload = True
    # with app.test_request_context():
    #     print(url_for('query_cols_view'))
    start_funboost_web_manager(debug=False)

    """
    funboost web manager 启动方式1：

    web代码在funboost包里面，所以可以直接使用命令行运行起来，不需要用户现亲自下载web代码就可以直接运行。
    
    第一步： 设置 PYTHONPATH 为你的项目根目录
    export PYTHONPATH=你的项目根目录 (这么做是为了这个web可以读取到你项目根目录下的 funboost_config.py里面的配置)
    (怎么设置环境变量应该不需要我来教，环境变量都没听说过太low了)
      例如 export PYTHONPATH=/home/ydf/codes/ydfhome
      或者 export PYTHONPATH=./   (./是相对路径，前提是已近cd到你的项目根目录了，也可以写绝对路径全路径)
      win cmd 设置环境变量语法是 set PYTHONPATH=/home/ydf/codes/ydfhome   
      win powershell 语法是  $env:PYTHONPATH = "/home/ydf/codes/ydfhome"   

    第二步： 启动flask app   
    win上这么做 python3 -m funboost.funboost_web_manager.app 

    linux上可以这么做性能好一些，也可以按win的做。
    gunicorn -w 4 --threads=30 --bind 0.0.0.0:27018 funboost.funboost_web_manager.app:app
    """

    """
    funboost web manager 启动方式2：
    在python代码中直接启动：

    ```python
    from  funboost.funboost_web_manager.app import start_funboost_web_manager
    start_funboost_web_manager()
    ```
    
    """

`````

--- **end of file: funboost/funboost_web_manager/app.py** (project: funboost) --- 

---


--- **start of file: funboost/funboost_web_manager/app_debug_start.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/funboost_web_manager/app_debug_start.py`

#### 📦 Imports

- `from funboost.funboost_web_manager.app import start_funboost_web_manager`


---

`````python



from funboost.funboost_web_manager.app import start_funboost_web_manager

if __name__ == '__main__':
    start_funboost_web_manager(
        port=27011,
        debug=True,
        care_project_name='test_project1',
        block=True
        )
   

`````

--- **end of file: funboost/funboost_web_manager/app_debug_start.py** (project: funboost) --- 

---


--- **start of file: funboost/funboost_web_manager/functions.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/funboost_web_manager/functions.py`

#### 📦 Imports

- `import datetime`
- `import json`
- `from pprint import pprint`
- `import time`
- `import copy`
- `import traceback`
- `from funboost import nb_print`
- `from funboost.constant import RedisKeys`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.serialization import Serialization`
- `from funboost.utils import time_util`
- `from funboost.utils import decorators`
- `from funboost.utils.mongo_util import MongoMixin`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`

#### 🔧 Public Functions (6)

- `def get_mongo_table_name_by_queue_name(queue_name: str) -> str`
  - *Line: 26*
  - **Docstring:**
  `````
  根据 queue_name 获取对应的 MongoDB 表名
  
  从队列配置的 function_result_status_persistance_conf.table_name 获取，
  如果没有配置 table_name，则使用 queue_name 作为表名
  
  Args:
      queue_name: 队列名称
      
  Returns:
      MongoDB 表名
  `````

- `def get_all_queue_table_info() -> dict`
  - *Line: 52*
  - **Docstring:**
  `````
  获取所有队列及其对应的 MongoDB 表名映射
  
  Returns:
      {queue_name: table_name, ...}
  `````

- `def get_cols(col_name_search: str)`
  - *Line: 71*
  - **Docstring:**
  `````
  获取队列列表，并返回每个队列对应的 MongoDB 表的记录数
  
  不再使用 db.list_collection_names()，而是从队列配置中获取表名
  注意：因为多个队列可能共享同一个表，所以查询时必须加上 queue_name 条件
  `````

- `def query_result(col_name, start_time, end_time, is_success, function_params: str, page, task_id: str = '')`
  - *Line: 104*
  - **Docstring:**
  `````
  查询函数执行结果
  
  Args:
      col_name: 队列名称（不是表名，会自动转换为对应的 MongoDB 表名）
  
  注意：因为多个队列可能共享同一个表，所以查询时必须加上 queue_name 条件
  `````

- `def get_speed(col_name, start_time, end_time)`
  - *Line: 151*
  - **Docstring:**
  `````
  获取指定时间范围内的消费速率统计
  
  Args:
      col_name: 队列名称（不是表名，会自动转换为对应的 MongoDB 表名）
  
  注意：因为多个队列可能共享同一个表，所以查询时必须加上 queue_name 条件
  `````

- `def get_consume_speed_curve(col_name: str, start_time: str, end_time: str, granularity: str = 'auto')`
  - *Line: 186*
  - **Docstring:**
  `````
  获取消费速率曲线数据
  
  Args:
      col_name: 队列名称（不是表名，会自动转换为对应的 MongoDB 表名）
      start_time: 开始时间，格式 'YYYY-MM-DD HH:MM:SS'
      end_time: 结束时间，格式 'YYYY-MM-DD HH:MM:SS'
      granularity: 时间粒度，'second', 'minute', 'hour', 'day' 或 'auto'
  
  Returns:
      {
          'time_arr': [...],
          'success_arr': [...],
          'fail_arr': [...],
          'total_success': int,
          'total_fail': int,
          'granularity': str
      }
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/9/19 0019 9:48
import datetime
import json
from pprint import pprint
import time
import copy
import traceback
from funboost import nb_print
from funboost.constant import RedisKeys

from funboost.core.func_params_model import TaskOptions, PublisherParams
from funboost.core.msg_result_getter import AsyncResult
from funboost.core.serialization import Serialization
from funboost.utils import time_util, decorators  # LoggerMixin 已废弃，Statistic类不再使用
from funboost.utils.mongo_util import MongoMixin
from funboost.utils.redis_manager import RedisMixin
from funboost.core.active_cousumer_info_getter import QueuesConusmerParamsGetter, SingleQueueConusmerParamsGetter

# from test_frame.my_patch_frame_config import do_patch_frame_config
#
# do_patch_frame_config()


def get_mongo_table_name_by_queue_name(queue_name: str) -> str:
    """
    根据 queue_name 获取对应的 MongoDB 表名
    
    从队列配置的 function_result_status_persistance_conf.table_name 获取，
    如果没有配置 table_name，则使用 queue_name 作为表名
    
    Args:
        queue_name: 队列名称
        
    Returns:
        MongoDB 表名
    """
    try:
        queue_params = SingleQueueConusmerParamsGetter(queue_name).get_one_queue_params_use_cache()
        if queue_params:
            persistance_conf = queue_params.get('function_result_status_persistance_conf', {})
            table_name = persistance_conf.get('table_name')
            if table_name:
                return table_name
    except Exception as e:
        nb_print(f'获取队列 {queue_name} 的表名失败: {e}')
    # 默认使用 queue_name 作为表名
    return queue_name


def get_all_queue_table_info() -> dict:
    """
    获取所有队列及其对应的 MongoDB 表名映射
    
    Returns:
        {queue_name: table_name, ...}
    """
    result = {}
    try:
        queues_config = QueuesConusmerParamsGetter().get_queues_params()
        for queue_name, params in queues_config.items():
            persistance_conf = params.get('function_result_status_persistance_conf', {})
            table_name = persistance_conf.get('table_name') or queue_name
            result[queue_name] = table_name
    except Exception as e:
        nb_print(f'获取所有队列表名映射失败: {e}')
    return result


def get_cols(col_name_search: str):
    """
    获取队列列表，并返回每个队列对应的 MongoDB 表的记录数
    
    不再使用 db.list_collection_names()，而是从队列配置中获取表名
    注意：因为多个队列可能共享同一个表，所以查询时必须加上 queue_name 条件
    """
    db = MongoMixin().mongo_db_task_status
    
    # 从队列配置获取所有队列及其对应的表名
    queue_table_map = get_all_queue_table_info()
    
    result = []
    for queue_name, table_name in queue_table_map.items():
        # 根据搜索条件过滤
        if col_name_search and col_name_search not in queue_name:
            continue
        
        try:
            # 必须加上 queue_name 条件，因为多个队列可能共享同一个表
            count = db.get_collection(table_name).count_documents({'queue_name': queue_name})
        except Exception:
            count = 0
        
        result.append({
            'collection_name': queue_name,  # 返回队列名（用于前端显示和后续查询）
            'table_name': table_name,       # 实际的 MongoDB 表名
            'count': count
        })
    
    return result


def query_result(col_name, start_time, end_time, is_success, function_params: str, page, task_id: str = ''):
    """
    查询函数执行结果
    
    Args:
        col_name: 队列名称（不是表名，会自动转换为对应的 MongoDB 表名）
    
    注意：因为多个队列可能共享同一个表，所以查询时必须加上 queue_name 条件
    """
    query_kw = copy.copy(locals())
    t0 = time.time()
    if not col_name:
        return []
    db = MongoMixin().mongo_db_task_status
    
    # 根据队列名获取实际的 MongoDB 表名
    table_name = get_mongo_table_name_by_queue_name(col_name)
    
    # 基础条件：必须加上 queue_name，因为多个队列可能共享同一个表
    condition = {'queue_name': col_name}
    
    # 如果传了 task_id，忽略其他条件（时间、运行状态等），直接根据 task_id 查询
    if task_id and task_id.strip():
        condition.update({'task_id': {'$regex': f'^{task_id.strip()}'}})
    else:
        # 正常查询：使用时间范围和其他条件
        condition.update({
            'insert_time': {'$gt': time_util.DatetimeConverter(start_time).datetime_obj,
                            '$lt': time_util.DatetimeConverter(end_time).datetime_obj},
        })
        if is_success in ('2', 2, True):
            condition.update({"success": True})
        elif is_success in ('3', 3, False):
            condition.update({"success": False})
        if function_params.strip():
            condition.update({'params_str': {'$regex': function_params.strip()}})
    
    # nb_print(col_name)
    # nb_print(condition)
    # with decorators.TimerContextManager():
    # 按时间逆序排序，最新的在前面
    results = list(db.get_collection(table_name).find(condition, {'insert_time': 0, 'utime': 0}).sort([('time_start', -1)]).skip(int(page) * 100).limit(100))
    # nb_print(results)
    nb_print(time.time() -t0, query_kw, len(results), f'table: {table_name}')
    return results


def get_speed(col_name, start_time, end_time):
    """
    获取指定时间范围内的消费速率统计
    
    Args:
        col_name: 队列名称（不是表名，会自动转换为对应的 MongoDB 表名）
    
    注意：因为多个队列可能共享同一个表，所以查询时必须加上 queue_name 条件
    """
    db = MongoMixin().mongo_db_task_status
    
    # 根据队列名获取实际的 MongoDB 表名
    table_name = get_mongo_table_name_by_queue_name(col_name)
    
    # 基础条件：必须加上 queue_name，因为多个队列可能共享同一个表
    condition = {
        'queue_name': col_name,
        'insert_time': {'$gt': time_util.DatetimeConverter(start_time).datetime_obj,
                        '$lt': time_util.DatetimeConverter(end_time).datetime_obj},
    }
    # condition = {
    #     'insert_time_str': {'$gt': time_util.DatetimeConverter(time.time() - 60).datetime_str},
    # }
    # nb_print(condition)
    with decorators.TimerContextManager():
        # success_num = db.get_collection(table_name).count({**{'success': True}, **condition})
        # fail_num = db.get_collection(table_name).count({**{'success': False}, **condition})
        success_num = db.get_collection(table_name).count_documents({**{'success': True,'run_status':'finish'}, **condition})
        fail_num = db.get_collection(table_name).count_documents({**{'success': False,'run_status':'finish'}, **condition})
        qps = (success_num + fail_num) / (time_util.DatetimeConverter(end_time).timestamp - time_util.DatetimeConverter(start_time).timestamp)
        return {'success_num': success_num, 'fail_num': fail_num, 'qps': round(qps, 1)}




def get_consume_speed_curve(col_name: str, start_time: str, end_time: str, granularity: str = 'auto'):
    """
    获取消费速率曲线数据
    
    Args:
        col_name: 队列名称（不是表名，会自动转换为对应的 MongoDB 表名）
        start_time: 开始时间，格式 'YYYY-MM-DD HH:MM:SS'
        end_time: 结束时间，格式 'YYYY-MM-DD HH:MM:SS'
        granularity: 时间粒度，'second', 'minute', 'hour', 'day' 或 'auto'
    
    Returns:
        {
            'time_arr': [...],
            'success_arr': [...],
            'fail_arr': [...],
            'total_success': int,
            'total_fail': int,
            'granularity': str
        }
    """
    db = MongoMixin().mongo_db_task_status
    
    # 根据队列名获取实际的 MongoDB 表名
    table_name = get_mongo_table_name_by_queue_name(col_name)
    
    start_dt = time_util.DatetimeConverter(start_time).datetime_obj
    end_dt = time_util.DatetimeConverter(end_time).datetime_obj
    
    # 计算时间跨度（秒）
    time_span = (end_dt - start_dt).total_seconds()
    
    # 自动选择粒度
    if granularity == 'auto':
        if time_span <= 120:  # <= 2分钟
            granularity = 'second'
        elif time_span <= 3600:  # <= 1小时
            granularity = 'minute'
        elif time_span <= 86400 * 2:  # <= 2天
            granularity = 'hour'
        else:
            granularity = 'day'
    
    # 根据粒度设置时间格式和步长
    if granularity == 'second':
        time_format = '%Y-%m-%d %H:%M:%S'
        step = datetime.timedelta(seconds=1)
        max_points = 120
    elif granularity == 'minute':
        time_format = '%Y-%m-%d %H:%M'
        step = datetime.timedelta(minutes=1)
        max_points = 120
    elif granularity == 'hour':
        time_format = '%Y-%m-%d %H:00'
        step = datetime.timedelta(hours=1)
        max_points = 168  # 7天
    else:  # day
        time_format = '%Y-%m-%d'
        step = datetime.timedelta(days=1)
        max_points = 60
    
    # 限制数据点数量，避免太多
    actual_points = int(time_span / step.total_seconds()) + 1
    if actual_points > max_points:
        # 调整步长
        step = datetime.timedelta(seconds=time_span / max_points)
        actual_points = max_points
    
    time_arr = []
    success_arr = []
    fail_arr = []
    total_success = 0
    total_fail = 0
    
    current = start_dt
    while current < end_dt:
        next_time = current + step
        if next_time > end_dt:
            next_time = end_dt
        
        # 基础条件：必须加上 queue_name，因为多个队列可能共享同一个表
        condition_base = {
            'queue_name': col_name,
            'insert_time': {'$gte': current, '$lt': next_time}
        }
        
        try:
            success_count = db.get_collection(table_name).count_documents({**condition_base, 'success': True, 'run_status': 'finish'})
            fail_count = db.get_collection(table_name).count_documents({**condition_base, 'success': False, 'run_status': 'finish'})
        except Exception as e:
            success_count = 0
            fail_count = 0
        
        time_arr.append(current.strftime(time_format))
        success_arr.append(success_count)
        fail_arr.append(fail_count)
        total_success += success_count
        total_fail += fail_count
        
        current = next_time
    
    return {
        'time_arr': time_arr,
        'success_arr': success_arr,
        'fail_arr': fail_arr,
        'total_success': total_success,
        'total_fail': total_fail,
        'granularity': granularity,
        'start_time': start_time,
        'end_time': end_time
    }


if __name__ == '__main__':
    pass
    # print(get_cols('4'))
    # pprint(query_result('queue_test54_task_status', '2019-09-15 00:00:00', '2019-09-25 00:00:00', True, '999', 0))
    # print(json.dumps(query_result(**{'col_name': 'queue_test56', 'start_time': '2019-09-18 16:03:29', 'end_time': '2019-09-21 16:03:29', 'is_success': '1', 'function_params': '', 'page': '0'}))[:1000])
    # nb_print(get_speed_last_minute('queue_test54'))

    # nb_print(get_speed('queue_test56', '2019-09-18 16:03:29', '2019-09-23 16:03:29'))
    # stat = Statistic('queue_test_f01t')
    # stat.build_result()
    # nb_print(stat.result)
    
    # res = rpc_call('queue_test_g02t',{'x':1,'y':2},True,60)
`````

--- **end of file: funboost/funboost_web_manager/functions.py** (project: funboost) --- 

---


--- **start of file: funboost/funboost_web_manager/templates/app.py中仍在使用的路由.md** (project: funboost) --- 

`````markdown


### 后续希望funboost web manager的后端都优先使用 faas 里面的接口。

### 保留的路由（前端正在使用）

| 路由 | 使用的模板 |
|------|-----------|
| `query_cols_view` | conusme_speed.html, fun_result_table.html |
| `query_result_view` | fun_result_table.html |
| `speed_stats` | fun_result_table.html |
| `consume_speed_curve` | conusme_speed.html |
| `get_msg_num_all_queues` | rpc_call.html |
| `hearbeat_info_*` | running_consumer_by_*.html |
| `get_queues_params_and_active_consumers` | queue_op.html |
| `get_time_series_data_by_queue_name` | queue_op.html (曲线图) |
`````

--- **end of file: funboost/funboost_web_manager/templates/app.py中仍在使用的路由.md** (project: funboost) --- 

---


--- **start of file: funboost/publishers/base_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/base_publisher.py`

#### 📦 Imports

- `from pathlib import Path`
- `import abc`
- `import copy`
- `import inspect`
- `import atexit`
- `import json`
- `import logging`
- `import multiprocessing`
- `import sys`
- `import threading`
- `import time`
- `import typing`
- `from functools import wraps`
- `from threading import Lock`
- `import nb_log`
- `from funboost.concurrent_pool.async_helper import simple_run_in_executor`
- `from funboost.constant import ConstStrForClassMethod`
- `from funboost.constant import FunctionKind`
- `from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config`
- `from funboost.core.func_params_model import PublisherParams`
- `from funboost.core.func_params_model import TaskOptions`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.helper_funs import MsgGenerater`
- `from funboost.core.loggers import develop_logger`
- `from funboost.core.loggers import LoggerLevelSetterMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import get_logger`
- `from funboost.core.msg_result_getter import AsyncResult`
- `from funboost.core.msg_result_getter import AioAsyncResult`
- `from funboost.core.serialization import PickleHelper`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.task_id_logger import TaskIdLogger`
- `from funboost.utils import decorators`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from nb_libs.path_helper import PathHelper`
- `from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker`
- `import amqpstorm`
- `from pikav1.exceptions import AMQPError as PikaAMQPError`

#### 🏛️ Classes (1)

##### 📌 `class AbstractPublisher(LoggerLevelSetterMixin)`
*Line: 43*

**Docstring:**
`````
发布消息到消息队列
同步编程，最重要的方法有 push publish，
asyncio异步编程，最重要的方法有 aio_push aio_publish，

用法是 booster.push(1,y=2)
或者 booster.publish({"x":1,"y":2},task_options=TaskOptions(max_retry_times=3,...)) 
总结就是push更简单更魔法，publish是更强大更灵活，因为publish除了发布函数入参自身，还可以传递task_options参数。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, publisher_params: PublisherParams)`
  - **Parameters:**
    - `self`
    - `publisher_params: PublisherParams`

**Public Methods (12):**
- `def custom_init(self)`
- `def publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None)`
  - **Docstring:**
  `````
  :param msg:函数的入参字典或者字典转json。,例如消费函数是 def add(x,y)，你就发布 {"x":1,"y":2}
  :param task_id:可以指定task_id,也可以不指定就随机生产uuid
  :param task_options:优先级配置，消息可以携带优先级配置，覆盖boost的配置。
  :return: AsyncResult 对象，可以用于等待结果。 例如 status_and_result =  async_result.status_and_result 来等待返回结果。
  
  funboost 消息体中的extra字典，包含的key就是 TaskOptions 中声明的字段。例如 task_id, publish_time, publish_time_format 等。
  如果用户传递了 task_options，则以 task_options 为准。
  如果用户没有传递 task_options，则以消息体中的extra字典为准。
  如果最终还是没有 task_id, publish_time, publish_time_format 等字段，则自动生成。
  
  意味着如果你想传递 task_options 中的值，你的msg字典，
  第一种：你可以有一个extra字段，里面存放 task_options的各种字段，（适合跨编程语言）
  第二种：你可以通过publish方法的 task_options指定一个 TaskOptions pydantic模型对象 （适合python语言，因为能章节用funboost）
  
  如果是跨业务跨编程语言，由于java不能调用python funboost的publish方法:
  java可以这样通过http接口或者funboost.faas  来发布消息 {"user_id":123,"name":"张三","extra": {"task_id":"1234567890","max_retry_times":3}} 
  `````
- `def send_msg(self, msg: typing.Union[dict, str])`
  - *直接发送任意消息内容到消息队列,不生成辅助参数,无视函数入参名字,不校验入参个数和键名*
- `def push(self, *func_args, **func_kwargs)`
  - **Docstring:**
  `````
  简写，只支持传递消费函数的本身参数，不支持task_options参数。
  类似于 publish和push的关系类似 apply_async 和 delay的关系。前者更强大，后者更简略。
  
  例如消费函数是
  def add(x,y):
      print(x+y)
  
  publish({"x":1,'y':2}) 和 push(1,2)是等效的。但前者可以传递task_options参数。后者只能穿add函数所接受的入参。
  :param func_args:
  :param func_kwargs:
  :return:
  `````
- `def sync_call(self, msg_dict: dict, is_return_rpc_data_obj = True) -> typing.Union[dict, FunctionResultStatus]`
  - *仅有部分中间件支持同步调用并阻塞等待返回结果,不依赖AsyncResult + redis作为rpc，例如 http grpc 等*
- `def clear(self)` `abc.abstractmethod`
- `def get_message_count(self)` `abc.abstractmethod`
- `def close(self)` `abc.abstractmethod`
- `async def aio_push(self, *func_args, **func_kwargs) -> AioAsyncResult`
  - **Docstring:**
  `````
  asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
  但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push
  `````
- `async def aio_publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None) -> AioAsyncResult`
  - **Docstring:**
  `````
  asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
  但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push
  `````
- `def check_func_msg_dict(self, msg_dict: dict)`
- `def check_func_input_params(self, *args, **kwargs)`
  - **Docstring:**
  `````
  校验 push 风格的参数: f.check_params(1, y=2)
  利用框架启动时已经解析好的 final_func_input_params_info 进行参数映射和校验。
  :param args: 位置参数
  :param kwargs: 关键字参数
  :return: 校验通过返回 True，失败抛出异常
  `````

**Properties (1):**
- `@property final_func_input_params_info`

**Class Variables (1):**
- `delay = push`

#### 🔧 Public Functions (1)

- `def deco_mq_conn_error(f)`
  - *Line: 364*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 11:57
from pathlib import Path

import abc
import copy
import inspect
import atexit
import json
import logging
import multiprocessing
import sys
import threading
import time
import typing
from functools import wraps
from threading import Lock

import nb_log
from funboost.concurrent_pool.async_helper import simple_run_in_executor
from funboost.constant import ConstStrForClassMethod, FunctionKind
from funboost.core.broker_kind__exclusive_config_default_define import generate_broker_exclusive_config
from funboost.core.func_params_model import PublisherParams, TaskOptions
from funboost.core.function_result_status_saver import FunctionResultStatus
from funboost.core.helper_funs import MsgGenerater
from funboost.core.loggers import develop_logger

# from nb_log import LoggerLevelSetterMixin, LoggerMixin
from funboost.core.loggers import LoggerLevelSetterMixin, FunboostFileLoggerMixin, get_logger
from funboost.core.msg_result_getter import AsyncResult, AioAsyncResult
from funboost.core.serialization import PickleHelper, Serialization
from funboost.core.task_id_logger import TaskIdLogger
from funboost.utils import decorators
from funboost.funboost_config_deafult import BrokerConnConfig, FunboostCommonConfig
from nb_libs.path_helper import PathHelper
from funboost.core.consuming_func_iniput_params_check import ConsumingFuncInputParamsChecker

RedisAsyncResult = AsyncResult  # 别名
RedisAioAsyncResult = AioAsyncResult  # 别名


class AbstractPublisher(LoggerLevelSetterMixin, metaclass=abc.ABCMeta, ):
    """
    发布消息到消息队列
    同步编程，最重要的方法有 push publish，
    asyncio异步编程，最重要的方法有 aio_push aio_publish，
    
    用法是 booster.push(1,y=2)
    或者 booster.publish({"x":1,"y":2},task_options=TaskOptions(max_retry_times=3,...)) 
    总结就是push更简单更魔法，publish是更强大更灵活，因为publish除了发布函数入参自身，还可以传递task_options参数。
    """
    def __init__(self, publisher_params: PublisherParams, ):
        self.publisher_params = publisher_params
        
        self.queue_name = self._queue_name = publisher_params.queue_name
        self.logger: logging.Logger
        self._build_logger()
        
        self.publisher_params.broker_exclusive_config = generate_broker_exclusive_config(self.publisher_params.broker_kind,self.publisher_params.broker_exclusive_config,self.logger)
        self.has_init_broker = 0
        self._lock_for_count = Lock()
        self._current_time = None
        self.count_per_minute = None
        self._init_count()
        self.custom_init()
        self.logger.info(f'{self.__class__} 被实例化了')
        self.publish_msg_num_total = 0
        
        ConsumingFuncInputParamsChecker.gen_final_func_input_params_info(publisher_params)
        self.publish_params_checker = ConsumingFuncInputParamsChecker(self.final_func_input_params_info) if publisher_params.consuming_function else None

        self.__init_time = time.time()
        atexit.register(self._at_exit)
        if publisher_params.clear_queue_within_init:
            self.clear()
    
    @property
    def final_func_input_params_info(self):
        """
        {...
         "auto_generate_info": {
    "where_to_instantiate": "D:\\codes\\funboost\\examples\\example_faas\\task_funs_dir\\sub.py:5",
    "final_func_input_params_info": {
      "func_name": "sub",
      "func_position": "<function sub at 0x00000272649BBA60>",
      "is_manual_func_input_params": false,
      "all_arg_name_list": [
        "a",
        "b"
      ],
      "must_arg_name_list": [
        "a",
        "b"
      ],
      "optional_arg_name_list": []
    }
  }}
        """
        return self.publisher_params.auto_generate_info['final_func_input_params_info']

    def _build_logger(self):
        logger_prefix = self.publisher_params.logger_prefix
        if logger_prefix != '':
            logger_prefix += '--'
        self.logger_name = self.publisher_params.logger_name or f'funboost.{logger_prefix}{self.__class__.__name__}--{self.queue_name}'
        self.log_filename = self.publisher_params.log_filename or f'funboost.{self.queue_name}.log'
        self.logger = nb_log.LogManager(self.logger_name, logger_cls=TaskIdLogger).get_logger_and_add_handlers(
            log_level_int=self.publisher_params.log_level,
            log_filename=self.log_filename if self.publisher_params.create_logger_file else None,
            error_log_filename=nb_log.generate_error_file_name(self.log_filename),
            formatter_template=FunboostCommonConfig.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER, )

    def _init_count(self):
        self._current_time = time.time()
        self.count_per_minute = 0

    def custom_init(self):
        pass

    @staticmethod
    def _get_from_other_extra_params(k: str, msg):
        # msg_dict = json.loads(msg) if isinstance(msg, str) else msg
        msg_dict = Serialization.to_dict(msg)
        return msg_dict['extra'].get('other_extra_params', {}).get(k, None)

    def _convert_msg(self, msg: typing.Union[str, dict], task_id=None,
                     task_options: TaskOptions = None) -> (typing.Dict, typing.Dict, typing.Dict, str):
        """
        
        """
        msg = Serialization.to_dict(msg)
        msg_function_kw = copy.deepcopy(msg)
        raw_extra = {}
        if 'extra' in msg:
            msg_function_kw.pop('extra')
            raw_extra = msg['extra']
        self.check_func_msg_dict(msg_function_kw)

        if task_options:
            task_options_dict = Serialization.to_dict(task_options.to_json(exclude_unset=True))
        else:
            task_options_dict = {}
        task_id = task_id or task_options_dict.get('task_id') or raw_extra.get('task_id') or MsgGenerater.generate_task_id(self._queue_name)
        task_options_dict['task_id'] = task_id
        task_options_dict['publish_time'] = task_options_dict.get('publish_time') or raw_extra.get('publish_time') or MsgGenerater.generate_publish_time()
        task_options_dict['publish_time_format'] = task_options_dict.get('publish_time_format') or raw_extra.get('publish_time_format') or MsgGenerater.generate_publish_time_format()
    
        new_extra = {}
        new_extra.update(raw_extra)
        new_extra.update(task_options_dict) # task_options.json 是为了充分使用 pydantic的自定义时间格式化字符串
        msg['extra'] = new_extra
        extra_params = new_extra
        return msg, msg_function_kw, extra_params, task_id

    def publish(self, msg: typing.Union[str, dict], task_id=None,
                task_options: TaskOptions = None):
        """

        :param msg:函数的入参字典或者字典转json。,例如消费函数是 def add(x,y)，你就发布 {"x":1,"y":2}
        :param task_id:可以指定task_id,也可以不指定就随机生产uuid
        :param task_options:优先级配置，消息可以携带优先级配置，覆盖boost的配置。
        :return: AsyncResult 对象，可以用于等待结果。 例如 status_and_result =  async_result.status_and_result 来等待返回结果。

        funboost 消息体中的extra字典，包含的key就是 TaskOptions 中声明的字段。例如 task_id, publish_time, publish_time_format 等。
        如果用户传递了 task_options，则以 task_options 为准。
        如果用户没有传递 task_options，则以消息体中的extra字典为准。
        如果最终还是没有 task_id, publish_time, publish_time_format 等字段，则自动生成。

        意味着如果你想传递 task_options 中的值，你的msg字典，
        第一种：你可以有一个extra字段，里面存放 task_options的各种字段，（适合跨编程语言）
        第二种：你可以通过publish方法的 task_options指定一个 TaskOptions pydantic模型对象 （适合python语言，因为能章节用funboost）

        如果是跨业务跨编程语言，由于java不能调用python funboost的publish方法:
        java可以这样通过http接口或者funboost.faas  来发布消息 {"user_id":123,"name":"张三","extra": {"task_id":"1234567890","max_retry_times":3}} 

        """
        msg = copy.deepcopy(msg)  # 字典是可变对象,不要改变影响用户自身的传参字典. 用户可能继续使用这个传参字典.
        msg, msg_function_kw, extra_params, task_id = self._convert_msg(msg, task_id, task_options)
        t_start = time.time()

        try:
            msg_json = Serialization.to_json_str(msg)
        except Exception as e:
            can_not_json_serializable_keys = Serialization.find_can_not_json_serializable_keys(msg)
            self.logger.warning(f'msg 中包含不能序列化的键: {can_not_json_serializable_keys}')
            # raise ValueError(f'msg 中包含不能序列化的键: {can_not_json_serializable_keys}')
            new_msg = copy.deepcopy(Serialization.to_dict(msg))
            for key in can_not_json_serializable_keys:
                new_msg[key] = PickleHelper.to_str(new_msg[key])
            new_msg['extra']['can_not_json_serializable_keys'] = can_not_json_serializable_keys
            msg_json = Serialization.to_json_str(new_msg)
        # print(msg_json)
        decorators.handle_exception(retry_times=10, is_throw_error=True, time_sleep=0.1)(
            self._publish_impl)(msg_json)

        self.logger.debug(f'向{self._queue_name} 队列，推送消息 耗时{round(time.time() - t_start, 4)}秒  {msg_json if self.publisher_params.publish_msg_log_use_full_msg else msg_function_kw}',
                          extra={'task_id': task_id} # 发布日志中显示task_id，方便排查问题。
                          )  # 显示msg太长了。
        with self._lock_for_count:
            self.count_per_minute += 1
            self.publish_msg_num_total += 1
            if time.time() - self._current_time > 10:
                self.logger.info(
                    f'10秒内推送了 {self.count_per_minute} 条消息,累计推送了 {self.publish_msg_num_total} 条消息到 {self._queue_name} 队列中')
                self._init_count()
        return AsyncResult(task_id,timeout=self.publisher_params.rpc_timeout)

    def send_msg(self, msg: typing.Union[dict, str]):
        """直接发送任意消息内容到消息队列,不生成辅助参数,无视函数入参名字,不校验入参个数和键名"""
        decorators.handle_exception(retry_times=10, is_throw_error=True, time_sleep=0.1)(
            self._publish_impl)(Serialization.to_json_str(msg))

    @staticmethod
    def __get_cls_file(cls: type):
        if cls.__module__ == '__main__':
            cls_file = Path(sys.argv[0]).resolve().as_posix()
        else:
            cls_file = Path(sys.modules[cls.__module__].__file__).resolve().as_posix()
        return cls_file

    def push(self, *func_args, **func_kwargs):
        """
        简写，只支持传递消费函数的本身参数，不支持task_options参数。
        类似于 publish和push的关系类似 apply_async 和 delay的关系。前者更强大，后者更简略。

        例如消费函数是
        def add(x,y):
            print(x+y)

        publish({"x":1,'y':2}) 和 push(1,2)是等效的。但前者可以传递task_options参数。后者只能穿add函数所接受的入参。
        :param func_args:
        :param func_kwargs:
        :return:
        """
        # print(func_args, func_kwargs, self.publish_params_checker.all_arg_name)
        msg_dict = func_kwargs
        # print(msg_dict)
        # print(self.publish_params_checker.position_arg_name_list)
        # print(func_args)
        func_args_list = list(func_args)

        # print(func_args_list)
        if self.publisher_params.consuming_function_kind == FunctionKind.CLASS_METHOD:
            # print(self.publish_params_checker.all_arg_name[0])
            # func_args_list.insert(0, {'first_param_name': self.publish_params_checker.all_arg_name[0],
            #        'cls_type': ClsHelper.get_classs_method_cls(self.publisher_params.consuming_function).__name__},
            #                       )
            cls = func_args_list[0]
            # print(cls,cls.__name__, sys.modules[cls.__module__].__file__)
            if not inspect.isclass(cls):
                raise ValueError(f'The consuming_function {self.publisher_params.consuming_function} is class_method,the first params of push must be a class')
            func_args_list[0] = {ConstStrForClassMethod.FIRST_PARAM_NAME: self.publish_params_checker.all_arg_name_list[0],
                                 ConstStrForClassMethod.CLS_NAME: cls.__name__,
                                 ConstStrForClassMethod.CLS_FILE: self.__get_cls_file(cls),
                                 ConstStrForClassMethod.CLS_MODULE: PathHelper(self.__get_cls_file(cls)).get_module_name(),
                                 }
        elif self.publisher_params.consuming_function_kind == FunctionKind.INSTANCE_METHOD:
            obj = func_args[0]

            cls = type(obj)
            if not hasattr(obj, ConstStrForClassMethod.OBJ_INIT_PARAMS):
                raise ValueError(f'''The consuming_function {self.publisher_params.consuming_function} is an instance method, and the instance must have the {ConstStrForClassMethod.OBJ_INIT_PARAMS} attribute.
The first argument of the push method must be the instance of the class.
                ''')
            func_args_list[0] = {ConstStrForClassMethod.FIRST_PARAM_NAME: self.publish_params_checker.all_arg_name_list[0],
                                 ConstStrForClassMethod.CLS_NAME: cls.__name__,
                                 ConstStrForClassMethod.CLS_FILE: self.__get_cls_file(cls),
                                 ConstStrForClassMethod.CLS_MODULE: PathHelper(self.__get_cls_file(cls)).get_module_name(),
                                 ConstStrForClassMethod.OBJ_INIT_PARAMS: getattr(obj, ConstStrForClassMethod.OBJ_INIT_PARAMS),

                                 }

        for index, arg in enumerate(func_args_list):
            # print(index,arg,self.publish_params_checker.position_arg_name_list)
            # msg_dict[self.publish_params_checker.position_arg_name_list[index]] = arg
            msg_dict[self.publish_params_checker.all_arg_name_list[index]] = arg

        # print(msg_dict)
        return self.publish(msg_dict)

    delay = push  # 那就来个别名吧，两者都可以。

    @abc.abstractmethod
    def _publish_impl(self, msg: str):
        raise NotImplementedError

    def sync_call(self, msg_dict: dict, is_return_rpc_data_obj=True) -> typing.Union[dict, FunctionResultStatus]:
        """仅有部分中间件支持同步调用并阻塞等待返回结果,不依赖AsyncResult + redis作为rpc，例如 http grpc 等"""
        raise NotImplementedError(f'broker  {self.publisher_params.broker_kind} not support sync_call method')

    @abc.abstractmethod
    def clear(self):
        raise NotImplementedError

    @abc.abstractmethod
    def get_message_count(self):
        raise NotImplementedError

    @abc.abstractmethod
    def close(self):
        raise NotImplementedError

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
        self.logger.warning(f'with中自动关闭publisher连接，累计推送了 {self.publish_msg_num_total} 条消息 ')

    def _at_exit(self):
        if multiprocessing.current_process().name == 'MainProcess':
            self.logger.warning(
                f'程序关闭前，{round(time.time() - self.__init_time)} 秒内，累计推送了 {self.publish_msg_num_total} 条消息 到 {self._queue_name} 中')

    async def aio_push(self, *func_args, **func_kwargs) -> AioAsyncResult:
        """asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
        但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push"""
        async_result = await simple_run_in_executor(self.push, *func_args, **func_kwargs)
        return AioAsyncResult(async_result.task_id,timeout=async_result.timeout )

    async def aio_publish(self, msg: typing.Union[str, dict], task_id=None,
                          task_options: TaskOptions = None) -> AioAsyncResult:
        """asyncio 生态下发布消息,因为同步push只需要消耗不到1毫秒,所以基本上大概可以直接在asyncio异步生态中直接调用同步的push方法,
        但为了更好的防止网络波动(例如发布消息到外网的消息队列耗时达到10毫秒),可以使用aio_push"""
        async_result = await simple_run_in_executor(self.publish, msg, task_id, task_options)
        return AioAsyncResult(async_result.task_id, timeout=async_result.timeout)

    def check_func_msg_dict(self,msg_dict:dict):
        if self.publish_params_checker and self.publisher_params.should_check_publish_func_params:
            if not isinstance(msg_dict,dict):
                raise ValueError(f"check_func_msg_dict 入参必须是字典, 当前是: {type(msg_dict)}")
            if 'extra' in msg_dict:
                msg_function_kw = copy.deepcopy(msg_dict)
                msg_function_kw.pop('extra')
            else:
                msg_function_kw = msg_dict
            self.publish_params_checker.check_func_msg_dict(msg_function_kw)
        return True

    def check_func_input_params(self, *args, **kwargs):
        """
        校验 push 风格的参数: f.check_params(1, y=2)
        利用框架启动时已经解析好的 final_func_input_params_info 进行参数映射和校验。
        :param args: 位置参数
        :param kwargs: 关键字参数
        :return: 校验通过返回 True，失败抛出异常
        """

        params_dict = dict(zip(self.publish_params_checker.all_arg_name_list, args))
        if kwargs:
            params_dict.update(kwargs)
        # print(4444,args,kwargs, params_dict)
        return self.check_func_msg_dict(params_dict)

        




has_init_broker_lock = threading.Lock()


def deco_mq_conn_error(f):
    @wraps(f)
    def _deco_mq_conn_error(self, *args, **kwargs):
        with has_init_broker_lock:
            if not self.has_init_broker:
                self.logger.warning(f'对象的方法 【{f.__name__}】 首次使用 进行初始化执行 init_broker 方法')
                self.init_broker()
                self.has_init_broker = 1
                return f(self, *args, **kwargs)
            # noinspection PyBroadException
            try:
                return f(self, *args, **kwargs)
            except Exception as e:
                import amqpstorm
                from pikav1.exceptions import AMQPError as PikaAMQPError
                if isinstance(e, (PikaAMQPError, amqpstorm.AMQPError)):
                    # except (PikaAMQPError, amqpstorm.AMQPError,) as e:  # except BaseException as e:   # 现在装饰器用到了绝大多出地方，单个异常类型不行。ex
                    self.logger.error(f'中间件链接出错   ,方法 {f.__name__}  出错 ，{e}')
                    self.init_broker()
                    return f(self, *args, **kwargs)
            except BaseException as e:
                self.logger.critical(e, exc_info=True)

    return _deco_mq_conn_error

`````

--- **end of file: funboost/publishers/base_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/celery_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/celery_publisher.py`

#### 📦 Imports

- `import os`
- `import sys`
- `import time`
- `import celery`
- `import celery.result`
- `import typing`
- `from funboost.assist.celery_helper import celery_app`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import TaskOptions`

#### 🏛️ Classes (1)

##### 📌 `class CeleryPublisher(AbstractPublisher)`
*Line: 15*

**Docstring:**
`````
使用celery作为中间件
`````

**Public Methods (4):**
- `def publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None) -> celery.result.AsyncResult`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import os
import sys
import time
import celery
import celery.result
import typing

from funboost.assist.celery_helper import celery_app
from funboost.publishers.base_publisher import AbstractPublisher, TaskOptions


class CeleryPublisher(AbstractPublisher, ):
    """
    使用celery作为中间件
    """

    def publish(self, msg: typing.Union[str, dict], task_id=None,
                task_options: TaskOptions = None) -> celery.result.AsyncResult:
        msg, msg_function_kw, extra_params,task_id = self._convert_msg(msg, task_id, task_options)
        t_start = time.time()
        celery_result = celery_app.send_task(name=self.queue_name, kwargs=msg_function_kw, task_id=extra_params['task_id'])  # type: celery.result.AsyncResult
        self.logger.debug(f'向{self._queue_name} 队列，推送消息 耗时{round(time.time() - t_start, 4)}秒  {msg_function_kw}')  # 显示msg太长了。
        with self._lock_for_count:
            self.count_per_minute += 1
            self.publish_msg_num_total += 1
            if time.time() - self._current_time > 10:
                self.logger.info(
                    f'10秒内推送了 {self.count_per_minute} 条消息,累计推送了 {self.publish_msg_num_total} 条消息到 {self._queue_name} 队列中')
                self._init_count()
        # return AsyncResult(task_id)
        return celery_result  # 这里返回celery结果原生对象，类型是 celery.result.AsyncResult。

    def _publish_impl(self, msg):
        pass

    def clear(self):
        python_executable = sys.executable
        cmd = f''' {python_executable} -m celery -A funboost.publishers.celery_publisher purge -Q {self.queue_name} -f'''
        self.logger.warning(f'刪除celery {self.queue_name} 隊列中的消息  {cmd}')
        os.system(cmd)

    def get_message_count(self):
        # return -1
        with celery_app.connection_or_acquire() as conn:
            msg_cnt = conn.default_channel.queue_declare(
                queue=self.queue_name, passive=False,durable=True,auto_delete=False).message_count

        return msg_cnt

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/celery_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/confluent_kafka_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/confluent_kafka_publisher.py`

#### 📦 Imports

- `import os`
- `from funboost.core.lazy_impoter import KafkaPythonImporter`
- `import atexit`
- `import time`
- `from confluent_kafka import Producer as ConfluentProducer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from pathlib import Path`
- `import sys`

#### 🏛️ Classes (2)

##### 📌 `class ConfluentKafkaPublisher(AbstractPublisher)`
*Line: 35*

**Docstring:**
`````
使用kafka作为中间件，这个confluent_kafka包的性能远强于 kafka-pyhton
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

##### 📌 `class SaslPlainKafkaPublisher(ConfluentKafkaPublisher)`
*Line: 83*

**Docstring:**
`````
使用kafka作为中间件，这个confluent_kafka包的性能远强于 kafka-pyhton
`````

**Public Methods (1):**
- `def custom_init(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/20 0008 12:12

import os

from funboost.core.lazy_impoter import KafkaPythonImporter

if os.name == 'nt':
    """
    为了保险起见，这样做一下,设置一下path，否则anaconda安装的python可能出现 ImportError: DLL load failed while importing cimpl: 找不到指定的模块。
    多设置没事，少设置了才麻烦。
    """
    from pathlib import Path
    import sys

    # print(sys.executable)  #F:\minicondadir\Miniconda2\envs\py38\python.exe
    # print(os.getenv('path'))
    python_install_path = Path(sys.executable).parent.absolute()
    kafka_libs_path = python_install_path / Path(r'.\Lib\site-packages\confluent_kafka.libs')
    dlls_path = python_install_path / Path(r'.\DLLs')
    library_bin_path = python_install_path / Path(r'.\Library\bin')
    # print(library_bin_path)
    path_env = os.getenv('path')
    os.environ['path'] = f'''{path_env};{kafka_libs_path};{dlls_path};{library_bin_path};'''

import atexit
import time

from confluent_kafka import Producer as ConfluentProducer
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher


class ConfluentKafkaPublisher(AbstractPublisher, ):
    """
    使用kafka作为中间件，这个confluent_kafka包的性能远强于 kafka-pyhton
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):

        # self._producer = KafkaProducer(bootstrap_servers=funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS)
        try:
            admin_client = KafkaPythonImporter().KafkaAdminClient(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
            admin_client.create_topics([KafkaPythonImporter().NewTopic(self._queue_name, 10, 1)])
            # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
        except KafkaPythonImporter().TopicAlreadyExistsError:
            pass
        except BaseException as e:
            self.logger.exception(e)
        atexit.register(self.close)  # 程序退出前不主动关闭，会报错。
        self._confluent_producer = ConfluentProducer({'bootstrap.servers': ','.join(BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)})
        self._recent_produce_time = time.time()

    # noinspection PyAttributeOutsideInit
    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        # self.logger.debug(msg)
        self._confluent_producer.produce(self._queue_name, msg.encode(), )
        if time.time() - self._recent_produce_time > 1:
            self._confluent_producer.flush()
            self._recent_produce_time = time.time()

    def clear(self):
        self.logger.warning('还没开始实现 kafka 清空 消息')
        # self._consumer.seek_to_end()
        # self.logger.warning(f'将kafka offset 重置到最后位置')

    def get_message_count(self):
        return -1  # 还没找到获取所有分区未消费数量的方法。

    def close(self):
        pass
        # self._confluent_producer.

    def _at_exit(self):
        # self._producer.flush()
        self._confluent_producer.flush()
        super()._at_exit()


class SaslPlainKafkaPublisher(ConfluentKafkaPublisher):
    """
    使用kafka作为中间件，这个confluent_kafka包的性能远强于 kafka-pyhton
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        # self._producer = KafkaProducer(bootstrap_servers=funboost_config_deafult.KAFKA_BOOTSTRAP_SERVERS)
        try:
            admin_client = KafkaPythonImporter().KafkaAdminClient(**BrokerConnConfig.KFFKA_SASL_CONFIG)
            admin_client.create_topics([KafkaPythonImporter().NewTopic(self._queue_name, 10, 1)])
            # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
        except KafkaPythonImporter().TopicAlreadyExistsError:
            pass
        except BaseException as e:
            self.logger.exception(e)
        atexit.register(self.close)  # 程序退出前不主动关闭，会报错。
        self._confluent_producer = ConfluentProducer({
            'bootstrap.servers': ','.join(BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS),
            'security.protocol': BrokerConnConfig.KFFKA_SASL_CONFIG['security_protocol'],
            'sasl.mechanisms': BrokerConnConfig.KFFKA_SASL_CONFIG['sasl_mechanism'],
            'sasl.username': BrokerConnConfig.KFFKA_SASL_CONFIG['sasl_plain_username'],
            'sasl.password': BrokerConnConfig.KFFKA_SASL_CONFIG['sasl_plain_password']
        })
        self._recent_produce_time = time.time()

`````

--- **end of file: funboost/publishers/confluent_kafka_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/dramatiq_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/dramatiq_publisher.py`

#### 📦 Imports

- `import copy`
- `import json`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.assist.dramatiq_helper import DramatiqHelper`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class DramatiqPublisher(AbstractPublisher)`
*Line: 13*

**Docstring:**
`````
使用dramatiq框架作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf

import copy
import json

from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.assist.dramatiq_helper import DramatiqHelper
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.utils.redis_manager import RedisMixin


class DramatiqPublisher(AbstractPublisher, ):
    """
    使用dramatiq框架作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        pass

    def _publish_impl(self, msg):
        if isinstance(msg, str):
            msg = json.loads(msg)
        msg_function_kw = copy.deepcopy(msg)
        if 'extra' in msg:
            msg_function_kw.pop('extra')
        DramatiqHelper.queue_name__actor_map[self.queue_name].send(**msg_function_kw)

    def clear(self):
        DramatiqHelper.broker.flush(self.queue_name)

    def get_message_count(self):
        # pass
        # return -1
        if BrokerConnConfig.DRAMATIQ_URL.startswith('redis'):
            return RedisMixin().redis_db_frame.llen(self.queue_name)  # redis 无，需要自己实现
        if BrokerConnConfig.DRAMATIQ_URL.startswith('amqp'):
            cnts = DramatiqHelper.broker.get_queue_message_counts(self.queue_name)
            return cnts[0]
        return -1

    def close(self):
        DramatiqHelper.broker.close()

`````

--- **end of file: funboost/publishers/dramatiq_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/empty_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/empty_publisher.py`

#### 📦 Imports

- `import abc`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class EmptyPublisher(AbstractPublisher)`
*Line: 9*

**Docstring:**
`````
空的发布者，空的实现，需要搭配 boost入参的 consumer_override_cls 和 publisher_override_cls使用，或者被继承。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)` `abc.abstractmethod`
- `def get_message_count(self)` `abc.abstractmethod`
- `def close(self)` `abc.abstractmethod`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 12:12

import abc
from funboost.publishers.base_publisher import AbstractPublisher


class EmptyPublisher(AbstractPublisher, metaclass=abc.ABCMeta):
    """
    空的发布者，空的实现，需要搭配 boost入参的 consumer_override_cls 和 publisher_override_cls使用，或者被继承。
    """

    def custom_init(self):
        pass

    @abc.abstractmethod
    def _publish_impl(self, msg: str):
        raise NotImplemented('not realization')

    @abc.abstractmethod
    def clear(self):
        raise NotImplemented('not realization')

    @abc.abstractmethod
    def get_message_count(self):
        raise NotImplemented('not realization')

    @abc.abstractmethod
    def close(self):
        raise NotImplemented('not realization')

`````

--- **end of file: funboost/publishers/empty_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/faststream_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/faststream_publisher.py`

#### 📦 Imports

- `import abc`
- `import asyncio`
- `import json`
- `import time`
- `import typing`
- `from funboost import TaskOptions`
- `from funboost.concurrent_pool.async_helper import get_or_create_event_loop`
- `from funboost.core.serialization import Serialization`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.assist.faststream_helper import app`
- `from funboost.assist.faststream_helper import get_broker`
- `from faststream import FastStream`
- `from faststream import Context`
- `from faststream.annotations import Logger`

#### 🏛️ Classes (1)

##### 📌 `class FastStreamPublisher(AbstractPublisher)`
*Line: 19*

**Docstring:**
`````
空的发布者，空的实现，需要搭配 boost入参的 consumer_override_cls 和 publisher_override_cls使用，或者被继承。
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 12:12

import abc
import asyncio
import json
import time
import typing

from funboost import TaskOptions
from funboost.concurrent_pool.async_helper import get_or_create_event_loop
from funboost.core.serialization import Serialization
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.assist.faststream_helper import app,get_broker
from faststream import FastStream,Context
from faststream.annotations import Logger

class FastStreamPublisher(AbstractPublisher, metaclass=abc.ABCMeta):
    """
    空的发布者，空的实现，需要搭配 boost入参的 consumer_override_cls 和 publisher_override_cls使用，或者被继承。
    """
    def custom_init(self):
        pass
        # asyncio.get_event_loop().run_until_complete(broker.start())
        self.broker = get_broker()
        get_or_create_event_loop().run_until_complete(self.broker.connect())

    def publish(self, msg: typing.Union[str, dict], task_id=None,
                task_options: TaskOptions = None) :
        msg, msg_function_kw, extra_params, task_id = self._convert_msg(msg, task_id, task_options)
        t_start = time.time()
        faststream_result =  get_or_create_event_loop().run_until_complete(self.broker.publish(Serialization.to_json_str(msg), self.queue_name))
        self.logger.debug(f'向{self._queue_name} 队列，推送消息 耗时{round(time.time() - t_start, 4)}秒  {msg_function_kw}')  # 显示msg太长了。
        with self._lock_for_count:
            self.count_per_minute += 1
            self.publish_msg_num_total += 1
            if time.time() - self._current_time > 10:
                self.logger.info(
                    f'10秒内推送了 {self.count_per_minute} 条消息,累计推送了 {self.publish_msg_num_total} 条消息到 {self._queue_name} 队列中')
                self._init_count()
        # return AsyncResult(task_id)
        return faststream_result  #

    def _publish_impl(self, msg):
        pass


    def clear(self):
        pass


    def get_message_count(self):
        return -1


    def close(self):
        pass

`````

--- **end of file: funboost/publishers/faststream_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/grpc_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/grpc_publisher.py`

#### 📦 Imports

- `import abc`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.assist.grpc_helper import funboost_grpc_pb2_grpc`
- `from funboost.assist.grpc_helper import funboost_grpc_pb2`
- `from funboost.core.serialization import Serialization`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `import grpc`

#### 🏛️ Classes (1)

##### 📌 `class GrpcPublisher(AbstractPublisher)`
*Line: 9*

**Docstring:**
`````
grpc 作为broker
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def sync_call(self, msg_dict: dict, is_return_rpc_data_obj = True)`
  - **Docstring:**
  `````
  同步请求,并阻塞等待结果返回.
  不像push那样依赖AsyncResult + redis 实现的rpc
  :param msg_dict:
  :return:
  `````
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
import abc
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.assist.grpc_helper import funboost_grpc_pb2_grpc, funboost_grpc_pb2
from funboost.core.serialization import Serialization
from funboost.core.function_result_status_saver import FunctionResultStatus
import grpc


class GrpcPublisher(AbstractPublisher, ):
    """grpc 作为broker"""

    def custom_init(self):
        host = self.publisher_params.broker_exclusive_config['host']
        port = self.publisher_params.broker_exclusive_config['port']
        channel = grpc.insecure_channel(f'{host}:{port}')
        stub = funboost_grpc_pb2_grpc.FunboostBrokerServiceStub(channel)
        self._stub = stub
        self._channel = channel

    def _publish_impl(self, msg: str):
        request = funboost_grpc_pb2.FunboostGrpcRequest(json_req=msg,call_type="publish")
        response = self._stub.Call(request)
        return response.json_resp

    def sync_call(self, msg_dict: dict, is_return_rpc_data_obj=True):
        """
        同步请求,并阻塞等待结果返回.
        不像push那样依赖AsyncResult + redis 实现的rpc
        :param msg_dict:
        :return:
        """

        """
        用法例子
        $booster.publisher.grpc_call({'x':i,'y':i*2}) 
        """
        request = funboost_grpc_pb2.FunboostGrpcRequest(json_req=Serialization.to_json_str(msg_dict),
                                                        call_type="sync_call")
        response = self._stub.Call(request)
        json_resp =  response.json_resp
        if is_return_rpc_data_obj:
            return FunctionResultStatus.parse_status_and_result_to_obj(Serialization.to_dict(json_resp))
        else:
            return Serialization.to_dict(json_resp)

    def clear(self):
        pass

    def get_message_count(self):
        return -1

    def close(self):
        self._channel.close()

`````

--- **end of file: funboost/publishers/grpc_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/httpsqs_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/httpsqs_publisher.py`

#### 📦 Imports

- `import json`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `import http.client`
- `from urllib.parse import quote`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `import urllib3`

#### 🏛️ Classes (1)

##### 📌 `class HttpsqsPublisher(AbstractPublisher)`
*Line: 16*

**Docstring:**
`````
使用httpsqs作为中间件
`````

**Public Methods (6):**
- `def custom_init(self)`
- `def opt_httpsqs000(self, opt = None, data = '')`
- `def opt_httpsqs(self, opt = None, data = '')`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import json
from funboost.publishers.base_publisher import AbstractPublisher
import http.client
from urllib.parse import quote
from funboost.funboost_config_deafult import BrokerConnConfig
import urllib3

"""
http://blog.zyan.cc/httpsqs/
"""


class HttpsqsPublisher(AbstractPublisher):
    """
    使用httpsqs作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        conn = http.client.HTTPConnection(host=BrokerConnConfig.HTTPSQS_HOST, port=BrokerConnConfig.HTTPSQS_PORT)
        url = f"/?name={self._queue_name}&opt=maxqueue&num=1000000000&auth={BrokerConnConfig.HTTPSQS_AUTH}&charset=utf-8"
        conn.request("GET", url)
        self.logger.info(conn.getresponse().read(1000))

        self.http = urllib3.PoolManager(20)

    def opt_httpsqs000(self, opt=None, data=''):
        data_url_encode = quote(data)
        resp = self.http.request('get', url=f'http://{BrokerConnConfig.HTTPSQS_HOST}:{BrokerConnConfig.HTTPSQS_PORT}' +
                                            f"/?name={self._queue_name}&opt={opt}&data={data_url_encode}&auth={BrokerConnConfig.HTTPSQS_AUTH}&charset=utf-8")
        return resp.data.decode()

    def opt_httpsqs(self, opt=None, data=''):
        conn = http.client.HTTPConnection(host=BrokerConnConfig.HTTPSQS_HOST, port=BrokerConnConfig.HTTPSQS_PORT)
        data_url_encode = quote(data)
        url = f"/?name={self._queue_name}&opt={opt}&data={data_url_encode}&auth={BrokerConnConfig.HTTPSQS_AUTH}&charset=utf-8"
        conn.request("GET", url)
        r = conn.getresponse()
        resp_text = r.read(1000000).decode()
        # print(url,r.status, resp_text)
        conn.close()
        return resp_text

    def _publish_impl(self, msg):
        # curl "http://host:port/?name=your_queue_name&opt=put&data=经过URL编码的文本消息&auth=mypass123"
        text = self.opt_httpsqs('put', msg)
        if text != 'HTTPSQS_PUT_OK':
            self.logger.critical(text)

    def clear(self):
        # curl "http://host:port/?name=your_queue_name&opt=reset&auth=mypass123"
        # HTTPSQS_RESET_OK
        text = self.opt_httpsqs('reset')
        if text != 'HTTPSQS_RESET_OK':
            self.logger.critical(text)
        else:
            self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    def get_message_count(self):
        text = self.opt_httpsqs('status_json')
        status_dict = json.loads(text)
        # print(status_dict)
        return status_dict['putpos'] - status_dict['getpos']

    def close(self):
        self.http.clear()

`````

--- **end of file: funboost/publishers/httpsqs_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/http_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/http_publisher.py`

#### 📦 Imports

- `import threading`
- `from funboost.core.function_result_status_saver import FunctionResultStatus`
- `from funboost.core.serialization import Serialization`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from urllib3 import PoolManager`

#### 🏛️ Classes (1)

##### 📌 `class HTTPPublisher(AbstractPublisher)`
*Line: 12*

**Docstring:**
`````
http实现的，不支持持久化。
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def sync_call(self, msg_dict: dict, is_return_rpc_data_obj = True)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import threading

from funboost.core.function_result_status_saver import FunctionResultStatus
from funboost.core.serialization import Serialization
from funboost.publishers.base_publisher import AbstractPublisher
from urllib3 import PoolManager


class HTTPPublisher(AbstractPublisher, ):
    """
    http实现的，不支持持久化。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._http = PoolManager(maxsize=100)
        self._ip = self.publisher_params.broker_exclusive_config['host']
        self._port = self.publisher_params.broker_exclusive_config['port']
        self._ip_port_str = f'{self._ip}:{self._port}'
        if self._port is None:
            raise ValueError('please specify port')


    def _publish_impl(self, msg):
        url = self._ip_port_str + '/queue'
        self._http.request('post', url, fields={'msg': msg,'call_type':'publish'})

    def sync_call(self, msg_dict: dict, is_return_rpc_data_obj=True):
        url = self._ip_port_str + '/queue'
        response = self._http.request('post', url, 
                  fields={'msg': Serialization.to_json_str(msg_dict),'call_type':'sync_call'})
        json_resp =  response.data.decode('utf-8')
        # import requests
        # response = requests.request('post', url, 
        #           data={'msg': Serialization.to_json_str(msg_dict),'call_type':'sync_call'})
        # json_resp =  response.text()
        if is_return_rpc_data_obj:
            return FunctionResultStatus.parse_status_and_result_to_obj(Serialization.to_dict(json_resp))
        else:
            return Serialization.to_dict(json_resp)


    def clear(self):
        pass  # udp没有保存消息

    def get_message_count(self):
        return -1  # http模式没有持久化保存消息

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/http_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/huey_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/huey_publisher.py`

#### 📦 Imports

- `import copy`
- `import json`
- `from huey import RedisHuey`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.assist.huey_helper import HueyHelper`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class HueyPublisher(AbstractPublisher)`
*Line: 15*

**Docstring:**
`````
使用huey框架作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf

import copy
import json

from huey import RedisHuey

from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.assist.huey_helper import HueyHelper
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.utils.redis_manager import RedisMixin


class HueyPublisher(AbstractPublisher, ):
    """
    使用huey框架作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._huey_task_fun = HueyHelper.queue_name__huey_task_fun_map[self.queue_name]
        self._huey_obj = HueyHelper.huey_obj # type: RedisHuey

    def _publish_impl(self, msg):
        if isinstance(msg, str):
            msg = json.loads(msg)
        msg_function_kw = copy.deepcopy(msg)
        if 'extra' in msg:
            msg_function_kw.pop('extra')
        self._huey_task_fun(**msg_function_kw)

    def clear(self):
        self._huey_obj.flush()

    def get_message_count(self):
        pass
        return -1


    def close(self):
        pass

`````

--- **end of file: funboost/publishers/huey_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/kafka_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/kafka_publisher.py`

#### 📦 Imports

- `import atexit`
- `from funboost.core.lazy_impoter import KafkaPythonImporter`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class KafkaPublisher(AbstractPublisher)`
*Line: 13*

**Docstring:**
`````
使用kafka作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/20 0008 12:12

# noinspection PyPackageRequirements
import atexit

from funboost.core.lazy_impoter import KafkaPythonImporter
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher


class KafkaPublisher(AbstractPublisher, ):
    """
    使用kafka作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._producer = KafkaPythonImporter().KafkaProducer(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
        self._admin_client = KafkaPythonImporter().KafkaAdminClient(bootstrap_servers=BrokerConnConfig.KAFKA_BOOTSTRAP_SERVERS)
        try:
            self._admin_client.create_topics([KafkaPythonImporter().NewTopic(self._queue_name,
                                                                             self.publisher_params.broker_exclusive_config['num_partitions'],
                                                                             self.publisher_params.broker_exclusive_config['replication_factor'])])
            # admin_client.create_partitions({self._queue_name: NewPartitions(total_count=16)})
        except KafkaPythonImporter().TopicAlreadyExistsError:
            pass
        except BaseException as e:
            self.logger.exception(e)
        atexit.register(self.close)  # 程序退出前不主动关闭，会报错。

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        # self.logger.debug(msg)
        # print(msg)
        self._producer.send(self._queue_name, msg.encode(), )

    def clear(self):
        self.logger.warning('还没开始实现 kafka 清空 消息')
        # self._consumer.seek_to_end()
        # self.logger.warning(f'将kafka offset 重置到最后位置')

    def get_message_count(self):
        # return -1 # 还没找到获取所有分区未消费数量的方法 。
        # print(self._admin_client.list_consumer_group_offsets('frame_group'))
        # print(self._admin_client.describe_consumer_groups('frame_group'))
        return -1

    def close(self):
        self._producer.close()

    def _at_exit(self):
        self._producer.flush()
        super()._at_exit()

`````

--- **end of file: funboost/publishers/kafka_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/kombu_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/kombu_publisher.py`

#### 📦 Imports

- `import os`
- `import json`
- `from kombu.transport.virtual.base import Channel`
- `from kombu.entity import Exchange`
- `from kombu.entity import Queue`
- `from kombu.connection import Connection`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import deco_mq_conn_error`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`

#### 🏛️ Classes (2)

##### 📌 `class NoEncode`
*Line: 28*

**Public Methods (2):**
- `def encode(self, s)`
- `def decode(self, s)`

##### 📌 `class KombuPublisher(AbstractPublisher)`
*Line: 42*

**Docstring:**
`````
使用kombu作为中间件,这个能直接一次性支持很多种小众中间件，但性能很差，除非是分布式函数调度框架没实现的中间件种类用户才可以用这种，用户也可以自己对比性能。
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def init_broker(self)`
- `def clear(self)` `deco_mq_conn_error`
- `def get_message_count(self)` `deco_mq_conn_error`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2021-04-15 0008 12:12
import os

import json

# noinspection PyUnresolvedReferences
from kombu.transport.virtual.base import Channel
from kombu.entity import Exchange, Queue
from kombu.connection import Connection

from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
from funboost.funboost_config_deafult import BrokerConnConfig, FunboostCommonConfig

# nb_log.get_logger(name=None,log_level_int=10)
"""
https://www.cnblogs.com/shenh/p/10497244.html

rabbitmq  交换机知识。

https://docs.celeryproject.org/projects/kombu/en/stable/introduction.html
kombu 教程
"""


# noinspection PyMethodMayBeStatic,PyRedundantParentheses
class NoEncode():
    def encode(self, s):
        # return bytes_to_str(base64.b64encode(str_to_bytes(s)))
        return s

    def decode(self, s):
        # return base64.b64decode(str_to_bytes(s))
        return s


Channel.codecs['no_encode'] = NoEncode()  # 不使用base64更分方便查看内容


# noinspection PyAttributeOutsideInit
class KombuPublisher(AbstractPublisher, ):
    """
    使用kombu作为中间件,这个能直接一次性支持很多种小众中间件，但性能很差，除非是分布式函数调度框架没实现的中间件种类用户才可以用这种，用户也可以自己对比性能。
    """

    def custom_init(self):
        self.kombu_url = self.publisher_params.broker_exclusive_config['kombu_url'] or BrokerConnConfig.KOMBU_URL
        self._kombu_broker_url_prefix = self.kombu_url.split(":")[0]
        # logger_name = f'{self._logger_prefix}{self.__class__.__name__}--{self._kombu_broker_url_prefix}--{self._queue_name}'
        # self.logger = get_logger(logger_name, log_level_int=self._log_level_int,
        #                          _log_filename=f'{logger_name}.log' if self._is_add_file_handler else None,
        #                          formatter_template=FunboostCommonConfig.NB_LOG_FORMATER_INDEX_FOR_CONSUMER_AND_PUBLISHER,
        #                          )  #
        if self.kombu_url.startswith('filesystem://'):
            self._create_msg_file_dir()

    def _create_msg_file_dir(self):
        os.makedirs(self.publisher_params.broker_exclusive_config['transport_options']['data_folder_in'], exist_ok=True)
        os.makedirs(self.publisher_params.broker_exclusive_config['transport_options']['data_folder_out'], exist_ok=True)
        processed_folder = self.publisher_params.broker_exclusive_config['transport_options'].get('processed_folder', None)
        if processed_folder:
            os.makedirs(processed_folder, exist_ok=True)

    def init_broker(self):
        self.exchange = Exchange('funboost_exchange', 'direct', durable=True)
        self.queue = Queue(self._queue_name, exchange=self.exchange, routing_key=self._queue_name, auto_delete=False)
        self.conn = Connection(self.kombu_url, transport_options=self.publisher_params.broker_exclusive_config['transport_options'])
        self.queue(self.conn).declare()
        self.producer = self.conn.Producer(serializer='json')
        self.channel = self.producer.channel  # type: Channel
        self.channel.body_encoding = 'no_encode'  # 这里改了编码，存到中间件的参数默认把消息base64了，我觉得没必要不方便查看消息明文。
        # self.channel = self.conn.channel()  # type: Channel
        # # self.channel.exchange_declare(exchange='distributed_framework_exchange', durable=True, type='direct')
        # self.queue = self.channel.queue_declare(queue=self._queue_name, durable=True)
        self.logger.warning(f'使用 kombu 库 连接 {self._kombu_broker_url_prefix} 中间件')

    @deco_mq_conn_error
    def _publish_impl(self, msg):
        self.producer.publish(json.loads(msg), exchange=self.exchange, routing_key=self._queue_name, declare=[self.queue])

    @deco_mq_conn_error
    def clear(self):
        self.logger.warning(f'kombu清空消息队列 {self.queue_name}')
        self.channel.queue_purge(self._queue_name)

    @deco_mq_conn_error
    def get_message_count(self):
        # queue = self.channel.queue_declare(queue=self._queue_name, durable=True)
        # return queue.method.message_count
        # self.logger.warning(self.channel._size(self._queue_name))
        queue_declare_ok_t_named_tuple = self.channel.queue_declare(queue=self._queue_name, durable=True, auto_delete=False)
        # print(queue_declare_ok_t_named_tuple)
        return queue_declare_ok_t_named_tuple.message_count
        # if self._kombu_broker_url_prefix == 'amqp' or True:
        #     '''amqp tries to use librabbitmq but falls back to pyamqp.'''
        #     queue_declare_ok_t_named_tuple = self.channel.queue_declare(queue=self._queue_name, durable=True, auto_delete=False)
        #     # queue_declare_ok_t(queue='test_rabbit_queue2', message_count=100000, consumer_count=0)
        #     # print(type(queue_declare_ok_t_named_tuple),queue_declare_ok_t_named_tuple)
        #     return queue_declare_ok_t_named_tuple.message_count
        # # noinspection PyProtectedMember
        # return self.channel._size(self._queue_name)

    def close(self):
        self.channel.close()
        self.conn.close()
        self.logger.warning('关闭 kombu 包 链接')

`````

--- **end of file: funboost/publishers/kombu_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/local_python_queue_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/local_python_queue_publisher.py`

#### 📦 Imports

- `from collections import deque`
- `from queue import Queue`
- `from queue import SimpleQueue`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.queues.memory_queues_map import PythonQueues`

#### 🏛️ Classes (3)

##### 📌 `class LocalPythonQueuePublisher(AbstractPublisher)`
*Line: 13*

**Docstring:**
`````
使用python内置queue对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
`````

**Public Methods (3):**
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

**Properties (1):**
- `@property local_python_queue -> Queue`

##### 📌 `class LocalPythonQueuePublisherSimpleQueue(AbstractPublisher)`
*Line: 41*

**Docstring:**
`````
使用python内置SimpleQueue对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

##### 📌 `class LocalPythonQueuePublisherDeque(AbstractPublisher)`
*Line: 69*

**Docstring:**
`````
使用python内置 Dequeu 对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:07
from collections import deque
from queue import Queue, SimpleQueue

from funboost.publishers.base_publisher import AbstractPublisher
from funboost.queues.memory_queues_map import PythonQueues

local_pyhton_queue_name__local_pyhton_queue_obj_map = dict()  # 使local queue和其他中间件完全一样的使用方式，使用映射保存队列的名字，使消费和发布通过队列名字能找到队列对象。


class LocalPythonQueuePublisher(AbstractPublisher):
    """
    使用python内置queue对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
    """

    # noinspection PyAttributeOutsideInit

    @property
    def local_python_queue(self) -> Queue:
        return PythonQueues.get_queue(self._queue_name)

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        pass
        self.local_python_queue.put(msg)

    def clear(self):
        # noinspection PyUnresolvedReferences
        self.local_python_queue.queue.clear()
        self.logger.warning(f'清除 本地队列中的消息成功')

    def get_message_count(self):
        return self.local_python_queue.qsize()

    def close(self):
        pass


class LocalPythonQueuePublisherSimpleQueue(AbstractPublisher):
    """
    使用python内置SimpleQueue对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        if self._queue_name not in local_pyhton_queue_name__local_pyhton_queue_obj_map:
            local_pyhton_queue_name__local_pyhton_queue_obj_map[self._queue_name] = SimpleQueue()
        self.queue = local_pyhton_queue_name__local_pyhton_queue_obj_map[self._queue_name]  # type: SimpleQueue

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        self.queue.put(msg)

    def clear(self):
        pass
        # noinspection PyUnresolvedReferences
        # self.queue._queue.clear()
        # self.logger.warning(f'清除 本地队列中的消息成功')

    def get_message_count(self):
        return self.queue.qsize()

    def close(self):
        pass


class LocalPythonQueuePublisherDeque(AbstractPublisher):
    """
    使用python内置 Dequeu 对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        if self._queue_name not in local_pyhton_queue_name__local_pyhton_queue_obj_map:
            local_pyhton_queue_name__local_pyhton_queue_obj_map[self._queue_name] = deque()
        self.queue = local_pyhton_queue_name__local_pyhton_queue_obj_map[self._queue_name]  # type: deque
        # deque.get = deque.pop
        # # setattr(self.queue,'get',self.queue.pop)

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        print(msg)
        self.queue.append(msg)

    def clear(self):
        pass
        # noinspection PyUnresolvedReferences
        self.queue.clear()
        self.logger.warning(f'清除 本地队列中的消息成功')

    def get_message_count(self):
        return len(self.queue)

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/local_python_queue_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/meomory_deque_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/meomory_deque_publisher.py`

#### 📦 Imports

- `from collections import deque`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class DequePublisher(AbstractPublisher)`
*Line: 11*

**Docstring:**
`````
使用python内置queue对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:07
from collections import deque

from funboost.publishers.base_publisher import AbstractPublisher

deque_queue_name__deque_obj_map = dict()  # 使local queue和其他中间件完全一样的使用方式，使用映射保存队列的名字，使消费和发布通过队列名字能找到队列对象。


class DequePublisher(AbstractPublisher):
    """
    使用python内置queue对象作为中间件。方便测试，每个中间件的消费者类是鸭子类，多态可以互相替换。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        if self._queue_name not in deque_queue_name__deque_obj_map:
            deque_queue_name__deque_obj_map[self._queue_name] = deque()
        self.queue = deque_queue_name__deque_obj_map[self._queue_name]  # type: deque

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        self.queue.append(msg)

    def clear(self):
        pass
        # noinspection PyUnresolvedReferences
        self.queue.clear()
        self.logger.warning(f'清除 本地队列中的消息成功')

    def get_message_count(self):
        return len(self.queue)

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/meomory_deque_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/mongomq_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/mongomq_publisher.py`

#### 📦 Imports

- `import os`
- `import json`
- `from funboost.constant import MongoDbName`
- `from funboost.utils.dependency_packages.mongomq import MongoQueue`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils import time_util`
- `from funboost.utils.mongo_util import MongoMixin`

#### 🏛️ Classes (1)

##### 📌 `class MongoMqPublisher(AbstractPublisher, MongoMixin)`
*Line: 14*

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

**Properties (1):**
- `@property queue`

**Class Variables (1):**
- `pid__queue_map = {}`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:23
import os

import json
from funboost.constant import MongoDbName
from funboost.utils.dependency_packages.mongomq import MongoQueue
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.utils import time_util
from funboost.utils.mongo_util import MongoMixin


class MongoMqPublisher(AbstractPublisher, MongoMixin):
    # 使用mongo-queue包实现的基于mongodb的队列。 队列是一个col，自动存放在consume_queues库中。
    # noinspection PyAttributeOutsideInit

    pid__queue_map = {}

    def custom_init(self):
        pass

    @property
    def queue(self):
        ''' 不能提前实例化，mongo fork进程不安全，这样是动态生成queue'''
        pid = os.getpid()
        key = (pid, MongoDbName.MONGOMQ_DB, self._queue_name)
        if key not in MongoMqPublisher.pid__queue_map:
            queuex = MongoQueue(
                self.get_mongo_collection(MongoDbName.MONGOMQ_DB, self._queue_name),
                consumer_id=f"consumer-{time_util.DatetimeConverter().datetime_str}",
                timeout=600,
                max_attempts=3,
                ttl=24 * 3600 * 365)
            MongoMqPublisher.pid__queue_map[key] = queuex
        return MongoMqPublisher.pid__queue_map[key]


    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        self.queue.put(json.loads(msg))

    def clear(self):
        self.queue.clear()
        self.logger.warning(f'清除 mongo队列 {self._queue_name} 中的消息成功')

    def get_message_count(self):
        # return self.queue.size()
        return self.queue.collection.count_documents({'status': 'queued'})

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/mongomq_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/mqtt_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/mqtt_publisher.py`

#### 📦 Imports

- `from funboost.core.lazy_impoter import PahoMqttImporter`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class MqttPublisher(AbstractPublisher)`
*Line: 68*

**Docstring:**
`````
使用 emq 作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
from funboost.core.lazy_impoter import PahoMqttImporter
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.funboost_config_deafult import BrokerConnConfig

"""
首先安装mqtt模块：


pip install paho-mqtt
写一个发布客户端pub.py：

import paho.mqtt.client as mqtt

def on_connect(client, userdata, flags, rc):
    print("Connected with result code: " + str(rc))

def on_message(client, userdata, msg):
    print(msg.topic + " " + str(msg.payload))

client = mqtt.Client()
client.on_connect = on_connect
client.on_message = on_message
client.connect('127.0.0.1', 1883, 600) # 600为keepalive的时间间隔
client.publish('fifa', payload='amazing', qos=0)






再写一个接受客户端sub.py：

import paho.mqtt.client as mqtt

def on_connect(client, userdata, flags, rc):
    print("Connected with result code: " + str(rc))

def on_message(client, userdata, msg):
    print(msg.topic + " " + str(msg.payload))

client = mqtt.Client()
client.on_connect = on_connect
client.on_message = on_message
client.connect('127.0.0.1', 1883, 600) # 600为keepalive的时间间隔
client.subscribe('fifa', qos=0)
client.loop_forever() # 保持连接

作者：赤色要塞满了
链接：https://www.jianshu.com/p/0ed4e59b1e8f
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
"""

# import paho.mqtt.client as mqtt


# def on_connect(client, userdata, flags, rc):
#     print("Connected with result code: " + str(rc))
#
#
# def on_message(client, userdata, msg):
#     print(msg.topic + " " + str(msg.payload))


class MqttPublisher(AbstractPublisher, ):
    """
    使用 emq 作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        client = PahoMqttImporter().mqtt.Client()
        # client.username_pw_set('admin', password='public')
        client.on_connect = self._on_connect
        client.on_socket_close = self._on_socket_close
        # client.on_message = on_message
        # print(frame_config.MQTT_HOST)
        client.connect(BrokerConnConfig.MQTT_HOST, BrokerConnConfig.MQTT_TCP_PORT, 600)  # 600为keepalive的时间间隔
        self._client = client

    def _on_socket_close(self, client, userdata, socket):
        self.logger.critical(f'{client, userdata, socket}')
        self.custom_init()

    def _on_connect(self, client, userdata, flags, rc):
        self.logger.info(f'连接mqtt服务端成功, {client, userdata, flags, rc}')

    def _publish_impl(self, msg):
        self._client.publish(self._queue_name, payload=msg, qos=0, retain=False)

    def clear(self):
        pass
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    def get_message_count(self):
        # nb_print(self.redis_db7,self._queue_name)
        return -1

    def close(self):
        # self.redis_db7.connection_pool.disconnect()
        pass

`````

--- **end of file: funboost/publishers/mqtt_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/mysql_cdc_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/mysql_cdc_publisher.py`

#### 📦 Imports

- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class MysqlCdcPublisher(AbstractPublisher)`
*Line: 5*

**Docstring:**
`````
A placeholder publisher for the CDC broker.
Publishing is handled automatically by the consumer by listening to binlog events.
Direct publishing is not supported and will raise an error.
`````

**Public Methods (3):**
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python


from funboost.publishers.base_publisher import AbstractPublisher

class MysqlCdcPublisher(AbstractPublisher):
    """
    A placeholder publisher for the CDC broker.
    Publishing is handled automatically by the consumer by listening to binlog events.
    Direct publishing is not supported and will raise an error.
    """

    def _publish_impl(self, msg: str):
        raise NotImplementedError("The 'funboost_cdc' broker does not support manual publishing. "
                                  "Tasks are generated automatically from database changes.")

    def clear(self):
        self.logger.warning("The 'funboost_cdc' broker does not have a queue to clear.")
        pass

    def get_message_count(self):
        return -1 # Not applicable

    def close(self):
        pass
`````

--- **end of file: funboost/publishers/mysql_cdc_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/nameko_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/nameko_publisher.py`

#### 📦 Imports

- `import copy`
- `import json`
- `import time`
- `import typing`
- `import uuid`
- `from nameko.standalone.rpc import ClusterRpcProxy`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import TaskOptions`

#### 🏛️ Classes (1)

##### 📌 `class NamekoPublisher(AbstractPublisher)`
*Line: 20*

**Docstring:**
`````
使用nameko作为中间件
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def publish(self, msg: typing.Union[str, dict], task_id = None, task_options: TaskOptions = None)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

#### 🔧 Public Functions (1)

- `def get_nameko_config()`
  - *Line: 16*


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 12:12
import copy
import json
import time
import typing
import uuid

from nameko.standalone.rpc import ClusterRpcProxy

from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher, TaskOptions


def get_nameko_config():
    return {'AMQP_URI': f'amqp://{BrokerConnConfig.RABBITMQ_USER}:{BrokerConnConfig.RABBITMQ_PASS}@{BrokerConnConfig.RABBITMQ_HOST}:{BrokerConnConfig.RABBITMQ_PORT}/{BrokerConnConfig.RABBITMQ_VIRTUAL_HOST}'}


class NamekoPublisher(AbstractPublisher, ):
    """
    使用nameko作为中间件
    """

    def custom_init(self):
        self._rpc = ClusterRpcProxy(get_nameko_config())

    def publish(self, msg: typing.Union[str, dict], task_id=None,
                task_options: TaskOptions = None):
        msg, msg_function_kw, extra_params, task_id = self._convert_msg(msg, task_id, task_options)
        t_start = time.time()
        with self._rpc as rpc:
            res = getattr(rpc, self.queue_name).call(**msg_function_kw)
        self.logger.debug(f'调用nameko的 {self.queue_name} service 的 call方法 耗时{round(time.time() - t_start, 4)}秒，入参  {msg_function_kw}')  # 显示msg太长了。
        return res

    def _publish_impl(self, msg):
        pass

    def clear(self):
        self.logger.warning('還沒開始實現')

    def get_message_count(self):
        return -1

    def close(self):
        # self.redis_db7.connection_pool.disconnect()
        pass

`````

--- **end of file: funboost/publishers/nameko_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/nats_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/nats_publisher.py`

#### 📦 Imports

- `from funboost.core.lazy_impoter import NatsImporter`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class NatsPublisher(AbstractPublisher)`
*Line: 6*

**Docstring:**
`````
使用nats作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
﻿from funboost.core.lazy_impoter import NatsImporter
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.funboost_config_deafult import BrokerConnConfig


class NatsPublisher(AbstractPublisher, ):
    """
    使用nats作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self.nats_client = NatsImporter().NATSClient(BrokerConnConfig.NATS_URL)
        self.nats_client.connect()

    def _publish_impl(self, msg):
        # print(msg)
        self.nats_client.publish(subject=self.queue_name, payload=msg.encode())

    def clear(self):
        pass

    def get_message_count(self):
        return -1

    def close(self):
        # self.redis_db7.connection_pool.disconnect()
        pass

`````

--- **end of file: funboost/publishers/nats_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/nsq_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/nsq_publisher.py`

#### 📦 Imports

- `from funboost.core.lazy_impoter import GnsqImporter`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class NsqPublisher(AbstractPublisher)`
*Line: 9*

**Docstring:**
`````
使用nsq作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/19 0008 12:12
from funboost.core.lazy_impoter import GnsqImporter
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.funboost_config_deafult import BrokerConnConfig


class NsqPublisher(AbstractPublisher, ):
    """
    使用nsq作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._nsqd_cleint = GnsqImporter().NsqdHTTPClient(BrokerConnConfig.NSQD_HTTP_CLIENT_HOST, BrokerConnConfig.NSQD_HTTP_CLIENT_PORT)
        self._producer = GnsqImporter().Producer(BrokerConnConfig.NSQD_TCP_ADDRESSES)
        self._producer.start()

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        self._producer.publish(self._queue_name, msg.encode())

    def clear(self):
        try:
            self._nsqd_cleint.empty_topic(self._queue_name)
        except GnsqImporter().NSQHttpError as e:
            self.logger.exception(e)  # 不能清除一个不存在的topoc会报错，和其他消息队列中间件不同。
        self.logger.warning(f'清除 {self._queue_name} topic中的消息成功')

    def get_message_count(self):
        return -1

    def close(self):
        self._producer.close()

`````

--- **end of file: funboost/publishers/nsq_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/peewee_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/peewee_publisher.py`

#### 📦 Imports

- `from funboost.queues.peewee_queue import PeeweeQueue`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class PeeweePublisher(AbstractPublisher)`
*Line: 9*

**Docstring:**
`````
使用Sqlachemy 操作数据库 ，实现的5种sql 数据库服务器作为 消息队列。包括sqlite mydql microsoftsqlserver postgre oracle
这个是使用数据库表模拟的消息队列。这不是突发奇想一意孤行，很多包库都实现了这。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:05
from funboost.queues.peewee_queue import PeeweeQueue
from funboost.publishers.base_publisher import AbstractPublisher


# noinspection PyProtectedMember
class PeeweePublisher(AbstractPublisher):
    """
    使用Sqlachemy 操作数据库 ，实现的5种sql 数据库服务器作为 消息队列。包括sqlite mydql microsoftsqlserver postgre oracle
    这个是使用数据库表模拟的消息队列。这不是突发奇想一意孤行，很多包库都实现了这。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self.queue = PeeweeQueue(self._queue_name, )

    def _publish_impl(self, msg):
        # print(msg)
        self.queue.push(body=msg, )

    def clear(self):
        self.queue.clear_queue()
        self.logger.warning(f'清除 sqlalchemy 数据库队列 {self._queue_name} 中的消息成功')

    def get_message_count(self):
        return self.queue.to_be_consumed_count

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/peewee_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/persist_queue_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/persist_queue_publisher.py`

#### 📦 Imports

- `import json`
- `import sqlite3`
- `import persistqueue`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.core.loggers import get_funboost_file_logger`

#### 🏛️ Classes (1)

##### 📌 `class PersistQueuePublisher(AbstractPublisher)`
*Line: 17*

**Docstring:**
`````
使用persistqueue实现的本地持久化队列。
这个是本地持久化，支持本地多个启动的python脚本共享队列任务。与LocalPythonQueuePublisher相比，不会随着python解释器退出，导致任务丢失。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:05
import json
import sqlite3

import persistqueue
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher
# from funboost.utils import LogManager
from funboost.core.loggers import get_funboost_file_logger

get_funboost_file_logger('persistqueue')


# noinspection PyProtectedMember
class PersistQueuePublisher(AbstractPublisher):
    """
    使用persistqueue实现的本地持久化队列。
    这个是本地持久化，支持本地多个启动的python脚本共享队列任务。与LocalPythonQueuePublisher相比，不会随着python解释器退出，导致任务丢失。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        # noinspection PyShadowingNames
        def _my_new_db_connection(self, path, multithreading, timeout):  # 主要是改了sqlite文件后缀，方便pycharm识别和打开。
            # noinspection PyUnusedLocal
            conn = None
            if path == self._MEMORY:
                conn = sqlite3.connect(path,
                                       check_same_thread=not multithreading)
            else:
                conn = sqlite3.connect('{}/data.sqlite'.format(path),
                                       timeout=timeout,
                                       check_same_thread=not multithreading)
            conn.execute('PRAGMA journal_mode=WAL;')
            return conn

        persistqueue.SQLiteAckQueue._new_db_connection = _my_new_db_connection  # 打猴子补丁。
        # REMIND 官方测试基于sqlite的本地持久化，比基于纯文件的持久化，使用相同固态硬盘和操作系统情况下，速度快3倍以上，所以这里选用sqlite方式。

        self.queue = persistqueue.SQLiteAckQueue(path=BrokerConnConfig.SQLLITE_QUEUES_PATH, name=self._queue_name, auto_commit=True, serializer=json, multithreading=True)

    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        self.queue.put(msg)

    def clear(self):
        sql = f'{"DELETE"}  {"FROM"} ack_queue_{self._queue_name}'
        self.logger.info(sql)
        self.queue._getter.execute(sql)
        self.queue._getter.commit()
        self.logger.warning(f'清除 本地持久化队列 {self._queue_name} 中的消息成功')

    def get_message_count(self):
        return self.queue._count()
        # return self.queue.qsize()

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/persist_queue_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/pulsar_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/pulsar_publisher.py`

#### 📝 Module Docstring

`````
import pulsar

client = pulsar.Client('pulsar://localhost:6650')

producer = client.create_producer('my-topic36')

for i in range(10):
    producer.send(('Hello-%d' % i).encode('utf-8'))

client.close()
`````

#### 📦 Imports

- `import os`
- `from pulsar.schema import schema`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `import pulsar`

#### 🏛️ Classes (1)

##### 📌 `class PulsarPublisher(AbstractPublisher)`
*Line: 27*

**Docstring:**
`````
使用pulsar作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
  - *用户换个 subscription_name 就可以重新消费了，不需要清空消息*
- `def get_message_count(self)`
- `def close(self)`


---

`````python
'''

import pulsar

client = pulsar.Client('pulsar://localhost:6650')

producer = client.create_producer('my-topic36')

for i in range(10):
    producer.send(('Hello-%d' % i).encode('utf-8'))

client.close()

'''

# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import os

from pulsar.schema import schema

from funboost.publishers.base_publisher import AbstractPublisher
from funboost.funboost_config_deafult import BrokerConnConfig


class PulsarPublisher(AbstractPublisher, ):
    """
    使用pulsar作为中间件
    """

    def custom_init(self):
        import pulsar
        self._client = pulsar.Client(BrokerConnConfig.PULSAR_URL, )
        self._producer = self._client.create_producer(self._queue_name, schema=schema.StringSchema(), producer_name=f'funboost_publisher_{os.getpid()}')

    def _publish_impl(self, msg):
        self._producer.send(msg)

    def clear(self):
        """用户换个 subscription_name 就可以重新消费了，不需要清空消息"""
        pass


    def get_message_count(self):
        return -1

    def close(self):
        # self.redis_db7.connection_pool.disconnect()
        self._client.close()

`````

--- **end of file: funboost/publishers/pulsar_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/rabbitmq_amqpstorm_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/rabbitmq_amqpstorm_publisher.py`

#### 📦 Imports

- `import amqpstorm`
- `from amqpstorm.basic import Basic as AmqpStormBasic`
- `from amqpstorm.queue import Queue as AmqpStormQueue`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import deco_mq_conn_error`
- `from funboost.utils import decorators`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqPublisherUsingAmqpStorm(AbstractPublisher)`
*Line: 12*

**Public Methods (5):**
- `def custom_init(self)`
- `def init_broker(self)`
- `def clear(self)` `deco_mq_conn_error`
- `def get_message_count(self)` `deco_mq_conn_error`
- `def close(self)`

**Class Variables (4):**
- `connection: amqpstorm.UriConnection`
- `channel: amqpstorm.Channel`
- `channel_wrapper_by_ampqstormbaic: AmqpStormBasic`
- `queue: AmqpStormQueue`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:06
import amqpstorm
from amqpstorm.basic import Basic as AmqpStormBasic
from amqpstorm.queue import Queue as AmqpStormQueue
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
from funboost.utils import decorators


class RabbitmqPublisherUsingAmqpStorm(AbstractPublisher):
    # 使用amqpstorm包实现的mq操作。
    # 实例属性没在__init__里面写，造成代码补全很麻烦，写在这里做类属性，方便pycharm补全
    connection : amqpstorm.UriConnection
    channel : amqpstorm.Channel
    channel_wrapper_by_ampqstormbaic : AmqpStormBasic
    queue : AmqpStormQueue


    def custom_init(self):
        arguments = {}     #  {'x-queue-type':'classic'} classic stream lazy quorum
        if self.publisher_params.broker_exclusive_config.get('x-max-priority'):
            arguments['x-max-priority'] = self.publisher_params.broker_exclusive_config['x-max-priority']
        self._queue_durable =  self.publisher_params.broker_exclusive_config['queue_durable']
        self.queue_declare_params = dict(queue=self._queue_name, durable=self._queue_durable, arguments=arguments,auto_delete=False)

    # noinspection PyAttrib_durableuteOutsideInit
    # @decorators.synchronized
    def init_broker(self):
        # username=app_config.RABBITMQ_USER, password=app_config.RABBITMQ_PASS, host=app_config.RABBITMQ_HOST, port=app_config.RABBITMQ_PORT, virtual_host=app_config.RABBITMQ_VIRTUAL_HOST, heartbeat=60 * 10
        self.logger.warning(f'使用AmqpStorm包 链接mq')
        self.connection = amqpstorm.UriConnection(
            f'amqp://{BrokerConnConfig.RABBITMQ_USER}:{BrokerConnConfig.RABBITMQ_PASS}@{BrokerConnConfig.RABBITMQ_HOST}:{BrokerConnConfig.RABBITMQ_PORT}/{BrokerConnConfig.RABBITMQ_VIRTUAL_HOST}?heartbeat={60 * 10}&timeout=20000'
        )
        self.channel = self.connection.channel()  # type:amqpstorm.Channel
        self.channel_wrapper_by_ampqstormbaic = AmqpStormBasic(self.channel)
        self.queue = AmqpStormQueue(self.channel)
        self.queue.declare(**self.queue_declare_params)

    # @decorators.tomorrow_threads(10)
    @deco_mq_conn_error
    def _publish_impl(self, msg: str):
        self.channel_wrapper_by_ampqstormbaic.publish(exchange='',
                                                      routing_key=self._queue_name,
                                                      body=msg,
                                                      properties={'delivery_mode': 2, 'priority': self._get_from_other_extra_params('priroty', msg)}, )
        # nb_print(msg)

    @deco_mq_conn_error
    def clear(self):
        self.queue.purge(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    @deco_mq_conn_error
    def get_message_count(self):
        # noinspection PyUnresolvedReferences
        return self.queue.declare(**self.queue_declare_params)['message_count']

    # @deco_mq_conn_error
    def close(self):
        self.channel.close()
        self.connection.close()
        self.logger.warning('关闭amqpstorm包 链接mq')

`````

--- **end of file: funboost/publishers/rabbitmq_amqpstorm_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/rabbitmq_complex_routing_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/rabbitmq_complex_routing_publisher.py`

#### 📦 Imports

- `import amqpstorm`
- `from amqpstorm.basic import Basic as AmqpStormBasic`
- `from amqpstorm.queue import Queue as AmqpStormQueue`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import deco_mq_conn_error`
- `from funboost.utils import decorators`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqComplexRoutingPublisher(AbstractPublisher)`
*Line: 12*

**Public Methods (5):**
- `def custom_init(self)`
- `def init_broker(self)`
- `def clear(self)` `deco_mq_conn_error`
- `def get_message_count(self)` `deco_mq_conn_error`
- `def close(self)`

**Class Variables (4):**
- `connection: amqpstorm.UriConnection`
- `channel: amqpstorm.Channel`
- `channel_wrapper_by_ampqstormbaic: AmqpStormBasic`
- `queue: AmqpStormQueue`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:06
import amqpstorm
from amqpstorm.basic import Basic as AmqpStormBasic
from amqpstorm.queue import Queue as AmqpStormQueue
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
from funboost.utils import decorators


class RabbitmqComplexRoutingPublisher(AbstractPublisher):
    # 使用amqpstorm包实现的mq操作。
    # 实例属性没在__init__里面写，造成代码补全很麻烦，写在这里做类属性，方便pycharm补全
    connection : amqpstorm.UriConnection
    channel : amqpstorm.Channel
    channel_wrapper_by_ampqstormbaic : AmqpStormBasic
    queue : AmqpStormQueue


    def custom_init(self):
        arguments = {}     #  {'x-queue-type':'classic'} classic stream lazy quorum
        if self.publisher_params.broker_exclusive_config.get('x-max-priority'):
            arguments['x-max-priority'] = self.publisher_params.broker_exclusive_config['x-max-priority']
        self._queue_durable = self.publisher_params.broker_exclusive_config['queue_durable']
        self.queue_declare_params = dict(queue=self._queue_name, durable=self._queue_durable,
                                         arguments=arguments,auto_delete=False)
        
        self._exchange_name = self.publisher_params.broker_exclusive_config['exchange_name']
        self._exchange_type = self.publisher_params.broker_exclusive_config['exchange_type']
        # 如果用户没有在 broker_exclusive_config 中指定 routing_key_for_publish，则默认使用队列名作为 routing_key
        self._routing_key_for_publish = self.publisher_params.broker_exclusive_config.get('routing_key_for_publish') or self._queue_name  # 这里你已经用了很好的实践

        self._exchange_declare_durable = self.publisher_params.broker_exclusive_config['exchange_declare_durable']

        self.init_broker()


    # noinspection PyAttributeOutsideInit
    # @decorators.synchronized
    def init_broker(self):
        # username=app_config.RABBITMQ_USER, password=app_config.RABBITMQ_PASS, host=app_config.RABBITMQ_HOST, port=app_config.RABBITMQ_PORT, virtual_host=app_config.RABBITMQ_VIRTUAL_HOST, heartbeat=60 * 10
        self.logger.warning(f'使用AmqpStorm包 链接mq')
        self.connection = amqpstorm.UriConnection(
            f'amqp://{BrokerConnConfig.RABBITMQ_USER}:{BrokerConnConfig.RABBITMQ_PASS}@{BrokerConnConfig.RABBITMQ_HOST}:{BrokerConnConfig.RABBITMQ_PORT}/{BrokerConnConfig.RABBITMQ_VIRTUAL_HOST}?heartbeat={60 * 10}&timeout=20000'
        )
        self.channel = self.connection.channel()  # type:amqpstorm.Channel
        self.channel_wrapper_by_ampqstormbaic = AmqpStormBasic(self.channel)
        # 发布者不声明队列，队列的声明和绑定完全由消费者负责。
        if self._exchange_name:
            self.channel.exchange.declare(exchange=self._exchange_name, exchange_type=self._exchange_type,
                                          durable=self._exchange_declare_durable)

    # @decorators.tomorrow_threads(10)
    @deco_mq_conn_error
    def _publish_impl(self, msg: str):
        routing_key_publish_dynamic = self._get_from_other_extra_params('routing_key_for_publish', msg)
        routing_key_publish = routing_key_publish_dynamic if routing_key_publish_dynamic is not None else self._routing_key_for_publish
        # 核心修正2：为 headers 交换机添加 headers 支持
        headers = self._get_from_other_extra_params('headers_for_publish', msg)

        self.channel_wrapper_by_ampqstormbaic.publish(exchange=self._exchange_name,
                                                      routing_key=routing_key_publish,
                                                      body=msg,
                                                      properties={'delivery_mode': 2,
                                                                  'priority': self._get_from_other_extra_params('priority', msg),
                                                                  'headers': headers}, )
        # nb_print(msg)

    @deco_mq_conn_error
    def clear(self):
        AmqpStormQueue(self.channel).purge(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    @deco_mq_conn_error
    def get_message_count(self):
        # noinspection PyUnresolvedReferences
        return AmqpStormQueue(self.channel).declare(**self.queue_declare_params)['message_count']

    # @deco_mq_conn_error
    def close(self):
        self.channel.close()
        self.connection.close()
        self.logger.warning('关闭amqpstorm包 链接mq')

`````

--- **end of file: funboost/publishers/rabbitmq_complex_routing_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/rabbitmq_pika_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/rabbitmq_pika_publisher.py`

#### 📦 Imports

- `from threading import Lock`
- `from pikav1 import BasicProperties`
- `import pikav1`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import deco_mq_conn_error`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqPublisher(AbstractPublisher)`
*Line: 11*

**Docstring:**
`````
使用pika实现的。
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def init_broker(self)`
- `def clear(self)` `deco_mq_conn_error`
- `def get_message_count(self)` `deco_mq_conn_error`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:03
from threading import Lock
from pikav1 import BasicProperties
import pikav1
from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
from funboost.funboost_config_deafult import BrokerConnConfig


class RabbitmqPublisher(AbstractPublisher):
    """
    使用pika实现的。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._lock_for_pika = Lock()

    # noinspection PyAttributeOutsideInit
    def init_broker(self):
        self.logger.warning(f'使用pika 链接mq')
        credentials = pikav1.PlainCredentials(BrokerConnConfig.RABBITMQ_USER, BrokerConnConfig.RABBITMQ_PASS)
        self.connection = pikav1.BlockingConnection(pikav1.ConnectionParameters(
            BrokerConnConfig.RABBITMQ_HOST, BrokerConnConfig.RABBITMQ_PORT, BrokerConnConfig.RABBITMQ_VIRTUAL_HOST, credentials, heartbeat=60))
        self.channel = self.connection.channel()
        self.queue = self.channel.queue_declare(queue=self._queue_name, durable=True)

    # noinspection PyAttributeOutsideInit
    @deco_mq_conn_error
    def _publish_impl(self, msg):
        with self._lock_for_pika:  # 亲测pika多线程publish会出错
            self.channel.basic_publish(exchange='',
                                       routing_key=self._queue_name,
                                       body=msg,
                                       properties=BasicProperties(
                                           delivery_mode=2,  # make message persistent   2(1是非持久化)
                                       )
                                       )

    @deco_mq_conn_error
    def clear(self):
        self.channel.queue_purge(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    @deco_mq_conn_error
    def get_message_count(self):
        with self._lock_for_pika:
            queue = self.channel.queue_declare(queue=self._queue_name, durable=True)
            return queue.method.message_count

    # @deco_mq_conn_error
    def close(self):
        self.channel.close()
        self.connection.close()
        self.logger.warning('关闭pika包 链接')

`````

--- **end of file: funboost/publishers/rabbitmq_pika_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/rabbitmq_rabbitpy_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/rabbitmq_rabbitpy_publisher.py`

#### 📦 Imports

- `import os`
- `import rabbitpy`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.base_publisher import deco_mq_conn_error`
- `from funboost.utils.rabbitmq_factory import RabbitMqFactory`
- `import time`

#### 🏛️ Classes (1)

##### 📌 `class RabbitmqPublisherUsingRabbitpy(AbstractPublisher)`
*Line: 11*

**Docstring:**
`````
使用rabbitpy包实现的。
`````

**Public Methods (4):**
- `def init_broker(self)`
- `def clear(self)` `deco_mq_conn_error`
- `def get_message_count(self)` `deco_mq_conn_error`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:04
import os
import rabbitpy

from funboost.publishers.base_publisher import AbstractPublisher, deco_mq_conn_error
from funboost.utils.rabbitmq_factory import RabbitMqFactory


class RabbitmqPublisherUsingRabbitpy(AbstractPublisher):
    """
    使用rabbitpy包实现的。
    """

    # noinspection PyAttributeOutsideInit
    def init_broker(self):
        self.logger.warning(f'使用rabbitpy包 链接mq')
        self.rabbit_client = RabbitMqFactory(is_use_rabbitpy=1).get_rabbit_cleint()
        self.channel = self.rabbit_client.creat_a_channel()
        self.queue = self.channel.queue_declare(queue=self._queue_name, durable=True)
        self.logger.critical('rabbitpy 快速发布 有问题会丢失大量任务，如果使用 rabbitmq 建议设置中间件为 BrokerEnum.RABBITMQ_AMQPSTORM')
        os._exit(444) # noqa

    # @decorators.tomorrow_threads(10)
    @deco_mq_conn_error
    def _publish_impl(self, msg):
        # noinspection PyTypeChecker
        import time
        # time.sleep(0.1)
        print(self.channel.basic_publish(
            exchange='',
            routing_key=self._queue_name,
            body=msg,
            properties={'delivery_mode': 2},
        ))


    @deco_mq_conn_error
    def clear(self):
        self.channel.queue_purge(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    @deco_mq_conn_error
    def get_message_count(self):
        # noinspection PyUnresolvedReferences
        ch_raw_rabbity = self.channel.channel
        return len(rabbitpy.amqp_queue.Queue(ch_raw_rabbity, self._queue_name, durable=True))

    # @deco_mq_conn_error
    def close(self):
        self.channel.close()
        self.rabbit_client.connection.close()
        self.logger.warning('关闭rabbitpy包 链接mq')

`````

--- **end of file: funboost/publishers/rabbitmq_rabbitpy_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_publisher.py`

#### 📦 Imports

- `import os`
- `import time`
- `from queue import Queue`
- `from queue import Empty`
- `from threading import Lock`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.redis_queue_flush_mixin import FlushRedisQueueMixin`
- `from funboost.utils import decorators`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisPublisher(FlushRedisQueueMixin, AbstractPublisher, RedisMixin)`
*Line: 17*

**Docstring:**
`````
使用redis作为中间件,这个是大幅优化了发布速度的方式。简单的发布是 redis_publisher_0000.py 中的代码方式。

这个是复杂版，批量推送，简单版在 funboost/publishers/redis_publisher_simple.py
`````

**Public Methods (3):**
- `def custom_init(self)`
- `def get_message_count(self)`
- `def close(self)`

**Class Variables (1):**
- `_push_method = 'rpush'`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import os
import time
# noinspection PyUnresolvedReferences
from queue import Queue, Empty
from threading import Lock

from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.publishers.redis_queue_flush_mixin import FlushRedisQueueMixin
from funboost.utils import decorators
from funboost.utils.redis_manager import RedisMixin


class RedisPublisher(FlushRedisQueueMixin, AbstractPublisher, RedisMixin, ):
    """
    使用redis作为中间件,这个是大幅优化了发布速度的方式。简单的发布是 redis_publisher_0000.py 中的代码方式。

    这个是复杂版，批量推送，简单版在 funboost/publishers/redis_publisher_simple.py
    """
    _push_method = 'rpush'

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._temp_msg_queue = Queue()
        self._temp_msg_list = list()
        self._lock_for_bulk_push = Lock()
        self._last_push_time = time.time()
        decorators.keep_circulating(time_sleep=0.1, is_display_detail_exception=True, block=False,
                                    daemon=True)(self._initiative_bulk_push_to_broker, )()

    def __bulk_push_and_init(self):
        if len(self._temp_msg_list) > 0:
            getattr(self.redis_db_frame, self._push_method)(self._queue_name, *self._temp_msg_list)
            self._temp_msg_list = []

    def _initiative_bulk_push_to_broker(self):  # 主动触发。_publish_impl防止发布最后一条后没达到2000但sleep很久，无法触发at_exit，不能自动触发进入消息队列。
        with self._lock_for_bulk_push:
            self.__bulk_push_and_init()

    def _publish_impl(self, msg):
        # print(getattr(frame_config,'has_start_a_consumer_flag',0))
        # 这里的 has_start_a_consumer_flag 是一个标志，借用此模块设置的一个标识变量而已，框架运行时候自动设定的，不要把这个变量写到模块里面。
        # if getattr(funboost_config_deafult, 'has_start_a_consumer_flag', 0) == 0:  # 加快速度推送，否则每秒只能推送4000次。如果是独立脚本推送，使用批量推送，如果是消费者中发布任务，为了保持原子性，用原来的单个推送。
        if self.publisher_params.broker_exclusive_config.get('redis_bulk_push', 0) == 1:  # RedisConsumer传了,  RedisAckAble  没传
            # self._temp_msg_queue.put(msg)
            with self._lock_for_bulk_push:
                self._temp_msg_list.append(msg)
                if len(self._temp_msg_list) >= 1000:
                    # print(len(self._temp_msg_list))
                    self.__bulk_push_and_init()
        else:
            getattr(self.redis_db_frame, self._push_method)(self._queue_name, msg)
            # print(msg)

    def get_message_count(self):
        # print(self.redis_db7,self._queue_name)
        return self.redis_db_frame.llen(self._queue_name)

    def close(self):
        pass

    def _at_exit(self):
        # time.sleep(2) # 不需要
        # self._real_bulk_push_to_broker()
        with self._lock_for_bulk_push:
            self.__bulk_push_and_init()
        super()._at_exit()

`````

--- **end of file: funboost/publishers/redis_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_publisher_lpush.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_publisher_lpush.py`

#### 📦 Imports

- `from funboost.publishers.redis_publisher import RedisPublisher`

#### 🏛️ Classes (1)

##### 📌 `class RedisPublisherLpush(RedisPublisher)`
*Line: 9*

**Docstring:**
`````
使用redis作为中间件,
`````

**Class Variables (1):**
- `_push_method = 'lpush'`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12


from funboost.publishers.redis_publisher import RedisPublisher


class RedisPublisherLpush(RedisPublisher):
    """
    使用redis作为中间件,
    """

    _push_method = 'lpush'



`````

--- **end of file: funboost/publishers/redis_publisher_lpush.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_publisher_priority.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_publisher_priority.py`

#### 📦 Imports

- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.redis_queue_flush_mixin import FlushRedisQueueMixin`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisPriorityPublisher(FlushRedisQueueMixin, AbstractPublisher, RedisMixin)`
*Line: 10*

**Docstring:**
`````
redis队列，支持任务优先级。
`````

**Public Methods (5):**
- `def custom_init(self)`
- `def build_queue_name_by_msg(self, msg)`
  - **Docstring:**
  `````
  根据消息的other_extra_params的 priority ，自动生成子队列名。例如 queue_name:1   queue_name:2  queue_name:3 queue_name:4
  :param msg:
  :return:
  `````
- `def get_message_count(self)`
- `def close(self)`
- `def clear(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12

from funboost.publishers.base_publisher import AbstractPublisher
from funboost.publishers.redis_queue_flush_mixin import FlushRedisQueueMixin
from funboost.utils.redis_manager import RedisMixin


class RedisPriorityPublisher(FlushRedisQueueMixin,AbstractPublisher, RedisMixin,):
    """
    redis队列，支持任务优先级。
    """

    def custom_init(self):
        queue_list = [self._queue_name]
        x_max_priority = self.publisher_params.broker_exclusive_config.get('x-max-priority')
        if x_max_priority:
            for i in range(1, x_max_priority + 1):
                queue_list.append(f'{self.queue_name}:{i}')
        queue_list.sort(reverse=True)
        self.queue_list = queue_list

    def build_queue_name_by_msg(self, msg):
        """
        根据消息的other_extra_params的 priority ，自动生成子队列名。例如 queue_name:1   queue_name:2  queue_name:3 queue_name:4
        :param msg:
        :return:
        """
        priority = self._get_from_other_extra_params('priroty', msg)
        x_max_priority = self.publisher_params.broker_exclusive_config['x-max-priority']
        queue_name = self.queue_name
        if x_max_priority and priority:
            priority = min(priority, x_max_priority)  # 防止有傻瓜发布消息的优先级priroty比最大支持的优先级还高。
            queue_name = f'{self.queue_name}:{priority}'
        return queue_name

    def _publish_impl(self, msg):
        queue_name = self.build_queue_name_by_msg(msg)
        # self.logger.debug([queue_name, msg])
        self.redis_db_frame.rpush(queue_name, msg)


    def get_message_count(self):
        count = 0
        for queue_name in self.queue_list:
            count += self.redis_db_frame.llen(queue_name)
        return count

    def close(self):
        pass

    def clear(self):
        self.logger.warning(f'清除 {self.queue_list} 中的消息')
        self.redis_db_frame.delete(*self.queue_list)
        FlushRedisQueueMixin.clear(self)

`````

--- **end of file: funboost/publishers/redis_publisher_priority.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_publisher_simple.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_publisher_simple.py`

#### 📦 Imports

- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.publishers.redis_queue_flush_mixin import FlushRedisQueueMixin`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisPublisher(FlushRedisQueueMixin, AbstractPublisher, RedisMixin)`
*Line: 9*

**Docstring:**
`````
使用redis作为中间件
`````

**Public Methods (2):**
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2023/8/8 0008 12:12
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.publishers.redis_queue_flush_mixin import FlushRedisQueueMixin
from funboost.utils.redis_manager import RedisMixin


class RedisPublisher(FlushRedisQueueMixin, AbstractPublisher, RedisMixin, ):
    """
    使用redis作为中间件
    """

    def _publish_impl(self, msg):
        self.redis_db_frame.rpush(self._queue_name, msg)

    def get_message_count(self):
        # nb_print(self.redis_db7,self._queue_name)
        return self.redis_db_frame.llen(self._queue_name)

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/redis_publisher_simple.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_pubsub_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_pubsub_publisher.py`

#### 📦 Imports

- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisPubSubPublisher(AbstractPublisher, RedisMixin)`
*Line: 8*

**Docstring:**
`````
使用redis作为中间件
`````

**Public Methods (3):**
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.utils.redis_manager import RedisMixin


class RedisPubSubPublisher(AbstractPublisher, RedisMixin, ):
    """
    使用redis作为中间件
    """

    def _publish_impl(self, msg):
        self.redis_db_frame.publish(self._queue_name, msg)

    def clear(self):
        self.redis_db_frame.delete(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    def get_message_count(self):
        return -1

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/redis_pubsub_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_queue_flush_mixin.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_queue_flush_mixin.py`

#### 🏛️ Classes (1)

##### 📌 `class FlushRedisQueueMixin`
*Line: 1*

**Public Methods (1):**
- `def clear(self)`


---

`````python
class FlushRedisQueueMixin:
    # noinspection PyUnresolvedReferences
    def clear(self):
        self.redis_db_frame.delete(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')
        # self.redis_db_frame.delete(f'{self._queue_name}__unack')
        unack_queue_name_list = self.redis_db_frame.scan(match=f'{self._queue_name}__unack_id_*', count=100000)[1] + \
                                self.redis_db_frame.scan(match=f'unack_{self._queue_name}_*', count=100000)[1]  # noqa
        if unack_queue_name_list:
            self.redis_db_frame.delete(*unack_queue_name_list)
            self.logger.warning(f'清除 {unack_queue_name_list} 队列中的消息成功')

`````

--- **end of file: funboost/publishers/redis_queue_flush_mixin.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/redis_stream_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/redis_stream_publisher.py`

#### 📦 Imports

- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from funboost.utils.redis_manager import RedisMixin`

#### 🏛️ Classes (1)

##### 📌 `class RedisStreamPublisher(AbstractPublisher, RedisMixin)`
*Line: 8*

**Docstring:**
`````
redis 的 stream 结构 作为中间件实现的。需要redis 5.0以上，redis stream结构 是redis的消息队列，功能远超 list结构。
`````

**Public Methods (3):**
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

**Class Variables (1):**
- `_has__check_redis_version = False`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2021/4/3 0008 13:32
from funboost.publishers.base_publisher import AbstractPublisher
from funboost.utils.redis_manager import RedisMixin


class RedisStreamPublisher(AbstractPublisher, RedisMixin):
    """
    redis 的 stream 结构 作为中间件实现的。需要redis 5.0以上，redis stream结构 是redis的消息队列，功能远超 list结构。
    """

    _has__check_redis_version = False

    def _check_redis_version(self):
        redis_server_info_dict = self.redis_db_frame.info()
        if float(redis_server_info_dict['redis_version'][0]) < 5:
            raise EnvironmentError('必须是5.0版本以上redis服务端才能支持  stream 数据结构，'
                                   '请升级服务端，否则使用 REDIS_ACK_ABLE 方式使用redis 的 list 结构')
        if self.redis_db_frame.type(self._queue_name) == 'list':
            raise EnvironmentError(f'检测到已存在 {self._queue_name} 这个键，且类型是list， 必须换个队列名字或者删除这个'
                                   f' list 类型的键。'
                                   f'RedisStreamConsumer 使用的是 stream数据结构')
        self._has__check_redis_version = True

    def _publish_impl(self, msg):
        # redis服务端必须是5.0以上，并且确保这个键的类型是stream不能是list数据结构。
        if not self._has__check_redis_version:
            self._check_redis_version()
        self.redis_db_frame.xadd(self._queue_name, {"": msg})

    def clear(self):
        self.redis_db_frame.delete(self._queue_name)
        self.logger.warning(f'清除 {self._queue_name} 队列中的消息成功')

    def get_message_count(self):
        # nb_print(self.redis_db7,self._queue_name)
        return self.redis_db_frame.xlen(self._queue_name)

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/redis_stream_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/rocketmq_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/rocketmq_publisher.py`

#### 📦 Imports

- `import threading`
- `import time`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`
- `from rocketmq.client import Producer`
- `from rocketmq.client import Message`

#### 🏛️ Classes (1)

##### 📌 `class RocketmqPublisher(AbstractPublisher)`
*Line: 12*

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`

**Class Variables (2):**
- `_group_id__rocketmq_producer = {}`
- `_lock_for_create_producer = threading.Lock()`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/7/9 0008 12:12
import threading
import time
from funboost.funboost_config_deafult import BrokerConnConfig

from funboost.publishers.base_publisher import AbstractPublisher



class RocketmqPublisher(AbstractPublisher, ):
    _group_id__rocketmq_producer = {}
    _lock_for_create_producer = threading.Lock()

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        try:
            from rocketmq.client import Producer
        except BaseException as e:
            # print(traceback.format_exc())
            raise ImportError(f'rocketmq包 只支持linux和mac {str(e)}')

        group_id = f'g-{self._queue_name}'
        with self._lock_for_create_producer:
            if group_id not in self.__class__._group_id__rocketmq_producer:  # 同一个进程中创建多个同组消费者会报错。
                producer = Producer(group_id)
                producer.set_namesrv_addr(BrokerConnConfig.ROCKETMQ_NAMESRV_ADDR)
                producer.start()
                self.__class__._group_id__rocketmq_producer[group_id] = producer
            else:
                producer = self.__class__._group_id__rocketmq_producer[group_id]
            self._producer = producer

    def _publish_impl(self, msg):
        try:
            from rocketmq.client import Message
        except BaseException as e:
            # print(traceback.format_exc())
            raise ImportError(f'rocketmq包 只支持linux和mac {str(e)}')
        rocket_msg = Message(self._queue_name)
        # rocket_msg.set_keys(msg)  # 利于检索
        # rocket_msg.set_tags('XXX')
        rocket_msg.set_body(msg)
        # print(msg)
        self._producer.send_sync(rocket_msg)

    def clear(self):
        self.logger.error('清除队列，python版的rocket包太弱了，没有方法设置偏移量或者删除主题。java才能做到')

    def get_message_count(self):
        if time.time() - getattr(self, '_last_warning_count', 0) > 300:
            setattr(self, '_last_warning_count', time.time())
            self.logger.warning('获取消息数量，python版的rocket包太弱了，没找到方法。java才能做到。')
        return -1

    def close(self):
        self._producer.shutdown()

`````

--- **end of file: funboost/publishers/rocketmq_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/rq_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/rq_publisher.py`

#### 📦 Imports

- `import json`
- `from funboost.assist.rq_helper import RqHelper`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class RqPublisher(AbstractPublisher)`
*Line: 10*

**Docstring:**
`````
使用redis作为中间件,这个是大幅优化了发布速度的方式。简单的发布是 redis_publisher_0000.py 中的代码方式。

这个是复杂版，批量推送，简单版在 funboost/publishers/redis_publisher_simple.py
`````

**Public Methods (3):**
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import json

from funboost.assist.rq_helper import RqHelper
from funboost.publishers.base_publisher import AbstractPublisher


class RqPublisher(AbstractPublisher):
    """
    使用redis作为中间件,这个是大幅优化了发布速度的方式。简单的发布是 redis_publisher_0000.py 中的代码方式。

    这个是复杂版，批量推送，简单版在 funboost/publishers/redis_publisher_simple.py
    """

    def _publish_impl(self, msg):
        func_kwargs = json.loads(msg)
        func_kwargs.pop('extra')
        RqHelper.queue_name__rq_job_map[self.queue_name].delay(**func_kwargs)

    def clear(self):
        pass

    def get_message_count(self):
        return -1

    def close(self):
        pass

    def _at_exit(self):
        pass

`````

--- **end of file: funboost/publishers/rq_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/sqla_queue_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/sqla_queue_publisher.py`

#### 📦 Imports

- `from funboost.queues import sqla_queue`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class SqlachemyQueuePublisher(AbstractPublisher)`
*Line: 10*

**Docstring:**
`````
使用Sqlachemy 操作数据库 ，实现的5种sql 数据库服务器作为 消息队列。包括sqlite mydql microsoftsqlserver postgre oracle
这个是使用数据库表模拟的消息队列。这不是突发奇想一意孤行，很多包库都实现了这。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 13:05
from funboost.queues import sqla_queue
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher


# noinspection PyProtectedMember
class SqlachemyQueuePublisher(AbstractPublisher):
    """
    使用Sqlachemy 操作数据库 ，实现的5种sql 数据库服务器作为 消息队列。包括sqlite mydql microsoftsqlserver postgre oracle
    这个是使用数据库表模拟的消息队列。这不是突发奇想一意孤行，很多包库都实现了这。
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self.queue = sqla_queue.SqlaQueue(self._queue_name, BrokerConnConfig.SQLACHEMY_ENGINE_URL)

    def _publish_impl(self, msg):
        self.queue.push(dict(body=msg, status=sqla_queue.TaskStatus.TO_BE_CONSUMED))

    def clear(self):
        self.queue.clear_queue()
        self.logger.warning(f'清除 sqlalchemy 数据库队列 {self._queue_name} 中的消息成功')

    def get_message_count(self):
        return self.queue.to_be_consumed_count

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/sqla_queue_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/tcp_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/tcp_publisher.py`

#### 📦 Imports

- `import socket`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class TCPPublisher(AbstractPublisher)`
*Line: 8*

**Docstring:**
`````
使用tcp作为中间件,不支持持久化，支持分布式
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import socket
from funboost.publishers.base_publisher import AbstractPublisher


class TCPPublisher(AbstractPublisher, ):
    """
    使用tcp作为中间件,不支持持久化，支持分布式
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._bufsize = self.publisher_params.broker_exclusive_config['bufsize']

    # noinspection PyAttributeOutsideInit
    def _publish_impl(self, msg):
        if not hasattr(self, '_tcp_cli_sock'):
            # ip__port_str = self.queue_name.split(':')
            # ip_port = (ip__port_str[0], int(ip__port_str[1]))
            self._ip = self.publisher_params.broker_exclusive_config['host']
            self._port = self.publisher_params.broker_exclusive_config['port']
            self.__ip_port = (self._ip, self._port)
            if self._port is None:
                raise ValueError('please specify port')
            tcp_cli_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            tcp_cli_sock.connect(self.__ip_port)
            self._tcp_cli_sock = tcp_cli_sock

        self._tcp_cli_sock.send(msg.encode())
        self._tcp_cli_sock.recv(self._bufsize)

    def clear(self):
        pass  # udp没有保存消息

    def get_message_count(self):
        # nb_print(self.redis_db7,self._queue_name)
        return -1  # udp没有保存消息

    def close(self):
        # self.redis_db7.connection_pool.disconnect()
        self._tcp_cli_sock.close()

`````

--- **end of file: funboost/publishers/tcp_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/txt_file_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/txt_file_publisher.py`

#### 📦 Imports

- `import shutil`
- `from pathlib import Path`
- `from nb_filelock import FileLock`
- `from persistqueue import Queue`
- `from persistqueue.serializers import json as json_serializer`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class TxtFilePublisher(AbstractPublisher)`
*Line: 15*

**Docstring:**
`````
使用txt文件作为中间件
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import shutil
from pathlib import Path

from nb_filelock import FileLock
from persistqueue import Queue
from persistqueue.serializers import json as json_serializer

from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.publishers.base_publisher import AbstractPublisher


class TxtFilePublisher(AbstractPublisher, ):
    """
    使用txt文件作为中间件
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._file_queue_path = str((Path(BrokerConnConfig.TXT_FILE_PATH) / self.queue_name).absolute())
        # Path(self._file_queue_path).mkdir(exist_ok=True)
        self.file_queue = Queue(self._file_queue_path,
                                autosave=True, serializer=json_serializer)
        self._file_lock = FileLock(Path(self._file_queue_path) / f'_funboost_txtfile_{self.queue_name}.lock')

    def _publish_impl(self, msg):
        with self._file_lock:
            self.file_queue.put(msg)

    def clear(self):
        shutil.rmtree(self._file_queue_path, ignore_errors=True)
        self.logger.warning(f'清除 {Path(self._file_queue_path).absolute()} 文件夹成功')

    def get_message_count(self):
        return self.file_queue.qsize()

    def close(self):
        pass

`````

--- **end of file: funboost/publishers/txt_file_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/udp_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/udp_publisher.py`

#### 📦 Imports

- `import socket`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class UDPPublisher(AbstractPublisher)`
*Line: 8*

**Docstring:**
`````
使用udp作为中间件,不支持持久化，支持分布式
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 12:12
import socket
from funboost.publishers.base_publisher import AbstractPublisher


class UDPPublisher(AbstractPublisher, ):
    """
    使用udp作为中间件,不支持持久化，支持分布式
    """

    # noinspection PyAttributeOutsideInit
    def custom_init(self):
        self._bufsize = self.publisher_params.broker_exclusive_config['bufsize']
        self.__udp_client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self._ip = self.publisher_params.broker_exclusive_config['host']
        self._port = self.publisher_params.broker_exclusive_config['port']
        self.__ip_port = (self._ip, self._port)
        if self._port is None:
            raise ValueError('please specify port')
        self.__udp_client.connect(self.__ip_port)

    # noinspection PyAttributeOutsideInit
    def _publish_impl(self, msg):
        self.__udp_client.send(msg.encode('utf-8'), )
        self.__udp_client.recv(self._bufsize)

    def clear(self):
        pass  # udp没有保存消息

    def get_message_count(self):
        # nb_print(self.redis_db7,self._queue_name)
        return -1  # udp没有保存消息

    def close(self):
        # self.redis_db7.connection_pool.disconnect()
        self.__udp_client.close()

`````

--- **end of file: funboost/publishers/udp_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/zeromq_publisher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/zeromq_publisher.py`

#### 📦 Imports

- `from funboost.core.lazy_impoter import ZmqImporter`
- `from funboost.publishers.base_publisher import AbstractPublisher`

#### 🏛️ Classes (1)

##### 📌 `class ZeroMqPublisher(AbstractPublisher)`
*Line: 8*

**Docstring:**
`````
zeromq 中间件的发布者，zeromq基于socket代码，不会持久化，且不需要安装软件。
`````

**Public Methods (4):**
- `def custom_init(self)`
- `def clear(self)`
- `def get_message_count(self)`
- `def close(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
from funboost.core.lazy_impoter import ZmqImporter
from funboost.publishers.base_publisher import AbstractPublisher


# noinspection PyProtectedMember
class ZeroMqPublisher(AbstractPublisher):
    """
    zeromq 中间件的发布者，zeromq基于socket代码，不会持久化，且不需要安装软件。
    """
    def custom_init(self):
        self._port = self.publisher_params.broker_exclusive_config['port']
        if self._port is None:
            raise ValueError('please specify port')

        context = ZmqImporter().zmq.Context()
        socket = context.socket(ZmqImporter().zmq.REQ)
        socket.connect(f"tcp://localhost:{int(self._port)}")
        self.socket =socket
        self.logger.warning('框架使用 zeromq 中间件方式，必须先启动消费者(消费者会顺便启动broker) ,只有启动了服务端才能发布任务')

    def _publish_impl(self, msg):
        self.socket.send(msg.encode())
        self.socket.recv()

    def clear(self):
        pass

    def get_message_count(self):
        return -1

    def close(self):
        pass


`````

--- **end of file: funboost/publishers/zeromq_publisher.py** (project: funboost) --- 

---


--- **start of file: funboost/publishers/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/publishers/__init__.py`

#### 📝 Module Docstring

`````
实现各种中间件类型的发布者。
`````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 11:50

"""
实现各种中间件类型的发布者。
"""
`````

--- **end of file: funboost/publishers/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/queues/memory_queues_map.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/queues/memory_queues_map.py`

#### 📦 Imports

- `import queue`

#### 🏛️ Classes (1)

##### 📌 `class PythonQueues`
*Line: 4*

**Public Methods (1):**
- `def get_queue(cls, queue_name)` `classmethod`

**Class Variables (1):**
- `local_pyhton_queue_name__local_pyhton_queue_obj_map = {}`


---

`````python
import queue


class PythonQueues:
    local_pyhton_queue_name__local_pyhton_queue_obj_map  = {}

    @classmethod
    def get_queue(cls,queue_name):
        if queue_name not in cls.local_pyhton_queue_name__local_pyhton_queue_obj_map:
            cls.local_pyhton_queue_name__local_pyhton_queue_obj_map[queue_name] = queue.Queue()
        return cls.local_pyhton_queue_name__local_pyhton_queue_obj_map[queue_name]
`````

--- **end of file: funboost/queues/memory_queues_map.py** (project: funboost) --- 

---


--- **start of file: funboost/queues/peewee_queue.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/queues/peewee_queue.py`

#### 📦 Imports

- `import datetime`
- `import time`
- `from funboost.core.loggers import LoggerLevelSetterMixin`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.core.lazy_impoter import PeeweeImporter`
- `from threadpool_executor_shrink_able import ThreadPoolExecutorShrinkAble`

#### 🏛️ Classes (2)

##### 📌 `class TaskStatus`
*Line: 14*

**Class Variables (5):**
- `TO_BE_CONSUMED = 'to_be_consumed'`
- `PENGDING = 'pengding'`
- `FAILED = 'failed'`
- `SUCCESS = 'success'`
- `REQUEUE = 'requeue'`

##### 📌 `class PeeweeQueue(FunboostFileLoggerMixin, LoggerLevelSetterMixin)`
*Line: 22*

**Docstring:**
`````
使用peewee操作数据库模拟消息队列
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name)`
  - **Parameters:**
    - `self`
    - `queue_name`

**Public Methods (8):**
- `def push(self, body)`
- `def get(self)`
- `def set_success(self, job_id, is_delete_the_task = False)`
- `def set_failed(self, job_id)`
- `def set_task_status(self, job_id, status: str)`
- `def requeue_task(self, job_id)`
- `def clear_queue(self)`
- `def get_count_by_status(self, status)`

**Properties (2):**
- `@property total_count`
- `@property to_be_consumed_count`


---

`````python
import datetime
import time
#
# from peewee import ModelSelect, Model, BigAutoField, CharField, DateTimeField, MySQLDatabase
# from playhouse.shortcuts import model_to_dict, dict_to_model

# from nb_log import LoggerMixin, LoggerLevelSetterMixin
from funboost.core.loggers import LoggerLevelSetterMixin,FunboostFileLoggerMixin
from funboost.funboost_config_deafult import BrokerConnConfig
# from peewee import *
from funboost.core.lazy_impoter import PeeweeImporter


class TaskStatus:
    TO_BE_CONSUMED = 'to_be_consumed'
    PENGDING = 'pengding'
    FAILED = 'failed'
    SUCCESS = 'success'
    REQUEUE = 'requeue'


class PeeweeQueue(FunboostFileLoggerMixin, LoggerLevelSetterMixin):
    """
    使用peewee操作数据库模拟消息队列
    """

    def __init__(self, queue_name):
        self.queue_name = queue_name
        self.FunboostMessage = None
        self._create_table()

    def _create_table(self):
        class FunboostMessage(PeeweeImporter().Model):
            """数据库的一行模拟一条消息"""
            job_id = PeeweeImporter().BigAutoField(primary_key=True, )
            body = PeeweeImporter().CharField(max_length=10240, null=False)
            publish_timestamp = PeeweeImporter().DateTimeField(default=datetime.datetime.now)
            status = PeeweeImporter().CharField(max_length=40, null=False)
            consume_start_timestamp = PeeweeImporter().DateTimeField(default=None, null=True)

            class Meta:
                db_table = self.queue_name
                conn_params = dict(
                    host=BrokerConnConfig.MYSQL_HOST,
                    port=BrokerConnConfig.MYSQL_PORT,
                    user=BrokerConnConfig.MYSQL_USER,
                    passwd=BrokerConnConfig.MYSQL_PASSWORD,
                    database=BrokerConnConfig.MYSQL_DATABASE,
                )
                database = PeeweeImporter().MySQLDatabase(**conn_params)

        FunboostMessage.create_table()
        self.FunboostMessage = FunboostMessage

    def push(self, body):
        msg = self.FunboostMessage(body=body, status=TaskStatus.TO_BE_CONSUMED, consume_start_timestamp=None)
        msg.save()

    def get(self):
        while True:
            ten_minitues_ago_datetime = datetime.datetime.now() + datetime.timedelta(minutes=-10)
            ret = self.FunboostMessage.select().where(self.FunboostMessage.status.in_([TaskStatus.TO_BE_CONSUMED, TaskStatus.REQUEUE])
                                                      | (
                                                              (self.FunboostMessage.status == TaskStatus.PENGDING) &
                                                              (self.FunboostMessage.consume_start_timestamp < ten_minitues_ago_datetime)
                                                      )).limit(1)
            # ret = self.FunboostMessage.select().where(self.FunboostMessage.status=='dsadsad').limit(1)
            # print(ret)
            if len(ret) == 1:
                row_obj = ret[0]
                row = PeeweeImporter().model_to_dict(row_obj)
                self.FunboostMessage.update(status=TaskStatus.PENGDING, consume_start_timestamp=datetime.datetime.now()
                                            ).where(self.FunboostMessage.job_id == row['job_id']).execute()
                return row
            else:
                time.sleep(0.2)

    def set_success(self, job_id, is_delete_the_task=False):
        if is_delete_the_task:
            self.FunboostMessage.delete_by_id(job_id)
        else:
            # ModelSelect.for_update()
            # print(self.FunboostMessage.update(status=TaskStatus.SUCCESS).where(self.FunboostMessage.job_id==job_id))
            self.FunboostMessage.update(status=TaskStatus.SUCCESS).where(self.FunboostMessage.job_id == job_id).execute()

    def set_failed(self, job_id, ):
        self.set_task_status(job_id, status=TaskStatus.FAILED)

    def set_task_status(self, job_id, status: str):
        self.FunboostMessage.update(status=status).where(self.FunboostMessage.job_id == job_id).execute()

    def requeue_task(self, job_id):
        self.set_task_status(job_id, TaskStatus.REQUEUE)

    def clear_queue(self):
        self.FunboostMessage.truncate_table()

    def get_count_by_status(self, status):
        return self.FunboostMessage.select().where(self.FunboostMessage.status == status).count()

    @property
    def total_count(self):
        return self.FunboostMessage.select().count()

    @property
    def to_be_consumed_count(self):
        return self.get_count_by_status(TaskStatus.TO_BE_CONSUMED)


if __name__ == '__main__':
    from threadpool_executor_shrink_able import ThreadPoolExecutorShrinkAble
    q = PeeweeQueue('peewee_queue')
    q.set_success(1)

    pool = ThreadPoolExecutorShrinkAble(200)
    # q.clear_queue()
    # t1 = time.time()
    #
    for i in range(10000):
        # q.push(body=f'{{"a":{i}}}',status=TaskStatus.TO_BE_CONSUMED)
        pool.submit(q.push, body=f'{{"a":{i}}}',)
    # # q.get()
    # # q.set_success(3,is_delete_the_task=False)
    # pool.shutdown()
    # print(time.time() - t1)
    # print(q.total_count)

`````

--- **end of file: funboost/queues/peewee_queue.py** (project: funboost) --- 

---


--- **start of file: funboost/queues/sqla_queue.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/queues/sqla_queue.py`

#### 📝 Module Docstring

`````
使用sqlachemy来使5种关系型数据库模拟消息队列。
`````

#### 📦 Imports

- `import datetime`
- `import json`
- `import time`
- `from pathlib import Path`
- `import sqlalchemy`
- `from sqlalchemy import Column`
- `from sqlalchemy import func`
- `from sqlalchemy import or_`
- `from sqlalchemy import and_`
- `from sqlalchemy import Table`
- `from sqlalchemy import MetaData`
- `from sqlalchemy import Integer`
- `from sqlalchemy import String`
- `from sqlalchemy import DateTime`
- `from sqlalchemy import create_engine`
- `from sqlalchemy.ext.automap import automap_base`
- `from sqlalchemy.ext.declarative import declarative_base`
- `from sqlalchemy.orm import sessionmaker`
- `from sqlalchemy.orm import scoped_session`
- `from sqlalchemy.pool import StaticPool`
- `from sqlalchemy_utils import database_exists`
- `from sqlalchemy_utils import create_database`
- `from funboost.utils import decorators`
- `from funboost.core.loggers import FunboostFileLoggerMixin`
- `from funboost.core.loggers import LoggerLevelSetterMixin`

#### 🏛️ Classes (3)

##### 📌 `class TaskStatus`
*Line: 27*

**Class Variables (5):**
- `TO_BE_CONSUMED = 'to_be_consumed'`
- `PENGDING = 'pengding'`
- `FAILED = 'failed'`
- `SUCCESS = 'success'`
- `REQUEUE = 'requeue'`

##### 📌 `class SessionContext`
*Line: 64*

**🔧 Constructor (`__init__`):**
- `def __init__(self, session)`
  - **Parameters:**
    - `self`
    - `session`

##### 📌 `class SqlaQueue(FunboostFileLoggerMixin, LoggerLevelSetterMixin)`
*Line: 78*

**🔧 Constructor (`__init__`):**
- `def __init__(self, queue_name: str, sqla_conn_url: str)`
  - **Parameters:**
    - `self`
    - `queue_name: str`
    - `sqla_conn_url: str`

**Public Methods (9):**
- `def push(self, sqla_task_dict)`
- `def bulk_push(self, sqla_task_dict_list: list)`
  - **Docstring:**
  `````
  queue = SqlaQueue('queue37', 'sqlite:////sqlachemy_queues/queues.db')
  queue.bulk_push([queue.SqlaQueueModel(body=json.dumps({'a': i, 'b': 2 * i}), status=TaskStatus.TO_BE_CONSUMED) for i in range(10000)])
  :param sqla_task_dict_list:
  :return:
  `````
- `def get(self)`
- `def set_success(self, sqla_task_dict, is_delete_the_task = True)`
- `def set_failed(self, sqla_task_dict)`
- `def set_task_status(self, sqla_task_dict, status: str)`
- `def requeue_task(self, sqla_task_dict)`
- `def clear_queue(self)`
- `def get_count_by_status(self, status)`

**Properties (2):**
- `@property total_count`
- `@property to_be_consumed_count`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/1/10 0010 18:42
"""
使用sqlachemy来使5种关系型数据库模拟消息队列。
"""
import datetime
import json
import time
from pathlib import Path


import sqlalchemy
from sqlalchemy import Column, func, or_, and_, Table, MetaData
from sqlalchemy import Integer
from sqlalchemy import String, DateTime
from sqlalchemy import create_engine
from sqlalchemy.ext.automap import automap_base
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.pool import StaticPool
from sqlalchemy_utils import database_exists, create_database

from funboost.utils import  decorators
from funboost.core.loggers import FunboostFileLoggerMixin,LoggerLevelSetterMixin

class TaskStatus:
    TO_BE_CONSUMED = 'to_be_consumed'
    PENGDING = 'pengding'
    FAILED = 'failed'
    SUCCESS = 'success'
    REQUEUE = 'requeue'


"""
class SqlaBase(Base):
    __abstract__ = True
    job_id = Column(Integer, primary_key=True, autoincrement=True)
    body = Column(String(10240))
    publish_timestamp = Column(DateTime, default=datetime.datetime.now, comment='发布时间')
    status = Column(String(20), index=True, nullable=True)
    consume_start_timestamp = Column(DateTime, default=None, comment='消费时间', index=True)

    def __init__(self, job_id=None, body=None, publish_timestamp=None, status=None, consume_start_timestamp=None):
        self.job_id = job_id
        self.body = body
        self.publish_timestamp = publish_timestamp
        self.status = status
        self.consume_start_timestamp = consume_start_timestamp

    def __str__(self):
        return f'{self.__class__} {self.__dict__}'

    def to_dict(self):
        # return {'job_id':self.job_id,'body':self.body,'publish_timestamp':self.publish_timestamp,'status':self.status}
        # noinspection PyUnresolvedReferences
        return {c.name: getattr(self, c.name) for c in self.__table__.columns}
"""





class SessionContext:
    # def __init__(self, session: sqlalchemy.orm.session.Session):
    def __init__(self, session):
        self.ss = session

    def __enter__(self):
        return self.ss

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.ss.commit()
        self.ss.close()


@decorators.flyweight
class SqlaQueue(FunboostFileLoggerMixin, LoggerLevelSetterMixin):
    # noinspection PyPep8Naming
    @decorators.where_is_it_called
    def __init__(self, queue_name: str, sqla_conn_url: str):
        class SqlaBaseMixin:
            # __abstract__ = True
            job_id = Column(Integer, primary_key=True, autoincrement=True)
            body = Column(String(10240))
            publish_timestamp = Column(DateTime, default=datetime.datetime.now, comment='发布时间')
            status = Column(String(20), index=False, nullable=True)
            consume_start_timestamp = Column(DateTime, default=None, comment='消费时间', index=False)

            def __init__(self, job_id=None, body=None, publish_timestamp=None, status=None, consume_start_timestamp=None):
                self.job_id = job_id
                self.body = body
                self.publish_timestamp = publish_timestamp
                self.status = status
                self.consume_start_timestamp = consume_start_timestamp

            def __str__(self):
                return f'{self.__class__} {self.to_dict()}'

            def to_dict(self):
                # return {'job_id':self.job_id,'body':self.body,'publish_timestamp':self.publish_timestamp,'status':self.status}
                # noinspection PyUnresolvedReferences
                return {c.name: getattr(self, c.name) for c in self.__table__.columns}

        self.logger.setLevel(20)
        self.queue_name = queue_name
        self._sqla_conn_url = sqla_conn_url
        self.__auto_create_database()

        if sqla_conn_url.startswith('sqlite'):
            engine = create_engine(sqla_conn_url,
                                   connect_args={'check_same_thread': False},
                                   # poolclass=StaticPool
                                   )
        else:
            engine = create_engine(sqla_conn_url, echo=False,
                                   max_overflow=30,  # 超过连接池大小外最多创建的连接
                                   pool_size=20,  # 连接池大小
                                   pool_timeout=300,  # 池中没有线程最多等待的时间，否则报错
                                   pool_recycle=-1  # 多久之后对线程池中的线程进行一次连接的回收（重置）
                                   )

        try:
            Base = declarative_base()  # type: sqlalchemy.ext.declarative.api.Base

            class SqlaQueueModel(SqlaBaseMixin, Base, ):
                __tablename__ = self.queue_name
                # __table_args__ = {'extend_existing': True， "mysql_engine": "MyISAM",
                #                     "mysql_charset": "utf8"}  # "useexisting": True

            SqlaQueueModel.metadata.create_all(engine, )
            self.Session = sessionmaker(bind=engine, expire_on_commit=False)
            self.SqlaQueueModel = SqlaQueueModel
        except BaseException as e:
            self.logger.warning(e)
            Base = automap_base()

            class SqlaQueueModel(SqlaBaseMixin, Base, ):
                __tablename__ = self.queue_name
                # __table_args__ = {'extend_existing': True}  # "useexisting": True

            Base.prepare(engine, reflect=True)
            self.Session = sessionmaker(bind=engine, expire_on_commit=False)
            self.SqlaQueueModel = SqlaQueueModel

        self._to_be_publish_task_list = []

    def __auto_create_database(self):
        # 'sqlite:////sqlachemy_queues/queues.db'
        if self._sqla_conn_url.startswith('sqlite:'):
            if not Path('/sqlachemy_queues').exists():
                Path('/sqlachemy_queues').mkdir()
        else:
            if not database_exists(self._sqla_conn_url):
                create_database(self._sqla_conn_url)

    def push(self, sqla_task_dict):
        with SessionContext(self.Session()) as ss:
            # sqla_task = ss.merge(sqla_task)
            self.logger.debug(sqla_task_dict)
            ss.add(self.SqlaQueueModel(**sqla_task_dict))

    def bulk_push(self, sqla_task_dict_list: list):
        """
        queue = SqlaQueue('queue37', 'sqlite:////sqlachemy_queues/queues.db')
        queue.bulk_push([queue.SqlaQueueModel(body=json.dumps({'a': i, 'b': 2 * i}), status=TaskStatus.TO_BE_CONSUMED) for i in range(10000)])
        :param sqla_task_dict_list:
        :return:
        """
        with SessionContext(self.Session()) as ss:
            self.logger.debug(sqla_task_dict_list)
            sqla_task_list = [self.SqlaQueueModel(**sqla_task_dict) for sqla_task_dict in sqla_task_dict_list]
            ss.add_all(sqla_task_list)

    def get(self):
        # print(ss)
        while True:
            with SessionContext(self.Session()) as ss:
                ten_minitues_ago_datetime = datetime.datetime.now() + datetime.timedelta(minutes=-10)
                # task = ss.query(self.SqlaQueueModel).filter_by(status=TaskStatus.TO_BE_CONSUMED).first()
                # query = ss.query(self.SqlaQueueModel).filter(self.SqlaQueueModel.status.in_([TaskStatus.TO_BE_CONSUMED, TaskStatus.REQUEUE]))
                # noinspection PyUnresolvedReferences
                query = ss.query(self.SqlaQueueModel).filter(or_(self.SqlaQueueModel.status.in_([TaskStatus.TO_BE_CONSUMED, TaskStatus.REQUEUE]),
                                                                 and_(self.SqlaQueueModel.status == TaskStatus.PENGDING,
                                                                      self.SqlaQueueModel.consume_start_timestamp < ten_minitues_ago_datetime)))
                # print(str(query))  # 打印原始语句。
                task = query.first()
                if task:
                    task.status = task.status = TaskStatus.PENGDING
                    task.consume_start_timestamp = datetime.datetime.now()
                    return task.to_dict()
                else:
                    time.sleep(0.2)

    def set_success(self, sqla_task_dict, is_delete_the_task=True):
        with SessionContext(self.Session()) as ss:
            # sqla_task = ss.merge(sqla_task)
            # print(sqla_task_dict)
            if is_delete_the_task:
                sqla_task = ss.query(self.SqlaQueueModel).filter_by(job_id=sqla_task_dict['job_id']).first()
                # print(sqla_task)
                if sqla_task:  # REMIND 如果中途把表清空了，则不会查找到。
                    ss.delete(sqla_task)
            else:
                sqla_task = ss.query(self.SqlaQueueModel).filter(self.SqlaQueueModel.job_id == sqla_task_dict['job_id']).first()
                if sqla_task:
                    sqla_task.status = TaskStatus.SUCCESS

    def set_failed(self, sqla_task_dict):
        with SessionContext(self.Session()) as ss:
            # sqla_task = ss.merge(sqla_task)
            task = ss.query(self.SqlaQueueModel).filter_by(job_id=sqla_task_dict['job_id']).first()
            task.status = TaskStatus.FAILED

    def set_task_status(self, sqla_task_dict, status: str):
        with SessionContext(self.Session()) as ss:
            # sqla_task = ss.merge(sqla_task)
            task = ss.query(self.SqlaQueueModel).filter(self.SqlaQueueModel.job_id == sqla_task_dict['job_id']).first()
            task.status = status

    def requeue_task(self, sqla_task_dict):
        self.set_task_status(sqla_task_dict, TaskStatus.REQUEUE)

    def clear_queue(self):
        with SessionContext(self.Session()) as ss:
            ss.query(self.SqlaQueueModel).delete(synchronize_session=False)

    def get_count_by_status(self, status):
        with SessionContext(self.Session()) as ss:
            return ss.query(func.count(self.SqlaQueueModel.job_id)).filter(self.SqlaQueueModel.status == status).scalar()

    @property
    def total_count(self):
        with SessionContext(self.Session()) as ss:
            return ss.query(func.count(self.SqlaQueueModel.job_id)).scalar()

    @property
    def to_be_consumed_count(self):
        return self.get_count_by_status(TaskStatus.TO_BE_CONSUMED)


if __name__ == '__main__':
    queue = SqlaQueue('queue37', 'sqlite:////sqlachemy_queues/queues.db').set_log_level(10)
    print()
    queue.bulk_push([dict(body=json.dumps({'a': i, 'b': 2 * i}), status=TaskStatus.TO_BE_CONSUMED) for i in range(10000)])
    print()
    for i in range(1000):
        queue.push(dict(body=json.dumps({'a': i, 'b': 2 * i}), status=TaskStatus.TO_BE_CONSUMED))
    task_dictx = queue.get()
    print(task_dictx)

`````

--- **end of file: funboost/queues/sqla_queue.py** (project: funboost) --- 

---


--- **start of file: funboost/queues/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/queues/__init__.py`


---

`````python

`````

--- **end of file: funboost/queues/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/timing_job/apscheduler_use_mysql_store.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/timing_job/apscheduler_use_mysql_store.py`

#### 📦 Imports

- `from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore`
- `from funboost.timing_job import FsdfBackgroundScheduler`


---

`````python
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore


from funboost.timing_job import FsdfBackgroundScheduler


"""
这个是使用mysql作为定时任务持久化，支持动态修改 添加定时任务,用户完全可以自己按照 funboost/timing_job/apscheduler_use_redis_store.py 中的代码实现，因为apscheduler支持SQLAlchemyJobStore
只是scheduler改个jobstores类型，和funboost知识毫无关系，是apscheduler的知识。
"""
`````

--- **end of file: funboost/timing_job/apscheduler_use_mysql_store.py** (project: funboost) --- 

---


--- **start of file: funboost/timing_job/apscheduler_use_redis_store.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/timing_job/apscheduler_use_redis_store.py`

#### 📦 Imports

- `from apscheduler.jobstores.redis import RedisJobStore`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.redis_manager import get_redis_conn_kwargs`
- `from funboost.timing_job import FunboostBackgroundScheduler`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.utils.decorators import RedisDistributedBlockLockContextManager`
- `from funboost.core.loggers import flogger`

#### 🏛️ Classes (1)

##### 📌 `class FunboostBackgroundSchedulerProcessJobsWithinRedisLock(FunboostBackgroundScheduler)`
*Line: 14*

**Docstring:**
`````
分布式或多进程都启动某个apscheduler实例，如果都使用的同一个数据库类型的jobstores ，_process_jobs有很大概率会造成报错， 因为_process_jobs使用的是线程锁，管不了其他进程和分布式机器。

https://groups.google.com/g/apscheduler/c/Gjc_JQMPePc 问题也提到了这个bug

继承 Custom schedulers https://apscheduler.readthedocs.io/en/3.x/extending.html   可以重写 _create_lock
`````

**Public Methods (1):**
- `def set_process_jobs_redis_lock_key(self, lock_key)`

**Class Variables (1):**
- `process_jobs_redis_lock_key = None`


---

`````python
from apscheduler.jobstores.redis import RedisJobStore
from funboost.utils.redis_manager import RedisMixin,get_redis_conn_kwargs

from funboost.timing_job import FunboostBackgroundScheduler
from funboost.funboost_config_deafult import BrokerConnConfig, FunboostCommonConfig
from funboost.utils.decorators import RedisDistributedBlockLockContextManager
from funboost.core.loggers import flogger

"""
这个是使用redis作为定时任务持久化，支持跨机器和跨进程，外部远程 动态修改/添加/删除定时任务
"""


class FunboostBackgroundSchedulerProcessJobsWithinRedisLock(FunboostBackgroundScheduler):
    """
    分布式或多进程都启动某个apscheduler实例，如果都使用的同一个数据库类型的jobstores ，_process_jobs有很大概率会造成报错， 因为_process_jobs使用的是线程锁，管不了其他进程和分布式机器。

    https://groups.google.com/g/apscheduler/c/Gjc_JQMPePc 问题也提到了这个bug

    继承 Custom schedulers https://apscheduler.readthedocs.io/en/3.x/extending.html   可以重写 _create_lock
    """

    process_jobs_redis_lock_key = None

    def set_process_jobs_redis_lock_key(self, lock_key):
        self.process_jobs_redis_lock_key = lock_key
        return self

    # def  _create_lock(self):
    #     return RedisDistributedBlockLockContextManager(RedisMixin().redis_db_frame,self.process_jobs_redis_lock_key,) 这个类的写法不适合固定的单例，
    #     RedisDistributedBlockLockContextManager的写法不适合 永远用一个 对象，所以还是放到 def  _process_jobs 里面运行

    # def _process_jobs(self):
    #     for i in range(10) :
    #         with RedisDistributedLockContextManager(RedisMixin().redis_db_frame, self.process_jobs_redis_lock_key, ) as lock:
    #             if lock.has_aquire_lock:
    #                 wait_seconds = super()._process_jobs()
    #                 return wait_seconds
    #             else:
    #                 time.sleep(0.1)
    #     return 0.1

    def _process_jobs(self):
        """
        funboost 的做法是 在任务取出阶段就加锁，从根本上防止了重复执行。
        这个很关键，防止多个apscheduler 实例同时扫描取出同一个定时任务，间接导致重复执行,
        在apscheduler 3.xx版本这样写来防止多个apscheduler实例 重复执行定时任务的问题,简直是神操作.

        _process_jobs 功能是扫描取出需要运行的定时任务,而不是直接运行定时任务
        只要扫描取出任务不会取出相同的任务,就间接的决定了不可能重复执行相同的定时任务了.
        

        不要以为随便在你自己的消费函数加个redis分布式锁就不会重复执行任务了,redis分布式锁是解决相同代码块不会并发执行,而不是解决重复执行.
        但funboost是神级别骚操作,把分布式锁加到_process_jobs里面,
        _process_jobs是获取一批即将运行的定时任务,是扫描并删除这个即将运行的定时任务,
        所以这里加分布式锁能间接解决不重复运行定时任务,一旦任务被取出，就会从 jobstore 中删除,其他实例就无法再取到这个任务了.

        """
        if self.process_jobs_redis_lock_key is None:
            raise ValueError('process_jobs_redis_lock_key is not set')
        try:    
            with RedisDistributedBlockLockContextManager(RedisMixin().redis_db_frame, self.process_jobs_redis_lock_key, ):
                return super()._process_jobs()
        except Exception as e:
             # 这里必须捕获错误，否则一旦RedisDistributedBlockLockContextManager redis 小概率报错断网一次，_main_loop 循环就会退出，导致定时器的扫描任务的while 线程从此不再运行了。
            flogger.exception(f'FunboostBackgroundSchedulerProcessJobsWithinRedisLock _process_jobs error: {e}')
            return 0.1


jobstores = {
    "default": RedisJobStore(**get_redis_conn_kwargs(),
                             jobs_key='funboost.apscheduler.jobs',run_times_key="funboost.apscheduler.run_times")
}

"""
建议不要亲自使用这个 funboost_background_scheduler_redis_store 对象，而是 ApsJobAdder来添加定时任务，自动多个apscheduler对象实例，
尤其是redis作为jobstores时候，使用不同的jobstores，每个消费函数使用各自单独的jobs_key和 run_times_key
"""
funboost_background_scheduler_redis_store = FunboostBackgroundSchedulerProcessJobsWithinRedisLock(timezone=FunboostCommonConfig.TIMEZONE, daemon=False, jobstores=jobstores)






"""
跨python解释器 跨机器动态修改定时任务配置的例子在

test_frame/test_apschedual/test_aps_redis_store.py
test_frame/test_apschedual/test_change_aps_conf.py

"""

`````

--- **end of file: funboost/timing_job/apscheduler_use_redis_store.py** (project: funboost) --- 

---


--- **start of file: funboost/timing_job/timing_job_base.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/timing_job/timing_job_base.py`

#### 📝 Module Docstring

`````
集成定时任务。
`````

#### 📦 Imports

- `import atexit`
- `import time`
- `from apscheduler.executors.pool import BasePoolExecutor`
- `from typing import Union`
- `import threading`
- `from apscheduler.schedulers.background import BackgroundScheduler`
- `from apscheduler.schedulers.base import STATE_STOPPED`
- `from apscheduler.schedulers.base import STATE_RUNNING`
- `from apscheduler.util import undefined`
- `from threading import TIMEOUT_MAX`
- `import deprecated`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from funboost.consumers.base_consumer import AbstractConsumer`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.booster import Booster`
- `from funboost.core.func_params_model import BoosterParams`
- `from funboost.concurrent_pool.custom_threadpool_executor import ThreadPoolExecutorShrinkAble`
- `from funboost.concurrent_pool.custom_threadpool_executor import ThreadPoolExecutorShrinkAbleNonDaemon`
- `import datetime`
- `from funboost import boost`
- `from funboost import BrokerEnum`
- `from funboost import fsdf_background_scheduler`
- `from funboost import timing_publish_deco`
- `from funboost import run_forever`
- `from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter`

#### 🏛️ Classes (2)

##### 📌 `class ThreadPoolExecutorForAps(BasePoolExecutor)`
*Line: 57*

**Docstring:**
`````
An executor that runs jobs in a concurrent.futures thread pool.

Plugin alias: ``threadpool``

:param max_workers: the maximum number of spawned threads.
:param pool_kwargs: dict of keyword arguments to pass to the underlying
    ThreadPoolExecutor constructor
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, max_workers = 100, pool_kwargs = None)`
  - **Parameters:**
    - `self`
    - `max_workers = 100`
    - `pool_kwargs = None`

##### 📌 `class FunboostBackgroundScheduler(BackgroundScheduler)`
*Line: 84*

**Docstring:**
`````
自定义的， 继承了官方BackgroundScheduler，
通过重写 _main_loop ，使得动态修改增加删除定时任务配置更好。
`````

**Public Methods (3):**
- `def add_timing_publish_job(self, func, trigger = None, args = None, kwargs = None, id = None, name = None, misfire_grace_time = undefined, coalesce = undefined, max_instances = undefined, next_run_time = undefined, jobstore = 'default', executor = 'default', replace_existing = False, **trigger_args)` `deprecated.deprecated(reason='以后不要再使用这种方式，对于job_store为数据库时候需要序列化不好。使用内存和数据库都兼容的添加任务方式: add_push_job')`
- `def add_push_job(self, func: Booster, trigger = None, args = None, kwargs = None, id = None, name = None, misfire_grace_time = undefined, coalesce = undefined, max_instances = undefined, next_run_time = undefined, jobstore = 'default', executor = 'default', replace_existing = False, **trigger_args)`
  - **Docstring:**
  `````
  :param func: 被@boost装饰器装饰的函数
  :param trigger:
  :param args:
  :param kwargs:
  :param id:
  :param name:
  :param misfire_grace_time:
  :param coalesce:
  :param max_instances:
  :param next_run_time:
  :param jobstore:
  :param executor:
  :param replace_existing:
  :param trigger_args:
  :return:
  `````
- `def start(self, paused = False, block_exit = True)`

**Class Variables (2):**
- `_last_wait_seconds = None`
- `_last_has_task = False`

#### 🔧 Public Functions (3)

- `def timing_publish_deco(consuming_func_decorated_or_consumer: Union[callable, AbstractConsumer])` `deprecated.deprecated(reason='以后不要再使用这种方式，对于job_store为数据库时候需要序列化不好。使用内存和数据库都兼容的添加任务方式: add_push_job')`
  - *Line: 30*

- `def push_fun_params_to_broker(queue_name: str, *args, **kwargs)`
  - *Line: 42*
  - **Docstring:**
  `````
  queue_name 队列名字
  *args **kwargs 是消费函数的入参
  `````

- `def consume_func(x, y)` `Booster(boost_params=BoosterParams(queue_name='queue_test_666', broker_kind=BrokerEnum.LOCAL_PYTHON_QUEUE))`
  - *Line: 224*


---

`````python
"""
集成定时任务。
"""
import atexit

import time
from apscheduler.executors.pool import BasePoolExecutor

from typing import Union
import threading

from apscheduler.schedulers.background import BackgroundScheduler
# noinspection PyProtectedMember
from apscheduler.schedulers.base import STATE_STOPPED, STATE_RUNNING
from apscheduler.util import undefined
from threading import TIMEOUT_MAX
import deprecated
from funboost.utils.redis_manager import RedisMixin

from funboost.funboost_config_deafult import FunboostCommonConfig

from funboost.consumers.base_consumer import AbstractConsumer
from funboost.core.booster import BoostersManager, Booster

from funboost.core.func_params_model import BoosterParams
from funboost.concurrent_pool.custom_threadpool_executor import ThreadPoolExecutorShrinkAble,ThreadPoolExecutorShrinkAbleNonDaemon


@deprecated.deprecated(reason='以后不要再使用这种方式，对于job_store为数据库时候需要序列化不好。使用内存和数据库都兼容的添加任务方式: add_push_job')
def timing_publish_deco(consuming_func_decorated_or_consumer: Union[callable, AbstractConsumer]):
    def _deco(*args, **kwargs):
        if getattr(consuming_func_decorated_or_consumer, 'is_decorated_as_consume_function', False) is True:
            consuming_func_decorated_or_consumer.push(*args, **kwargs)
        elif isinstance(consuming_func_decorated_or_consumer, AbstractConsumer):
            consuming_func_decorated_or_consumer.publisher_of_same_queue.push(*args, **kwargs)
        else:
            raise TypeError('consuming_func_decorated_or_consumer 必须是被 boost 装饰的函数或者consumer类型')

    return _deco


def push_fun_params_to_broker(queue_name: str, *args, **kwargs):
    """
    queue_name 队列名字
    *args **kwargs 是消费函数的入参
    """
    try:
        booster = BoostersManager.get_or_create_booster_by_queue_name(queue_name)
        return booster.push(*args, **kwargs)
    except KeyError as e:
        from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter
        publisher = SingleQueueConusmerParamsGetter(queue_name).gen_publisher_for_faas()
        return publisher.push(*args, **kwargs)
        


class ThreadPoolExecutorForAps(BasePoolExecutor):
    """
    An executor that runs jobs in a concurrent.futures thread pool.

    Plugin alias: ``threadpool``

    :param max_workers: the maximum number of spawned threads.
    :param pool_kwargs: dict of keyword arguments to pass to the underlying
        ThreadPoolExecutor constructor
    """

    def __init__(self, max_workers=100, pool_kwargs=None):

        # pool = ThreadPoolExecutorShrinkAble(int(max_workers), )
        pool = ThreadPoolExecutorShrinkAbleNonDaemon(int(max_workers), ) 

        """
        raise RuntimeError('cannot schedule new futures after ' RuntimeError: cannot schedule new futures after interpreter shutdown
        
        ThreadPoolExecutorShrinkAbleNonDaemon 这个更好，阻止主线程退出导致apschrduler使用了守护线程的线程池而导致这个报错。
        ThreadPoolExecutorShrinkAbleNonDaemon 线程池里面的线程不是守护线程，
        
        """

        super().__init__(pool)


class FunboostBackgroundScheduler(BackgroundScheduler):
    """
    自定义的， 继承了官方BackgroundScheduler，
    通过重写 _main_loop ，使得动态修改增加删除定时任务配置更好。
    """

    _last_wait_seconds = None
    _last_has_task = False

    @deprecated.deprecated(reason='以后不要再使用这种方式，对于job_store为数据库时候需要序列化不好。使用内存和数据库都兼容的添加任务方式: add_push_job')
    def add_timing_publish_job(self, func, trigger=None, args=None, kwargs=None, id=None, name=None,
                               misfire_grace_time=undefined, coalesce=undefined, max_instances=undefined,
                               next_run_time=undefined, jobstore='default', executor='default',
                               replace_existing=False, **trigger_args):
        return self.add_job(timing_publish_deco(func), trigger, args, kwargs, id, name,
                            misfire_grace_time, coalesce, max_instances,
                            next_run_time, jobstore, executor,
                            replace_existing, **trigger_args)

    def add_push_job(self, func: Booster, trigger=None, args=None, kwargs=None, 
                     id=None, name=None,
                     misfire_grace_time=undefined, coalesce=undefined, max_instances=undefined,
                     next_run_time=undefined, jobstore='default', executor='default',
                     replace_existing=False, **trigger_args, ):
        """
        :param func: 被@boost装饰器装饰的函数
        :param trigger:
        :param args:
        :param kwargs:
        :param id:
        :param name:
        :param misfire_grace_time:
        :param coalesce:
        :param max_instances:
        :param next_run_time:
        :param jobstore:
        :param executor:
        :param replace_existing:
        :param trigger_args:
        :return:
        """
        # args = args or {}
        # kwargs['queue_name'] = func.queue_name

        """
        用户如果不使用funboost的 FunboostBackgroundScheduler 类型对象，而是使用原生的apscheduler类型对象，可以scheduler.add_job(push_fun_params_to_broker,args=(,),kwargs={}) 
        push_fun_params_to_broker函数入参是消费函数队列的 queue_name 加上 原消费函数的入参
        """
        if args is None:
            args = tuple()
        
        args_list = list(args)
        args_list.insert(0, func.queue_name)
        args = tuple(args_list)
        if name is None:
            name = f'push_fun_params_to_broker_for_queue_{func.queue_name}'
        func.publisher.check_func_input_params(*args[1:], **(kwargs or {})) # 这一行是检查入参是否合法，防止添加了不合法的定时入参，到执行时候才发现，这比官方apscheduler更靠谱。
        return self.add_job(push_fun_params_to_broker, trigger, args, kwargs, id, name,
                            misfire_grace_time, coalesce, max_instances,
                            next_run_time, jobstore, executor,
                            replace_existing, **trigger_args, )

    def start(self, paused=False, block_exit=True):
        # def _block_exit():
        #     while True:
        #         time.sleep(3600)
        #
        # threading.Thread(target=_block_exit,).start()  # 既不希望用BlockingScheduler阻塞主进程也不希望定时退出。
        # self._daemon = False
        # def _when_exit():
        #     while 1:
        #         # print('阻止退出')
        #         time.sleep(100)

        # if block_exit:
        #     atexit.register(_when_exit)
        self._daemon = False   # 这里强制默认改成非守护线程。默认是守护线程，主线程退出会报错。
        super().start(paused=paused, )
        # _block_exit()   # python3.9 判断守护线程结束必须主线程在运行。你自己在你的运行代碼的最末尾加上 while 1： time.sleep(100)  ,来阻止主线程退出。

    def _main_loop00000(self):
        """
        原来的代码是这，动态添加任务不友好。
        :return:
        """
        wait_seconds = threading.TIMEOUT_MAX
        while self.state != STATE_STOPPED:
            print(6666, self._event.is_set(), wait_seconds)
            self._event.wait(wait_seconds)
            print(7777, self._event.is_set(), wait_seconds)
            self._event.clear()
            wait_seconds = self._process_jobs()

    def _main_loop(self):
        """原来的_main_loop 删除所有任务后wait_seconds 会变成None，无限等待。
        或者下一个需要运行的任务的wait_seconds是3600秒后，此时新加了一个动态任务需要3600秒后，
        现在最多只需要1秒就能扫描到动态新增的定时任务了。
        """
        MAX_WAIT_SECONDS_FOR_NEX_PROCESS_JOBS = 0.5
        wait_seconds = None
        while self.state != STATE_STOPPED:
            if wait_seconds is None:
                wait_seconds = MAX_WAIT_SECONDS_FOR_NEX_PROCESS_JOBS
            self._last_wait_seconds = min(wait_seconds, MAX_WAIT_SECONDS_FOR_NEX_PROCESS_JOBS)
            if wait_seconds in (None, TIMEOUT_MAX):
                self._last_has_task = False
            else:
                self._last_has_task = True
            time.sleep(self._last_wait_seconds)  # 这个要取最小值，不然例如定时间隔0.1秒运行，不取最小值，不会每隔0.1秒运行。
            wait_seconds = self._process_jobs()

    def _create_default_executor(self):
        return ThreadPoolExecutorForAps()  # 必须是apscheduler pool的子类


FsdfBackgroundScheduler = FunboostBackgroundScheduler  # 兼容一下名字，fsdf是 function-scheduling-distributed-framework 老框架名字的缩写
# funboost_aps_scheduler定时配置基于内存的，不可以跨机器远程动态添加/修改/删除定时任务配置。如果需要动态增删改查定时任务，可以使用funboost_background_scheduler_redis_store

"""
建议不要亲自使用这个 funboost_aps_scheduler 对象，而是 ApsJobAdder来添加定时任务，自动多个apscheduler对象实例，
尤其是redis作为jobstores时候，使用不同的jobstores，每个消费函数使用各自单独的jobs_key和 run_times_key
"""
funboost_aps_scheduler = FunboostBackgroundScheduler(timezone=FunboostCommonConfig.TIMEZONE, daemon=False, )
fsdf_background_scheduler = funboost_aps_scheduler  # 兼容一下老名字。



if __name__ == '__main__':

    """
    下面的例子过时了，可以用但不建议，建议统一使用 ApsJobAdder 来添加定时任务。

    """

    # 定时运行消费演示
    import datetime
    from funboost import boost, BrokerEnum, fsdf_background_scheduler, timing_publish_deco, run_forever


    @Booster(boost_params=BoosterParams(queue_name='queue_test_666', broker_kind=BrokerEnum.LOCAL_PYTHON_QUEUE))
    def consume_func(x, y):
        print(f'{x} + {y} = {x + y}')


    print(consume_func, type(consume_func))

    # 定时每隔3秒执行一次。
    funboost_aps_scheduler.add_push_job(consume_func,
                                        'interval', id='3_second_job', seconds=3, kwargs={"x": 5, "y": 6})

    # 定时，只执行一次
    funboost_aps_scheduler.add_push_job(consume_func,
                                        'date', run_date=datetime.datetime(2020, 7, 24, 13, 53, 6), args=(5, 6,))

    # 定时，每天的11点32分20秒都执行一次。
    funboost_aps_scheduler.add_push_job(consume_func,
                                        'cron', day_of_week='*', hour=18, minute=22, second=20, args=(5, 6,))

    # 启动定时
    funboost_aps_scheduler.start()

    # 启动消费
    consume_func.consume()
    run_forever()

`````

--- **end of file: funboost/timing_job/timing_job_base.py** (project: funboost) --- 

---


--- **start of file: funboost/timing_job/timing_push.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/timing_job/timing_push.py`

#### 📦 Imports

- `from funboost.utils import redis_manager`
- `from funboost.core.booster import BoostersManager`
- `from funboost.core.booster import Booster`
- `from apscheduler.jobstores.redis import RedisJobStore`
- `from funboost.timing_job.timing_job_base import funboost_aps_scheduler`
- `from funboost.timing_job.timing_job_base import undefined`
- `from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`
- `from apscheduler.schedulers.base import BaseScheduler`
- `from funboost.constant import RedisKeys`
- `from funboost import boost`
- `from funboost import BrokerEnum`
- `from funboost import ctrl_c_recv`
- `from funboost import BoosterParams`
- `from funboost import ApsJobAdder`

#### 🏛️ Classes (1)

##### 📌 `class ApsJobAdder`
*Line: 11*

**Docstring:**
`````
20250116新增加的统一的新增定时任务的方式，推荐这种方式。
用户不用像之前再去关心使用哪个apscheduler对象去添加定时任务了。

例如 add_numbers 是@boost装饰的消费函数
ApsJobAdder(add_numbers,job_store_kind='memory').add_push_job(
    args=(1, 2),
    trigger='date',  # 使用日期触发器
    run_date='2025-01-16 18:23:50',  # 设置运行时间
    # id='add_numbers_job'  # 任务ID
)
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, booster: Booster, job_store_kind: str = 'memory', is_auto_start = True, is_auto_paused = False)`
  - **Docstring:**
  `````
  Initialize the ApsJobAdder.
  
  :param booster: A Booster object representing the function to be scheduled.
  :param job_store_kind: The type of job store to use. Default is 'memory'.
                         Can be 'memory' or 'redis'.
  `````
  - **Parameters:**
    - `self`
    - `booster: Booster`
    - `job_store_kind: str = 'memory'`
    - `is_auto_start = True`
    - `is_auto_paused = False`

**Public Methods (3):**
- `def get_funboost_redis_apscheduler(cls, queue_name)` `classmethod`
  - **Docstring:**
  `````
  每个队列名字的定时任务有自己单独的 aspchedule r定时器,
  每隔定时器用不同的redis jobstore的 jobs_key 和 run_times_key，防止互相干扰和取出不属于自己的任务.
  如果所有函数使用同一个定时器和一个jobs_key ,当用户只想运行f1定时任务,如果用户把f2删了,或者不需要运行f2定时任务,那就报错或者不方便.
  `````
- `def get_aps_obj(cls, queue_name, job_store_kind)` `classmethod`
- `def add_push_job(self, trigger = None, args = None, kwargs = None, id = None, name = None, misfire_grace_time = undefined, coalesce = undefined, max_instances = undefined, next_run_time = undefined, jobstore = 'default', executor = 'default', replace_existing = False, **trigger_args)`
  - **Docstring:**
  `````
  1. 这里的入参都是和apscheduler的add_job的入参一样的，funboost作者没有创造新的入参。
  但是官方apscheduler的入参第一个入参是函数，
  funboost的ApsJobAdder对象.add_push_job入参去掉了函数，因为类的实例化时候会把函数传进来，不需要再麻烦用户一次了。
  
  
  2. add_push_job目的是 定时运行 消费函数.push方法发布消息到消费队列， 而不是 定时直接运行 消费函数自身。
  
  相当于 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....)
  那为什么 不直接使用 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....) 呢？因为 消费函数.push是实例方法，
  如果redis作为 jobstore， 消费函数.push 会报错，因为 消费函数.push 是实例方法，不能被序列化。只有普通函数和静态方法才能被序列化。
  所以开发了一个 add_push_job方法， 里面再去用 add_job， 使用 push_fun_params_to_broker 这个普通函数作为 add_job 的第一个入参，
  这个普通函数里面再去调用 消费函数.push 方法， 相当于是曲线救国避免 aps_obj.add_job(消费函数.push 不可序列化问题。
  
  
  3. 用户也可以自己定义一个普通函数my_push，你这个普通函数my_push 里面去调用消费函数.push方法；然后使用 aps_obj.add_job 使用你自己定义的这个my_push作为第一个入参。
  这种方式更容易你去理解，和apscheduler 官方库的原生写法一模一样。 但是不如 add_push_job 方便，因为 需要你亲自给每个消费函数分别定义一个普通函数my_push。
  `````

**Properties (1):**
- `@property aps_obj -> BaseScheduler`

**Class Variables (1):**
- `queue__redis_aps_map = {}`

#### 🔧 Public Functions (1)

- `def sum_two_numbers(x, y)` `BoosterParams(queue_name='sum_queue3', broker_kind=BrokerEnum.REDIS)`
  - *Line: 125*


---

`````python
from funboost.utils import redis_manager
from funboost.core.booster import BoostersManager, Booster

from apscheduler.jobstores.redis import RedisJobStore
from funboost.timing_job.timing_job_base import funboost_aps_scheduler, undefined
from funboost.timing_job.apscheduler_use_redis_store import FunboostBackgroundSchedulerProcessJobsWithinRedisLock
from funboost.funboost_config_deafult import FunboostCommonConfig
from apscheduler.schedulers.base import BaseScheduler
from funboost.constant import RedisKeys

class ApsJobAdder:
    """
    20250116新增加的统一的新增定时任务的方式，推荐这种方式。
    用户不用像之前再去关心使用哪个apscheduler对象去添加定时任务了。

    例如 add_numbers 是@boost装饰的消费函数
    ApsJobAdder(add_numbers,job_store_kind='memory').add_push_job(
        args=(1, 2),
        trigger='date',  # 使用日期触发器
        run_date='2025-01-16 18:23:50',  # 设置运行时间
        # id='add_numbers_job'  # 任务ID
    )

    """

    queue__redis_aps_map = {}

    def __init__(self, booster: Booster, job_store_kind: str = 'memory',is_auto_start=True,is_auto_paused=False):
        """
        Initialize the ApsJobAdder.

        :param booster: A Booster object representing the function to be scheduled.
        :param job_store_kind: The type of job store to use. Default is 'memory'.
                               Can be 'memory' or 'redis'.
        """
        self.booster = booster
        self.job_store_kind = job_store_kind
        if getattr(self.aps_obj, 'has_started_flag', False) is False:
            if is_auto_start:
                self.aps_obj.has_started_flag = True
                self.aps_obj.start(paused=is_auto_paused)



    @classmethod
    def get_funboost_redis_apscheduler(cls, queue_name):
        """ 
        每个队列名字的定时任务有自己单独的 aspchedule r定时器,
        每隔定时器用不同的redis jobstore的 jobs_key 和 run_times_key，防止互相干扰和取出不属于自己的任务.
        如果所有函数使用同一个定时器和一个jobs_key ,当用户只想运行f1定时任务,如果用户把f2删了,或者不需要运行f2定时任务,那就报错或者不方便.
        """
        if queue_name in cls.queue__redis_aps_map:
            return cls.queue__redis_aps_map[queue_name]
        redis_jobstores = {

            "default": RedisJobStore(**redis_manager.get_redis_conn_kwargs(),
                                    jobs_key=RedisKeys.gen_funboost_redis_apscheduler_jobs_key_by_queue_name(queue_name),
                                    run_times_key=RedisKeys.gen_funboost_redis_apscheduler_run_times_key_by_queue_name(queue_name),
                                     )
        }
        redis_aps = FunboostBackgroundSchedulerProcessJobsWithinRedisLock(timezone=FunboostCommonConfig.TIMEZONE,
                                                                          daemon=False, jobstores=redis_jobstores)
        redis_aps.set_process_jobs_redis_lock_key(RedisKeys.gen_funboost_apscheduler_redis_lock_key_by_queue_name(queue_name))
        cls.queue__redis_aps_map[queue_name] = redis_aps
        return redis_aps

    @property
    def aps_obj(self) -> BaseScheduler:
        return self.get_aps_obj(self.booster.queue_name,self.job_store_kind)

    @classmethod
    def get_aps_obj(cls,queue_name,job_store_kind):
        if job_store_kind == 'redis':
            return cls.get_funboost_redis_apscheduler(queue_name)
        elif job_store_kind == 'memory':
            return funboost_aps_scheduler
        else:
            raise ValueError('Unsupported job_store_kind')


    def add_push_job(self, trigger=None, args=None, kwargs=None,
                     id=None, name=None,
                     misfire_grace_time=undefined, coalesce=undefined, max_instances=undefined,
                     next_run_time=undefined, jobstore='default', executor='default',
                     replace_existing=False, **trigger_args, ):
        """
        1. 这里的入参都是和apscheduler的add_job的入参一样的，funboost作者没有创造新的入参。
        但是官方apscheduler的入参第一个入参是函数，
        funboost的ApsJobAdder对象.add_push_job入参去掉了函数，因为类的实例化时候会把函数传进来，不需要再麻烦用户一次了。
        

        2. add_push_job目的是 定时运行 消费函数.push方法发布消息到消费队列， 而不是 定时直接运行 消费函数自身。

        相当于 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....)
        那为什么 不直接使用 aps_obj.add_job(消费函数.push, trigger, args, kwargs, id, name, .....) 呢？因为 消费函数.push是实例方法，
        如果redis作为 jobstore， 消费函数.push 会报错，因为 消费函数.push 是实例方法，不能被序列化。只有普通函数和静态方法才能被序列化。
        所以开发了一个 add_push_job方法， 里面再去用 add_job， 使用 push_fun_params_to_broker 这个普通函数作为 add_job 的第一个入参，
        这个普通函数里面再去调用 消费函数.push 方法， 相当于是曲线救国避免 aps_obj.add_job(消费函数.push 不可序列化问题。


        3. 用户也可以自己定义一个普通函数my_push，你这个普通函数my_push 里面去调用消费函数.push方法；然后使用 aps_obj.add_job 使用你自己定义的这个my_push作为第一个入参。
        这种方式更容易你去理解，和apscheduler 官方库的原生写法一模一样。 但是不如 add_push_job 方便，因为 需要你亲自给每个消费函数分别定义一个普通函数my_push。

        """

        # if not getattr(self.aps_obj, 'has_started_flag', False):
        #     self.aps_obj.has_started_flag = True
        #     self.aps_obj.start(paused=False)
        return self.aps_obj.add_push_job(self.booster, trigger, args, kwargs, id, name,
                                         misfire_grace_time, coalesce, max_instances,
                                         next_run_time, jobstore, executor,
                                         replace_existing, **trigger_args, )


if __name__ == '__main__':
    """
    2025年后定时任务现在推荐使用 ApsJobAdder 写法 ，用户不需要亲自选择使用 apscheduler对象来添加定时任务
    特别是使用redis作为jobstores时候，你可以看源码就知道了。
    """
    from funboost import boost, BrokerEnum, ctrl_c_recv, BoosterParams, ApsJobAdder


    # 定义任务处理函数
    @BoosterParams(queue_name='sum_queue3', broker_kind=BrokerEnum.REDIS)
    def sum_two_numbers(x, y):
        result = x + y
        print(f'The sum of {x} and {y} is {result}')

    # 启动消费者
    # sum_two_numbers.consume()

    # 发布任务
    sum_two_numbers.push(3, 5)
    sum_two_numbers.push(10, 20)



    # 使用ApsJobAdder添加定时任务， 里面的定时语法，和apscheduler是一样的，用户需要自己熟悉知名框架apscheduler的add_job定时入参

    # 方式1：指定日期执行一次
    ApsJobAdder(sum_two_numbers, job_store_kind='redis').add_push_job(
        trigger='date',
        run_date='2025-01-17 23:25:40',
        args=(7, 8),
        id='date_job1'
    )

    # 方式2：固定间隔执行
    ApsJobAdder(sum_two_numbers, job_store_kind='memory').add_push_job(
        trigger='interval',
        seconds=5,
        args=(4, 6),
        id='interval_job1'
    )

    # 方式3：使用cron表达式定时执行,周期运行
    ApsJobAdder(sum_two_numbers, job_store_kind='redis').add_push_job(
        trigger='cron',
        day_of_week='*',
        hour=23,
        minute=49,
        second=50,
        kwargs={"x": 50, "y": 60},
        replace_existing=True,
        id='cron_job1')
    


    # ctrl_c_recv() # 启动了守护线程的定时器，一定要阻止主线程退出。 你可以代码最末尾加这个 ctrl_c_recv() 或者加个 while 1:time.sleep(10)

`````

--- **end of file: funboost/timing_job/timing_push.py** (project: funboost) --- 

---


--- **start of file: funboost/timing_job/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/timing_job/__init__.py`

#### 📦 Imports

- `from funboost.timing_job.timing_job_base import FsdfBackgroundScheduler`
- `from funboost.timing_job.timing_job_base import funboost_aps_scheduler`
- `from funboost.timing_job.timing_job_base import fsdf_background_scheduler`
- `from funboost.timing_job.timing_job_base import timing_publish_deco`
- `from funboost.timing_job.timing_job_base import FunboostBackgroundScheduler`
- `from funboost.timing_job.timing_job_base import push_fun_params_to_broker`
- `from funboost.timing_job.timing_push import ApsJobAdder`


---

`````python
from  funboost.timing_job.timing_job_base import (FsdfBackgroundScheduler ,
funboost_aps_scheduler ,fsdf_background_scheduler,timing_publish_deco,FunboostBackgroundScheduler,push_fun_params_to_broker )



from funboost.timing_job.timing_push import ApsJobAdder
`````

--- **end of file: funboost/timing_job/__init__.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/apscheduler_monkey.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/apscheduler_monkey.py`

#### 📦 Imports

- `from datetime import datetime`
- `from datetime import timedelta`
- `from traceback import format_tb`
- `import logging`
- `import sys`
- `from pytz import utc`
- `import six`
- `import apscheduler`
- `from apscheduler.events import JobExecutionEvent`
- `from apscheduler.events import EVENT_JOB_MISSED`
- `from apscheduler.events import EVENT_JOB_ERROR`
- `from apscheduler.events import EVENT_JOB_EXECUTED`
- `import traceback`

#### 🔧 Public Functions (2)

- `def my_run_job(job, jobstore_alias, run_times, logger_name)`
  - *Line: 15*
  - *主要是把函数的入参放到event上，便于listener获取函数对象和函数入参。*

- `def patch_run_job()`
  - *Line: 86*


---

`````python
from datetime import datetime, timedelta
from traceback import format_tb
import logging
import sys

from pytz import utc
import six

import apscheduler

from apscheduler.events import (
    JobExecutionEvent, EVENT_JOB_MISSED, EVENT_JOB_ERROR, EVENT_JOB_EXECUTED)


def my_run_job(job, jobstore_alias, run_times, logger_name):
    """
    主要是把函数的入参放到event上，便于listener获取函数对象和函数入参。
    """

    """
    Called by executors to run the job. Returns a list of scheduler events to be dispatched by the
    scheduler.

    """
    events = []
    logger = logging.getLogger(logger_name)
    for run_time in run_times:
        # See if the job missed its run time window, and handle
        # possible misfires accordingly
        # print(job.misfire_grace_time) # add_job不设置时候默认为1秒。
        if job.misfire_grace_time is not None:
            # print(job,dir(job),job.args,job.kwargs)
            difference = datetime.now(utc) - run_time
            grace_time = timedelta(seconds=job.misfire_grace_time)
            if difference > grace_time:
                ev = JobExecutionEvent(EVENT_JOB_MISSED, job.id, jobstore_alias,
                                       run_time)
                ev.function_args = job.args
                ev.function_kwargs = job.kwargs
                ev.function = job.func

                events.append(ev)
                logger.warning('Run time of job "%s" was missed by %s', job, difference)
                continue

        logger.info('Running job "%s" (scheduled at %s)', job, run_time)
        try:
            retval = job.func(*job.args, **job.kwargs)
        except BaseException:
            exc, tb = sys.exc_info()[1:]
            formatted_tb = ''.join(format_tb(tb))

            ev = JobExecutionEvent(EVENT_JOB_ERROR, job.id, jobstore_alias, run_time,
                                   exception=exc, traceback=formatted_tb)
            ev.function_args = job.args
            ev.function_kwargs = job.kwargs
            ev.function = job.func

            events.append(ev)
            logger.exception('Job "%s" raised an exception', job)

            # This is to prevent cyclic references that would lead to memory leaks
            if six.PY2:
                sys.exc_clear()
                del tb
            else:
                import traceback
                traceback.clear_frames(tb)
                del tb
        else:
            ev = JobExecutionEvent(EVENT_JOB_EXECUTED, job.id, jobstore_alias, run_time,
                                   retval=retval)
            ev.function_args = job.args
            ev.function_kwargs = job.kwargs
            ev.function = job.func

            events.append(ev)
            logger.info('Job "%s" executed successfully', job)

    return events





def patch_run_job():
    # from apscheduler.executors import base
    # base.run_job = my_run_job
    apscheduler.executors.base.run_job = my_run_job
    apscheduler.executors.pool.run_job = my_run_job

`````

--- **end of file: funboost/utils/apscheduler_monkey.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/block_exit.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/block_exit.py`

#### 📦 Imports

- `import time`

#### 🔧 Public Functions (1)

- `def block_python_main_thread_exit()`
  - *Line: 6*


---

`````python



import time

def block_python_main_thread_exit():
    while 1:
        time.sleep(100)
`````

--- **end of file: funboost/utils/block_exit.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/bulk_operation.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/bulk_operation.py`

#### 📝 Module Docstring

`````
@author:Administrator
@file: bulk_operation.py
@time: 2018/08/27

三大数据库的更简单的批次操作，自动聚合一定时间内的离散任务为批次任务。免除手工数组切片的烦恼。
`````

#### 📦 Imports

- `import atexit`
- `import re`
- `import os`
- `from threading import Thread`
- `from typing import Union`
- `import abc`
- `import time`
- `from queue import Queue`
- `from queue import Empty`
- `import unittest`
- `from pymongo import UpdateOne`
- `from pymongo import InsertOne`
- `from pymongo import UpdateMany`
- `from pymongo import collection`
- `from pymongo import MongoClient`
- `import redis`
- `from funboost.core.lazy_impoter import ElasticsearchImporter`
- `from funboost.utils.redis_manager import RedisMixin`
- `from funboost.utils.time_util import DatetimeConverter`
- `from funboost.utils import LoggerMixin`
- `from funboost.utils import decorators`

#### 🏛️ Classes (6)

##### 📌 `class RedisOperation`
*Line: 29*

**Docstring:**
`````
redis的操作，此类作用主要是规范下格式而已
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, operation_name: str, key: str, value: str)`
  - **Docstring:**
  `````
  :param operation_name: redis操作名字，例如 sadd lpush等
  :param key: redis的键
  :param value: reids键的值
  `````
  - **Parameters:**
    - `self`
    - `operation_name: str`
    - `key: str`
    - `value: str`

##### 📌 `class BaseBulkHelper(LoggerMixin)`
*Line: 43*

**Docstring:**
`````
批量操纵抽象基类
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, base_object: Union[collection.Collection, redis.Redis], threshold: int = 100, max_time_interval = 10, is_print_log: bool = True)`
  - **Parameters:**
    - `self`
    - `base_object: Union[collection.Collection, redis.Redis]`
    - `threshold: int = 100`
    - `max_time_interval = 10`
    - `is_print_log: bool = True`

**Public Methods (1):**
- `def add_task(self, base_operation: Union[UpdateOne, InsertOne, RedisOperation, tuple, dict])`
  - *添加单个需要执行的操作，程序自动聚合陈批次操作*

**Class Variables (1):**
- `bulk_helper_map = {}`

##### 📌 `class MongoBulkWriteHelper(BaseBulkHelper)`
*Line: 109*

**Docstring:**
`````
一个更简单的批量插入,可以直接提交一个操作，自动聚合多个操作为一个批次再插入，速度快了n倍。
`````

##### 📌 `class ElasticBulkHelper(BaseBulkHelper)`
*Line: 137*

**Docstring:**
`````
elastic批量插入。
`````

##### 📌 `class RedisBulkWriteHelper(BaseBulkHelper)`
*Line: 163*

**Docstring:**
`````
redis批量插入，比自带的更方便操作非整除批次
`````

##### 📌 `class _Test(unittest.TestCase, LoggerMixin)`
*Line: 206*

**Public Methods (2):**
- `def test_mongo_bulk_write(self)`
- `def test_redis_bulk_write(self)` `unittest.skip`


---

`````python
# coding=utf8
"""
@author:Administrator
@file: bulk_operation.py
@time: 2018/08/27

三大数据库的更简单的批次操作，自动聚合一定时间内的离散任务为批次任务。免除手工数组切片的烦恼。
"""
import atexit
import re
import os
# from elasticsearch import helpers
from threading import Thread
from typing import Union
import abc
import time
from queue import Queue, Empty
import unittest
# noinspection PyUnresolvedReferences
from pymongo import UpdateOne, InsertOne, UpdateMany, collection, MongoClient
import redis

from funboost.core.lazy_impoter import ElasticsearchImporter
from funboost.utils.redis_manager import RedisMixin
from funboost.utils.time_util import DatetimeConverter
from funboost.utils import LoggerMixin, decorators


class RedisOperation:
    """redis的操作，此类作用主要是规范下格式而已"""

    def __init__(self, operation_name: str, key: str, value: str):
        """
        :param operation_name: redis操作名字，例如 sadd lpush等
        :param key: redis的键
        :param value: reids键的值
        """
        self.operation_name = operation_name
        self.key = key
        self.value = value


class BaseBulkHelper(LoggerMixin, metaclass=abc.ABCMeta):
    """批量操纵抽象基类"""
    bulk_helper_map = {}

    def __new__(cls, base_object, *args, **kwargs):
        cls_key = f'{str(base_object)}-{os.getpid()}'
        if cls_key not in cls.bulk_helper_map:  # 加str是由于有一些类型的实例不能被hash作为字典的键
            self = super().__new__(cls)
            return self
        else:
            return cls.bulk_helper_map[cls_key]

    def __init__(self, base_object: Union[collection.Collection, redis.Redis], threshold: int = 100, max_time_interval=10, is_print_log: bool = True):
        cls_key = f'{str(base_object)}-{os.getpid()}'
        if cls_key not in self.bulk_helper_map:
            self._custom_init(base_object, threshold, max_time_interval, is_print_log)
            self.bulk_helper_map[cls_key] = self

    def _custom_init(self, base_object, threshold, max_time_interval, is_print_log):
        self.base_object = base_object
        self._threshold = threshold
        self._max_time_interval = max_time_interval
        self._is_print_log = is_print_log
        self._to_be_request_queue = Queue(threshold * 2)
        self._current_time = time.time()
        self._last_has_task_time = time.time()
        atexit.register(self.__do_something_before_exit)  # 程序自动结束前执行注册的函数
        self._main_thread_has_exit = False
        # Thread(target=self.__excute_bulk_operation_in_other_thread).start()
        # Thread(target=self.__check_queue_size).start()
        self.__excute_bulk_operation_in_other_thread()
        self.__check_queue_size()
        self.logger.debug(f'{self.__class__}被实例化')

    def add_task(self, base_operation: Union[UpdateOne, InsertOne, RedisOperation, tuple, dict]):
        """添加单个需要执行的操作，程序自动聚合陈批次操作"""
        self._to_be_request_queue.put(base_operation)
        # self.logger.debug(base_operation)

    # @decorators.tomorrow_threads(100)
    @decorators.keep_circulating(1, block=False, daemon=True)  # redis异常或网络异常，使其自动恢复。
    def __excute_bulk_operation_in_other_thread(self):
        while True:
            if self._to_be_request_queue.qsize() >= self._threshold or time.time() > self._current_time + self._max_time_interval:
                self._do_bulk_operation()
            if self._main_thread_has_exit and self._to_be_request_queue.qsize() == 0:
                pass
                # break
            time.sleep(10 ** -1)

    @decorators.keep_circulating(60, block=False, daemon=True)
    def __check_queue_size(self):
        if self._to_be_request_queue.qsize() > 0:
            self._last_has_task_time = time.time()
        if time.time() - self._last_has_task_time > 60:
            self.logger.info(f'{self.base_object} 最近一次有任务的时间是 ： {DatetimeConverter(self._last_has_task_time)}')

    @abc.abstractmethod
    def _do_bulk_operation(self):
        raise NotImplementedError

    def __do_something_before_exit(self):
        self._main_thread_has_exit = True
        self.logger.critical(f'程序自动结束前执行  [{str(self.base_object)}]  执行剩余的任务')


class MongoBulkWriteHelper(BaseBulkHelper):
    """
    一个更简单的批量插入,可以直接提交一个操作，自动聚合多个操作为一个批次再插入，速度快了n倍。
    """

    def _do_bulk_operation(self):
        if self._to_be_request_queue.qsize() > 0:
            t_start = time.time()
            count = 0
            request_list = []
            for _ in range(0, self._threshold):
                try:
                    request = self._to_be_request_queue.get_nowait()
                    # print(request)
                    count += 1
                    request_list.append(request)
                except Empty:
                    pass
                    break
            if request_list:
                # print(request_list)
                self.base_object.bulk_write(request_list, ordered=False)
            if self._is_print_log:
                mongo_col_str = re.sub(r"document_class=dict, tz_aware=False, connect=True\),", "", str(self.base_object))
                self.logger.info(f'【{mongo_col_str}】  批量插入的任务数量是 {count} 消耗的时间是 {round(time.time() - t_start, 6)}')
            self._current_time = time.time()


class ElasticBulkHelper(BaseBulkHelper):
    """
    elastic批量插入。
    """

    def _do_bulk_operation(self):
        if self._to_be_request_queue.qsize() > 0:
            t_start = time.time()
            count = 0
            request_list = []
            for _ in range(self._threshold):
                try:
                    request = self._to_be_request_queue.get_nowait()
                    count += 1
                    request_list.append(request)
                except Empty:
                    pass
                    break
            if request_list:
                # self.base_object.bulk_write(request_list, ordered=False)
                ElasticsearchImporter().helpers.bulk(self.base_object, request_list)
            if self._is_print_log:
                self.logger.info(f'【{self.base_object}】  批量插入的任务数量是 {count} 消耗的时间是 {round(time.time() - t_start, 6)}')
            self._current_time = time.time()


class RedisBulkWriteHelper(BaseBulkHelper):
    """redis批量插入，比自带的更方便操作非整除批次"""

    def _do_bulk_operation(self):
        if self._to_be_request_queue.qsize() > 0:
            t_start = time.time()
            count = 0
            pipeline = self.base_object.pipeline()  # type: redis.client.Pipeline
            for _ in range(self._threshold):
                try:
                    request = self._to_be_request_queue.get_nowait()
                    count += 1
                except Empty:
                    break
                    pass
                else:
                    getattr(pipeline, request.operation_name)(request.key, request.value)
            pipeline.execute()
            pipeline.reset()
            if self._is_print_log:
                self.logger.info(f'[{str(self.base_object)}]  批量插入的任务数量是 {count} 消耗的时间是 {round(time.time() - t_start, 6)}')
            self._current_time = time.time()

    def _do_bulk_operation2(self):
        if self._to_be_request_queue.qsize() > 0:
            t_start = time.time()
            count = 0
            with self.base_object.pipeline() as pipeline:  # type: redis.client.Pipeline
                for _ in range(self._threshold):
                    try:
                        request = self._to_be_request_queue.get_nowait()
                        count += 1
                    except Empty:
                        pass
                    else:
                        getattr(pipeline, request.operation_name)(request.key, request.value)
                pipeline.execute()
            if self._is_print_log:
                self.logger.info(f'[{str(self.base_object)}]  批量插入的任务数量是 {count} 消耗的时间是 {round(time.time() - t_start, 6)}')
            self._current_time = time.time()


# noinspection SpellCheckingInspection,PyMethodMayBeStatic
class _Test(unittest.TestCase, LoggerMixin):
    # @unittest.skip
    def test_mongo_bulk_write(self):
        # col = MongoMixin().mongo_16_client.get_database('test').get_collection('ydf_test2')
        col = MongoClient('mongodb://myUserAdmin:XXXXXXX@192.168.199.202:27016/admin').get_database('test').get_collection('ydf_test3')
        with decorators.TimerContextManager():
            for i in range(5000 + 13):
                # time.sleep(0.01)
                item = {'_id': i, 'field1': i * 2}
                mongo_helper = MongoBulkWriteHelper(col, 100, is_print_log=True)
                # mongo_helper.add_task(UpdateOne({'_id': item['_id']}, {'$set': item}, upsert=True))
                mongo_helper.add_task(InsertOne({'_id': item['_id']}))

    @unittest.skip
    def test_redis_bulk_write(self):

        with decorators.TimerContextManager():
            # r = redis.Redis(password='123456')
            r = RedisMixin().redis_db0
            redis_helper = RedisBulkWriteHelper(r, 200)
            # redis_helper = RedisBulkWriteHelper(r, 100)  # 放在外面可以
            for i in range(1003):
                # time.sleep(0.2)
                # 也可以在这里无限实例化
                redis_helper.add_task(RedisOperation('sadd', 'key1', str(i)))


if __name__ == '__main__':
    unittest.main()

`````

--- **end of file: funboost/utils/bulk_operation.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/class_utils.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/class_utils.py`

#### 📦 Imports

- `import copy`
- `import gc`
- `import inspect`
- `import re`
- `import sys`
- `import typing`
- `import nb_log`
- `from types import MethodType`
- `from types import FunctionType`
- `from funboost.constant import FunctionKind`

#### 🏛️ Classes (1)

##### 📌 `class ClsHelper`
*Line: 14*

**Public Methods (8):**
- `def get_instncae_method_cls(instncae_method)` `staticmethod`
- `def get_classs_method_cls(class_method)` `staticmethod`
- `def is_class_method(method)` `staticmethod`
- `def is_static_method(method)` `staticmethod`
- `def is_instance_method(cls, method)` `classmethod`
- `def is_common_function(cls, method)` `classmethod`
- `def get_method_kind(cls, method: typing.Callable) -> str` `classmethod`
- `def get_obj_init_params_for_funboost(obj_init_params: dict)` `staticmethod`


---

`````python
import copy
import gc
import inspect
import re
import sys
import typing

import nb_log
from types import MethodType, FunctionType

from funboost.constant import FunctionKind


class ClsHelper:
    @staticmethod
    def get_instncae_method_cls(instncae_method):
        # print(instncae_method)
        # print(instncae_method.__qualname__)
        # print(instncae_method.__module__)
        return getattr(sys.modules[instncae_method.__module__],instncae_method.__qualname__.split('.')[0])
        # return instncae_method.__self__.__class__

    @staticmethod
    def get_classs_method_cls(class_method):
        # print(class_method)
        # print(class_method.__qualname__)
        # print(class_method.__module__)
        return getattr(sys.modules[class_method.__module__],class_method.__qualname__.split('.')[0])

    @staticmethod
    def is_class_method(method):
        # if inspect.ismethod(method):
        #     if hasattr(method, '__self__') and inspect.isclass(method.__self__):
        #         return True
        # return False

        sourcelines = inspect.getsourcelines(method)
        # print(sourcelines)
        line0: str = sourcelines[0][0]
        if line0.replace(' ', '').startswith('@classmethod'):
            return True

    @staticmethod
    def is_static_method(method):
        sourcelines = inspect.getsourcelines(method)
        line0: str = sourcelines[0][0]
        if line0.replace(' ', '').startswith('@staticmethod'):
            return True

    @classmethod
    def is_instance_method(cls, method):
        if cls.is_class_method(method):
            return False
        if cls.is_static_method(method):
            return False
        if isinstance(method, FunctionType):
            sourcelines = inspect.getsourcelines(method)
            for line in sourcelines[0][:50]:
                if not line.replace( ' ','').startswith('#'):
                    if not line.startswith('def') and re.search('\(\s*?self\s*?,',line):
                        return True
        # method_class = getattr(method, '__qualname__', '').rsplit('.', 1)[0]
        # if method_class:  # 如果能找到类名，说明是类的成员
        #     print( f"{method.__name__} 属于类 {method_class} 的成员")
        #
        #     return True

    @classmethod
    def is_common_function(cls, method):
        if cls.is_static_method(method):
            return False
        if cls.is_class_method(method):
            return False
        if cls.is_instance_method(method):
            return False
        if isinstance(method, FunctionType):
            sourcelines = inspect.getsourcelines(method)
            for line in sourcelines[0][:50]:
                if not line.replace(' ', '').startswith('#'):
                    if not re.search('\(\s*?self\s*?,', line):
                        return True

    @classmethod
    def get_method_kind(cls, method: typing.Callable) -> str:
        if cls.is_class_method(method):
            return FunctionKind.CLASS_METHOD
        elif cls.is_static_method(method):
            return FunctionKind.STATIC_METHOD
        elif cls.is_instance_method(method):
            return FunctionKind.INSTANCE_METHOD
        elif cls.is_common_function(method):
            return FunctionKind.COMMON_FUNCTION

    @staticmethod
    def get_obj_init_params_for_funboost(obj_init_params: dict):
        obj_init_params.pop('self')
        return copy.deepcopy(obj_init_params)


if __name__ == '__main__':
    pass
`````

--- **end of file: funboost/utils/class_utils.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/ctrl_c_end.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/ctrl_c_end.py`

#### 📦 Imports

- `import os`
- `import sys`
- `import time`
- `import signal`

#### 🔧 Public Functions (2)

- `def signal_handler(signum, frame)`
  - *Line: 7*

- `def ctrl_c_recv()`
  - *Line: 13*
  - **Docstring:**
  `````
  主要目的就是阻止主线程退出而已。 因为funboost为了方便用户连续启动多个consume都是子线程运行循环调度的。
  apscheduler background 类型必须有主线程在运行，否则会很快结束。所以需要阻止主线程退出。
  在代码最最末尾加上 ctrl_c_recv() 就可以阻止主线程退出。
  
  你也可以不用ctrl_c_recv(),  直接在你的启动脚本文件的最末尾加上：
  while 1:
      time.sleep(100) 
  来达到阻止主线程退出的目的。
  `````


---

`````python
import os
import sys
import time
import signal


def signal_handler(signum, frame):
    print(f'收到信号 {signum}，程序准备退出', flush=True)
    sys.exit(4)
    os._exit(44)


def ctrl_c_recv():
    """ 
    主要目的就是阻止主线程退出而已。 因为funboost为了方便用户连续启动多个consume都是子线程运行循环调度的。
    apscheduler background 类型必须有主线程在运行，否则会很快结束。所以需要阻止主线程退出。
    在代码最最末尾加上 ctrl_c_recv() 就可以阻止主线程退出。
    
    你也可以不用ctrl_c_recv(),  直接在你的启动脚本文件的最末尾加上：
    while 1:
        time.sleep(100) 
    来达到阻止主线程退出的目的。
    """
    # signal.signal(signal.SIGTERM, signal_handler)
    
    for i in range(3):
        while 1:
            try:
                time.sleep(2)
            except (KeyboardInterrupt,) as e:
                # time.sleep(2)
                print(f'{type(e)} 你按了ctrl c ,程序退出, 第 {i + 1} 次', flush=True)
                # time.sleep(2)
                break
    # sys.exit(4)
    os._exit(44)
    # exit(444)

`````

--- **end of file: funboost/utils/ctrl_c_end.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/decorators.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/decorators.py`

#### 📦 Imports

- `import base64`
- `import copy`
- `import abc`
- `import logging`
- `import random`
- `import uuid`
- `from typing import TypeVar`
- `from contextlib import contextmanager`
- `import functools`
- `import json`
- `import os`
- `import sys`
- `import threading`
- `import time`
- `import traceback`
- `import unittest`
- `from functools import wraps`
- `import pysnooper`
- `from tomorrow3 import threads as tomorrow_threads`
- `from funboost.utils import LogManager`
- `from funboost.utils import nb_print`
- `from funboost.utils import LoggerMixin`
- `from nb_log import LoggerLevelSetterMixin`
- `import json`

#### 🏛️ Classes (15)

##### 📌 `class CustomException(Exception)`
*Line: 35*

**🔧 Constructor (`__init__`):**
- `def __init__(self, err = '')`
  - **Parameters:**
    - `self`
    - `err = ''`

##### 📌 `class SingletonMeta(type)`
*Line: 182*

**Class Variables (1):**
- `_instances = {}`

##### 📌 `class SingletonBaseCall`
*Line: 191*

**Docstring:**
`````
单例基类。任何继承自这个基类的子类都会自动成为单例。

示例：
class MyClass(SingletonBase):
    pass

instance1 = MyClass()
instance2 = MyClass()

assert instance1 is instance2  # 实例1和实例2实际上是同一个对象
`````

##### 📌 `class SingletonBaseNew`
*Line: 210*

**Class Variables (1):**
- `_instance = None`

##### 📌 `class SingletonBaseCustomInit`
*Line: 223*

**Class Variables (1):**
- `_instance = None`

##### 📌 `class TimerContextManager(LoggerMixin)`
*Line: 295*

**Docstring:**
`````
用上下文管理器计时，可对代码片段计时
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, is_print_log = True)`
  - **Parameters:**
    - `self`
    - `is_print_log = True`

##### 📌 `class RedisDistributedLockContextManager(LoggerMixin, LoggerLevelSetterMixin)`
*Line: 319*

**Docstring:**
`````
分布式redis锁上下文管理.
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, redis_client, redis_lock_key, expire_seconds = 30)`
  - **Parameters:**
    - `self`
    - `redis_client`
    - `redis_lock_key`
    - `expire_seconds = 30`

**Class Variables (1):**
- `unlock_script = '\n       if redis.call("get",KEYS[1]) == ARGV[1] then\n           return redis.call("del",KEYS[1])\n       else\n           return 0\n       end'`

##### 📌 `class RedisDistributedBlockLockContextManager(RedisDistributedLockContextManager)`
*Line: 369*

**🔧 Constructor (`__init__`):**
- `def __init__(self, redis_client, redis_lock_key, expire_seconds = 30, check_interval = 0.1)`
  - **Parameters:**
    - `self`
    - `redis_client`
    - `redis_lock_key`
    - `expire_seconds = 30`
    - `check_interval = 0.1`

##### 📌 `class ExceptionContextManager`
*Line: 407*

**Docstring:**
`````
用上下文管理器捕获异常，可对代码片段进行错误捕捉，比装饰器更细腻
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, logger_name = 'ExceptionContextManager', verbose = 100, donot_raise__exception = True)`
  - **Docstring:**
  `````
  :param verbose: 打印错误的深度,对应traceback对象的limit，为正整数
  :param donot_raise__exception:是否不重新抛出错误，为Fasle则抛出，为True则不抛出
  `````
  - **Parameters:**
    - `self`
    - `logger_name = 'ExceptionContextManager'`
    - `verbose = 100`
    - `donot_raise__exception = True`

##### 📌 `class cached_class_property(object)`
*Line: 479*

**Docstring:**
`````
类属性缓存装饰器
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, func)`
  - **Parameters:**
    - `self`
    - `func`

##### 📌 `class cached_property(object)`
*Line: 494*

**Docstring:**
`````
实例属性缓存装饰器
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, func)`
  - **Parameters:**
    - `self`
    - `func`

##### 📌 `class FunctionResultCacher`
*Line: 543*

**Public Methods (1):**
- `def cached_function_result_for_a_time(cls, cache_time: float)` `classmethod`
  - **Docstring:**
  `````
  函数的结果缓存一段时间装饰器,不要装饰在返回结果是超大字符串或者其他占用大内存的数据结构上的函数上面。
  :param cache_time :缓存的时间
  :type cache_time : float
  `````

**Class Variables (2):**
- `logger = LogManager('FunctionResultChche').get_logger_and_add_handlers(log_level_int=20)`
- `func_result_dict = {}`

##### 📌 `class __KThread(threading.Thread)`
*Line: 594*

**🔧 Constructor (`__init__`):**
- `def __init__(self, *args, **kwargs)`
  - **Parameters:**
    - `self`
    - `*args`
    - `**kwargs`

**Public Methods (4):**
- `def start(self)`
  - *Start the thread.*
- `def globaltrace(self, frame, why, arg)`
- `def localtrace(self, frame, why, arg)`
- `def kill(self)`

##### 📌 `class TIMEOUT_EXCEPTION(Exception)`
*Line: 629*

**Docstring:**
`````
function run timeout
`````

##### 📌 `class _Test(unittest.TestCase)`
*Line: 675*

**Public Methods (12):**
- `def test_superposition(self)` `unittest.skip`
  - *测试多次运行和异常重试,测试装饰器叠加*
- `def test_run_many_times(self)` `unittest.skip`
  - *测试运行5次*
- `def test_tomorrow_threads(self)` `unittest.skip`
  - *测试多线程装饰器,每2秒打印5次*
- `def test_singleton(self)` `unittest.skip`
  - *测试单例模式的装饰器*
- `def test_flyweight(self)` `unittest.skip`
- `def test_keep_circulating(self)` `unittest.skip`
  - *测试间隔时间，循环运行*
- `def test_timer(self)` `unittest.skip`
  - *测试计时器装饰器*
- `def test_timer_context(self)` `unittest.skip`
  - *测试上下文，对代码片段进行计时*
- `def test_where_is_it_called(self)` `unittest.skip`
  - *测试函数被调用的装饰器，被调用2次将会记录2次被调用的日志*
- `def test_cached_function_result(self)`
- `def test_exception_context_manager(self)` `unittest.skip`
- `def test_timeout(self)` `unittest.skip`
  - **Docstring:**
  `````
  测试超时装饰器
  :return:
  `````

#### 🔧 Public Functions (16)

- `def run_many_times(times = 1)`
  - *Line: 41*
  - **Docstring:**
  `````
  把函数运行times次的装饰器
  :param times:运行次数
  没有捕获错误，出错误就中断运行，可以配合handle_exception装饰器不管是否错误都运行n次。
  `````

- `def handle_exception(retry_times = 0, error_detail_level = 0, is_throw_error = False, time_sleep = 0)`
  - *Line: 60*
  - **Docstring:**
  `````
  捕获函数错误的装饰器,重试并打印日志
  :param retry_times : 重试次数
  :param error_detail_level :为0打印exception提示，为1打印3层深度的错误堆栈，为2打印所有深度层次的错误堆栈
  :param is_throw_error : 在达到最大次数时候是否重新抛出错误
  :type error_detail_level: int
  `````

- `def keep_circulating(time_sleep = 0.001, exit_if_function_run_sucsess = False, is_display_detail_exception = True, block = True, daemon = False)`
  - *Line: 102*
  - **Docstring:**
  `````
  间隔一段时间，一直循环运行某个方法的装饰器
  :param time_sleep :循环的间隔时间
  :param exit_if_function_run_sucsess :如果成功了就退出循环
  :param is_display_detail_exception
  :param block :是否阻塞主主线程，False时候开启一个新的线程运行while 1。
  `````

- `def synchronized(func)`
  - *Line: 139*
  - *线程锁装饰器，可以加在单例模式上*

- `def singleton(cls: ClSX) -> ClSX`
  - *Line: 151*
  - *单例模式装饰器,新加入线程锁，更牢固的单例模式，主要解决多线程如100线程同时实例化情况下可能会出现三例四例的情况,实测。*

- `def singleton_no_lock(cls: ClSX) -> ClSX`
  - *Line: 167*
  - *单例模式装饰器,新加入线程锁，更牢固的单例模式，主要解决多线程如100线程同时实例化情况下可能会出现三例四例的情况,实测。*

- `def flyweight(cls)`
  - *Line: 237*

- `def timer(func)`
  - *Line: 277*
  - *计时器装饰器，只能用来计算函数运行时间*

- `def where_is_it_called(func)`
  - *Line: 435*
  - *一个装饰器，被装饰的函数，如果被调用，将记录一条日志,记录函数被什么文件的哪一行代码所调用*

- `def cached_method_result(fun)`
  - *Line: 508*
  - *方法的结果装饰器,不接受self以外的多余参数，主要用于那些属性类的property方法属性上，配合property装饰器，主要是在pycahrm自动补全上比上面的装饰器好*

- `def cached_method_result_for_instance(fun)`
  - *Line: 526*
  - *方法的结果装饰器,不接受self以外的多余参数，主要用于那些属性类的property方法属性上*

- `def timeout(seconds)`
  - *Line: 634*
  - **Docstring:**
  `````
  超时装饰器，指定超时时间
  
  若被装饰的方法在指定的时间内未返回，则抛出Timeout异常
  `````

- `def lock_func(*args, **kwargs)` `wraps(func)`
  - *Line: 144*

- `def inner(self)` `wraps(fun)`
  - *Line: 512*

- `def inner(self)` `wraps(fun)`
  - *Line: 530*

- `def timeout_decorator(func)`
  - *Line: 639*


---

`````python
# coding=utf-8
import base64
import copy
import abc
import logging
import random
import uuid
from typing import TypeVar
# noinspection PyUnresolvedReferences
from contextlib import contextmanager
import functools
import json
import os
import sys
import threading
import time
import traceback
import unittest
from functools import wraps
# noinspection PyUnresolvedReferences
import pysnooper
from tomorrow3 import threads as tomorrow_threads

from funboost.utils import LogManager, nb_print, LoggerMixin
# noinspection PyUnresolvedReferences
# from funboost.utils.custom_pysnooper import _snoop_can_click, snoop_deco, patch_snooper_max_variable_length
from nb_log import LoggerLevelSetterMixin

os_name = os.name
# nb_print(f' 操作系统类型是  {os_name}')
handle_exception_log = LogManager('function_error').get_logger_and_add_handlers()
run_times_log = LogManager('run_many_times').get_logger_and_add_handlers(20)


class CustomException(Exception):
    def __init__(self, err=''):
        err0 = 'fatal exception\n'
        Exception.__init__(self, err0 + err)


def run_many_times(times=1):
    """把函数运行times次的装饰器
    :param times:运行次数
    没有捕获错误，出错误就中断运行，可以配合handle_exception装饰器不管是否错误都运行n次。
    """

    def _run_many_times(func):
        @wraps(func)
        def __run_many_times(*args, **kwargs):
            for i in range(times):
                run_times_log.debug('* ' * 50 + '当前是第 {} 次运行[ {} ]函数'.format(i + 1, func.__name__))
                func(*args, **kwargs)

        return __run_many_times

    return _run_many_times


# noinspection PyIncorrectDocstring
def handle_exception(retry_times=0, error_detail_level=0, is_throw_error=False, time_sleep=0):
    """捕获函数错误的装饰器,重试并打印日志
    :param retry_times : 重试次数
    :param error_detail_level :为0打印exception提示，为1打印3层深度的错误堆栈，为2打印所有深度层次的错误堆栈
    :param is_throw_error : 在达到最大次数时候是否重新抛出错误
    :type error_detail_level: int
    """

    if error_detail_level not in [0, 1, 2]:
        raise Exception('error_detail_level参数必须设置为0 、1 、2')

    def _handle_exception(func):
        @wraps(func)
        def __handle_exception(*args, **keyargs):
            for i in range(0, retry_times + 1):
                try:
                    result = func(*args, **keyargs)
                    if i:
                        handle_exception_log.debug(
                            u'%s\n调用成功，调用方法--> [  %s  ] 第  %s  次重试成功' % ('# ' * 40, func.__name__, i))
                    return result

                except BaseException as e:
                    error_info = ''
                    if error_detail_level == 0:
                        error_info = '错误类型是：' + str(e.__class__) + '  ' + str(e)
                    elif error_detail_level == 1:
                        error_info = '错误类型是：' + str(e.__class__) + '  ' + traceback.format_exc(limit=3)
                    elif error_detail_level == 2:
                        error_info = '错误类型是：' + str(e.__class__) + '  ' + traceback.format_exc()

                    handle_exception_log.exception(
                        u'%s\n记录错误日志，调用方法--> [  %s  ] 第  %s  次错误重试， %s\n' % ('- ' * 40, func.__name__, i, error_info))
                    if i == retry_times and is_throw_error:  # 达到最大错误次数后，重新抛出错误
                        raise e
                time.sleep(time_sleep)

        return __handle_exception

    return _handle_exception


def keep_circulating(time_sleep=0.001, exit_if_function_run_sucsess=False, is_display_detail_exception=True, block=True, daemon=False):
    """间隔一段时间，一直循环运行某个方法的装饰器
    :param time_sleep :循环的间隔时间
    :param exit_if_function_run_sucsess :如果成功了就退出循环
    :param is_display_detail_exception
    :param block :是否阻塞主主线程，False时候开启一个新的线程运行while 1。
    """
    if not hasattr(keep_circulating, 'keep_circulating_log'):
        keep_circulating.log = LogManager('keep_circulating').get_logger_and_add_handlers()

    def _keep_circulating(func):
        @wraps(func)
        def __keep_circulating(*args, **kwargs):

            # noinspection PyBroadException
            def ___keep_circulating():
                while 1:
                    try:
                        result = func(*args, **kwargs)
                        if exit_if_function_run_sucsess:
                            return result
                    except BaseException as e:
                        msg = func.__name__ + '   运行出错\n ' + traceback.format_exc(limit=10) if is_display_detail_exception else str(e)
                        keep_circulating.log.error(msg)
                    finally:
                        time.sleep(time_sleep)

            if block:
                return ___keep_circulating()
            else:
                threading.Thread(target=___keep_circulating, daemon=daemon).start()

        return __keep_circulating

    return _keep_circulating


def synchronized(func):
    """线程锁装饰器，可以加在单例模式上"""
    func.__lock__ = threading.Lock()

    @wraps(func)
    def lock_func(*args, **kwargs):
        with func.__lock__:
            return func(*args, **kwargs)

    return lock_func

ClSX = TypeVar('CLSX')
def singleton(cls:ClSX)  -> ClSX:
    """
    单例模式装饰器,新加入线程锁，更牢固的单例模式，主要解决多线程如100线程同时实例化情况下可能会出现三例四例的情况,实测。
    """
    _instance = {}
    singleton.__lock = threading.Lock()

    @wraps(cls)
    def _singleton(*args, **kwargs):
        with singleton.__lock:
            if cls not in _instance:
                _instance[cls] = cls(*args, **kwargs)
            return _instance[cls]

    return _singleton

def singleton_no_lock(cls:ClSX)  -> ClSX:
    """
    单例模式装饰器,新加入线程锁，更牢固的单例模式，主要解决多线程如100线程同时实例化情况下可能会出现三例四例的情况,实测。
    """
    _instance = {}


    @wraps(cls)
    def _singleton(*args, **kwargs):
        if cls not in _instance:
            _instance[cls] = cls(*args, **kwargs)
        return _instance[cls]

    return _singleton

class SingletonMeta(type):
    _instances = {}

    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]


class SingletonBaseCall(metaclass=SingletonMeta):
    """
    单例基类。任何继承自这个基类的子类都会自动成为单例。

    示例：
    class MyClass(SingletonBase):
        pass

    instance1 = MyClass()
    instance2 = MyClass()

    assert instance1 is instance2  # 实例1和实例2实际上是同一个对象
    """

    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        # 可以在此处添加对子类的额外处理，比如检查其是否符合单例要求等


class SingletonBaseNew:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        # 可以在此处添加对子类的额外处理，比如检查其是否符合单例要求等


class SingletonBaseCustomInit(metaclass=abc.ABCMeta):
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super().__new__(cls)
            cls._instance._custom_init(*args, **kwargs)
        return cls._instance

    def _custom_init(self, *args, **kwargs):
        raise NotImplemented



def flyweight(cls):
    # 1. 闭包内的存储，每个类独立拥有自己的实例缓存，互不干扰
    _instances = {}
    
    # 2. 为每个类创建一个独立的锁，避免全局锁竞争
    _class_lock = threading.Lock()

    def _make_key(args, kwds):
        """
        生成唯一的 Key。
        为了防止冲突，必须区分 args 和 kwargs。
        frozenset 用于让 kwargs 可哈希且无视顺序。
        添加一个分隔符或者将其放入元组结构中以确保唯一性。
        """
        if not kwds:
            return args
        
        # 将 kwargs 转换为可哈希的 frozenset
        # 结构: (args_tuple, kwargs_frozenset)
        # 这样 (1, 2) 和 (1, a=2) 永远不会相等
        return (args, frozenset(kwds.items()))

    @wraps(cls)
    def _flyweight(*args, **kwargs):
        # 1. 生成 Key
        cache_key = _make_key(args, kwargs)
        
        # 2. 第一次检查 (无锁，高性能)
        if cache_key not in _instances:
            # 3. 加锁 (仅针对当前类加锁)
            with _class_lock:
                # 4. 第二次检查 (Double-Checked Locking)
                if cache_key not in _instances:
                    _instances[cache_key] = cls(*args, **kwargs)
        
        return _instances[cache_key]

    return _flyweight


def timer(func):
    """计时器装饰器，只能用来计算函数运行时间"""
    if not hasattr(timer, 'log'):
        timer.log = LogManager(f'timer_{func.__name__}').get_logger_and_add_handlers(log_filename=f'timer_{func.__name__}.log')

    @wraps(func)
    def _timer(*args, **kwargs):
        t1 = time.time()
        result = func(*args, **kwargs)
        t2 = time.time()
        t_spend = round(t2 - t1, 2)
        timer.log.debug('执行[ {} ]方法用时 {} 秒'.format(func.__name__, t_spend))
        return result

    return _timer


# noinspection PyProtectedMember
class TimerContextManager(LoggerMixin):
    """
    用上下文管理器计时，可对代码片段计时
    """

    def __init__(self, is_print_log=True):
        self._is_print_log = is_print_log
        self.t_spend = None
        self._line = None
        self._file_name = None
        self.time_start = None

    def __enter__(self):
        self._line = sys._getframe().f_back.f_lineno  # 调用此方法的代码的函数
        self._file_name = sys._getframe(1).f_code.co_filename  # 哪个文件调了用此方法
        self.time_start = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.t_spend = time.time() - self.time_start
        if self._is_print_log:
            self.logger.debug(f'对下面代码片段进行计时:  \n执行"{self._file_name}:{self._line}" 用时 {round(self.t_spend, 2)} 秒')


class RedisDistributedLockContextManager(LoggerMixin, LoggerLevelSetterMixin):
    """
    分布式redis锁上下文管理.
    """
    '''
    redis 官方推荐的 redlock-py
    https://github.com/SPSCommerce/redlock-py/blob/master/redlock/__init__.py
    '''
    unlock_script = """
       if redis.call("get",KEYS[1]) == ARGV[1] then
           return redis.call("del",KEYS[1])
       else
           return 0
       end"""

    def __init__(self, redis_client, redis_lock_key, expire_seconds=30, ):
        self.redis_client = redis_client
        self.redis_lock_key = redis_lock_key
        self._expire_seconds = expire_seconds
        self.identifier = str(uuid.uuid4())
        self.has_aquire_lock = False
        self.logger.setLevel(logging.INFO)

    def __enter__(self):
        self._line = sys._getframe().f_back.f_lineno  # 调用此方法的代码的函数
        self._file_name = sys._getframe(1).f_code.co_filename  # 哪个文件调了用此方法
        ret = self.redis_client.set(self.redis_lock_key, value=self.identifier, ex=self._expire_seconds, nx=True)

        self.has_aquire_lock = False if ret is None else True
        if self.has_aquire_lock:
            log_msg = f'\n"{self._file_name}:{self._line}" 这行代码获得了redis锁 {self.redis_lock_key}'
        else:
            log_msg = f'\n"{self._file_name}:{self._line}" 这行代码此次没有获得redis锁 {self.redis_lock_key}'
        # print(self.logger.level,log_msg)
        self.logger.debug(log_msg)
        return self

    def __bool__(self):
        return self.has_aquire_lock

    def __exit__(self, exc_type, exc_val, exc_tb):
        # self.redis_client.delete(self.redis_lock_key)
        unlock = self.redis_client.register_script(self.unlock_script)
        result = unlock(keys=[self.redis_lock_key], args=[self.identifier])
        if result:
            return True
        else:
            return False


class RedisDistributedBlockLockContextManager(RedisDistributedLockContextManager):
    def __init__(self, redis_client, redis_lock_key, expire_seconds=30, check_interval=0.1):
        super().__init__(redis_client,redis_lock_key,expire_seconds)
        self.check_interval = check_interval
        # self.logger.setLevel(logging.DEBUG)

    def __enter__(self):
        while True:
            self._line = sys._getframe().f_back.f_lineno  # 调用此方法的代码的函数
            self._file_name = sys._getframe(1).f_code.co_filename  # 哪个文件调了用此方法
            ret = self.redis_client.set(self.redis_lock_key, value=self.identifier, ex=self._expire_seconds, nx=True)
            has_aquire_lock = False if ret is None else True
            if has_aquire_lock:
                log_msg = f'\n"{self._file_name}:{self._line}" 这行代码获得了redis锁 {self.redis_lock_key}'
            else:
                log_msg = f'\n"{self._file_name}:{self._line}" 这行代码此次没有获得redis锁 {self.redis_lock_key}'
            # print(self.logger.level,log_msg)
            self.logger.debug(log_msg)
            if has_aquire_lock:
                break
            else:
                time.sleep(self.check_interval)


"""
@contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>
"""





class ExceptionContextManager:
    """
    用上下文管理器捕获异常，可对代码片段进行错误捕捉，比装饰器更细腻
    """

    def __init__(self, logger_name='ExceptionContextManager', verbose=100, donot_raise__exception=True, ):
        """
        :param verbose: 打印错误的深度,对应traceback对象的limit，为正整数
        :param donot_raise__exception:是否不重新抛出错误，为Fasle则抛出，为True则不抛出
        """
        self.logger = LogManager(logger_name).get_logger_and_add_handlers()
        self._verbose = verbose
        self._donot_raise__exception = donot_raise__exception

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # print(exc_val)
        # print(traceback.format_exc())
        exc_str = str(exc_type) + '  :  ' + str(exc_val)
        exc_str_color = '\033[0;30;45m%s\033[0m' % exc_str
        if self._donot_raise__exception:
            if exc_tb is not None:
                self.logger.error('\n'.join(traceback.format_tb(exc_tb)[:self._verbose]) + exc_str_color)
        return self._donot_raise__exception  # __exit__方法必须retuen True才会不重新抛出错误


def where_is_it_called(func):
    """一个装饰器，被装饰的函数，如果被调用，将记录一条日志,记录函数被什么文件的哪一行代码所调用"""
    if not hasattr(where_is_it_called, 'log'):
        where_is_it_called.log = LogManager('where_is_it_called').get_logger_and_add_handlers()

    # noinspection PyProtectedMember
    @wraps(func)
    def _where_is_it_called(*args, **kwargs):
        # 获取被调用函数名称
        # func_name = sys._getframe().f_code.co_name
        func_name = func.__name__
        # 什么函数调用了此函数
        which_fun_call_this = sys._getframe(1).f_code.co_name  # NOQA

        # 获取被调用函数在被调用时所处代码行数
        line = sys._getframe().f_back.f_lineno

        # 获取被调用函数所在模块文件名
        file_name = sys._getframe(1).f_code.co_filename

        # noinspection PyPep8
        where_is_it_called.log.debug(
            f'文件[{func.__code__.co_filename}]的第[{func.__code__.co_firstlineno}]行即模块 [{func.__module__}] 中的方法 [{func_name}] 正在被文件 [{file_name}] 中的'
            f'方法 [{which_fun_call_this}] 中的第 [{line}] 行处调用，传入的参数为[{args},{kwargs}]')
        try:
            t0 = time.time()
            result = func(*args, **kwargs)
            result_raw = result
            t_spend = round(time.time() - t0, 2)
            if isinstance(result, dict):
                result = json.dumps(result)
            if len(str(result)) > 200:
                result = str(result)[0:200] + '  。。。。。。  '
            where_is_it_called.log.debug('执行函数[{}]消耗的时间是{}秒，返回的结果是 --> '.format(func_name, t_spend) + str(result))
            return result_raw
        except BaseException as e:
            where_is_it_called.log.debug('执行函数{}，发生错误'.format(func_name))
            where_is_it_called.log.exception(e)
            raise e

    return _where_is_it_called


# noinspection PyPep8Naming
class cached_class_property(object):
    """类属性缓存装饰器"""

    def __init__(self, func):
        self.func = func

    def __get__(self, obj, cls):
        if obj is None:
            return self
        value = self.func(obj)
        setattr(cls, self.func.__name__, value)
        return value


# noinspection PyPep8Naming
class cached_property(object):
    """实例属性缓存装饰器"""

    def __init__(self, func):
        self.func = func

    def __get__(self, obj, cls):
        print(obj, cls)
        if obj is None:
            return self
        value = obj.__dict__[self.func.__name__] = self.func(obj)
        return value


def cached_method_result(fun):
    """方法的结果装饰器,不接受self以外的多余参数，主要用于那些属性类的property方法属性上，配合property装饰器，主要是在pycahrm自动补全上比上面的装饰器好"""

    @wraps(fun)
    def inner(self):
        if not hasattr(fun, 'result'):
            result = fun(self)
            fun.result = result
            fun_name = fun.__name__
            setattr(self.__class__, fun_name, result)
            setattr(self, fun_name, result)
            return result
        else:
            return fun.result

    return inner


def cached_method_result_for_instance(fun):
    """方法的结果装饰器,不接受self以外的多余参数，主要用于那些属性类的property方法属性上"""

    @wraps(fun)
    def inner(self):
        if not hasattr(fun, 'result'):
            result = fun(self)
            fun.result = result
            fun_name = fun.__name__
            setattr(self, fun_name, result)
            return result
        else:
            return fun.result

    return inner


class FunctionResultCacher:
    logger = LogManager('FunctionResultChche').get_logger_and_add_handlers(log_level_int=20)
    func_result_dict = {}
    """
    {
        (f1,(1,2,3,4)):(10,1532066199.739),
        (f2,(5,6,7,8)):(26,1532066211.645),
    }
    """

    @classmethod
    def cached_function_result_for_a_time(cls, cache_time: float):
        """
        函数的结果缓存一段时间装饰器,不要装饰在返回结果是超大字符串或者其他占用大内存的数据结构上的函数上面。
        :param cache_time :缓存的时间
        :type cache_time : float
        """

        def _cached_function_result_for_a_time(fun):

            @wraps(fun)
            def __cached_function_result_for_a_time(*args, **kwargs):
                # print(cls.func_result_dict)
                # if len(cls.func_result_dict) > 1024:
                if sys.getsizeof(cls.func_result_dict) > 100 * 1000 * 1000:
                    cls.func_result_dict.clear()

                key = cls._make_arguments_to_key(args, kwargs)
                if (fun, key) in cls.func_result_dict and time.time() - cls.func_result_dict[(fun, key)][1] < cache_time:
                    return cls.func_result_dict[(fun, key)][0]
                else:
                    cls.logger.debug('函数 [{}] 此次不能使用缓存'.format(fun.__name__))
                    result = fun(*args, **kwargs)
                    cls.func_result_dict[(fun, key)] = (result, time.time())
                    return result

            return __cached_function_result_for_a_time

        return _cached_function_result_for_a_time

    @staticmethod
    def _make_arguments_to_key(args, kwds):
        key = args
        if kwds:
            sorted_items = sorted(kwds.items())
            for item in sorted_items:
                key += item
        return key  # 元祖可以相加。


# noinspection PyUnusedLocal
class __KThread(threading.Thread):
    def __init__(self, *args, **kwargs):
        threading.Thread.__init__(self, *args, **kwargs)
        self.killed = False
        self.__run_backup = None

    # noinspection PyAttributeOutsideInit
    def start(self):
        """Start the thread."""
        self.__run_backup = self.run
        self.run = self.__run  # Force the Thread to install our trace.
        threading.Thread.start(self)

    def __run(self):
        """Hacked run function, which installs the trace."""
        sys.settrace(self.globaltrace)
        self.__run_backup()
        self.run = self.__run_backup

    def globaltrace(self, frame, why, arg):
        if why == 'call':
            return self.localtrace
        return None

    def localtrace(self, frame, why, arg):
        if self.killed:
            if why == 'line':
                raise SystemExit()
        return self.localtrace

    def kill(self):
        self.killed = True


# noinspection PyPep8Naming
class TIMEOUT_EXCEPTION(Exception):
    """function run timeout"""
    pass


def timeout(seconds):
    """超时装饰器，指定超时时间

    若被装饰的方法在指定的时间内未返回，则抛出Timeout异常"""

    def timeout_decorator(func):

        def _(*args, **kwargs):
            def _new_func(oldfunc, result, oldfunc_args, oldfunc_kwargs):
                result.append(oldfunc(*oldfunc_args, **oldfunc_kwargs))

            result = []
            new_kwargs = {
                'oldfunc': func,
                'result': result,
                'oldfunc_args': args,
                'oldfunc_kwargs': kwargs
            }

            thd = __KThread(target=_new_func, args=(), kwargs=new_kwargs)
            thd.start()
            thd.join(seconds)
            alive = thd.is_alive()
            thd.kill()  # kill the child thread

            if alive:
                # raise TIMEOUT_EXCEPTION('function run too long, timeout %d seconds.' % seconds)
                raise TIMEOUT_EXCEPTION(f'{func.__name__}运行时间超过{seconds}秒')
            else:
                if result:
                    return result[0]
                return result

        _.__name__ = func.__name__
        _.__doc__ = func.__doc__
        return _

    return timeout_decorator


# noinspection PyMethodMayBeStatic
class _Test(unittest.TestCase):
    @unittest.skip
    def test_superposition(self):
        """测试多次运行和异常重试,测试装饰器叠加"""

        @run_many_times(3)
        @handle_exception(2, 1)
        def f():
            import json
            json.loads('a', ac='ds')

        f()

    @unittest.skip
    def test_run_many_times(self):
        """测试运行5次"""

        @run_many_times(5)
        def f1():
            print('hello')
            time.sleep(1)

        f1()

    @unittest.skip
    def test_tomorrow_threads(self):
        """测试多线程装饰器,每2秒打印5次"""

        @tomorrow_threads(5)
        def f2():
            print(time.strftime('%H:%M:%S'))
            time.sleep(2)

        [f2() for _ in range(9)]

    @unittest.skip
    def test_singleton(self):
        """测试单例模式的装饰器"""

        @singleton
        class A(object):
            def __init__(self, x):
                self.x = x

        a1 = A(3)
        a2 = A(4)
        self.assertEqual(id(a1), id(a2))
        print(a1.x, a2.x)

    @unittest.skip
    def test_flyweight(self):
        @flyweight
        class A:
            def __init__(self, x, y, z, q=4):
                in_param = copy.deepcopy(locals())
                nb_print(f'执行初始化啦, {in_param}')

        @flyweight
        class B:
            def __init__(self, x, y, z):
                in_param = copy.deepcopy(locals())
                nb_print(f'执行初始化啦, {in_param}')

        A(1, 2, 3)
        A(1, 2, 3)
        A(1, 2, 4)
        B(1, 2, 3)

    @unittest.skip
    def test_keep_circulating(self):
        """测试间隔时间，循环运行"""

        @keep_circulating(3)
        def f6():
            print("每隔3秒，一直打印   " + time.strftime('%H:%M:%S'))

        f6()

    @unittest.skip
    def test_timer(self):
        """测试计时器装饰器"""

        @timer
        def f7():
            time.sleep(2)

        f7()

    @unittest.skip
    def test_timer_context(self):
        """
        测试上下文，对代码片段进行计时
        """
        with TimerContextManager(is_print_log=False) as tc:
            time.sleep(2)
        print(tc.t_spend)

    @unittest.skip
    def test_where_is_it_called(self):
        """测试函数被调用的装饰器，被调用2次将会记录2次被调用的日志"""

        @where_is_it_called
        def f9(a, b):
            result = a + b
            print(result)
            time.sleep(0.1)
            return result

        f9(1, 2)

        f9(3, 4)

    # noinspection PyArgumentEqualDefault
    # @unittest.skip
    def test_cached_function_result(self):
        @FunctionResultCacher.cached_function_result_for_a_time(3)
        def f10(a, b, c=3, d=4):
            print('计算中。。。')
            return a + b + c + d

        print(f10(1, 2, 3, d=6))
        print(f10(1, 2, 3, d=4))
        print(f10(1, 2, 3, 4))
        print(f10(1, 2, 3, 4))
        time.sleep(4)
        print(f10(1, 2, 3, 4))

    @unittest.skip
    def test_exception_context_manager(self):
        def f1():
            # noinspection PyStatementEffect,PyTypeChecker
            1 + '2'

        def f2():
            f1()

        def f3():
            f2()

        def f4():
            f3()

        def run():
            f4()

        # noinspection PyUnusedLocal
        with ExceptionContextManager() as ec:
            run()

        print('finish')

    @unittest.skip
    def test_timeout(self):
        """
        测试超时装饰器
        :return:
        """

        @timeout(3)
        def f(time_to_be_sleep):
            time.sleep(time_to_be_sleep)
            print('hello wprld')

        f(5)


if __name__ == '__main__':
    pass
    unittest.main()

`````

--- **end of file: funboost/utils/decorators.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/develop_log.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/develop_log.py`

#### 📦 Imports

- `import nb_log`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`


---

`````python
import nb_log
from funboost.funboost_config_deafult import FunboostCommonConfig

#开发时候的调试日志，比print方便通过级别一键屏蔽。
# develop_logger = nb_log.get_logger('fsdf_develop', log_level_int=FunboostCommonConfig.FSDF_DEVELOP_LOG_LEVEL)

`````

--- **end of file: funboost/utils/develop_log.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/expire_lock.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/expire_lock.py`

#### 📝 Module Docstring

`````
基于程序内存的过期锁。
`````

#### 📦 Imports

- `import copy`
- `from threading import Thread`
- `from threading import Event`
- `from threading import Lock`
- `import time`
- `import typing`
- `import uuid`
- `from funboost.utils import time_util`
- `from nb_log import get_logger`

#### 🏛️ Classes (3)

##### 📌 `class LockStore`
*Line: 17*

**Public Methods (2):**
- `def set(cls, lock_key, value, ex)` `classmethod`
- `def delete(cls, lock_key, value)` `classmethod`

**Class Variables (6):**
- `lock_for_operate_store = Lock()`
- `lock_key__info_map: typing.Dict[str, typing.Dict] = {}`
- `_has_start_delete_expire_lock_key_thread = False`
- `THREAD_DELETE_DAEMON = False`
- `DELETE_INTERVAL = 0.01`
- `logger = get_logger('LockStore')`

##### 📌 `class ExpireLockConf`
*Line: 71*

**🔧 Constructor (`__init__`):**
- `def __init__(self, expire_seconds = 30, lock_key = None)`
  - **Parameters:**
    - `self`
    - `expire_seconds = 30`
    - `lock_key = None`

##### 📌 `class ExpireLockContextManager`
*Line: 77*

**Docstring:**
`````
分布式redis锁上下文管理.
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, lock_expire_conf: ExpireLockConf)`
  - **Parameters:**
    - `self`
    - `lock_expire_conf: ExpireLockConf`

**Public Methods (2):**
- `def acquire(self)`
- `def realese(self)`

#### 🔧 Public Functions (2)

- `def f(x)`
  - *Line: 122*

- `def test_raw_lock_fun(x)`
  - *Line: 131*


---

`````python
'''
基于程序内存的过期锁。
'''

import copy
from threading import Thread, Event, Lock
import time
import typing
import uuid

from funboost.utils import time_util
from nb_log import get_logger

lock_key__event_is_free_map: typing.Dict[str, Event] = {}


class LockStore:
    lock_for_operate_store = Lock()

    lock_key__info_map: typing.Dict[str, typing.Dict] = {}

    _has_start_delete_expire_lock_key_thread = False

    THREAD_DELETE_DAEMON = False
    DELETE_INTERVAL = 0.01

    logger = get_logger('LockStore')

    @classmethod
    def _auto_delete_expire_lock_key_thread(cls):
        while 1:
            with cls.lock_for_operate_store:
                lock_key__info_map_copy = copy.copy(cls.lock_key__info_map)
                for lock_key, info in lock_key__info_map_copy.items():
                    if time.time() - info['set_time'] > info['ex']:
                        cls.lock_key__info_map.pop(lock_key)
                        cls.logger.warning(f'''自动删除占用耗时长的锁 {lock_key} {time_util.DatetimeConverter(info['set_time'])} {info['ex']}''')
                        lock_key__event_is_free_map[lock_key].set()
            time.sleep(cls.DELETE_INTERVAL)

    @classmethod
    def set(cls, lock_key, value, ex):
        set_succ = False
        with cls.lock_for_operate_store:
            if lock_key not in cls.lock_key__info_map:
                cls.lock_key__info_map[lock_key] = {'value': value, 'ex': ex, 'set_time': time.time()}
                set_succ = True

                event_is_free = Event()
                event_is_free.set()
                lock_key__event_is_free_map[lock_key] = event_is_free

            if cls._has_start_delete_expire_lock_key_thread is False:
                cls._has_start_delete_expire_lock_key_thread = True
                Thread(target=cls._auto_delete_expire_lock_key_thread, daemon=cls.THREAD_DELETE_DAEMON).start()

        return set_succ

    @classmethod
    def delete(cls, lock_key, value):
        with cls.lock_for_operate_store:
            if lock_key in cls.lock_key__info_map:
                if cls.lock_key__info_map[lock_key]['value'] == value:
                    cls.lock_key__info_map.pop(lock_key)
                    lock_key__event_is_free_map[lock_key].set()
                    cls.logger.warning(f'expire delete {lock_key}')
                    return True
            return False


class ExpireLockConf:
    def __init__(self, expire_seconds=30, lock_key=None, ):
        self.expire_seconds = expire_seconds
        self.lock_key = lock_key or uuid.uuid4().hex


class ExpireLockContextManager:
    """
    分布式redis锁上下文管理.
    """

    def __init__(self, lock_expire_conf: ExpireLockConf):
        self.expire_seconds = lock_expire_conf.expire_seconds
        self.lock_key = lock_expire_conf.lock_key
        self.identifier = str(uuid.uuid4())
        self.has_aquire_lock = False

    def acquire(self):
        # self._line = sys._getframe().f_back.f_lineno  # noqa 调用此方法的代码的函数
        # self._file_name = sys._getframe(1).f_code.co_filename  # noqa 哪个文件调了用此方法

        while 1:
            # print(self.lock_key)
            ret = LockStore.set(self.lock_key, value=self.identifier, ex=self.expire_seconds)
            self.has_aquire_lock = ret

            if not self.has_aquire_lock:
                lock_key__event_is_free_map[self.lock_key].wait()
                continue
            else:
                lock_key__event_is_free_map[self.lock_key].clear()
                break

    def realese(self):
        return LockStore.delete(self.lock_key, self.identifier)

    def __enter__(self):
        return self.acquire()

    def __bool__(self):
        return self.has_aquire_lock

    def __exit__(self, exc_type, exc_val, exc_tb):
        result = self.realese()


if __name__ == '__main__':

    lockx1_expire = ExpireLockConf(expire_seconds=4, lock_key='test_lock_name_expire', )


    def f(x):
        with ExpireLockContextManager(lockx1_expire):
            print(x, time.time())
            time.sleep(5)


    test_raw_lock = Lock()


    def test_raw_lock_fun(x):
        try:
            test_raw_lock.acquire(timeout=4)
            print(x, time.time())
            time.sleep(5)
            test_raw_lock.release()
        except Exception as e:
            if 'release unlocked lock' in str(e):
                return
            print(e)


    for i in range(100):
        Thread(target=f, args=[i]).start()
        # Thread(target=test_raw_lock_fun, args=[i]).start()

`````

--- **end of file: funboost/utils/expire_lock.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/json_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/json_helper.py`

#### 📦 Imports

- `import json`
- `import typing`
- `from datetime import datetime as _datetime`
- `from datetime import date as _date`

#### 🏛️ Classes (1)

##### 📌 `class _CustomEncoder(json.JSONEncoder)`
*Line: 17*

**Docstring:**
`````
自定义的json解析器，mongodb返回的字典中的时间格式是datatime，json直接解析出错
`````

**Public Methods (1):**
- `def default(self, obj)`

#### 🔧 Public Functions (2)

- `def dict_to_un_strict_json(dictx: dict, indent = 4)`
  - *Line: 6*

- `def monkey_patch_json()`
  - *Line: 44*


---

`````python
import json
import typing
from datetime import datetime as _datetime
from datetime import date as _date

def dict_to_un_strict_json(dictx: dict, indent=4):
    dict_new = {}
    for k, v in dictx.items():
        # only_print_on_main_process(f'{k} :  {v}')
        if isinstance(v, (bool, tuple, dict, float, int)):
            dict_new[k] = v
        else:
            dict_new[k] = str(v)
    return json.dumps(dict_new, ensure_ascii=False, indent=indent)


class _CustomEncoder(json.JSONEncoder):
    """自定义的json解析器，mongodb返回的字典中的时间格式是datatime，json直接解析出错"""

    def default(self, obj):
        if isinstance(obj, _datetime):
            return obj.strftime('%Y-%m-%d %H:%M:%S')
        elif isinstance(obj, _date):
            return obj.strftime('%Y-%m-%d')
        else:
            return json.JSONEncoder.default(self, obj)


# noinspection PyProtectedMember,PyPep8,PyRedundantParentheses
def _dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=_CustomEncoder, indent=None, separators=None,
           default=None, sort_keys=False, **kw):
    # 全局patch ensure_ascii = False 会引起极少数库不兼容。
    if (not skipkeys and ensure_ascii and check_circular and allow_nan and cls is None and indent is None and separators is None and default is None and not sort_keys and not kw):
        return json._default_encoder.encode(obj)
    if cls is None:
        cls = json.JSONEncoder
    return cls(
        skipkeys=skipkeys, ensure_ascii=ensure_ascii,
        check_circular=check_circular, allow_nan=allow_nan, indent=indent,
        separators=separators, default=default, sort_keys=sort_keys, ).encode(obj)



def monkey_patch_json():
    json.dumps = _dumps


# class JsonUtils:
#     @staticmethod
#     def to_dict(obj:typing.Union[str,dict,list]):
#         if isinstance(obj,str):
#             return json.loads(obj)
#         else:
#             return obj
#
#     @staticmethod
#     def to_json_str(obj:typing.Union[str,dict,list]):
#         if isinstance(obj,str):
#             return obj
#         else:
#             return json.dumps(obj,ensure_ascii=False)

if __name__ == '__main__':
    pass

`````

--- **end of file: funboost/utils/json_helper.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/mongo_util.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/mongo_util.py`

#### 📦 Imports

- `import functools`
- `import os`
- `import pymongo`
- `from pymongo.collection import Collection`
- `from funboost.constant import MongoDbName`
- `from funboost.utils import decorators`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (1)

##### 📌 `class MongoMixin`
*Line: 20*

**Docstring:**
`````
mixin类被继承，也可以直接实例化。

这个是修改后的，当使用f.multi_process_connsume() + linux +  保存结果到mongo + pymongo.0.2 时候不再报错了。

在linux上 即使写 connect=False，如果在主进程操作了collection，那么就破坏了 connect=False，在子进程中继续操作这个collection全局变量就会报错。
设计了多进程+fork 每次都 get_mongo_collection() 是最保险的
`````

**Public Methods (1):**
- `def get_mongo_collection(self, database_name, colleciton_name) -> pymongo.collection.Collection`

**Properties (2):**
- `@property mongo_client -> pymongo.MongoClient`
- `@property mongo_db_task_status`

**Class Variables (3):**
- `processid__client_map = {}`
- `processid__db_map = {}`
- `processid__col_map = {}`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/9/17 0017 15:26
import functools
import os
import pymongo
from pymongo.collection import Collection
from funboost.constant import MongoDbName
from funboost.utils import decorators


@functools.lru_cache()
def _get_mongo_url():
    from funboost.funboost_config_deafult import BrokerConnConfig
    return BrokerConnConfig.MONGO_CONNECT_URL




class MongoMixin:
    """
    mixin类被继承，也可以直接实例化。

    这个是修改后的，当使用f.multi_process_connsume() + linux +  保存结果到mongo + pymongo.0.2 时候不再报错了。

    在linux上 即使写 connect=False，如果在主进程操作了collection，那么就破坏了 connect=False，在子进程中继续操作这个collection全局变量就会报错。
    设计了多进程+fork 每次都 get_mongo_collection() 是最保险的
    """
    processid__client_map = {}
    processid__db_map = {}
    processid__col_map = {}

    @property
    def mongo_client(self) -> pymongo.MongoClient:
        pid = os.getpid()
        key = pid
        if key not in MongoMixin.processid__client_map:
            MongoMixin.processid__client_map[key] = pymongo.MongoClient(_get_mongo_url(),
                                                                        connect=False, maxIdleTimeMS=60 * 1000, minPoolSize=3, maxPoolSize=20)
        return MongoMixin.processid__client_map[key]

    @property
    def mongo_db_task_status(self):
        pid = os.getpid()
        key = (pid, MongoDbName.TASK_STATUS_DB)
        if key not in MongoMixin.processid__db_map:
            MongoMixin.processid__db_map[key] = self.mongo_client.get_database(MongoDbName.TASK_STATUS_DB)
        return MongoMixin.processid__db_map[key]

    def get_mongo_collection(self, database_name, colleciton_name) -> pymongo.collection.Collection:
        pid = os.getpid()
        key = (pid, database_name, colleciton_name)
        if key not in MongoMixin.processid__col_map:
            MongoMixin.processid__col_map[key] = self.mongo_client.get_database(database_name).get_collection(colleciton_name)
        return MongoMixin.processid__col_map[key]


if __name__ == '__main__':
    print(MongoMixin().get_mongo_collection('db2', 'col2'))
    print(MongoMixin().get_mongo_collection('db2', 'col3'))

`````

--- **end of file: funboost/utils/mongo_util.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/monkey_color_log.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/monkey_color_log.py`

#### 📝 Module Docstring

`````
如果老项目没用使用Logmanager,可以打此猴子补丁，自动使项目中的任何日志变彩色和可跳转。
`````

#### 📦 Imports

- `import sys`
- `import os`
- `import logging`
- `from logging import StreamHandler`

#### 🏛️ Classes (1)

##### 📌 `class ColorHandler(logging.Handler)`
*Line: 14*

**Docstring:**
`````
A handler class which writes logging records, appropriately formatted,
to a stream. Note that this class does not close the stream, as
sys.stdout or sys.stderr may be used.
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, stream = None)`
  - **Docstring:**
  `````
  Initialize the handler.
  
  If stream is not specified, sys.stderr is used.
  `````
  - **Parameters:**
    - `self`
    - `stream = None`

**Public Methods (4):**
- `def setFormatter(self, fmt)`
- `def flush(self)`
  - *Flushes the stream.*
- `def emit0(self, record)`
  - **Docstring:**
  `````
  前后彩色不分离的方式
  Emit a record.
  
  If a formatter is specified, it is used to format the record.
  The record is then written to the stream with a trailing newline.  If
  exception information is present, it is formatted using
  traceback.print_exception and appended to the stream.  If the stream
  has an 'encoding' attribute, it is used to determine how to do the
  output to the stream.
  `````
- `def emit(self, record)`
  - **Docstring:**
  `````
  前后彩色分离的方式。
  Emit a record.
  
  If a formatter is specified, it is used to format the record.
  The record is then written to the stream with a trailing newline.  If
  exception information is present, it is formatted using
  traceback.print_exception and appended to the stream.  If the stream
  has an 'encoding' attribute, it is used to determine how to do the
  output to the stream.
  `````

**Class Variables (4):**
- `os_name = os.name`
- `terminator = '\n'`
- `bule = 96 if os_name == 'nt' else 36`
- `yellow = 93 if os_name == 'nt' else 33`

#### 🔧 Public Functions (1)

- `def my_func()`
  - *Line: 163*
  - **Docstring:**
  `````
  模拟常规使用控制台StreamHandler日志的方式。自动变彩。
  :return:
  `````


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/1 0001 17:54
"""
如果老项目没用使用Logmanager,可以打此猴子补丁，自动使项目中的任何日志变彩色和可跳转。

"""

import sys
import os
import logging


class ColorHandler(logging.Handler):
    """
    A handler class which writes logging records, appropriately formatted,
    to a stream. Note that this class does not close the stream, as
    sys.stdout or sys.stderr may be used.
    """
    os_name = os.name
    terminator = '\n'
    bule = 96 if os_name == 'nt' else 36
    yellow = 93 if os_name == 'nt' else 33

    def __init__(self, stream=None, ):
        """
        Initialize the handler.

        If stream is not specified, sys.stderr is used.
        """
        logging.Handler.__init__(self)
        self.formatter = logging.Formatter(
            '%(asctime)s - %(name)s - "%(pathname)s:%(lineno)d" - %(funcName)s - %(levelname)s - %(message)s',
            "%Y-%m-%d %H:%M:%S")
        if stream is None:
            stream = sys.stdout  # stderr无彩。
        self.stream = stream
        self._display_method = 7 if self.os_name == 'posix' else 0

    def setFormatter(self, fmt):
        pass  # 禁止私自设置日志模板。固定使用可跳转的模板。

    def flush(self):
        """
        Flushes the stream.
        """
        self.acquire()
        try:
            if self.stream and hasattr(self.stream, "flush"):
                self.stream.flush()
        finally:
            self.release()

    def emit0(self, record):
        """
        前后彩色不分离的方式
        Emit a record.

        If a formatter is specified, it is used to format the record.
        The record is then written to the stream with a trailing newline.  If
        exception information is present, it is formatted using
        traceback.print_exception and appended to the stream.  If the stream
        has an 'encoding' attribute, it is used to determine how to do the
        output to the stream.
        """
        # noinspection PyBroadException
        try:
            msg = self.format(record)
            stream = self.stream
            if record.levelno == 10:
                # msg_color = ('\033[0;32m%s\033[0m' % msg)  # 绿色
                msg_color = ('\033[%s;%sm%s\033[0m' % (self._display_method, 32, msg))  # 绿色
            elif record.levelno == 20:
                msg_color = ('\033[%s;%sm%s\033[0m' % (self._display_method, self.bule, msg))  # 青蓝色 36    96
            elif record.levelno == 30:
                msg_color = ('\033[%s;%sm%s\033[0m' % (self._display_method, self.yellow, msg))
            elif record.levelno == 40:
                msg_color = ('\033[%s;35m%s\033[0m' % (self._display_method, msg))  # 紫红色
            elif record.levelno == 50:
                msg_color = ('\033[%s;31m%s\033[0m' % (self._display_method, msg))  # 血红色
            else:
                msg_color = msg
            # print(msg_color,'***************')
            stream.write(msg_color)
            stream.write(self.terminator)
            self.flush()
        except BaseException :
            self.handleError(record)

    def emit(self, record):
        """
        前后彩色分离的方式。
        Emit a record.

        If a formatter is specified, it is used to format the record.
        The record is then written to the stream with a trailing newline.  If
        exception information is present, it is formatted using
        traceback.print_exception and appended to the stream.  If the stream
        has an 'encoding' attribute, it is used to determine how to do the
        output to the stream.
        """
        # noinspection PyBroadException
        try:
            msg = self.format(record)
            stream = self.stream
            msg1, msg2 = self.__spilt_msg(record.levelno, msg)
            if record.levelno == 10:
                # msg_color = ('\033[0;32m%s\033[0m' % msg)  # 绿色
                msg_color = f'\033[0;32m{msg1}\033[0m \033[7;32m{msg2}\033[0m'  # 绿色
            elif record.levelno == 20:
                # msg_color = ('\033[%s;%sm%s\033[0m' % (self._display_method, self.bule, msg))  # 青蓝色 36    96
                msg_color = f'\033[0;{self.bule}m{msg1}\033[0m \033[7;{self.bule}m{msg2}\033[0m'
            elif record.levelno == 30:
                # msg_color = ('\033[%s;%sm%s\033[0m' % (self._display_method, self.yellow, msg))
                msg_color = f'\033[0;{self.yellow}m{msg1}\033[0m \033[7;{self.yellow}m{msg2}\033[0m'
            elif record.levelno == 40:
                # msg_color = ('\033[%s;35m%s\033[0m' % (self._display_method, msg))  # 紫红色
                msg_color = f'\033[0;35m{msg1}\033[0m \033[7;35m{msg2}\033[0m'
            elif record.levelno == 50:
                # msg_color = ('\033[%s;31m%s\033[0m' % (self._display_method, msg))  # 血红色
                msg_color = f'\033[0;31m{msg1}\033[0m \033[7;31m{msg2}\033[0m'
            else:
                msg_color = msg
            # print(msg_color,'***************')
            stream.write(msg_color)
            stream.write(self.terminator)
            self.flush()
        except BaseException :
            self.handleError(record)

    @staticmethod
    def __spilt_msg(log_level, msg: str):
        split_text = '- 级别 -'
        if log_level == 10:
            split_text = '- DEBUG -'
        elif log_level == 20:
            split_text = '- INFO -'
        elif log_level == 30:
            split_text = '- WARNING -'
        elif log_level == 40:
            split_text = '- ERROR -'
        elif log_level == 50:
            split_text = '- CRITICAL -'
        msg_split = msg.split(split_text, maxsplit=1)
        return msg_split[0] + split_text, msg_split[-1]

    def __repr__(self):
        level = logging.getLevelName(self.level)
        name = getattr(self.stream, 'name', '')
        if name:
            name += ' '
        return '<%s %s(%s)>' % (self.__class__.__name__, name, level)


logging.StreamHandler = ColorHandler  # REMIND 这一行就是打猴子补丁，可以尝试注释掉这一行对比。
"""
这里就是打猴子补丁,要在脚本最开始打猴子补丁，越早越好。
否则原来脚本中使用from logging import StreamHandler变为不了彩色的handler。
只有import logging，logging.StreamHandler的这种用法才会变彩。所以猴子补丁要趁早打。
"""


def my_func():
    """
    模拟常规使用控制台StreamHandler日志的方式。自动变彩。
    :return:
    """
    from logging import StreamHandler
    logger = logging.getLogger('abc')
    print(logger.handlers)
    print(StreamHandler().formatter)
    logger.addHandler(StreamHandler())
    logger.setLevel(10)
    print(logger.handlers)
    for _ in range(100):
        logger.debug('一个debug级别的日志' * 5)
        logger.info('一个info级别的日志' * 5)
        logger.warning('一个warning级别的日志' * 5)
        logger.error('一个error级别的日志' * 5)
        logger.critical('一个critical级别的日志' * 5)


if __name__ == '__main__':
    my_func()

`````

--- **end of file: funboost/utils/monkey_color_log.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/monkey_patches.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/monkey_patches.py`

#### 📦 Imports

- `import collections.abc`


---

`````python


import collections.abc

setattr(collections,'MutableMapping',collections.abc.MutableMapping)





'''

Traceback (most recent call last):
  File "D:\codes\funboost\funboost\concurrent_pool\async_pool_executor0223.py", line 267, in <module>
    test_async_pool_executor()
  File "D:\codes\funboost\funboost\concurrent_pool\async_pool_executor0223.py", line 225, in test_async_pool_executor
    from funboost.concurrent_pool import CustomThreadPoolExecutor as ThreadPoolExecutor
  File "D:\codes\funboost\funboost\__init__.py", line 8, in <module>
    from funboost.set_frame_config import patch_frame_config, show_frame_config
  File "D:\codes\funboost\funboost\set_frame_config.py", line 167, in <module>
    use_config_form_funboost_config_module()
  File "D:\codes\funboost\funboost\set_frame_config.py", line 115, in use_config_form_funboost_config_module
    m = importlib.import_module('funboost_config')
  File "D:\ProgramData\Miniconda3\envs\py310\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "D:\codes\funboost\funboost_config.py", line 8, in <module>
    from funboost import concurrent_pool
  File "D:\codes\funboost\funboost\concurrent_pool\__init__.py", line 14, in <module>
    from .custom_evenlet_pool_executor import CustomEventletPoolExecutor
  File "D:\codes\funboost\funboost\concurrent_pool\custom_evenlet_pool_executor.py", line 7, in <module>
    from eventlet import greenpool, monkey_patch, patcher, Timeout
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\__init__.py", line 17, in <module>
    from eventlet import convenience
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\convenience.py", line 7, in <module>
    from eventlet.green import socket
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\green\socket.py", line 21, in <module>
    from eventlet.support import greendns
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\support\greendns.py", line 79, in <module>
    setattr(dns, pkg, import_patched('dns.' + pkg))
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\support\greendns.py", line 61, in import_patched
    return patcher.import_patched(module_name, **modules)
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\patcher.py", line 132, in import_patched
    return inject(
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\eventlet\patcher.py", line 109, in inject
    module = __import__(module_name, {}, {}, module_name.split('.')[:-1])
  File "D:\ProgramData\Miniconda3\envs\py310\lib\site-packages\dns\namedict.py", line 35, in <module>
    class NameDict(collections.MutableMapping):
AttributeError: module 'collections' has no attribute 'MutableMapping'
'''

`````

--- **end of file: funboost/utils/monkey_patches.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/mqtt_util.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/mqtt_util.py`

#### 📦 Imports

- `import urllib3`
- `import json`
- `import nb_log`
- `import decorator_libs`

#### 🏛️ Classes (1)

##### 📌 `class MqttHttpHelper(nb_log.LoggerMixin, nb_log.LoggerLevelSetterMixin)`
*Line: 24*

**🔧 Constructor (`__init__`):**
- `def __init__(self, mqtt_publish_url = 'http://127.0.0.1:18083/api/v2/mqtt/publish', user = 'admin', passwd = 'public', display_full_msg = False)`
  - **Docstring:**
  `````
  :param mqtt_publish_url: mqtt的http接口，这是mqtt中间件自带的，不是重新自己实现的接口。不需要导入paho.mqtt.client,requeests urllib3即可。
  :param display_full_msg: 时候打印发布的任务
  `````
  - **Parameters:**
    - `self`
    - `mqtt_publish_url = 'http://127.0.0.1:18083/api/v2/mqtt/publish'`
    - `user = 'admin'`
    - `passwd = 'public'`
    - `display_full_msg = False`

**Public Methods (1):**
- `def pub_message(self, topic, msg)`


---

`````python
import urllib3
import json
import nb_log
import decorator_libs

# https://www.cnblogs.com/YrRoom/p/14054282.html

"""
-p 18083 服务器启动端口
-p 1882 TCP端口
-p 8083 WS端口
-p 8084 WSS端口
-p 8883 SSL端口
"""

"""
非常适合 前端订阅唯一uuid的topic 然后表单中带上这个topic名字请求python接口 -> 接口中发布任务到rabbitmq或redis消息队列 ->
后台消费进程执行任务消费,并将结果发布到mqtt的那个唯一uuid的topic -> mqtt 把结果推送到前端。

使用ajax轮训或者后台导入websocket相关的包来做和前端的长耗时任务的交互都是伪命题，没有mqtt好。
"""


class MqttHttpHelper(nb_log.LoggerMixin, nb_log.LoggerLevelSetterMixin):

    def __init__(self, mqtt_publish_url='http://127.0.0.1:18083/api/v2/mqtt/publish', user='admin', passwd='public', display_full_msg=False):
        """
        :param mqtt_publish_url: mqtt的http接口，这是mqtt中间件自带的，不是重新自己实现的接口。不需要导入paho.mqtt.client,requeests urllib3即可。
        :param display_full_msg: 时候打印发布的任务
        """
        self._mqtt_publish_url = mqtt_publish_url
        self.http = urllib3.PoolManager()
        self._headers = urllib3.util.make_headers(basic_auth=f'{user}:{passwd}')
        self._headers['Content-Type'] = 'application/json'
        self._display_full_msg = display_full_msg

    # @decorator_libs.tomorrow_threads(10)
    def pub_message(self, topic, msg):
        msg = json.dumps(msg) if isinstance(msg, (dict, list)) else msg
        if not isinstance(msg, str):
            raise Exception('推送的不是字符串')
        post_data = {"qos": 1, "retain": False, "topic": topic, "payload": msg}
        try:  # UnicodeEncodeError: 'latin-1' codec can't encode character '\u6211' in position 145: Body ('我') is not valid Latin-1. Use body.encode('utf-8') if you want to send it encoded in UTF-8.
            resp_dict = json.loads(self.http.request('post', self._mqtt_publish_url, body=json.dumps(post_data),
                                                     headers=self._headers).data)
        except UnicodeEncodeError as e:
            self.logger.warning(e)
            post_data['payload'] = post_data['payload'].encode().decode('latin-1')
            resp_dict = json.loads(self.http.request('post', self._mqtt_publish_url, body=json.dumps(post_data),
                                                     headers=self._headers).data)
        if resp_dict['code'] == 0:
            self.logger.debug(f' 推送mqtt成功 ，主题名称是:{topic} ，长度是 {len(msg)}， 消息是 {msg if self._display_full_msg else msg[:200]} ')
        else:
            self.logger.debug(f' 推送mqtt失败,主题名称是:{topic},mqtt返回响应是 {json.dumps(resp_dict)} ， 消息是 {msg if self._display_full_msg else msg[:200]}')


if __name__ == '__main__':
    with decorator_libs.TimerContextManager():
        mp = MqttHttpHelper('http://192.168.6.130:18083/api/v2/mqtt/publish')
        for i in range(2000):
            mp.pub_message('/topic_test_uuid123456', 'msg_test3')

`````

--- **end of file: funboost/utils/mqtt_util.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/paramiko_util.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/paramiko_util.py`

#### 📦 Imports

- `import os`
- `import re`
- `import sys`
- `import time`
- `from nb_log import LoggerMixin`
- `from nb_log import LoggerLevelSetterMixin`
- `import paramiko`

#### 🏛️ Classes (1)

##### 📌 `class ParamikoFolderUploader(LoggerMixin, LoggerLevelSetterMixin)`
*Line: 10*

**Docstring:**
`````
paramoki 实现的文件夹上传
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, host, port, user, password, local_dir: str, remote_dir: str, path_pattern_exluded_tuple = ('/.git/', '/.idea/', '/dist/', '/build/'), file_suffix_tuple_exluded = ('.pyc', '.log', '.gz'), only_upload_within_the_last_modify_time = 3650 * 24 * 60 * 60, file_volume_limit = 1000 * 1000, sftp_log_level = 20, pkey_file_path = None)`
  - **Docstring:**
  `````
  :param host:
  :param port:
  :param user:
  :param password:
  :param local_dir:
  :param remote_dir:
  :param path_pattern_exluded_tuple: 命中了这些正则的直接排除
  :param file_suffix_tuple_exluded: 这些结尾的文件排除
  :param only_upload_within_the_last_modify_time: 仅仅上传最近多少天修改的文件
  :param file_volume_limit: 大于这个体积的不上传，单位b。
  :param sftp_log_level:日志级别
  :param pkey_file_path: 私钥文件路径，如果设置了这个，那么使用私钥登录。
  `````
  - **Parameters:**
    - `self`
    - `host`
    - `port`
    - `user`
    - `password`
    - `local_dir: str`
    - `remote_dir: str`
    - `path_pattern_exluded_tuple = ('/.git/', '/.idea/', '/dist/', '/build/')`
    - `file_suffix_tuple_exluded = ('.pyc', '.log', '.gz')`
    - `only_upload_within_the_last_modify_time = 3650 * 24 * 60 * 60`
    - `file_volume_limit = 1000 * 1000`
    - `sftp_log_level = 20`
    - `pkey_file_path = None`

**Public Methods (1):**
- `def upload(self)`


---

`````python
#coding=utf-8
import os
import re
import sys
import time
from nb_log import LoggerMixin, LoggerLevelSetterMixin
import paramiko


class ParamikoFolderUploader(LoggerMixin, LoggerLevelSetterMixin):
    """
    paramoki 实现的文件夹上传
    """

    def __init__(self, host, port, user, password, local_dir: str, remote_dir: str,
                 path_pattern_exluded_tuple=('/.git/', '/.idea/', '/dist/', '/build/'),
                 file_suffix_tuple_exluded=('.pyc', '.log', '.gz'),
                 only_upload_within_the_last_modify_time=3650 * 24 * 60 * 60,
                 file_volume_limit=1000 * 1000, sftp_log_level=20, pkey_file_path=None):
        """

        :param host:
        :param port:
        :param user:
        :param password:
        :param local_dir:
        :param remote_dir:
        :param path_pattern_exluded_tuple: 命中了这些正则的直接排除
        :param file_suffix_tuple_exluded: 这些结尾的文件排除
        :param only_upload_within_the_last_modify_time: 仅仅上传最近多少天修改的文件
        :param file_volume_limit: 大于这个体积的不上传，单位b。
        :param sftp_log_level:日志级别
        :param pkey_file_path: 私钥文件路径，如果设置了这个，那么使用私钥登录。
        """
        self._host = host
        self._port = port
        self._user = user
        self._password = password

        self._local_dir = str(local_dir).replace('\\', '/')
        if not self._local_dir.endswith('/'):
            self._local_dir += '/'
        self._remote_dir = str(remote_dir).replace('\\', '/')
        if not self._remote_dir.endswith('/'):
            self._remote_dir += '/'
        self._path_pattern_exluded_tuple = path_pattern_exluded_tuple
        self._file_suffix_tuple_exluded = file_suffix_tuple_exluded
        self._only_upload_within_the_last_modify_time = only_upload_within_the_last_modify_time
        self._file_volume_limit = file_volume_limit

        t = paramiko.Transport((host, port))
        if pkey_file_path is not None and os.path.exists(pkey_file_path):
            pkey = paramiko.RSAKey.from_private_key_file(pkey_file_path)
            t.connect(username=user, pkey=pkey)
        else:
            t.connect(username=user, password=password)
        self.sftp = paramiko.SFTPClient.from_transport(t)

        ssh = paramiko.SSHClient()
        ssh.load_system_host_keys()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(host, port=port, username=user, password=password, compress=True)
        self.ssh = ssh

        self.set_log_level(sftp_log_level)

    def _judge_need_filter_a_file(self, filename: str):
        ext = filename.split('.')[-1]
        if '.' + ext in self._file_suffix_tuple_exluded:
            return True
        for path_pattern_exluded in self._path_pattern_exluded_tuple:
            # print(path_pattern_exluded,filename)
            if re.search(path_pattern_exluded, filename):
                return True
        file_st_mtime = os.stat(filename).st_mtime
        volume = os.path.getsize(filename)
        if time.time() - file_st_mtime > self._only_upload_within_the_last_modify_time:
            return True
        if volume > self._file_volume_limit:
            return True
        return False

    def _make_dir(self, dirc, final_dir):
        """
        sftp.mkdir 不能直接越级创建深层级文件夹。
        :param dirc:
        :param final_dir:
        :return:
        """
        # print(dir,final_dir)
        try:
            self.sftp.mkdir(dirc)
            if dirc != final_dir:
                self._make_dir(final_dir, final_dir)
        except (FileNotFoundError,):
            parrent_dir = os.path.split(dirc)[0]
            self._make_dir(parrent_dir, final_dir)

    def upload(self):
        for parent, dirnames, filenames in os.walk(self._local_dir):
            for filename in filenames:
                file_full_name = os.path.join(parent, filename).replace('\\', '/')
                if not self._judge_need_filter_a_file(file_full_name):
                    remote_full_file_name = re.sub(f'^{self._local_dir}', self._remote_dir, file_full_name)
                    try:
                        self.logger.debug(f'本地：{file_full_name}   远程： {remote_full_file_name}')
                        self.sftp.put(file_full_name, remote_full_file_name)
                    except (FileNotFoundError,) as e:
                        # self.logger.warning(remote_full_file_name)
                        self._make_dir(os.path.split(remote_full_file_name)[0], os.path.split(remote_full_file_name)[0])
                        self.sftp.put(file_full_name, remote_full_file_name)
                else:
                    if '/.git' not in file_full_name and '.pyc' not in file_full_name:
                        self.logger.debug(f'根据过滤规则，不上传这个文件 {file_full_name}')


if __name__ == '__main__':
    uploader = ParamikoFolderUploader('192.168.6.133', 22, 'ydf', '372148', sys.path[1], '/home/ydf/codes/dssf/')
    uploader.upload()

`````

--- **end of file: funboost/utils/paramiko_util.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/rabbitmq_factory.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/rabbitmq_factory.py`

#### 📦 Imports

- `import pikav0 as pika`
- `import rabbitpy`
- `from pikav0.adapters.blocking_connection import BlockingChannel`
- `from funboost.funboost_config_deafult import BrokerConnConfig`

#### 🏛️ Classes (3)

##### 📌 `class RabbitmqClientRabbitPy`
*Line: 11*

**Docstring:**
`````
使用rabbitpy包。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, username, password, host, port, virtual_host, heartbeat = 0)`
  - **Parameters:**
    - `self`
    - `username`
    - `password`
    - `host`
    - `port`
    - `virtual_host`
    - `heartbeat = 0`

**Public Methods (1):**
- `def creat_a_channel(self) -> rabbitpy.AMQP`

##### 📌 `class RabbitmqClientPika`
*Line: 25*

**Docstring:**
`````
使用pika包,多线程不安全的包。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, username, password, host, port, virtual_host, heartbeat = 0)`
  - **Docstring:**
  `````
  parameters = pika.URLParameters('amqp://guest:guest@localhost:5672/%2F')
  
  connection = pika.SelectConnection(parameters=parameters,
                            on_open_callback=on_open)
  :param username:
  :param password:
  :param host:
  :param port:
  :param virtual_host:
  :param heartbeat:
  `````
  - **Parameters:**
    - `self`
    - `username`
    - `password`
    - `host`
    - `port`
    - `virtual_host`
    - `heartbeat = 0`

**Public Methods (1):**
- `def creat_a_channel(self) -> BlockingChannel`

##### 📌 `class RabbitMqFactory`
*Line: 53*

**🔧 Constructor (`__init__`):**
- `def __init__(self, heartbeat = 600, is_use_rabbitpy = 0)`
  - **Docstring:**
  `````
  :param heartbeat:
  :param is_use_rabbitpy: 为0使用pika，多线程不安全。为1使用rabbitpy，多线程安全的包。
  `````
  - **Parameters:**
    - `self`
    - `heartbeat = 600`
    - `is_use_rabbitpy = 0`

**Public Methods (1):**
- `def get_rabbit_cleint(self)`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 11:51
import pikav0 as pika
import rabbitpy
from pikav0.adapters.blocking_connection import BlockingChannel

from funboost.funboost_config_deafult import BrokerConnConfig


class RabbitmqClientRabbitPy:
    """
    使用rabbitpy包。
    """

    # noinspection PyUnusedLocal
    def __init__(self, username, password, host, port, virtual_host, heartbeat=0):
        rabbit_url = f'amqp://{username}:{password}@{host}:{port}/{virtual_host}?heartbeat={heartbeat}'
        self.connection = rabbitpy.Connection(rabbit_url)

    def creat_a_channel(self) -> rabbitpy.AMQP:
        return rabbitpy.AMQP(self.connection.channel())  # 使用适配器，使rabbitpy包的公有方法几乎接近pika包的channel的方法。


class RabbitmqClientPika:
    """
    使用pika包,多线程不安全的包。
    """

    def __init__(self, username, password, host, port, virtual_host, heartbeat=0):
        """
        parameters = pika.URLParameters('amqp://guest:guest@localhost:5672/%2F')

        connection = pika.SelectConnection(parameters=parameters,
                                  on_open_callback=on_open)
        :param username:
        :param password:
        :param host:
        :param port:
        :param virtual_host:
        :param heartbeat:
        """
        credentials = pika.PlainCredentials(username, password)
        self.connection = pika.BlockingConnection(pika.ConnectionParameters(
            host, port, virtual_host, credentials, heartbeat=heartbeat))
        # self.connection = pika.SelectConnection(pika.ConnectionParameters(
        #     host, port, virtual_host, credentials, heartbeat=heartbeat))

    def creat_a_channel(self) -> BlockingChannel:
        return self.connection.channel()


class RabbitMqFactory:
    def __init__(self, heartbeat=600 , is_use_rabbitpy=0):
        """
        :param heartbeat:
        :param is_use_rabbitpy: 为0使用pika，多线程不安全。为1使用rabbitpy，多线程安全的包。
        """
        if is_use_rabbitpy:
            self.rabbit_client = RabbitmqClientRabbitPy(BrokerConnConfig.RABBITMQ_USER, BrokerConnConfig.RABBITMQ_PASS,
                                                        BrokerConnConfig.RABBITMQ_HOST, BrokerConnConfig.RABBITMQ_PORT,
                                                        BrokerConnConfig.RABBITMQ_VIRTUAL_HOST, heartbeat)
        else:
            self.rabbit_client = RabbitmqClientPika(BrokerConnConfig.RABBITMQ_USER, BrokerConnConfig.RABBITMQ_PASS,
                                                    BrokerConnConfig.RABBITMQ_HOST, BrokerConnConfig.RABBITMQ_PORT,
                                                    BrokerConnConfig.RABBITMQ_VIRTUAL_HOST, heartbeat)

    def get_rabbit_cleint(self):
        return self.rabbit_client

`````

--- **end of file: funboost/utils/rabbitmq_factory.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/README.md** (project: funboost) --- 

`````markdown
# 这里的utils功能是从已有项目复制出来的，大部分没用到，不要管这里。

# 最主要的是要看base_consumer.py,框架90%逻辑流程在 AbstractConsumer
`````

--- **end of file: funboost/utils/README.md** (project: funboost) --- 

---


--- **start of file: funboost/utils/redis_manager.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/redis_manager.py`

#### 📦 Imports

- `import copy`
- `import os`
- `import threading`
- `import redis5`
- `from funboost.funboost_config_deafult import BrokerConnConfig`
- `from funboost.utils import decorators`

#### 🏛️ Classes (3)

##### 📌 `class RedisManager(object)`
*Line: 28*

**🔧 Constructor (`__init__`):**
- `def __init__(self, host = '127.0.0.1', port = 6379, db = 0, username = '', password = '', ssl = False)`
  - **Parameters:**
    - `self`
    - `host = '127.0.0.1'`
    - `port = 6379`
    - `db = 0`
    - `username = ''`
    - `password = ''`
    - `ssl = False`

**Public Methods (1):**
- `def get_redis(self) -> redis5.Redis`
  - *:rtype :redis5.Redis*

**Class Variables (2):**
- `_redis_db__conn_map = {}`
- `_lock = threading.Lock()`

##### 📌 `class RedisMixin(object)`
*Line: 69*

**Docstring:**
`````
可以被作为万能mixin能被继承，也可以单独实例化使用。
`````

**Public Methods (2):**
- `def redis_db_n(self, db)`
- `def timestamp(self)`
  - *如果是多台机器做分布式控频 乃至确认消费，每台机器取自己的时间，如果各机器的时间戳不一致会发生问题，改成统一使用从redis服务端获取时间，单位是时间戳秒。*

**Properties (2):**
- `@property redis_db_frame`
- `@property redis_db_filter_and_rpc_result`

##### 📌 `class AioRedisMixin(object)`
*Line: 94*

**Properties (1):**
- `@property aioredis_db_filter_and_rpc_result`

#### 🔧 Public Functions (1)

- `def get_redis_conn_kwargs()`
  - *Line: 16*


---

`````python
# coding=utf8

import copy
import os
import threading
# import redis2 as redis
# import redis3
import redis5
from funboost.funboost_config_deafult import BrokerConnConfig
from funboost.utils import decorators

# from aioredis.client import Redis as AioRedis



def get_redis_conn_kwargs():
    return {'host': BrokerConnConfig.REDIS_HOST, 'port': BrokerConnConfig.REDIS_PORT,
            'username': BrokerConnConfig.REDIS_USERNAME,'ssl' : BrokerConnConfig.REDIS_SSL,
            'password': BrokerConnConfig.REDIS_PASSWORD, 'db': BrokerConnConfig.REDIS_DB}


def _get_redis_conn_kwargs_by_db(db):
    conn_kwargs = copy.copy(get_redis_conn_kwargs())
    conn_kwargs['db'] = db
    return conn_kwargs


class RedisManager(object):
    _redis_db__conn_map = {}
    _lock = threading.Lock()

    def __init__(self, host='127.0.0.1', port=6379, db=0, username='', password='',ssl=False):
        pid = os.getpid()
        self._key = (host, port, db, username, password,ssl,pid)
        if self._key not in self.__class__._redis_db__conn_map:
            with self.__class__._lock:
                 if self._key not in self.__class__._redis_db__conn_map:
                     self.__class__._redis_db__conn_map[self._key] = redis5.Redis(host=host, port=port, db=db, username=username,
                                                                            password=password, max_connections=100,
                                                                            ssl=ssl,
                                                                            decode_responses=True)
        self.redis = self.__class__._redis_db__conn_map[self._key]

    def get_redis(self) -> redis5.Redis:
        """
        :rtype :redis5.Redis
        """
        return self.redis


# class AioRedisManager(object):
#     _redis_db__conn_map = {}
#
#     def __init__(self, host='127.0.0.1', port=6379, db=0, username='', password=''):
#         self._key = (host, port, db, username, password,)
#         if self._key not in self.__class__._redis_db__conn_map:
#             self.__class__._redis_db__conn_map[self._key] = AioRedis(host=host, port=port, db=db, username=username,
#                                                                      password=password, max_connections=1000, decode_responses=True)
#         self.redis = self.__class__._redis_db__conn_map[self._key]
#
#     def get_redis(self) -> AioRedis:
#         """
#         :rtype :redis5.Redis
#         """
#         return self.redis


# noinspection PyArgumentEqualDefault
class RedisMixin(object):
    """
    可以被作为万能mixin能被继承，也可以单独实例化使用。
    """

    def redis_db_n(self, db):
        return RedisManager(**_get_redis_conn_kwargs_by_db(db)).get_redis()

    @property
    @decorators.cached_method_result
    def redis_db_frame(self):
        return RedisManager(**get_redis_conn_kwargs()).get_redis()

    @property
    @decorators.cached_method_result
    def redis_db_filter_and_rpc_result(self):
        return RedisManager(**_get_redis_conn_kwargs_by_db(BrokerConnConfig.REDIS_DB_FILTER_AND_RPC_RESULT)).get_redis()

    def timestamp(self):
        """ 如果是多台机器做分布式控频 乃至确认消费，每台机器取自己的时间，如果各机器的时间戳不一致会发生问题，改成统一使用从redis服务端获取时间，单位是时间戳秒。"""
        time_tuple = self.redis_db_frame.time()
        # print(time_tuple)
        return time_tuple[0] + time_tuple[1] / 1000000


class AioRedisMixin(object):
    @property
    @decorators.cached_method_result
    def aioredis_db_filter_and_rpc_result(self):
        # aioredis 包已经不再更新了,推荐使用redis包的asyncio中的类
        # return AioRedisManager(**_get_redis_conn_kwargs_by_db(BrokerConnConfig.REDIS_DB_FILTER_AND_RPC_RESULT)).get_redis()
        return redis5.asyncio.Redis(**_get_redis_conn_kwargs_by_db(BrokerConnConfig.REDIS_DB_FILTER_AND_RPC_RESULT),decode_responses=True)

`````

--- **end of file: funboost/utils/redis_manager.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/redis_manager_old.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/redis_manager_old.py`


---

`````python
# # coding=utf8
# import redis2 as redis
# import redis3
# # from funboost.funboost_config_deafult import BrokerConnConfig
# from funboost.utils import decorators
#
# from aioredis.client import Redis as AioRedis
#
#
# class RedisManager(object):
#     _pool_dict = {}
#
#     def __init__(self, host='127.0.0.1', port=6379, db=0, username='',password='123456'):
#         if (host, port, db, password) not in self.__class__._pool_dict:
#             # print ('创建一个连接池')
#             self.__class__._pool_dict[(host, port, db, password)] = redis.ConnectionPool(host=host, port=port, db=db,username=username,
#                                                                                          password=password,max_connections=100)
#         self._r = redis.Redis(connection_pool=self._pool_dict[(host, port, db, password)])
#         self._ping()
#
#     def get_redis(self):
#         """
#         :rtype :redis.Redis
#         """
#         return self._r
#
#     def _ping(self):
#         try:
#             self._r.ping()
#         except BaseException as e:
#             raise e
#
#
# # noinspection PyArgumentEqualDefault
# class RedisMixin(object):
#     """
#     可以被作为万能mixin能被继承，也可以单独实例化使用。
#     """
#
#     @property
#     @decorators.cached_method_result
#     def redis_db0(self):
#         return RedisManager(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=0,username=funboost_config_deafult.REDIS_USERNAME).get_redis()
#
#     @property
#     @decorators.cached_method_result
#     def redis_db8(self):
#         return RedisManager(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=8,username=funboost_config_deafult.REDIS_USERNAME).get_redis()
#
#     @property
#     @decorators.cached_method_result
#     def redis_db7(self):
#         return RedisManager(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=7,username=funboost_config_deafult.REDIS_USERNAME).get_redis()
#
#     @property
#     @decorators.cached_method_result
#     def redis_db6(self):
#         return RedisManager(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=6,username=funboost_config_deafult.REDIS_USERNAME).get_redis()
#
#     @property
#     @decorators.cached_method_result
#     def redis_db_frame(self):
#         return RedisManager(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=funboost_config_deafult.REDIS_DB,
#                             username=funboost_config_deafult.REDIS_USERNAME).get_redis()
#
#     @property
#     @decorators.cached_method_result
#     def redis_db_frame_version3(self):
#         ''' redis 3和2 入参和返回差别很大，都要使用'''
#         return redis3.Redis(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=funboost_config_deafult.REDIS_DB,
#                             username=funboost_config_deafult.REDIS_USERNAME,decode_responses=True)
#
#     @property
#     @decorators.cached_method_result
#     def redis_db_filter_and_rpc_result(self):
#         return RedisManager(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=funboost_config_deafult.REDIS_DB_FILTER_AND_RPC_RESULT,
#                             username=funboost_config_deafult.REDIS_USERNAME).get_redis()
#
#     @property
#     @decorators.cached_method_result
#     def redis_db_filter_and_rpc_result_version3(self):
#         return redis3.Redis(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                             password=funboost_config_deafult.REDIS_PASSWORD, db=funboost_config_deafult.REDIS_DB_FILTER_AND_RPC_RESULT,
#                             username=funboost_config_deafult.REDIS_USERNAME,
#                             decode_responses=True)
#
#     def timestamp(self):
#         """ 如果是多台机器做分布式控频 乃至确认消费，每台机器取自己的时间，如果各机器的时间戳不一致会发生问题，改成统一使用从redis服务端获取时间，单位是时间戳秒。"""
#         time_tuple = self.redis_db_frame.time()
#         # print(time_tuple)
#         return time_tuple[0] + time_tuple[1] / 1000000
#
#
# class AioRedisMixin(object):
#     @property
#     @decorators.cached_method_result
#     def aioredis_db_filter_and_rpc_result(self):
#         return AioRedis(host=funboost_config_deafult.REDIS_HOST, port=funboost_config_deafult.REDIS_PORT,
#                         password=funboost_config_deafult.REDIS_PASSWORD, db=funboost_config_deafult.REDIS_DB_FILTER_AND_RPC_RESULT,
#                         username=funboost_config_deafult.REDIS_USERNAME,
#                         decode_responses=True)

`````

--- **end of file: funboost/utils/redis_manager_old.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/resource_monitoring.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/resource_monitoring.py`

#### 📦 Imports

- `import datetime`
- `import json`
- `import socket`
- `import sys`
- `import threading`
- `import time`
- `from funboost.core.lazy_impoter import PsutilImporter`
- `from funboost.utils import LoggerLevelSetterMixin`
- `from funboost.utils import LoggerMixin`
- `from funboost.utils import decorators`
- `from funboost.utils.mongo_util import MongoMixin`

#### 🏛️ Classes (1)

##### 📌 `class ResourceMonitor(LoggerMixin, LoggerLevelSetterMixin, MongoMixin)`
*Line: 61*

**🔧 Constructor (`__init__`):**
- `def __init__(self, process = PsutilImporter().psutil.Process(), is_save_info_to_mongo = False, mongo_col = 'default')`
  - **Parameters:**
    - `self`
    - `process = PsutilImporter().psutil.Process()`
    - `is_save_info_to_mongo = False`
    - `mongo_col = 'default'`

**Public Methods (11):**
- `def divide_1m(value)` `staticmethod`
- `def get_current_process_memory(self) -> float`
- `def get_current_process_cpu(self)`
- `def get_os_cpu_percpu(self)`
- `def get_os_cpu_totalcpu(self)`
- `def get_os_cpu_avaragecpu(self)`
- `def get_os_virtual_memory(self) -> dict`
- `def get_os_net_info(self)`
- `def get_all_info(self)`
- `def start_build_info_loop(self, interval = 60)`
- `def start_build_info_loop_on_daemon_thread(self, interval = 60)`

**Class Variables (2):**
- `cpu_count = PsutilImporter().psutil.cpu_count()`
- `host_name = socket.gethostname()`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/9/18 0018 10:29
import datetime
import json
import socket
import sys
import threading
import time

from funboost.core.lazy_impoter import PsutilImporter
from funboost.utils import LoggerLevelSetterMixin, LoggerMixin, decorators
from funboost.utils.mongo_util import MongoMixin

"""
# psutil.virtual_memory()
svmem = namedtuple(
    'svmem', ['total', 'available', 'percent', 'used', 'free',
              'active', 'inactive', 'buffers', 'cached', 'shared', 'slab'])
# psutil.disk_io_counters()
sdiskio = namedtuple(
    'sdiskio', ['read_count', 'write_count',
                'read_bytes', 'write_bytes',
                'read_time', 'write_time',
                'read_merged_count', 'write_merged_count',
                'busy_time'])
# psutil.Process().open_files()
popenfile = namedtuple(
    'popenfile', ['path', 'fd', 'position', 'mode', 'flags'])
# psutil.Process().memory_info()
pmem = namedtuple('pmem', 'rss vms shared text lib data dirty')
# psutil.Process().memory_full_info()
pfullmem = namedtuple('pfullmem', pmem._fields + ('uss', 'pss', 'swap'))
# psutil.Process().memory_maps(grouped=True)
pmmap_grouped = namedtuple(
    'pmmap_grouped',
    ['path', 'rss', 'size', 'pss', 'shared_clean', 'shared_dirty',
     'private_clean', 'private_dirty', 'referenced', 'anonymous', 'swap'])
# psutil.Process().memory_maps(grouped=False)
pmmap_ext = namedtuple(
    'pmmap_ext', 'addr perms ' + ' '.join(pmmap_grouped._fields))
# psutil.Process.io_counters()
pio = namedtuple('pio', ['read_count', 'write_count',
                         'read_bytes', 'write_bytes',
                         'read_chars', 'write_chars'])


p = psutil.Process()
print(p)
print(p.memory_info()[0])

print(p.cpu_percent(interval=1))
print(p.cpu_percent(interval=1))

print(psutil.cpu_percent(1,percpu=True))
print(psutil.virtual_memory())

"""


class ResourceMonitor(LoggerMixin, LoggerLevelSetterMixin, MongoMixin):
    # ResourceMonitor(is_save_info_to_mongo=True).set_log_level(20).start_build_info_loop_on_daemon_thread(60)
    cpu_count = PsutilImporter().psutil.cpu_count()
    host_name = socket.gethostname()

    def __init__(self, process=PsutilImporter().psutil.Process(), is_save_info_to_mongo=False, mongo_col='default'):
        self.process = process
        self.logger.setLevel(20)
        self.all_info = {}
        self._is_save_info_to_mongo = is_save_info_to_mongo
        self._mongo_col = mongo_col

    @staticmethod
    def divide_1m(value):
        return round(value / (1024 * 1024), 2)

    def get_current_process_memory(self) -> float:
        result = self.process.memory_info()
        self.logger.debug(result)
        return self.divide_1m(result[0])

    def get_current_process_cpu(self):
        result = self.process.cpu_percent(interval=1)
        self.logger.debug(result)
        return result

    def get_os_cpu_percpu(self):
        result = PsutilImporter().psutil.cpu_percent(1, percpu=True)
        self.logger.debug(result)
        return result

    def get_os_cpu_totalcpu(self):
        result = round(PsutilImporter().psutil.cpu_percent(1, percpu=False) * self.cpu_count, 2)
        self.logger.debug(result)
        return result

    def get_os_cpu_avaragecpu(self):
        result = PsutilImporter().psutil.cpu_percent(1, percpu=False)
        self.logger.debug(result)
        return result

    def get_os_virtual_memory(self) -> dict:
        memory_tuple = PsutilImporter().psutil.virtual_memory()
        self.logger.debug(memory_tuple)
        return {
            'total': self.divide_1m(memory_tuple[0]),
            'available': self.divide_1m(memory_tuple[1]),
            'used': self.divide_1m(memory_tuple[3]),
        }

    def get_os_net_info(self):
        result1 = PsutilImporter().psutil.net_io_counters(pernic=False)
        time.sleep(1)
        result2 = PsutilImporter().psutil.net_io_counters(pernic=False)
        speed_dict = dict()
        speed_dict['up_speed'] = self.divide_1m(result2[0] - result1[0])
        speed_dict['down_speed'] = self.divide_1m(result2[1] - result1[1])
        speed_dict['packet_sent_speed'] = result2[2] - result1[2]
        speed_dict['packet_recv_speed'] = result2[3] - result1[3]
        self.logger.debug(result1)
        return speed_dict

    def get_all_info(self):
        self.all_info = {
            'host_name': self.host_name,
            'process_id': self.process.pid,
            'process_name': self.process.name(),
            'process_script': sys.argv[0],
            'memory': self.get_current_process_memory(),
            'cpu': self.get_current_process_cpu(),
            'os_memory': self.get_os_virtual_memory(),
            'os_cpu': {'cpu_count': self.cpu_count, 'total_cpu': self.get_os_cpu_totalcpu(), 'avarage_cpu': self.get_os_cpu_avaragecpu()},
            'net_info': self.get_os_net_info()
        }
        # nb_print(json.dumps(self.all_info,indent=4))
        self.logger.info(json.dumps(self.all_info, indent=4))
        if self._is_save_info_to_mongo:
            self.all_info.update({'update_time': datetime.datetime.now()})
            self.mongo_client.get_database('process_info').get_collection(self._mongo_col).insert_one(self.all_info)
        return self.all_info

    def start_build_info_loop(self, interval=60, ):
        decorators.keep_circulating(interval)(self.get_all_info)()

    def start_build_info_loop_on_daemon_thread(self, interval=60, ):
        threading.Thread(target=self.start_build_info_loop, args=(interval,), daemon=True).start()

`````

--- **end of file: funboost/utils/resource_monitoring.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/restart_python.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/restart_python.py`

#### 📦 Imports

- `import datetime`
- `import os`
- `import sys`
- `import threading`
- `import time`
- `import nb_log`

#### 🔧 Public Functions (1)

- `def restart_program(seconds)`
  - *Line: 19*
  - **Docstring:**
  `````
  间隔n秒重启脚本
  :param seconds:
  :return:
  `````


---

`````python
import datetime
import os
import sys
import threading
import time

import nb_log

# print(sys.path)

logger = nb_log.get_logger('restart_program')

""" 这个只能在 win cmd 或者 linux下测试重启功能，
   不能在pycharm中观察有无打印来判断是否重启了，因为重启后python进程变化了，pycharm控制台不能捕捉到新进程的打印输出，所以不要在pycharm下运行python来验证重启功能。

"""


def restart_program(seconds):
    '''
    间隔n秒重启脚本
    :param seconds:
    :return:
    '''
    """ 
    这个只能在 win cmd 或者 linux下测试重启功能，
    不能在pycharm中观察有无打印来判断是否重启了，因为重启后python进程变化了，pycharm控制台不能捕捉到新进程的打印输出，所以不要在pycharm下运行python来验证重启功能。
    """

    def _restart_program():
        time.sleep(seconds)
        python = sys.executable
        logger.warning(f'重启当前python程序 {python} , {sys.argv}')
        os.execl(python, python, *sys.argv)

    threading.Thread(target=_restart_program).start()


def _run():
    print(datetime.datetime.now(),'开始运行程序')
    for i in range(1000):
        time.sleep(0.5)
        print(datetime.datetime.now(),i)

if __name__ == '__main__':
    restart_program(10)  # 每隔10秒重启。
    _run()

`````

--- **end of file: funboost/utils/restart_python.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/simple_data_class.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/simple_data_class.py`

#### 📦 Imports

- `import json`
- `import copy`
- `import typing`
- `from funboost.utils import json_helper`
- `from funboost.utils.str_utils import PwdEnc`
- `from funboost.utils.str_utils import StrHelper`
- `import datetime`

#### 🏛️ Classes (2)

##### 📌 `class DataClassBase`
*Line: 10*

**Docstring:**
`````
使用类实现的 简单数据类。
也可以使用装饰器来实现数据类
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, **kwargs)`
  - **Parameters:**
    - `self`
    - `**kwargs`

**Public Methods (5):**
- `def get_dict(self)`
- `def get_json(self, indent = 4)`
- `def get_pwd_enc_json(self, indent = 4)`
  - *防止打印密码明文,泄漏密码*
- `def update_cls_attribute(cls, **kwargs)` `classmethod`
- `def update_instance_attribute(self, **kwargs)`

##### 📌 `class A(DataClassBase)`
*Line: 70*

**Class Variables (3):**
- `x = 1`
- `y = 2`
- `z = datetime.datetime.now()`


---

`````python
import json

import copy
import typing

from funboost.utils import json_helper
from funboost.utils.str_utils import PwdEnc, StrHelper


class DataClassBase:
    """
    使用类实现的 简单数据类。
    也可以使用装饰器来实现数据类
    """

    def __new__(cls, **kwargs):
        self = super().__new__(cls)
        self.__dict__ = copy.copy({k: v for k, v in cls.__dict__.items() if not k.startswith('__')})
        return self

    def __init__(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)

    def __call__(self, ) -> dict:
        return self.get_dict()

    def get_dict(self):
        return {k: v.get_dict() if isinstance(v, DataClassBase) else v for k, v in self.__dict__.items()}

    def __str__(self):
        return f"{self.__class__}    {self.get_dict()}"

    def __getitem__(self, item):
        return getattr(self, item)

    def get_json(self,indent=4):
        return json_helper.dict_to_un_strict_json(self.get_dict(),indent=indent)

    def get_pwd_enc_json(self,indent=4):
        """防止打印密码明文,泄漏密码"""
        dict_new = {}
        for k, v in self.get_dict().items():
            # only_print_on_main_process(f'{k} :  {v}')
            if isinstance(v, (bool, tuple, dict, float, int)):
                dict_new[k] = v
            else:
                v_enc =PwdEnc.enc_broker_uri(str(v))
                if StrHelper(k).judge_contains_str_list(['pwd', 'pass_word', 'password', 'passwd', 'pass']):
                    v_enc = PwdEnc.enc_pwd(v_enc)
                dict_new[k] = v_enc
        return json.dumps(dict_new, ensure_ascii=False, indent=indent)

    @classmethod
    def update_cls_attribute(cls,**kwargs):
        for k ,v in kwargs.items():
            setattr(cls,k,v)
        return cls

    def update_instance_attribute(self, **kwargs):
        for k, v in kwargs.items():
            setattr(self, k, v)
        return self


if __name__ == '__main__':
    import datetime


    class A(DataClassBase):
        x = 1
        y = 2
        z = datetime.datetime.now()


    print(A())
    print(A(y=3))
    print(A(y=5).get_dict())

    print(A()['y'])
    print(A().y)

`````

--- **end of file: funboost/utils/simple_data_class.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/str_utils.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/str_utils.py`

#### 📦 Imports

- `import re`

#### 🏛️ Classes (2)

##### 📌 `class PwdEnc`
*Line: 4*

**Public Methods (2):**
- `def enc_broker_uri(cls, uri: str)` `classmethod`
- `def enc_pwd(pwd: str, plain_len = 3)` `staticmethod`

##### 📌 `class StrHelper`
*Line: 30*

**🔧 Constructor (`__init__`):**
- `def __init__(self, strx: str)`
  - **Parameters:**
    - `self`
    - `strx: str`

**Public Methods (1):**
- `def judge_contains_str_list(self, str_list: list, ignore_case = True)`


---

`````python
import re


class PwdEnc:

    @classmethod
    def enc_broker_uri(cls, uri: str):
        protocol_split_list = uri.split('://')
        if len(protocol_split_list) != 2:
            return uri
        user_pass__ip_port_split_list = protocol_split_list[1].split('@')
        if len(user_pass__ip_port_split_list) != 2:
            return uri
        user__pass_split_list = user_pass__ip_port_split_list[0].split(':')
        if len(user__pass_split_list) != 2:
            return uri
        user = user__pass_split_list[0]
        pwd = user__pass_split_list[1]
        pwd_enc = cls.enc_pwd(pwd)
        return f'{protocol_split_list[0]}://{user}:{pwd_enc}@{user_pass__ip_port_split_list[1]}'

    @staticmethod
    def enc_pwd(pwd: str, plain_len=3):
        pwd_enc = pwd
        if len(pwd_enc) > plain_len:
            pwd_enc = f'{pwd_enc[:plain_len]}{"*" * (len(pwd_enc) - plain_len)}'
        return pwd_enc


class StrHelper:
    def __init__(self, strx: str):
        self.strx = strx

    def judge_contains_str_list(self, str_list: list, ignore_case=True):
        for str1 in str_list:
            if str1 in self.strx:
                return True
            if ignore_case:
                if str1.lower() in self.strx.lower():
                    return True
        return False


if __name__ == '__main__':
    str1 = "amqp://admin:abc234@108.55.33.99:5672/"
    str2 = "redis://:myRedisPass1234@127.0.0.1:6379/0"
    print(PwdEnc.enc_broker_uri(str1))
    print(PwdEnc.enc_broker_uri(str2))
    print(PwdEnc.enc_pwd('465460dsdsd'))



`````

--- **end of file: funboost/utils/str_utils.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/task_dispatcher.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/task_dispatcher.py`

#### 📦 Imports

- `import inspect`
- `import asyncio`
- `from functools import wraps`
- `from typing import Callable`
- `from typing import Any`

#### 🏛️ Classes (1)

##### 📌 `class LocalFunctionsDispatcher`
*Line: 8*

**Docstring:**
`````
本地内存中函数分发运行
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self)`
  - **Parameters:**
    - `self`

**Public Methods (3):**
- `def task(self, name: str = None)`
  - *注册任务的装饰器*
- `def run(self, task_name: str, *args, **kwargs) -> Any`
  - *同步调用任务，不支持直接 await 异步函数*
- `async def aio_run(self, task_name: str, *args, **kwargs) -> Any`
  - *异步调用任务，普通函数通过线程池执行*

#### 🔧 Public Functions (3)

- `def add(a, b)` `dispatcher.task()`
  - *Line: 59*

- `async def mul(a, b)` `dispatcher.task(name='mul_task')`
  - *Line: 63*

- `async def main()`
  - *Line: 74*


---

`````python


import inspect
import asyncio
from functools import wraps
from typing import Callable, Any

class LocalFunctionsDispatcher:
    """
    本地内存中函数分发运行
    """  
    def __init__(self):
        self._registry = {}

    def task(self, name: str = None):
        """注册任务的装饰器"""
        def decorator(func: Callable):
            task_name = name or func.__name__
            if task_name in self._registry:
                raise ValueError(f"Task '{task_name}' is already registered")
            sig = inspect.signature(func)
            self._registry[task_name] = (func, sig)  # 直接存原函数
            return func
        return decorator

    def run(self, task_name: str, *args, **kwargs) -> Any:
        """同步调用任务，不支持直接 await 异步函数"""
        if task_name not in self._registry:
            raise ValueError(f"Task '{task_name}' not registered")
        
        func, sig = self._registry[task_name]
        sig.bind(*args, **kwargs)  # 参数校验

        if inspect.iscoroutinefunction(func):
            # 如果是 async 函数，直接用 asyncio.run 调用（在主线程可用）
            return asyncio.run(func(*args, **kwargs))
        else:
            return func(*args, **kwargs)

    async def aio_run(self, task_name: str, *args, **kwargs) -> Any:
        """异步调用任务，普通函数通过线程池执行"""
        if task_name not in self._registry:
            raise ValueError(f"Task '{task_name}' not registered")
        
        func, sig = self._registry[task_name]
        sig.bind(*args, **kwargs)  # 参数校验

        if inspect.iscoroutinefunction(func):
            return await func(*args, **kwargs)
        else:
            # 普通函数通过线程池运行，不阻塞事件循环
            return await asyncio.to_thread(func, *args, **kwargs)


if __name__ == '__main__':
    dispatcher = LocalFunctionsDispatcher()

    @dispatcher.task()
    def add(a, b):
        return a + b

    @dispatcher.task(name='mul_task')
    async def mul(a, b):
        await asyncio.sleep(0.1)
        return a * b

    print(add(1,2)) # 直接调用

    # 同步调用
    print(dispatcher.run("add", 2, 3))  # 5
    print(dispatcher.run("mul_task", 4, 5))  # 20，asyncio.run 自动运行

    # 异步调用
    async def main():
        print(await dispatcher.aio_run("add", 6, 7))  # 13
        print(await dispatcher.aio_run("mul_task", 3, 5))  # 15

    asyncio.run(main())

`````

--- **end of file: funboost/utils/task_dispatcher.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/time_util.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/time_util.py`

#### 📦 Imports

- `import functools`
- `import typing`
- `import datetime`
- `import time`
- `import re`
- `import pytz`
- `from funboost.core.funboost_time import FunboostTime`
- `from funboost.utils import nb_print`
- `from funboost.funboost_config_deafult import FunboostCommonConfig`

#### 🏛️ Classes (1)

##### 📌 `class DatetimeConverter`
*Line: 56*

**Docstring:**
`````
最爽的时间操作方式。使用真oop需要实例化，调用方式比纯静态方法工具类好太多。
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, datetimex: typing.Union[int, float, datetime.datetime, str] = None)`
  - **Docstring:**
  `````
  :param datetimex: 接受时间戳  datatime类型 和 时间字符串三种类型
  `````
  - **Parameters:**
    - `self`
    - `datetimex: typing.Union[int, float, datetime.datetime, str] = None`

**Public Methods (2):**
- `def bulid_conveter_with_other_formatter(cls, datetime_str, datetime_formatter)` `classmethod`
  - **Docstring:**
  `````
  :param datetime_str: 时间字符串
  :param datetime_formatter: 能够格式化该字符串的模板
  :return:
  `````
- `def is_greater_than_now(self)`

**Properties (5):**
- `@property datetime_str`
- `@property time_str`
- `@property date_str`
- `@property timestamp`
- `@property one_hour_ago_datetime_converter`

**Class Variables (3):**
- `DATETIME_FORMATTER = '%Y-%m-%d %H:%M:%S'`
- `DATETIME_FORMATTER2 = '%Y-%m-%d'`
- `DATETIME_FORMATTER3 = '%H:%M:%S'`

#### 🔧 Public Functions (5)

- `def build_defualt_date()`
  - *Line: 17*
  - **Docstring:**
  `````
  获取今天和明天的日期
  :return:
  `````

- `def get_day_by_interval(n)`
  - *Line: 29*
  - **Docstring:**
  `````
  :param n: 离当天的日期，可为正负整数
  :return:
  `````

- `def get_ahead_one_hour(datetime_str)`
  - *Line: 40*
  - **Docstring:**
  `````
  获得提前一小时的时间字符串和时间戳
  :return:
  `````

- `def timestamp_to_datetime_str(timestamp)`
  - *Line: 50*

- `def seconds_to_hour_minute_second(seconds)`
  - *Line: 130*
  - **Docstring:**
  `````
  把秒转化成还需要的时间
  :param seconds:
  :return:
  `````


---

`````python
# coding=utf-8
import functools
import typing
import datetime
import time
import re
import pytz
from funboost.core.funboost_time import FunboostTime

from funboost.utils import nb_print

@functools.lru_cache()
def _get_funboost_timezone():
    from funboost.funboost_config_deafult import FunboostCommonConfig
    return FunboostCommonConfig.TIMEZONE

def build_defualt_date():
    """
    获取今天和明天的日期
    :return:
    """
    today = datetime.date.today()
    today_str = today.__str__()
    tomorrow = today + datetime.timedelta(days=1)
    tomorrow_str = str(tomorrow)
    return today, tomorrow, today_str, tomorrow_str


def get_day_by_interval(n):
    """
    :param n: 离当天的日期，可为正负整数
    :return:
    """
    today = datetime.date.today()
    day = today + datetime.timedelta(days=n)
    day_str = str(day)
    return day, day_str


def get_ahead_one_hour(datetime_str):
    """
    获得提前一小时的时间字符串和时间戳
    :return:
    """
    datetime_obj = datetime.datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')
    datetime_obj_one_hour_ahead = datetime_obj + datetime.timedelta(hours=-1)
    return datetime_obj_one_hour_ahead.strftime('%Y-%m-%d %H:%M:%S'), datetime_obj_one_hour_ahead.timestamp()


def timestamp_to_datetime_str(timestamp):
    time_local = time.localtime(timestamp)
    # 转换成新的时间格式(2016-05-05 20:28:54)
    return time.strftime("%Y-%m-%d %H:%M:%S", time_local)


class DatetimeConverter:
    """
    最爽的时间操作方式。使用真oop需要实例化，调用方式比纯静态方法工具类好太多。
    """
    DATETIME_FORMATTER = "%Y-%m-%d %H:%M:%S"
    DATETIME_FORMATTER2 = "%Y-%m-%d"
    DATETIME_FORMATTER3 = "%H:%M:%S"

    @classmethod
    def bulid_conveter_with_other_formatter(cls, datetime_str, datetime_formatter):
        """
        :param datetime_str: 时间字符串
        :param datetime_formatter: 能够格式化该字符串的模板
        :return:
        """
        datetime_obj = datetime.datetime.strptime(datetime_str, datetime_formatter)
        return cls(datetime_obj)

    def __init__(self, datetimex: typing.Union[int, float, datetime.datetime, str] = None):  # REMIND 不要写成默认 datetime.datetime.now()或time.time()，否则默认参数值运行一次
        """
        :param datetimex: 接受时间戳  datatime类型 和 时间字符串三种类型
        """
        # if isinstance(datetimex, str):
        #     if not re.match(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', datetimex):
        #         raise ValueError('时间字符串的格式不符合此传参的规定')
        #     else:
        #         self.datetime_obj = datetime.datetime.strptime(datetimex, self.DATETIME_FORMATTER)
        # elif isinstance(datetimex, (int, float)):
        #     if datetimex < 1:
        #         datetimex += 86400
        #     self.datetime_obj = datetime.datetime.fromtimestamp(datetimex, tz=pytz.timezone(_get_funboost_timezone()))  # 时间戳0在windows会出错。
        # elif isinstance(datetimex, datetime.datetime):
        #     self.datetime_obj = datetimex
        # elif datetimex is None:
        #     self.datetime_obj = datetime.datetime.now(tz=pytz.timezone(_get_funboost_timezone()))
        # else:
        #     raise ValueError('实例化时候的传参不符合规定')
        self.datetime_obj = FunboostTime(datetimex).datetime_obj

    @property
    def datetime_str(self):
        return self.datetime_obj.strftime(self.DATETIME_FORMATTER)

    @property
    def time_str(self):
        return self.datetime_obj.strftime(self.DATETIME_FORMATTER3)

    @property
    def date_str(self):
        return self.datetime_obj.strftime(self.DATETIME_FORMATTER2)

    @property
    def timestamp(self):
        return self.datetime_obj.timestamp()

    @property
    def one_hour_ago_datetime_converter(self):
        """
        酒店经常需要提前一小时免费取消，直接封装在这里
        :return:
        """
        one_hour_ago_datetime_obj = self.datetime_obj + datetime.timedelta(hours=-1)
        return self.__class__(one_hour_ago_datetime_obj)

    def is_greater_than_now(self):
        return self.timestamp > time.time()

    def __str__(self):
        return self.datetime_str

    def __call__(self):
        return self.datetime_obj


def seconds_to_hour_minute_second(seconds):
    """
    把秒转化成还需要的时间
    :param seconds:
    :return:
    """
    m, s = divmod(seconds, 60)
    h, m = divmod(m, 60)
    return "%02d:%02d:%02d" % (h, m, s)


if __name__ == '__main__':
    """
    1557113661.0
    '2019-05-06 12:34:21'
    '2019/05/06 12:34:21'
    DatetimeConverter(1557113661.0)()
    """
    # noinspection PyShadowingBuiltins
    print = nb_print
    o3 = DatetimeConverter('2019-05-06 12:34:21')
    print(o3)
    print('- - - - -  - - -')

    o = DatetimeConverter.bulid_conveter_with_other_formatter('2019/05/06 12:34:21', '%Y/%m/%d %H:%M:%S')
    print(o)
    print(o.date_str)
    print(o.timestamp)
    print('***************')
    o2 = o.one_hour_ago_datetime_converter
    print(o2)
    print(o2.date_str)
    print(o2.timestamp)
    print(o2.is_greater_than_now())
    print(o2(), type(o2()))
    print(DatetimeConverter())
    print(datetime.datetime.now())
    time.sleep(5)
    print(DatetimeConverter())
    print(datetime.datetime.now())
    print(DatetimeConverter(3600 * 24))

    print(seconds_to_hour_minute_second(3600 * 2))

`````

--- **end of file: funboost/utils/time_util.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/un_strict_json_dumps.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/un_strict_json_dumps.py`

#### 📦 Imports

- `import json`

#### 🔧 Public Functions (1)

- `def dict2json(dictx: dict, indent = 4)`
  - *Line: 4*


---

`````python
import json


def dict2json(dictx: dict, indent=4):
    dict_new = {}
    for k, v in dictx.items():
        # only_print_on_main_process(f'{k} :  {v}')
        if isinstance(v, (bool, tuple, dict, float, int)):
            dict_new[k] = v
        else:
            dict_new[k] = str(v)
    return json.dumps(dict_new, ensure_ascii=False, indent=indent)


if __name__ == '__main__':
    pass

`````

--- **end of file: funboost/utils/un_strict_json_dumps.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/uuid7.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/uuid7.py`

#### 📝 Module Docstring

`````
python3.7 没有uuid7，自己实现。

uuid7比uuid4对数据库更友好，类似雪花算法

UUIDv4 完全无法知道生成时间；
UUIDv7 可以精确还原生成时间（毫秒级）。
`````

#### 📦 Imports

- `import time`
- `import secrets`
- `import uuid`
- `import datetime`

#### 🔧 Public Functions (2)

- `def uuid7() -> uuid.UUID`
  - *Line: 16*
  - *RFC 9562 UUIDv7*

- `def parse_uuid7_timestamp(uuid_str: str) -> dict`
  - *Line: 45*
  - *解析 UUIDv7 字符串，返回包含时间戳信息的字典*


---

`````python

"""
python3.7 没有uuid7，自己实现。

uuid7比uuid4对数据库更友好，类似雪花算法

UUIDv4 完全无法知道生成时间；
UUIDv7 可以精确还原生成时间（毫秒级）。
"""

import time
import secrets
import uuid
import datetime

def uuid7() -> uuid.UUID:
    """
    RFC 9562 UUIDv7
    """
    # 1. 毫秒时间戳（48 bits）
    ts_ms = int(time.time() * 1000) & ((1 << 48) - 1)

    # 2. 填充剩余的 80 bits 为随机数
    # 注意：我们先填满低 80 位，后面再通过位运算覆盖 Version 和 Variant
    rand_payload = secrets.randbits(80)

    # 3. 拼接时间戳到高位
    value = (ts_ms << 80) | rand_payload

    # 4. 设置 Version 7 (0111)
    # 位置：bits 76-79 (从右往左数，0-indexed)
    value &= ~(0xF << 76)  # 清除这 4 位
    value |= (0x7 << 76)   # 写入 0111

    # 5. 设置 Variant (10xx) - 这是原代码缺失的关键部分
    # 位置：bits 62-63
    # RFC 9562 要求 Variant 为 2 (即二进制 10)
    value &= ~(0x3 << 62)  # 清除这 2 位
    value |= (0x2 << 62)   # 写入 10

    return uuid.UUID(int=value)



def parse_uuid7_timestamp(uuid_str: str) -> dict:
    """
    解析 UUIDv7 字符串，返回包含时间戳信息的字典
    """
    try:
        # 1. 转换为 UUID 对象（自动处理格式验证）
        u = uuid.UUID(uuid_str)
        
        # 2. 检查版本是否为 7
        if u.version != 7:
            raise ValueError(f"该 UUID 版本为 {u.version}，不是 v7")

        # 3. 提取时间戳
        # UUID 总共 128 位，前 48 位是时间戳
        # 这里的 int 是 128 位的整数，右移 80 位即可拿到高 48 位
        ts_ms = u.int >> 80
        
        # 4. 转换为秒 (float)
        ts_seconds = ts_ms / 1000.0
        
        # 5. 生成 datetime 对象
        dt_local = datetime.fromtimestamp(ts_seconds)
        
        return {
            "timestamp_ms": ts_ms,
            "datetime_local": dt_local,
            "iso_format": dt_local.isoformat()
        }

    except ValueError as e:
        return {"error": str(e)}




if __name__ == '__main__':
    uuid7_str = str(uuid7())
    print(uuid7_str)
    print(parse_uuid7_timestamp(uuid7_str))
`````

--- **end of file: funboost/utils/uuid7.py** (project: funboost) --- 

---


--- **start of file: funboost/utils/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `funboost/utils/__init__.py`

#### 📦 Imports

- `from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath`
- `from nb_log import LogManager`
- `from nb_log import simple_logger`
- `from nb_log import LoggerMixin`
- `from nb_log import LoggerLevelSetterMixin`
- `from nb_log import LoggerMixinDefaultWithFileHandler`
- `from nb_log import nb_print`
- `from nb_log import patch_print`
- `from nb_log import reverse_patch_print`
- `from nb_log import get_logger`
- `from funboost.utils.json_helper import monkey_patch_json`


---

`````python
# -*- coding: utf-8 -*-
# @Author  : ydf
# @Time    : 2022/8/8 0008 9:48


from funboost.utils.dependency_packages_in_pythonpath import add_to_pythonpath

from nb_log import (LogManager, simple_logger, LoggerMixin, LoggerLevelSetterMixin,
                    LoggerMixinDefaultWithFileHandler,nb_print,patch_print,reverse_patch_print,get_logger)

# from funboost.utils.redis_manager import RedisMixin

from funboost.utils.json_helper import monkey_patch_json


#################以下为打猴子补丁#####################
monkey_patch_json()






`````

--- **end of file: funboost/utils/__init__.py** (project: funboost) --- 

---

# markdown content namespace: boost_spider codes 


## funboost File Tree (relative dir: `boost_spider`)


`````

└── boost_spider
    ├── __init__.py
    ├── http
    │   ├── __init__.py
    │   ├── request_client.py
    │   └── user_agent.py
    ├── sink
    │   ├── __init__.py
    │   ├── dataset_sink.py
    │   ├── excel_sink.py
    │   ├── json_sink.py
    │   ├── momgo_sink.py
    │   ├── mysql_sink.py
    │   ├── sink_helper.py
    │   └── sqlite_sink.py
    └── utils
        ├── __init__.py
        └── thread_local_obj.py

`````

---


## funboost (relative dir: `boost_spider`)  Included Files (total: 14 files)


- `boost_spider/__init__.py`

- `boost_spider/http/request_client.py`

- `boost_spider/http/user_agent.py`

- `boost_spider/http/__init__.py`

- `boost_spider/sink/dataset_sink.py`

- `boost_spider/sink/excel_sink.py`

- `boost_spider/sink/json_sink.py`

- `boost_spider/sink/momgo_sink.py`

- `boost_spider/sink/mysql_sink.py`

- `boost_spider/sink/sink_helper.py`

- `boost_spider/sink/sqlite_sink.py`

- `boost_spider/sink/__init__.py`

- `boost_spider/utils/thread_local_obj.py`

- `boost_spider/utils/__init__.py`


---


--- **start of file: boost_spider/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/__init__.py`

#### 📝 Module Docstring

`````
boost_spider
是一款自由奔放写法的爬虫框架，无任何束缚，和用户手写平铺直叙的爬虫函数一样，
是横冲直撞的思维写的, 不需要callback回调解析方法, 不需要继承BaseSpider类, 没有BaseSpider类, 大开大合自由奔放.
只需要加上boost装饰器就可以自动加速并发，控制手段比传统爬虫框架多太多
`````

#### 📦 Imports

- `from boost_spider.http.request_client import RequestClient`
- `from boost_spider.sink.momgo_sink import MongoSink`
- `from boost_spider.sink.mysql_sink import MysqlSink`
- `from funboost import *`
- `import json`
- `import re`


---

`````python
"""
boost_spider
是一款自由奔放写法的爬虫框架，无任何束缚，和用户手写平铺直叙的爬虫函数一样，
是横冲直撞的思维写的, 不需要callback回调解析方法, 不需要继承BaseSpider类, 没有BaseSpider类, 大开大合自由奔放.
只需要加上boost装饰器就可以自动加速并发，控制手段比传统爬虫框架多太多
"""

from boost_spider.http.request_client import RequestClient
from boost_spider.sink.momgo_sink import MongoSink
from boost_spider.sink.mysql_sink import MysqlSink
from funboost import *

import json
import re
`````

--- **end of file: boost_spider/__init__.py** (project: funboost) --- 

---


--- **start of file: boost_spider/http/request_client.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/http/request_client.py`

#### 📝 Module Docstring

`````
改版包装requests的Session类，主要使用的是代理模式
1、支持一键设多种代理ip
2、支持3种类型的cookie添加
3、支持长会话，保持cookie状态, ss = RequestClient() , 一直用这个ss对象就可以自动保持cookie了
4、支持一键设置requests请求重试次数，确保请求成功，默认重试一次。
5、记录下当天的请求到文件，方便统计，同时开放了日志级别设置参数，用于禁止日志。
6、从使用requests修改为使用RequstClient门槛很低，三方包的request方法和此类的方法入参和返回完全100%保持了一致。
7、支持多个代理厂商自动切换。需要将proxy_name设置为一个列表，指定多个代理厂商的名字。
8、支持继承 RequestClient 来增加使用各种代理的请求方法，新增加代理商后，将请求方法名字加到 PROXYNAME__REQUEST_METHED_MAP 中。
`````

#### 📦 Imports

- `import json`
- `import logging`
- `import typing`
- `from enum import Enum`
- `from functools import lru_cache`
- `from pathlib import Path`
- `import nb_log`
- `import copy`
- `import time`
- `from typing import Union`
- `import requests`
- `from requests.cookies import RequestsCookieJar`
- `import urllib3.exceptions`
- `from boost_spider.http.user_agent import rand_get_useragent`
- `from parsel import Selector`
- `import re`

#### 🏛️ Classes (3)

##### 📌 `class HttpStatusError(Exception)`
*Line: 35*

**🔧 Constructor (`__init__`):**
- `def __init__(self, http_status_code)`
  - **Parameters:**
    - `self`
    - `http_status_code`

##### 📌 `class SpiderResponse(requests.Response)`
*Line: 43*

**🔧 Constructor (`__init__`):**
- `def __init__(self, resp: requests.Response)`
  - **Parameters:**
    - `self`
    - `resp: requests.Response`

**Public Methods (4):**
- `def re_search(self, pattern, flags = 0)`
- `def re_findall(self, pattern, flags = 0)`
- `def xpath(self, query)`
- `def css(self, query)`

**Properties (3):**
- `@property selector -> Selector`
- `@property resp_dict -> typing.Dict`
- `@property text -> str`

**Class Variables (1):**
- `re_pattern_map = {}`

##### 📌 `class RequestClient`
*Line: 89*

**🔧 Constructor (`__init__`):**
- `def __init__(self, proxy_name_list = None, ua = None, default_use_pc_ua = True, is_change_ua_every_request = False, timeout: Union[tuple, float] = (30, 40), verify = False, allow_redirects = True, is_close_session = True, request_retry_times = 2, using_platfrom = '')`
  - **Docstring:**
  `````
  :param proxy_name_list: 轮流使用代理服务商名字，可设置为 None,'noproxy', 'kuai', 'abuyun', 'crawlera',为None不使用代理
  :param ua:  useragent，如果不设置就随机分配一个欺骗的
  :param is_change_ua_every_request: 为每次请求设置新的useragent
  :param timeout: 超时设置
  :param verify:  是否校验服务器证书
  :param allow_redirects
  :param is_close_session: 是否在请求后关闭会话，连续型的请求需要cookie保持的，请设置为False，并且一直使用RequestClient实例化后的对象
  :param logger_level:日志级别，10 20 30 40 50
  `````
  - **Parameters:**
    - `self`
    - `proxy_name_list = None`
    - `ua = None`
    - `default_use_pc_ua = True`
    - `is_change_ua_every_request = False`
    - `timeout: Union[tuple, float] = (30, 40)`
    - `verify = False`
    - `allow_redirects = True`
    - `is_close_session = True`
    - `request_retry_times = 2`
    - `using_platfrom = ''`

**Public Methods (9):**
- `def get_cookie_jar(self)`
  - *返回cookiejar*
- `def get_cookie_dict(self)`
  - *返回cookie字典*
- `def get_cookie_str(self)`
  - *返回cookie字典*
- `def add_cookies(self, cookies: Union[str, dict, RequestsCookieJar])`
  - **Docstring:**
  `````
  :param cookies: 浏览器复制的cookie字符串或字典类型或者CookieJar类型
  :return:
  `````
- `def request(self, method: str, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs) -> typing.Optional[SpiderResponse]`
  - **Docstring:**
  `````
  使用指定名字的代理请求,从_proxy_name读取,当请求出错时候轮流使用各种代理ip。
  :param method:
  :param url:
  :param verify:
  :param timeout:
  :param headers:
  :param cookies:
  :param kwargs:
  :param kwargs :可接受一切requests.request方法中的参数
  :return:
  `````
- `def get(self, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs)`
- `def post(self, url: str, verify: bool = None, timeout: Union[int, float, tuple] = None, headers: dict = None, cookies: dict = None, **kwargs)`
- `def close_session(self)`
- `def save_picture(self, url, pic_path, pic_file = None)`

**Class Variables (5):**
- `logger = request_logger`
- `PROXY_NOPROXY = 'noproxy'`
- `PROXY_ABUYUN = 'abuyun'`
- `PROXY_KUAI = 'kuai'`
- `PROXYNAME__REQUEST_METHED_MAP = {'noproxy': _request_with_no_proxy, 'abuyun': _request_with_abuyun_proxy, 'kuai': _request_with_kuai_proxy}`


---

`````python
# coding=utf-8
"""
改版包装requests的Session类，主要使用的是代理模式
1、支持一键设多种代理ip
2、支持3种类型的cookie添加
3、支持长会话，保持cookie状态, ss = RequestClient() , 一直用这个ss对象就可以自动保持cookie了
4、支持一键设置requests请求重试次数，确保请求成功，默认重试一次。
5、记录下当天的请求到文件，方便统计，同时开放了日志级别设置参数，用于禁止日志。
6、从使用requests修改为使用RequstClient门槛很低，三方包的request方法和此类的方法入参和返回完全100%保持了一致。
7、支持多个代理厂商自动切换。需要将proxy_name设置为一个列表，指定多个代理厂商的名字。
8、支持继承 RequestClient 来增加使用各种代理的请求方法，新增加代理商后，将请求方法名字加到 PROXYNAME__REQUEST_METHED_MAP 中。
"""
import json
import logging
import typing
from enum import Enum
from functools import lru_cache
from pathlib import Path

import nb_log
import copy
import time
from typing import Union
import requests
from requests.cookies import RequestsCookieJar
import urllib3.exceptions

from boost_spider.http.user_agent import rand_get_useragent

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
from parsel import Selector
import re


class HttpStatusError(Exception):
    def __init__(self, http_status_code):
        super().__init__(f'请求返回的状态码不是200，是{http_status_code}')


request_logger = nb_log.get_logger('RequestClient', log_level_int=logging.DEBUG)


class SpiderResponse(requests.Response):  # 继承主要是方便代码补全提示，
    # noinspection PyMissingConstructor

    re_pattern_map = {}  # type: typing.Dict[str,re.Pattern]

    def __init__(self, resp: requests.Response):
        self.__dict__.update(resp.__dict__)  # 使 SpiderResponse 类具备requests.Response的所有属性

    @property
    @lru_cache()
    def selector(self) -> Selector:
        return Selector(self.text)

    @property
    @lru_cache()
    def resp_dict(self) -> typing.Dict:
        return json.loads(self.text)

    @property
    @lru_cache()
    def text(self) -> str:
        return super().text

    def re_search(self, pattern, flags=0):
        key = f'{pattern} {flags}'
        if key not in self.re_pattern_map:
            pa_obj = re.compile(pattern=pattern, flags=flags)
            self.re_pattern_map[key] = pa_obj
        return self.re_pattern_map[key].search(self.text)

    def re_findall(self, pattern, flags=0):
        # return re.findall(pattern, self.text, flags)
        key = f'{pattern} {flags}'
        if key not in self.re_pattern_map:
            pa_obj = re.compile(pattern=pattern, flags=flags)
            self.re_pattern_map[key] = pa_obj
        return self.re_pattern_map[key].findall(self.text)

    def xpath(self, query):
        return self.selector.xpath(query)

    def css(self, query):
        return self.selector.css(query)


# noinspection PyBroadException
class RequestClient:
    logger = request_logger

    def __init__(self, proxy_name_list=None,
                 ua=None, default_use_pc_ua=True, is_change_ua_every_request=False,
                 timeout: Union[tuple, float] = (30, 40),
                 verify=False, allow_redirects=True, is_close_session=True,
                 request_retry_times=2,
                 using_platfrom=''):
        """
        :param proxy_name_list: 轮流使用代理服务商名字，可设置为 None,'noproxy', 'kuai', 'abuyun', 'crawlera',为None不使用代理
        :param ua:  useragent，如果不设置就随机分配一个欺骗的
        :param is_change_ua_every_request: 为每次请求设置新的useragent
        :param timeout: 超时设置
        :param verify:  是否校验服务器证书
        :param allow_redirects
        :param is_close_session: 是否在请求后关闭会话，连续型的请求需要cookie保持的，请设置为False，并且一直使用RequestClient实例化后的对象
        :param logger_level:日志级别，10 20 30 40 50
        """
        if proxy_name_list is None:
            proxy_name_list = ['noproxy']
        if not isinstance(proxy_name_list, list):
            proxy_name_list = [proxy_name_list]
        if not set(proxy_name_list).issubset(set(self.PROXYNAME__REQUEST_METHED_MAP.keys())):
            raise Exception('设置的代理名称错误')
        self._proxy_name_list = proxy_name_list
        default_ua = (
            'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36' if default_use_pc_ua else
            'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Mobile Safari/537.36')
        self._ua = ua if ua else default_ua
        self._default_use_pc_ua = default_use_pc_ua
        self._is_change_ua_every_request = is_change_ua_every_request
        self._timeout = timeout
        self._verify = verify
        self._allow_redirects = allow_redirects
        self._is_close_session = is_close_session
        self.ss = requests.Session()
        self._max_request_retry_times = request_retry_times
        self._using_platfrom = using_platfrom

    def __add_ua_to_headers(self, headers):
        # noinspection PyDictCreation
        if not headers:
            headers = dict()
            headers['user-agent'] = self._ua
        else:
            if 'user-agent' not in headers and 'User-Agent' not in headers:
                headers['user-agent'] = self._ua
        if self._is_change_ua_every_request:
            if self._default_use_pc_ua:
                headers['user-agent'] = rand_get_useragent('chrome')
            else:
                headers['user-agent'] = rand_get_useragent('mobile')
        headers.update({'Accept-Language': 'zh-CN,zh;q=0.8'})
        return headers

    def get_cookie_jar(self):
        """返回cookiejar"""
        return self.ss.cookies

    def get_cookie_dict(self):
        """返回cookie字典"""
        return self.ss.cookies.get_dict()

    def get_cookie_str(self):
        """返回cookie字典"""
        cookie_str = ''
        for cookie_item in self.get_cookie_dict().items():
            cookie_str += cookie_item[0] + '=' + cookie_item[1] + ';'
        return cookie_str[:-1]

    def add_cookies(self, cookies: Union[str, dict, RequestsCookieJar]):
        """
        :param cookies: 浏览器复制的cookie字符串或字典类型或者CookieJar类型
        :return:
        """
        cookies_dict = dict()
        if not isinstance(cookies, (str, dict, RequestsCookieJar)):
            raise TypeError('传入的cookie类型错误')
        if isinstance(cookies, str):
            cookie_pairs = cookies.split('; ')
            for cookie_pair in cookie_pairs:
                k, v = cookie_pair.split('=', maxsplit=1)
                cookies_dict[k] = v
        if isinstance(cookies, (dict, RequestsCookieJar)):
            cookies_dict = cookies
        self.ss.cookies = requests.sessions.merge_cookies(self.ss.cookies, cookies_dict)

    def request(self, method: str, url: str, verify: bool = None,
                timeout: Union[int, float, tuple] = None, headers: dict = None,
                cookies: dict = None, **kwargs) -> typing.Optional[SpiderResponse]:
        """
        使用指定名字的代理请求,从_proxy_name读取,当请求出错时候轮流使用各种代理ip。
        :param method:
        :param url:
        :param verify:
        :param timeout:
        :param headers:
        :param cookies:
        :param kwargs:
        :param kwargs :可接受一切requests.request方法中的参数
        :return:
        """
        # self.logger.debug(locals())
        key_word_args = copy.copy(locals())
        key_word_args['headers'] = self.__add_ua_to_headers(headers)
        # key_word_args.pop('self')
        key_word_args.pop('kwargs')
        key_word_args.update(kwargs)
        if 'allow_redirects' not in key_word_args:
            key_word_args['allow_redirects'] = self._allow_redirects

        resp = None
        # self.logger.debug('starting {} this url -->  '.format(method) + url)
        # print(key_word_args)
        exception_request = None
        proxy_list = self._proxy_name_list * (self._max_request_retry_times + 1)
        for i in range(self._max_request_retry_times + 1):
            current_proxy_name = proxy_list[i]
            t_start = time.time()
            try:
                request_proxy_method = self.PROXYNAME__REQUEST_METHED_MAP[current_proxy_name]
                resp = request_proxy_method(**key_word_args)
                time_spend = round(time.time() - t_start, 2)
                resp.time_spend = time_spend
                resp.ts = time_spend  # 简写
                resp_log_dict = {
                    'time_spend': round(time_spend, 2),
                    'status_code': resp.status_code,
                    'method': method,
                    'current_retry_time': i,
                    'current_proxy_name': current_proxy_name,
                    'is_redirect': resp.is_redirect,
                    'resp_len': len(resp.text),
                    'resp_url': resp.url,
                }
                msg = f''' {self._using_platfrom}  request响应状态: {json.dumps(resp_log_dict, ensure_ascii=False)}'''
                self.logger.debug(msg, extra=resp_log_dict)
                if resp.status_code != 200 and i < self._max_request_retry_times + 1:
                    self.logger.warning(msg, extra=resp_log_dict)
                    raise HttpStatusError(resp.status_code)
                if i != 0:
                    pass
                    # self.logger.info(f'第 {i} 次重试请求成功')
                break
            except Exception as e:
                exception_request = e
                if i != self._max_request_retry_times:
                    self.logger.warning(
                        f'{self._using_platfrom} RequestClient内部第{i}次请求出错，此次使用的代理是{current_proxy_name}, url: {url}'
                        f'浪费时间[{round(time.time() - t_start, 2)}],再重试一次，原因是：{type(e)}    {e}')
        self.close_session()
        if resp is not None:  # 如<Response [404]>也是false,但不是none
            return SpiderResponse(resp)
        else:
            raise exception_request

    def get(self, url: str, verify: bool = None,
            timeout: Union[int, float, tuple] = None, headers: dict = None,
            cookies: dict = None, **kwargs):
        params = copy.copy(locals())
        params.pop('self')
        params.pop('kwargs')
        params.update(kwargs)
        params['method'] = 'get'
        return self.request(**params)

    def post(self, url: str, verify: bool = None,
             timeout: Union[int, float, tuple] = None, headers: dict = None,
             cookies: dict = None, **kwargs):
        params = copy.copy(locals())
        params.pop('self')
        params.pop('kwargs')
        params.update(kwargs)
        params['method'] = 'post'
        return self.request(**params)

    def close_session(self):
        if self._is_close_session:
            try:
                self.ss.close()
            except Exception:
                pass

    def save_picture(self, url, pic_path, pic_file=None, ):
        resp = self.get(url)
        if pic_file is None:
            pic_file = url.split('/')[-1]
        Path(pic_path).mkdir(exist_ok=True)
        full_path = Path(pic_path) / Path(pic_file)
        full_path.write_bytes(resp.content)

    def _request_with_no_proxy(self, method, url, verify=None, timeout=None, headers=None, cookies=None, **kwargs):
        """普通不使用代理"""

        return self.ss.request(method, url, verify=verify or self._verify, timeout=timeout or self._timeout,
                               headers=headers, cookies=cookies, **kwargs)

    def _request_with_abuyun_proxy(self, method, url, verify=None, timeout=None, headers=None, cookies=None, **kwargs):
        # 代理服务器
        proxy_host = "http-dyn.abuyun.com"
        proxy_port = "9020"

        # 代理隧道验证信息
        proxy_user = "HH65YN4C381XXXXX"
        proxy_pass = "7176BE32A00YYYYY"

        proxy_meta = "http://%(user)s:%(pass)s@%(host)s:%(port)s" % {
            "host": proxy_host,
            "port": proxy_port,
            "user": proxy_user,
            "pass": proxy_pass,
        }

        proxies = {
            "http": proxy_meta,
            "https": proxy_meta,
        }
        resp = self.ss.request(method, url, verify=verify or self._verify, timeout=timeout or self._timeout,
                               headers=headers, cookies=cookies,
                               proxies=proxies, **kwargs)
        if resp.status_code == 429 or "429 Too Many Requests'" in resp.text or "429 To Many Requests'" in resp.text:
            raise IOError(f'阿布云返回的状态是 {resp.status_code}')
        return resp

    def _request_with_kuai_proxy(self, method, url, verify=None, timeout=None, headers=None, cookies=None, **kwargs):
        """使用redis中的快代理池子,怎么从redis拿代理ip和requests怎么使用代理，用户自己写"""

        raise NotImplemented


    PROXY_NOPROXY = 'noproxy'  # 方便代理名称补全.
    PROXY_ABUYUN = 'abuyun'
    PROXY_KUAI = 'kuai'

    PROXYNAME__REQUEST_METHED_MAP = {'noproxy': _request_with_no_proxy,
                                     'abuyun': _request_with_abuyun_proxy,
                                     'kuai': _request_with_kuai_proxy
                                     }  # 用户新增了方法后，在这里添加代理名字和请求方法的映射映射

    """
    用户可以继承 RequestClient ,增加代理商的ip使用方法,然后在 PROXYNAME__REQUEST_METHED_MAP 新增代理商名字 对应的 方法名 映射 ,
    根据入参 proxy_name_list 的 代理商名字, 自动轮流使用用户自己的各个ip代理商 发请求.
    """

    """
# 扩展方式例如:
    
class MyRequestClient(RequestClient):

    def _request_with_my_redis_ip_proxy(self, method, url, **kwargs):
        # 实现你自己的代理逻辑
      
        proxies = {
            "http": $从你的redis ip代理池随机取一个ip,
            "https": $从你的redis ip代理池随机取一个ip,
        }
        return self.ss.request(method, url, proxies=proxies, **kwargs)
    
    # 扩展代理映射
    RequestClient.PROXYNAME__REQUEST_METHED_MAP['my_proxy'] = _request_with_my_redis_ip_proxy
  
    """


if __name__ == '__main__':
    rc = RequestClient(using_platfrom='爬百度的')
    resp = rc.get('https://www.baidu.com')
    print(resp.request.headers)
    print(resp.status_code)
    print(resp.selector)
    print(resp.selector)

    rc.save_picture('https://scarb-images.oss-cn-hangzhou.aliyuncs.com/img/202207142159934.png', '/pics')

`````

--- **end of file: boost_spider/http/request_client.py** (project: funboost) --- 

---


--- **start of file: boost_spider/http/user_agent.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/http/user_agent.py`

#### 📝 Module Docstring

`````
Created on 2016-12-28 17:55
---------
@summary:
---------
@author: Boris
@email: boris_liu@foxmail.com
`````

#### 📦 Imports

- `import random`
- `import typing`

#### 🔧 Public Functions (1)

- `def rand_get_useragent(ua_type: str = None)`
  - *Line: 382*
  - **Docstring:**
  `````
  :param ua_type:  chrome  firefox opera internetexplorer safari  mobile
  :return:
  `````


---

`````python
# -*- coding: utf-8 -*-
"""
Created on 2016-12-28 17:55
---------
@summary:
---------
@author: Boris
@email: boris_liu@foxmail.com
"""

import random
import typing

USER_AGENTS = {
    "chrome": [
        "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2226.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.4; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2225.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2224.3 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.93 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.124 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 4.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.67 Safari/537.36",
        "Mozilla/5.0 (X11; OpenBSD i386) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1944.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.3319.102 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2309.372 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.2117.157 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1866.237 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.137 Safari/4E423F",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.517 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1667.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1664.3 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1664.3 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.16 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1623.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/30.0.1599.17 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.62 Safari/537.36",
        "Mozilla/5.0 (X11; CrOS i686 4319.74.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.57 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.2 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1468.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1467.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1464.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1500.55 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36",
        "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.90 Safari/537.36",
        "Mozilla/5.0 (X11; NetBSD) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36",
        "Mozilla/5.0 (X11; CrOS i686 3912.101.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36",
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.60 Safari/537.17",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1309.0 Safari/537.17",
        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.15 (KHTML, like Gecko) Chrome/24.0.1295.0 Safari/537.15",
        "Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.14 (KHTML, like Gecko) Chrome/24.0.1292.0 Safari/537.14",
    ],
    "opera": [
        "Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16",
        "Opera/9.80 (Windows NT 6.0) Presto/2.12.388 Version/12.14",
        "Mozilla/5.0 (Windows NT 6.0; rv:2.0) Gecko/20100101 Firefox/4.0 Opera 12.14",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0) Opera 12.14",
        "Opera/12.80 (Windows NT 5.1; U; en) Presto/2.10.289 Version/12.02",
        "Opera/9.80 (Windows NT 6.1; U; es-ES) Presto/2.9.181 Version/12.00",
        "Opera/9.80 (Windows NT 5.1; U; zh-sg) Presto/2.9.181 Version/12.00",
        "Opera/12.0(Windows NT 5.2;U;en)Presto/22.9.168 Version/12.00",
        "Opera/12.0(Windows NT 5.1;U;en)Presto/22.9.168 Version/12.00",
        "Mozilla/5.0 (Windows NT 5.1) Gecko/20100101 Firefox/14.0 Opera/12.0",
        "Opera/9.80 (Windows NT 6.1; WOW64; U; pt) Presto/2.10.229 Version/11.62",
        "Opera/9.80 (Windows NT 6.0; U; pl) Presto/2.10.229 Version/11.62",
        "Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52",
        "Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; de) Presto/2.9.168 Version/11.52",
        "Opera/9.80 (Windows NT 5.1; U; en) Presto/2.9.168 Version/11.51",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; de) Opera 11.51",
        "Opera/9.80 (X11; Linux x86_64; U; fr) Presto/2.9.168 Version/11.50",
        "Opera/9.80 (X11; Linux i686; U; hu) Presto/2.9.168 Version/11.50",
        "Opera/9.80 (X11; Linux i686; U; ru) Presto/2.8.131 Version/11.11",
        "Opera/9.80 (X11; Linux i686; U; es-ES) Presto/2.8.131 Version/11.11",
        "Mozilla/5.0 (Windows NT 5.1; U; en; rv:1.8.1) Gecko/20061208 Firefox/5.0 Opera 11.11",
        "Opera/9.80 (X11; Linux x86_64; U; bg) Presto/2.8.131 Version/11.10",
        "Opera/9.80 (Windows NT 6.0; U; en) Presto/2.8.99 Version/11.10",
        "Opera/9.80 (Windows NT 5.1; U; zh-tw) Presto/2.8.131 Version/11.10",
        "Opera/9.80 (Windows NT 6.1; Opera Tablet/15165; U; en) Presto/2.8.149 Version/11.1",
        "Opera/9.80 (X11; Linux x86_64; U; Ubuntu/10.10 (maverick); pl) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (X11; Linux i686; U; ja) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (X11; Linux i686; U; fr) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 6.1; U; zh-tw) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 6.1; U; zh-cn) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 6.1; U; sv) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 6.1; U; en-US) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 6.1; U; cs) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 6.0; U; pl) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 5.2; U; ru) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 5.1; U;) Presto/2.7.62 Version/11.01",
        "Opera/9.80 (Windows NT 5.1; U; cs) Presto/2.7.62 Version/11.01",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.2.13) Gecko/20101213 Opera/9.80 (Windows NT 6.1; U; zh-tw) Presto/2.7.62 Version/11.01",
        "Mozilla/5.0 (Windows NT 6.1; U; nl; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 Opera 11.01",
        "Mozilla/5.0 (Windows NT 6.1; U; de; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 Opera 11.01",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; de) Opera 11.01",
        "Opera/9.80 (X11; Linux x86_64; U; pl) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (X11; Linux i686; U; it) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (Windows NT 6.1; U; zh-cn) Presto/2.6.37 Version/11.00",
        "Opera/9.80 (Windows NT 6.1; U; pl) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (Windows NT 6.1; U; ko) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (Windows NT 6.1; U; fi) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (Windows NT 6.1; U; en-GB) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (Windows NT 6.1 x64; U; en) Presto/2.7.62 Version/11.00",
        "Opera/9.80 (Windows NT 6.0; U; en) Presto/2.7.39 Version/11.00",
    ],
    "firefox": [
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.1",
        "Mozilla/5.0 (Windows NT 6.3; rv:36.0) Gecko/20100101 Firefox/36.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10; rv:33.0) Gecko/20100101 Firefox/33.0",
        "Mozilla/5.0 (X11; Linux i586; rv:31.0) Gecko/20100101 Firefox/31.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:31.0) Gecko/20130401 Firefox/31.0",
        "Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:29.0) Gecko/20120101 Firefox/29.0",
        "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:25.0) Gecko/20100101 Firefox/29.0",
        "Mozilla/5.0 (X11; OpenBSD amd64; rv:28.0) Gecko/20100101 Firefox/28.0",
        "Mozilla/5.0 (X11; Linux x86_64; rv:28.0) Gecko/20100101  Firefox/28.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:27.3) Gecko/20130101 Firefox/27.3",
        "Mozilla/5.0 (Windows NT 6.2; Win64; x64; rv:27.0) Gecko/20121011 Firefox/27.0",
        "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:25.0) Gecko/20100101 Firefox/25.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:25.0) Gecko/20100101 Firefox/25.0",
        "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0",
        "Mozilla/5.0 (Windows NT 6.0; WOW64; rv:24.0) Gecko/20100101 Firefox/24.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:24.0) Gecko/20100101 Firefox/24.0",
        "Mozilla/5.0 (Windows NT 6.2; rv:22.0) Gecko/20130405 Firefox/23.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20130406 Firefox/23.0",
        "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:23.0) Gecko/20131011 Firefox/23.0",
        "Mozilla/5.0 (Windows NT 6.2; rv:22.0) Gecko/20130405 Firefox/22.0",
        "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:22.0) Gecko/20130328 Firefox/22.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:22.0) Gecko/20130405 Firefox/22.0",
        "Mozilla/5.0 (Microsoft Windows NT 6.2.9200.0); rv:22.0) Gecko/20130405 Firefox/22.0",
        "Mozilla/5.0 (Windows NT 6.2; Win64; x64; rv:16.0.1) Gecko/20121011 Firefox/21.0.1",
        "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:16.0.1) Gecko/20121011 Firefox/21.0.1",
        "Mozilla/5.0 (Windows NT 6.2; Win64; x64; rv:21.0.0) Gecko/20121011 Firefox/21.0.0",
        "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:21.0) Gecko/20130331 Firefox/21.0",
        "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (X11; Linux i686; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.2; WOW64; rv:21.0) Gecko/20130514 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.2; rv:21.0) Gecko/20130326 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20130401 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20130331 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20130330 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:21.0) Gecko/20130401 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:21.0) Gecko/20130328 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 5.1; rv:21.0) Gecko/20130401 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 5.1; rv:21.0) Gecko/20130331 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 5.1; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 5.0; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:21.0) Gecko/20100101 Firefox/21.0",
        "Mozilla/5.0 (Windows NT 6.2; Win64; x64;) Gecko/20100101 Firefox/20.0",
        "Mozilla/5.0 (Windows x86; rv:19.0) Gecko/20100101 Firefox/19.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:6.0) Gecko/20100101 Firefox/19.0",
        "Mozilla/5.0 (Windows NT 6.1; rv:14.0) Gecko/20100101 Firefox/18.0.1",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:18.0)  Gecko/20100101 Firefox/18.0",
        "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:17.0) Gecko/20100101 Firefox/17.0.6",
    ],
    "internetexplorer": [
        "Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like Gecko",
        "Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0;  rv:11.0) like Gecko",
        "Mozilla/5.0 (compatible; MSIE 10.6; Windows NT 6.1; Trident/5.0; InfoPath.2; SLCC1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 2.0.50727) 3gpp-gba UNTRUSTED/1.0",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 7.0; InfoPath.3; .NET CLR 3.1.40767; Trident/6.0; en-IN)",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/5.0)",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/4.0; InfoPath.2; SV1; .NET CLR 2.0.50727; WOW64)",
        "Mozilla/5.0 (compatible; MSIE 10.0; Macintosh; Intel Mac OS X 10_7_3; Trident/6.0)",
        "Mozilla/4.0 (Compatible; MSIE 8.0; Windows NT 5.2; Trident/6.0)",
        "Mozilla/4.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/5.0)",
        "Mozilla/1.22 (compatible; MSIE 10.0; Windows 3.1)",
        "Mozilla/5.0 (Windows; U; MSIE 9.0; WIndows NT 9.0; en-US))",
        "Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 7.1; Trident/5.0)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; Media Center PC 6.0; InfoPath.3; MS-RTC LM 8; Zune 4.7)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; Media Center PC 6.0; InfoPath.3; MS-RTC LM 8; Zune 4.7",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; Zune 4.0; InfoPath.3; MS-RTC LM 8; .NET4.0C; .NET4.0E)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 2.0.50727; SLCC2; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; Zune 4.0; Tablet PC 2.0; InfoPath.3; .NET4.0C; .NET4.0E)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; yie8)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.2; .NET CLR 1.1.4322; .NET4.0C; Tablet PC 2.0)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; FunWebProducts)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; chromeframe/13.0.782.215)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0; chromeframe/11.0.696.57)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0) chromeframe/10.0.648.205",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/4.0; GTB7.4; InfoPath.1; SV1; .NET CLR 2.8.52393; WOW64; en-US)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0; chromeframe/11.0.696.57)",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/4.0; GTB7.4; InfoPath.3; SV1; .NET CLR 3.1.76908; WOW64; en-US)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0; GTB7.4; InfoPath.2; SV1; .NET CLR 3.3.69573; WOW64; en-US)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; InfoPath.1; SV1; .NET CLR 3.8.36217; WOW64; en-US)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; .NET CLR 2.7.58687; SLCC2; Media Center PC 5.0; Zune 3.4; Tablet PC 3.6; InfoPath.3)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.2; Trident/4.0; Media Center PC 4.0; SLCC1; .NET CLR 3.0.04320)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SLCC1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 1.1.4322)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; InfoPath.2; SLCC1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 2.0.50727)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.50727)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.1; SLCC1; .NET CLR 1.1.4322)",
        "Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.0; Trident/4.0; InfoPath.1; SV1; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; .NET CLR 3.0.04506.30)",
        "Mozilla/5.0 (compatible; MSIE 7.0; Windows NT 5.0; Trident/4.0; FBSMTWB; .NET CLR 2.0.34861; .NET CLR 3.0.3746.3218; .NET CLR 3.5.33652; msn OptimizedIE8;ENUS)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.2; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; Media Center PC 6.0; InfoPath.2; MS-RTC LM 8)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; Media Center PC 6.0; InfoPath.2; MS-RTC LM 8",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; Media Center PC 6.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET4.0C)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; InfoPath.3; .NET4.0C; .NET4.0E; .NET CLR 3.5.30729; .NET CLR 3.0.30729; MS-RTC LM 8)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; InfoPath.2)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; Zune 3.0)",
    ],
    "safari": [
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/537.13+ (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/534.55.3 (KHTML, like Gecko) Version/5.1.3 Safari/534.53.10",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; de-at) AppleWebKit/533.21.1 (KHTML, like Gecko) Version/5.0.5 Safari/533.21.1",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_7; da-dk) AppleWebKit/533.21.1 (KHTML, like Gecko) Version/5.0.5 Safari/533.21.1",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; tr-TR) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; ko-KR) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; fr-FR) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; cs-CZ) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; ja-JP) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; PPC Mac OS X 10_5_8; zh-cn) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; PPC Mac OS X 10_5_8; ja-jp) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_7; ja-jp) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; zh-cn) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; sv-se) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; ko-kr) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; ja-jp) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; it-it) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; fr-fr) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; es-es) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; en-us) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; en-gb) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; de-de) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.4 Safari/533.20.27",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; sv-SE) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; ja-JP) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; de-DE) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; hu-HU) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; de-DE) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 5.1; ru-RU) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 5.1; ja-JP) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 5.1; it-IT) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/533.20.25 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_7; en-us) AppleWebKit/534.16+ (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; fr-ch) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_5; de-de) AppleWebKit/534.15+ (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_5; ar) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Android 2.2; Windows; U; Windows NT 6.1; en-US) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.3 Safari/533.19.4",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; zh-HK) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; tr-TR) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; nb-NO) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Windows; U; Windows NT 6.0; fr-FR) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-TW) AppleWebKit/533.19.4 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Windows; U; Windows NT 5.1; ru-RU) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_8; zh-cn) AppleWebKit/533.18.1 (KHTML, like Gecko) Version/5.0.2 Safari/533.18.5",
    ],
    "mobile": [
        "Mozilla/5.0 (PlayBook; U; RIM Tablet OS 2.1.0; en-US) AppleWebKit/536.2+ (KHTML like Gecko) Version/14.2 Safari/536.2+",
        "Mozilla/5.0 (PlayBook; U; RIM Tablet OS 2.1.0; en-US) AppleWebKit/536.2+ (KHTML like Gecko) Version/14.2 Safari/536.2+",
        "Mozilla/5.0 (BB10; Touch) AppleWebKit/537.10+ (KHTML, like Gecko) Version/14.2 Mobile Safari/537.10+",
        "Mozilla/5.0 (BB10; Touch) AppleWebKit/537.10+ (KHTML, like Gecko) Version/14.2 Mobile Safari/537.10+",
        "Mozilla/5.0 (Linux; U; Android 4.3; en-us; SM-N900T Build/JSS15J) AppleWebKit/534.30 (KHTML, like Gecko) Version/14.2 Mobile Safari/534.30",
        "Mozilla/5.0 (Linux; U; Android 4.3; en-us; SM-N900T Build/JSS15J) AppleWebKit/534.30 (KHTML, like Gecko) Version/14.2 Mobile Safari/534.30",
        "Mozilla/5.0 (Linux; U; Android 4.1; en-us; GT-N7100 Build/JRO03C) AppleWebKit/534.30 (KHTML, like Gecko) Version/14.2 Mobile Safari/534.30",
        "Mozilla/5.0 (Linux; U; Android 4.1; en-us; GT-N7100 Build/JRO03C) AppleWebKit/534.30 (KHTML, like Gecko) Version/14.2 Mobile Safari/534.30",
        "Mozilla/5.0 (Linux; U; Android 4.0; en-us; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/14.2 Mobile Safari/534.30",
        "Mozilla/5.0 (Linux; U; Android 4.0; en-us; GT-I9300 Build/IMM76D) AppleWebKit/534.30 (KHTML, like Gecko) Version/14.2 Mobile Safari/534.30",
        "Mozilla/5.0 (Linux; Android 5.0; SM-G900P Build/LRX21T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 5.0; SM-G900P Build/LRX21T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 7.0; SM-G950U Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 7.0; SM-G950U Build/NRD90M) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; SM-G965U Build/R16NW) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; SM-G965U Build/R16NW) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.1.0; SM-T837A) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.1.0; SM-T837A) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/14.2 Mobile/14E304 Safari/602.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 10_3_1 like Mac OS X) AppleWebKit/603.1.30 (KHTML, like Gecko) Version/14.2 Mobile/14E304 Safari/602.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/14.2 Mobile/15A372 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (iPhone; CPU iPhone OS 14_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Mobile/15E148 Safari/604.1",
        "Mozilla/5.0 (Mobile; LYF/F300B/LYF-F300B-001-01-15-130718-i;Android; rv:89.0 Gecko/48.0 Firefox/90.0 KAIOS/2.5",
        "Mozilla/5.0 (Mobile; LYF/F300B/LYF-F300B-001-01-15-130718-i;Android; rv:89.0 Gecko/48.0 Firefox/90.0 KAIOS/2.5",
        "Mozilla/5.0 (Linux; U; en-us; KFAPWI Build/JDQ39) AppleWebKit/535.19 (KHTML, like Gecko) Silk/3.13 Safari/535.19 Silk-Accelerated=true",
        "Mozilla/5.0 (Linux; U; en-us; KFAPWI Build/JDQ39) AppleWebKit/535.19 (KHTML, like Gecko) Silk/3.13 Safari/535.19 Silk-Accelerated=true",
        "Mozilla/5.0 (Linux; U; Android 4.4.2; en-us; LGMS323 Build/KOT49I.MS32310c) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; U; Android 4.4.2; en-us; LGMS323 Build/KOT49I.MS32310c) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Windows Phone 10.0; Android 4.2.1; Microsoft; Lumia 550) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36 Edge/14.14263",
        "Mozilla/5.0 (Windows Phone 10.0; Android 4.2.1; Microsoft; Lumia 550) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36 Edge/14.14263",
        "Mozilla/5.0 (Windows Phone 10.0; Android 4.2.1; Microsoft; Lumia 950) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36 Edge/14.14263",
        "Mozilla/5.0 (Windows Phone 10.0; Android 4.2.1; Microsoft; Lumia 950) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36 Edge/14.14263",
        "Mozilla/5.0 (Linux; Android 6.0.1; Nexus 10 Build/MOB31T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (Linux; Android 6.0.1; Nexus 10 Build/MOB31T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 4.4.2; Nexus 4 Build/KOT49H) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; Nexus 5X Build/OPR4.170623.006) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; Nexus 5X Build/OPR4.170623.006) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 7.1.1; Nexus 6 Build/N6F26U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 7.1.1; Nexus 6 Build/N6F26U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; Nexus 6P Build/OPP3.170518.006) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; Nexus 6P Build/OPP3.170518.006) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 6.0.1; Nexus 7 Build/MOB30X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (Linux; Android 6.0.1; Nexus 7 Build/MOB30X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 520)",
        "Mozilla/5.0 (compatible; MSIE 10.0; Windows Phone 8.0; Trident/6.0; IEMobile/10.0; ARM; Touch; NOKIA; Lumia 520)",
        "Mozilla/5.0 (MeeGo; NokiaN9) AppleWebKit/534.13 (KHTML, like Gecko) NokiaBrowser/8.5.0 Mobile Safari/534.13",
        "Mozilla/5.0 (MeeGo; NokiaN9) AppleWebKit/534.13 (KHTML, like Gecko) NokiaBrowser/8.5.0 Mobile Safari/534.13",
        "Mozilla/5.0 (Linux; Android 8.0; Pixel 2 Build/OPD3.170816.012) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0; Pixel 2 Build/OPD3.170816.012) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; Pixel 2 XL Build/OPD1.170816.004) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 8.0.0; Pixel 2 XL Build/OPD1.170816.004) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 9; Pixel 3 Build/PQ1A.181105.017.A1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 9; Pixel 3 Build/PQ1A.181105.017.A1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 10; Pixel 4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 10; Pixel 4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 11; Pixel 4a (5G)) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 11; Pixel 4a (5G)) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 11; Pixel 5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 11; Pixel 5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 7.0; Moto G (4)) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Linux; Android 7.0; Moto G (4)) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Mobile Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36 Edg/93.0.4576.0",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0 Gecko/20100101 Firefox/90.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.2 Safari/605.1.15",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4576.0 Safari/537.36 Edg/93.0.4576.0",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0 Gecko/20100101 Firefox/90.0",
    ],
}


def rand_get_useragent(ua_type: str = None):
    """

    :param ua_type:  chrome  firefox opera internetexplorer safari  mobile
    :return:
    """
    if not ua_type:
        ua_type = random.choice(list(USER_AGENTS.keys()))
    elif ua_type not in USER_AGENTS:
        raise ValueError(
            "ua_type error, expect one of {}".format(list(USER_AGENTS.keys()))
        )

    return random.choice(USER_AGENTS[ua_type])

`````

--- **end of file: boost_spider/http/user_agent.py** (project: funboost) --- 

---


--- **start of file: boost_spider/http/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/http/__init__.py`


---

`````python

`````

--- **end of file: boost_spider/http/__init__.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/dataset_sink.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/dataset_sink.py`

#### 📝 Module Docstring

`````
dataset 很适合保存一个字典到各种数据库 mysql postgre sqlite
`````

#### 📦 Imports

- `import dataset`

#### 🏛️ Classes (1)

##### 📌 `class DatasetSink`
*Line: 7*

**🔧 Constructor (`__init__`):**
- `def __init__(self, db_url)`
  - **Parameters:**
    - `self`
    - `db_url`

**Public Methods (2):**
- `def save(self, table_name: str, data: dict)`
- `def get_instance(cls, db_url)` `classmethod`

**Class Variables (2):**
- `_instances = {}`
- `_has__init_set = set()`


---

`````python
"""
dataset 很适合保存一个字典到各种数据库 mysql postgre sqlite
"""
import dataset


class DatasetSink:
    # 类级别的实例缓存，按 db_url 存储
    _instances = {}
    _has__init_set = set()

    def __new__(cls, db_url):
        # 如果 db_url 已存在，直接返回已有实例
        if db_url not in cls._instances:
            # 创建新实例并存入缓存
            self = super(DatasetSink, cls).__new__(cls)
            cls._instances[db_url] = self
        return cls._instances[db_url]

    def __init__(self, db_url):
        if id(self) not in self.__class__._has__init_set:
            print(f'创建连接 {db_url}')
            self.db = dataset.connect(db_url, ensure_schema=True)
            self.__class__._has__init_set.add(id(self))

    def save(self, table_name: str, data: dict, ):
        # 使用已有的连接插入数据
        table = self.db[table_name]
        table.insert(data)

    @classmethod
    def get_instance(cls, db_url):
        # 提供一个显式的获取实例方法（可选）
        return cls(db_url)


if __name__ == '__main__':
    dataset_sink1 = DatasetSink("mysql+pymysql://root:123456@localhost/testdb2")
    DatasetSink("mysql+pymysql://root:123456@localhost/testdb2")
    data = {'user': 'user2', 'oderid': 222}
    dataset_sink1.save('your_table', data)  # 使用第一个数据库

`````

--- **end of file: boost_spider/sink/dataset_sink.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/excel_sink.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/excel_sink.py`


---

`````python

`````

--- **end of file: boost_spider/sink/excel_sink.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/json_sink.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/json_sink.py`

#### 📦 Imports

- `import datetime`
- `import json`
- `import threading`
- `import time`
- `from pathlib import Path`
- `from boost_spider.sink.sink_helper import log_save_item`

#### 🏛️ Classes (1)

##### 📌 `class JsonFileSink`
*Line: 10*

**🔧 Constructor (`__init__`):**
- `def __init__(self, path, file)`
  - **Parameters:**
    - `self`
    - `path`
    - `file`

**Public Methods (2):**
- `def save(self, item: dict)`
- `def read_json(self)`

**Class Variables (2):**
- `_lock = threading.Lock()`
- `full_path__f_map = {}`


---

`````python
import datetime
import json
import threading
import time
from pathlib import Path

from boost_spider.sink.sink_helper import log_save_item


class JsonFileSink:
    _lock = threading.Lock()
    # path__has_create_map = {}
    full_path__f_map = {}

    def __init__(self, path, file):
        self.full_path = Path(path) / Path(file)
        self._key = f'{path}{file}'
        if self._key not in self.full_path__f_map:
            Path(path).mkdir(exist_ok=True)
            self.full_path__f_map[self._key] = Path(self.full_path).open('a+', encoding='utf8')
        self.f = self.full_path__f_map[self._key]

    def save(self, item: dict):
        item['item_insert_time'] = str(datetime.datetime.now())
        with self._lock:
            self.f.write(json.dumps(item) + ',\n')
        # log_save_item(item,'jsonfile',self.full_path,'')

    def read_json(self):
        text = Path(self.full_path).read_text(encoding='utf8')
        json_text = f'[{text[:-2]}]'
        return json.loads(json_text)


if __name__ == '__main__':
    t1 = time.time()
    for i in range(1000):
        # JsonFileSink('/codedir', 'testjsonfile2.json').save({'a': i, 'b': f'{i*2}'})
        JsonFileSink('/codedir', 'testjsonfile.json').save({'a': 63, 'b': 4})
        pass
    print(time.time() - t1)
    # print(JsonFileSink('/codedir', 'testjsonfile2.json').read_json())

`````

--- **end of file: boost_spider/sink/json_sink.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/momgo_sink.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/momgo_sink.py`

#### 📦 Imports

- `import os`
- `from pymongo.collection import Collection`
- `from pymongo import MongoClient`
- `from boost_spider.sink.sink_helper import log_save_item`

#### 🏛️ Classes (1)

##### 📌 `class MongoSink`
*Line: 12*

**🔧 Constructor (`__init__`):**
- `def __init__(self, db: str, col: str, uniqu_key: str, mongo_connect_url = 'mongodb://127.0.0.1')`
  - **Parameters:**
    - `self`
    - `db: str`
    - `col: str`
    - `uniqu_key: str`
    - `mongo_connect_url = 'mongodb://127.0.0.1'`

**Public Methods (2):**
- `def get_col(self) -> Collection`
  - *封装一个函数，判断pid*
- `def save(self, item)`

**Class Variables (1):**
- `pid__col_map = {}`


---

`````python
import os
from pymongo.collection import Collection
from pymongo import MongoClient
from boost_spider.sink.sink_helper import log_save_item

"""
此模块封装的pymongo是在linux上子进程安全的。
在win上无所谓都正常。
"""


class MongoSink:
    pid__col_map = {}

    def __init__(self, db: str, col: str, uniqu_key: str, mongo_connect_url='mongodb://127.0.0.1', ):
        self.db = db
        self.col = col
        self.uniqu_key = uniqu_key
        self.mongo_connect_url = mongo_connect_url

    def get_col(self, ) -> Collection:
        """封装一个函数，判断pid"""
        pid = os.getpid()
        key = (pid, self.mongo_connect_url, self.db, self.col)
        if key not in self.pid__col_map:
            self.pid__col_map[key] = MongoClient(self.mongo_connect_url).get_database(self.db).get_collection(self.col)
        return self.pid__col_map[key]

    def save(self, item):
        item['_id'] = item[self.uniqu_key]
        self.get_col().replace_one({'_id': item['_id']}, item, upsert=True)
        log_save_item(item, 'mongo', self.db, self.col)

`````

--- **end of file: boost_spider/sink/momgo_sink.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/mysql_sink.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/mysql_sink.py`

#### 📦 Imports

- `import typing`
- `import pymysql.cursors`
- `from universal_object_pool import ObjectPool`
- `from universal_object_pool.contrib.pymysql_pool import PyMysqlOperator`
- `from boost_spider.sink.sink_helper import log_save_item`

#### 🏛️ Classes (1)

##### 📌 `class MysqlSink`
*Line: 15*

**Docstring:**
`````
不推荐,使用dataset_sink 就好了.
`````

**🔧 Constructor (`__init__`):**
- `def __init__(self, host = '127.0.0.1', port = 3306, user = 'root', password = '123456', db = None, table = None)`
  - **Parameters:**
    - `self`
    - `host = '127.0.0.1'`
    - `port = 3306`
    - `user = 'root'`
    - `password = '123456'`
    - `db = None`
    - `table = None`

**Public Methods (1):**
- `def save(self, item: dict)`

**Class Variables (1):**
- `_key__pool_map = {}`


---

`````python

import typing

import pymysql.cursors
from universal_object_pool import ObjectPool
from universal_object_pool.contrib.pymysql_pool import PyMysqlOperator

from boost_spider.sink.sink_helper import log_save_item


"""
保存到 mysql,不推荐,直接 使用dataset_sink 就好了.
"""

class MysqlSink:
    """不推荐,使用dataset_sink 就好了."""
    _key__pool_map = {}

    def _get_pool(self):
        if self._pool_key not in self._key__pool_map:
            self._key__pool_map[self._pool_key] = ObjectPool(object_type=PyMysqlOperator,
                                                             object_pool_size=100,
                                                             object_init_kwargs=self._mysql_conn_kwargs)
        return self._key__pool_map[self._pool_key]

    def __init__(self, host='127.0.0.1', port=3306, user='root', password='123456', db=None, table=None):
        self._mysql_conn_kwargs = {'host': host, 'user': user, 'password': password, 'port': port,'database':db}
        self._pool_key = f'{host} {port} {user} {password} {db}'
        self.db = db
        self.table = table

    def save(self, item: dict):
        mysql_pool = self._get_pool()
        sql = self._build_sql(item)
        with mysql_pool.get() as operator:  # type: typing.Union[PyMysqlOperator,pymysql.cursors.DictCursor] #利于补全
            operator.execute(sql,args=None)
        log_save_item(item, 'mysql', self.db, self.table)

    def _build_sql(self, item: dict):
        """
        这段字典转sql代码是复制网上的，可以使用dataset_sink来直接保存字典。
        :param item:
        :return:
        """
        key_list = []
        value_list = []
        for k, v in item.items():
            key_list.append(k)
            value_list.append(v)
        keys_str = ''
        for k in key_list:
            keys_str += f'`{k}`,'
        keys_str = f'( {keys_str[:-1]} )'

        values_str = ''
        for v in value_list:
            if isinstance(v, str):
                v = f"'{v}'"
            values_str += f'{v},'
        values_str = f'( {values_str[:-1]} )'
        sql = f"replace into {self.table} {keys_str} values {values_str}"
        return sql


if __name__ == '__main__':
    print(MysqlSink(db='testdb', table='test_table')._build_sql({'a': 1, 'b': 2}))
    MysqlSink(db='testdb', table='t2').save({'uname': 'uname1', 'age': 1})

`````

--- **end of file: boost_spider/sink/mysql_sink.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/sink_helper.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/sink_helper.py`

#### 📦 Imports

- `import nb_log`

#### 🔧 Public Functions (1)

- `def log_save_item(item, dbtype, db, table)`
  - *Line: 6*


---

`````python
import nb_log

logger = nb_log.get_logger(__name__, log_filename='boost_spider_sink.log')


def log_save_item(item, dbtype, db, table):
    logger.info(f'保存结果到 {dbtype} {db}.{table} 中成功,  {item} ')

`````

--- **end of file: boost_spider/sink/sink_helper.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/sqlite_sink.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/sqlite_sink.py`

#### 📦 Imports

- `import os`
- `import sqlite3`
- `import threading`
- `from pathlib import Path`
- `import nb_log`
- `from pymongo.collection import Collection`
- `from pymongo import MongoClient`
- `from boost_spider.sink.sink_helper import log_save_item`

#### 🏛️ Classes (1)

##### 📌 `class SqliteSink`
*Line: 15*

**🔧 Constructor (`__init__`):**
- `def __init__(self, path, db, table)`
  - **Parameters:**
    - `self`
    - `path`
    - `db`
    - `table`

**Public Methods (1):**
- `def save(self, item: dict)`

**Class Variables (4):**
- `db__cusor_map = {}`
- `db__conn_map = {}`
- `_op_lock = threading.Lock()`
- `logger = nb_log.get_logger('SqliteSink')`


---

`````python
import os
import sqlite3
import threading
from pathlib import Path
import nb_log
from pymongo.collection import Collection
from pymongo import MongoClient
from boost_spider.sink.sink_helper import log_save_item

"""
保存到sqlite,不推荐,直接 使用dataset_sink 就好了.
"""


class SqliteSink:
    db__cusor_map = {}
    db__conn_map = {}
    _op_lock = threading.Lock()

    logger = nb_log.get_logger('SqliteSink')

    def __init__(self, path, db, table):
        self.db = db
        self.table = table
        self._key = f'{path} {db}'
        if self._key not in self.db__cusor_map:
            Path(path).mkdir(exist_ok=True)
            full_path = Path(path) / Path(f'{db}.db')
            conn = sqlite3.connect(full_path)
            cursor = conn.cursor()
            self.logger.debug(f'创建 {full_path} sqlite连接成功')
            self.db__cusor_map[self._key] = cursor
            self.db__conn_map[self._key] = conn
        self.cusror = self.db__cusor_map[self._key]
        self.conn = self.db__conn_map[self._key]

    def save(self, item: dict):
        sql = self._build_sql(item)
        with self._op_lock:
            self.cusror.execute(sql)
            self.conn.commit()
            log_save_item(item, 'sqlite', self.db, self.table)

    def _build_sql(self, item: dict):
        key_list = []
        value_list = []
        for k, v in item.items():
            key_list.append(k)
            value_list.append(v)
        # keys_str = str(tuple(key_list)).replace("'", "`")
        keys_str = ''
        for k in key_list:
            keys_str += f'`{k}`,'
        keys_str = f'( {keys_str[:-1]} )'

        values_str = ''
        for v in value_list:
            if isinstance(v, str):
                v = f"'{v}'"
            values_str += f'{v},'
        values_str = f'( {values_str[:-1]} )'
        sql = f"replace into {self.table} {keys_str} values {values_str}"
        return sql


if __name__ == '__main__':
    SqliteSink('/codedir/sqlite/', 'testdb', 'testtable').save({'a': '1', 'b': 2})
    SqliteSink('/codedir/sqlite/', 'testdb', 'testtable').save({'a': '7', 'b': 8})

`````

--- **end of file: boost_spider/sink/sqlite_sink.py** (project: funboost) --- 

---


--- **start of file: boost_spider/sink/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/sink/__init__.py`


---

`````python

`````

--- **end of file: boost_spider/sink/__init__.py** (project: funboost) --- 

---


--- **start of file: boost_spider/utils/thread_local_obj.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/utils/thread_local_obj.py`

#### 📦 Imports

- `import abc`
- `import threading`
- `import time`
- `from typing import Type`
- `from typing import TypeVar`
- `import httpx`
- `from concurrent.futures import ThreadPoolExecutor`

#### 🏛️ Classes (2)

##### 📌 `class BaseThreadLocalObjGetter`
*Line: 9*

**Public Methods (1):**
- `def get_obj(self, obj_type: T) -> T`

**Class Variables (1):**
- `thread_local = threading.local()`

##### 📌 `class AsyncClientGetter(BaseThreadLocalObjGetter)`
*Line: 30*

#### 🔧 Public Functions (1)

- `def t()`
  - *Line: 35*


---

`````python
import abc
import threading
import time
from typing import Type, TypeVar

T = TypeVar('T')


class BaseThreadLocalObjGetter(metaclass=abc.ABCMeta):
    thread_local = threading.local()

    def get_obj(self, obj_type: T,) -> T:
        obj_name = str(type(self))
        if not getattr(self.thread_local, obj_name, None):
            obj = self._get_obj()
            print(f'生成线程变量 {obj}')
            setattr(self.thread_local, obj_name, obj)
        return getattr(self.thread_local, obj_name)

    @abc.abstractmethod
    def _get_obj(self):
        raise NotImplemented


if __name__ == '__main__':
    import httpx
    from concurrent.futures import ThreadPoolExecutor


    class AsyncClientGetter(BaseThreadLocalObjGetter):
        def _get_obj(self):
            return httpx.AsyncClient()


    def t():
        for i in range(5):
            print(AsyncClientGetter().get_obj(httpx.AsyncClient))


    pool = ThreadPoolExecutor(20)
    for i in range(10):
        pool.submit(t)

`````

--- **end of file: boost_spider/utils/thread_local_obj.py** (project: funboost) --- 

---


--- **start of file: boost_spider/utils/__init__.py** (project: funboost) --- 


### 📄 Python File Metadata: `boost_spider/utils/__init__.py`


---

`````python

`````

--- **end of file: boost_spider/utils/__init__.py** (project: funboost) --- 

---


