# -*- coding: utf-8 -*-
"""
å®šæ—¶ä»»åŠ¡è¯Šæ–­è„šæœ¬ - æ£€æŸ¥ APScheduler Redis JobStore çŠ¶æ€
"""

from funboost.core.active_cousumer_info_getter import SingleQueueConusmerParamsGetter, QueuesConusmerParamsGetter
from funboost.timing_job.timing_push import ApsJobAdder
from funboost.utils import redis_manager
from funboost.constant import RedisKeys
import json

def diagnose_timing_jobs(queue_name=None):
    """è¯Šæ–­å®šæ—¶ä»»åŠ¡çŠ¶æ€"""
    
    print("="*60)
    print("å®šæ—¶ä»»åŠ¡è¯Šæ–­æŠ¥å‘Š")
    print("="*60)
    
    # 1. æ£€æŸ¥æ‰€æœ‰é˜Ÿåˆ—
    all_queues = list(QueuesConusmerParamsGetter().get_all_queue_names())
    print(f"\nğŸ“‹ å·²æ³¨å†Œçš„é˜Ÿåˆ—æ•°é‡: {len(all_queues)}")
    print(f"é˜Ÿåˆ—åˆ—è¡¨: {all_queues}")
    
    # 2. æ£€æŸ¥ Redis ä¸­çš„ä»»åŠ¡
    redis_conn = redis_manager.get_redis_connection()
    
    if queue_name:
        queues_to_check = [queue_name]
    else:
        queues_to_check = all_queues
    
    print(f"\nğŸ” æ£€æŸ¥é˜Ÿåˆ—: {queues_to_check}\n")
    
    for q_name in queues_to_check:
        print(f"\n{'â”€'*60}")
        print(f"é˜Ÿåˆ—: {q_name}")
        print(f"{'â”€'*60}")
        
        # æ£€æŸ¥ Redis ä¸­çš„ jobs_key
        jobs_key = RedisKeys.gen_funboost_redis_apscheduler_jobs_key_by_queue_name(q_name)
        run_times_key = RedisKeys.gen_funboost_redis_apscheduler_run_times_key_by_queue_name(q_name)
        lock_key = RedisKeys.gen_funboost_apscheduler_redis_lock_key_by_queue_name(q_name)
        
        print(f"ğŸ“Œ Redis Keys:")
        print(f"   Jobs Key: {jobs_key}")
        print(f"   Run Times Key: {run_times_key}")
        print(f"   Lock Key: {lock_key}")
        
        # æ£€æŸ¥ Redis ä¸­æ˜¯å¦æœ‰ä»»åŠ¡
        jobs_in_redis = redis_conn.hgetall(jobs_key)
        run_times_in_redis = redis_conn.zrange(run_times_key, 0, -1, withscores=True)
        
        print(f"\nğŸ“Š Redis å­˜å‚¨çŠ¶æ€:")
        print(f"   Jobs æ•°é‡: {len(jobs_in_redis)}")
        print(f"   Run Times æ•°é‡: {len(run_times_in_redis)}")
        
        if jobs_in_redis:
            print(f"\n   Jobs è¯¦æƒ…:")
            for job_id, job_data in jobs_in_redis.items():
                print(f"     - Job ID: {job_id.decode() if isinstance(job_id, bytes) else job_id}")
                try:
                    import pickle
                    job_obj = pickle.loads(job_data)
                    print(f"       è§¦å‘å™¨: {job_obj.trigger}")
                    print(f"       ä¸‹æ¬¡æ‰§è¡Œ: {job_obj.next_run_time}")
                except Exception as e:
                    print(f"       (æ— æ³•è§£æ: {e})")
        
        # 3. æ£€æŸ¥é€šè¿‡ ApsJobAdder èƒ½å¦è·å–ä»»åŠ¡
        try:
            booster = SingleQueueConusmerParamsGetter(q_name).generate_booster_by_funboost_redis_info_for_timing_push()
            job_adder = ApsJobAdder(booster, job_store_kind='redis', is_auto_start=True)
            
            jobs = job_adder.aps_obj.get_jobs()
            
            print(f"\nğŸ”„ APScheduler è·å–çš„ä»»åŠ¡:")
            print(f"   ä»»åŠ¡æ•°é‡: {len(jobs)}")
            
            for job in jobs:
                print(f"\n   â¤ Job ID: {job.id}")
                print(f"     è§¦å‘å™¨: {job.trigger}")
                print(f"     ä¸‹æ¬¡æ‰§è¡Œ: {job.next_run_time}")
                print(f"     çŠ¶æ€: {'å·²æš‚åœ' if job.next_run_time is None else 'è¿è¡Œä¸­'}")
                if hasattr(job, 'kwargs') and job.kwargs:
                    print(f"     å‚æ•°: {job.kwargs}")
            
            # æ£€æŸ¥è°ƒåº¦å™¨çŠ¶æ€
            print(f"\nâš™ï¸  APScheduler çŠ¶æ€:")
            print(f"   æ˜¯å¦è¿è¡Œ: {job_adder.aps_obj.running}")
            print(f"   State: {job_adder.aps_obj.state}")
            
        except Exception as e:
            print(f"\nâŒ è·å–ä»»åŠ¡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\n{'='*60}")
    print("è¯Šæ–­å®Œæˆ")
    print(f"{'='*60}\n")


if __name__ == '__main__':
    # è¯Šæ–­æ‰€æœ‰é˜Ÿåˆ—
    diagnose_timing_jobs()
    
    # æˆ–è€…è¯Šæ–­æŒ‡å®šé˜Ÿåˆ—
    # diagnose_timing_jobs('test_funboost_task3')
